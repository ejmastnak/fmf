\documentclass[11pt, a4paper]{article}
\usepackage{mwe}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{graphicx}
\graphicspath{{"figures/"}}
\usepackage{xcolor}
\usepackage{bm} % for bold vectors in math mode
\usepackage{physics} % for differential notation, etc...
\usepackage[separate-uncertainty=true]{siunitx}

\usepackage[margin=3cm]{geometry}
\usepackage[normalem]{ulem}  % for underline with line wrapping
\usepackage[colorlinks = true, allcolors=blue]{hyperref}

\setlength{\parindent}{0pt} % to stop indenting new paragraphs
\newcommand{\diff}{\mathop{}\!\mathrm{d}} % differential
\newcommand{\eqtext}[1]{\qquad \text{#1} \qquad}
\newcommand{\Schro}{Schr\"{o}dinger\xspace}
\newcommand{\pert}{perturbation\xspace}
\newcommand{\Ham}{Hamiltonian\xspace}


\renewcommand{\vec}[1]{\bm{#1}} % for vectors
\renewcommand{\op}[1]{\hat{#1}} % for operators
\newcommand{\mat}[1]{\mathbf{#1}} % for matrices
\newcommand{\dvec}[1]{\dot{\vec{#1}}} % for dotted vector quantity
\newcommand{\tvec}[1]{\tilde{\vec{#1}}} % for tilde vector quantities
\newcommand{\uvec}[1]{\hat{\vec{#1}}} % for dotted vector quantity

\renewcommand{\t}[1]{\tilde{#1}}

\newcommand{\tev}{e^{-i\frac{H}{\hbar}t}}  % time evolution operator
\newcommand{\tevp}{e^{i\frac{H}{\hbar}t}}  % time evolution operator with positive exponent

\newcommand{\m}{\vec{\mu}}  % magnetic moment
\renewcommand{\H}{\mathcal{H}}  % Hilbert space
\newcommand{\ua}{\uparrow}  % for spin up states
\newcommand{\da}{\downarrow}  % for spin down states
\renewcommand{\k}{\vec{k}}  % wave vector

\newcommand{\T}{\mathcal{T}}  % time reversal operator
\newcommand{\evb}[1]{\big \langle {#1} \big \rangle}  % for expectation values of fixed size
\newcommand{\bket}[1]{\big | {#1} \big \rangle}  % for big ket
\newcommand{\bbra}[1]{\big \langle {#1} \big |}  % for big bra
\newcommand{\bbraket}[2]{\big \langle {#1} \big | {#2} \big \rangle}  % for \big brakets

\newcommand{\threebraket}[3]{\left \langle {#1} \left | {#2} \right | {#3} \right \rangle}  % braket with three terms, variable size
\newcommand{\bthreebraket}[3]{\big \langle {#1} \big | {#2} \big | {#3} \big \rangle}  % braket with three terms, fixed \big size

\begin{document}
\title{Quantum Mechanics Exercises Notes}
\author{Elijan Mastnak}
\date{Winter Semester 2020-2021}
\maketitle
%\tableofcontents


\begin{center}
\textbf{About These Notes}
\end{center}

These are my notes from the Exercises portion of the class \textit{Kvanta Mehanika} (Quantum Mechanics), a required course for third-year physics students at the Faculty of Math and Physics in Ljubljana, Slovenia. The exact problem sets herein are specific to the physics program at the University of Ljubljana, but the content is fairly standard for an late-undergraduate Quantum Mechanics course. I am making the notes publicly available in the hope that they might help others learning the same material.

\vspace{2mm}
\textit{Navigation}: For easier document navigation, the table of contents is ``clickable'', meaning you can jump directly to a section by clicking the colored section names in the table of contents. Unfortunately, \uline{the clickable links do not work in most online or mobile PDF viewers}; you have to download the file first.

\vspace{2mm}
\textit{On Authorship:} 
The exercises are led by Asst. Prof. Toma\v{z} Rejec, who has curated the problem sets and guides us through the solutions. Accordingly, credit for the problems in these notes goes to Prof. Rejec. I have merely typeset the problems and provided additional explanations where I saw fit.

\vspace{2mm}
\textit{Disclaimer:} Mistakes---both trivial typos and legitimate errors---are likely. Keep in mind that these are the notes of an undergraduate student in the process of learning the material himself---take what you read with a grain of salt. If you find mistakes and feel like telling me, by \href{https://github.com/ejmastnak/fmf}{Github} pull request, \href{mailto:ejmastnak@gmail.com}{email} or some other means, I'll be happy to hear from you, even for the most trivial of errors.


\tableofcontents

\newpage

\section{First Section}

\subsection{First Exercise Set}

\subsubsection{Theory: Basic Concepts in Quantum Mechanics}
\begin{itemize}
	\item The fundamental quantity in quantum mechanics is the wave function. In one dimension, this is $ \psi(x, t) $. Any measurable quantity can be derived from the wave function, e.g. probability density
	\begin{equation*}
		\rho(x, t) = \abs{\psi(x, t)}^{2} = \dv{p}{x}
	\end{equation*}
	$ \diff p $ represents the probability of finding particle with wave function $ \psi(x, t) $ in the $ x $ interval $ \diff x $ at time $ t $. 
		
	\item The Hamiltonian operator is
	\begin{equation*}
		\op{H} = \frac{\op{p}^{2}}{2m} + V(x) \eqtext{where} \op{p} = - i\hbar \pdv{}{x}
	\end{equation*}
	\textbf{Notation:} By convention, we usually write operators without the hat symbol and distinguish between operators and scalar quantities based on context.
	
	\item We will often solve the stationary \Schro equation, which reads
	\begin{equation*}
		H\psi_{n}(x) = E_{n}\psi_{n}(x)
	\end{equation*}
	Note that there is no time dependence of $ \psi $ here, and that this is an eigenvalue equation, where $ E_{n} $ are the eigenvalues of the Hamiltonian operator and $ \psi_{n} $ are the corresponding eigenfunctions.
	
	We then use the solutions $ \psi_{n}(x) $ of the stationary \Schro equation to get the time-dependent wave function $ \psi(x, t) $. This process is called \textit{time evolution}. 
	
	\item The time evolution procedure goes as follows: Start with an initial wavefunction $ \psi(x, 0) $ at time $ t = 0 $. Expand $ \psi(x, 0) $ over a basis of the eigenfunctions $ \psi_{n}(x) $.
	\begin{equation*}
		\psi(x, 0) = \sum_{n} c_{n} \psi_{n}(x)
	\end{equation*}
	The time-dependent wave function is then
	\begin{equation*}
		\psi(x, t) = \sum_{n} c_{n}e^{-\frac{iE_{n}}{\hbar}t}\psi_{n}(x)
	\end{equation*}
	We have essentially replaced the constant coefficients $ c_{n} $ in the stationary expansion with the time-dependent coefficients $ \tilde{c}_{n} = c_{n}e^{-\frac{iE_{n}}{\hbar}t} $.
	
	\item Next, on to a particle's energy eigenvalues. A particle or quantum system typically has many eigenvalues as the dimension of the Hilbert space containing the system's wave functions. Often this is infinite! The set of all energy eigenvalues is $ \{E_{n}\} $, and is often called the spectrum. 
	
	The number of linearly independent eigenfunctions a system has at a given energy eigenvalue $ E_{n} $ is the eigenvalue's degeneracy.
	
	\item Next, on to the eigenfunctions. Consider a non-degenerate energy level with eigenfunction $ \psi_{n} $ satisfying
	\begin{equation*}
		H\psi_{n}(x) = E_{n}\psi_{n}(x)
	\end{equation*}
	If $ \psi_{n} $ solves the eigenvalue problem, then mathematically $ \lambda \psi_{n} $ also solves the eigenvalue problem for all $ \lambda \in \mathbb{C} $. But physically, there is a restriction: the probability density must be normalized to unity, i.e. 
	\begin{equation*}
		\int_{-\infty}^{\infty} \abs{\psi_{n}(x)}^{2} \diff x = 1
	\end{equation*}
	The normalization condition requires $ \abs{\lambda} = 1$, often written $ \lambda = e^{i \alpha} $ where $ \alpha \in \mathbb{R} $. This result is important: essentially, any eigenfunction $ \psi_{n} $ is undetermined up to a constant phase factor $ \lambda = e^{i\alpha} $ of magnitude $ \abs{\lambda} = 1 $.
	
	\item In other words, suppose we have two eigenfunctions
	\begin{equation*}
		\psi_{n}(x) \eqtext{and} e^{i \alpha}\psi_{n}(x)
	\end{equation*}
	Physically, the two wave functions are the same! We can't distinguish between the two in experiments, because the phase factor $ e^{i \alpha} $ is lost during the process of finding the probability density when squaring the absolute value! \textit{All wave functions are determined only up to a constant phase factor of magnitude one.}
	
	As an example, consider the infinite potential well from $ 0 $ to $ a $. The energy eigenvalues are
	\begin{equation*}
		E_{n} = \frac{\hbar^{2} \pi^{2} n^{2}}{2ma^{2}} \eqtext{and} \psi_{n}(x) = \sqrt{\frac{2}{a}} \sin \frac{n\pi x}{a}, \qquad n \in \mathbb{N}^{+}
	\end{equation*}
	However, e.g. $ \tilde{\psi}_{n}(x) = i \sqrt{\frac{2}{a}} \sin \frac{n\pi x}{a}, n \in \mathbb{N}^{+} $ represents the same physical information as $ \psi_{n} $. 
\end{itemize}

\subsubsection{Bound States in a Finite Potential Well}
\textit{Find the energy eigenvalues of the bound states of a particle with energy $ E $ in a finite potential well of depth $ V_{0} > 0 $ and width $ a $. Assume $ \abs{E} < V_{0} $; note that bound states have negative energies.}
\begin{itemize}
	\item Split the $ x $ axis into three regions: to the left of the well, inside the well, and to the right of the well, e.g. regions 1, 2 and 3, respectively. The potential energy is
	\begin{equation*}
		V(x) =
		\begin{cases}
			0, & x \in \text{region 1}\\
			- V_{0}, & x \in \text{region 2}\\
			0, & x \in \text{region 3}
		\end{cases}
	\end{equation*}
	
	\item The \Schro equation for region 1 is
	\begin{equation*}
		- \frac{\hbar^{2}}{2m}\pdv[2]{\psi}{x} + 0 \cdot \psi = E \psi 
	\end{equation*}
	remember that $ V = 0 $ in region 1. The general solution is a linear combination of exponential functions:
	\begin{equation*}
		\psi_{1}(x) = A e^{\kappa x} + B e^{- \kappa x}
	\end{equation*}
	To find $ \kappa $, insert $ \psi_{1} $ into the \Schro equation for region 1. Differentiating, canceling the wave function terms from both sides, and rearranging gives
	\begin{equation*}
		-\frac{\hbar^{2}}{2m} \kappa^{2}\left(Ae^{i\kappa x} + B e^{- i\kappa x}\right) = E \left(A e^{i\kappa x} + B e^{- i\kappa x}\right) \implies \kappa^{2} = \frac{2mE_{0}}{\hbar^{2}}
	\end{equation*}
	where $ E_{0} = - E $ is a positive quantity.
	
	\item The \Schro equation for region 2 is
	\begin{equation*}
		- \frac{\hbar^{2}}{2m}\pdv[2]{\psi}{x} - V_{0} \cdot \psi = E \psi
	\end{equation*}
	We use a plane wave ansatz:
	\begin{equation*}
		\psi_{2}(x) = Ce^{ikx} + De^{-ikx}
	\end{equation*}
	To find $ k $, insert $ \psi_{2} $ into the \Schro equation for region 2. The result after differentiation is
	\begin{equation*}
		+\frac{\hbar^{2}}{2m} k^{2}\left(Ce^{ik x} + D e^{- ik x}\right) - V_{0}\left(C e^{ik x} + D e^{- ik x}\right)  = E \left(C e^{ik x} + D e^{- ik x}\right) 
	\end{equation*}
	The wave functions terms in parentheses cancel, leading to $ k^{2} = \frac{2m(V_{0}-E_{0})}{\hbar^{2}} $ where $ E_{0} = - E $ is a positive quantity.
	
	\item The \Schro equation for region 3 is analogous to the equation for region 1. Following a similar procedure, we would get
	\begin{equation*}
		\psi_{3} = Fe^{\kappa x} + Ge^{-\kappa x} \eqtext{where} \kappa^{2} = \frac{2mE_{0}}{\hbar^{2}}
	\end{equation*}
	
	\item Next, to find energy, we apply boundary conditions, namely that the wave function is continuous and continuously differentiable at the boundaries between regions and that the functions vanishes at $ \pm \infty $, meaning there is no probability of finding the particle infinitely far away from the well. The conditions are:
	\[
		\begin{array}{ccc}
			\text{Region} & \text{Condition 1} & \text{Condition 2}\\
			1/2 & \psi_{1}(0) = \psi_{2}(0) &\displaystyle \pdv{\psi_{1}}{x} (0) = \pdv{\psi_{2}}{x} (0)\\[3mm]
			2\big/3 & \psi_{2}(a) = \psi_{3} (a) &\displaystyle \pdv{\psi_{2}}{x} (a) = \pdv{\psi_{3}}{x} (a)\\[2.5mm]
			\pm \infty & \psi_{1}(-\infty) = 0 & \psi_{3}(\infty) = 0
		\end{array}
	\]
	The last two conditions at $ \pm \infty $ require that $ B = 0 $ and $ F = 0 $, respectively; otherwise $ \psi_{1} $ and $ \psi_{3} $ would diverge.
	
	The continuity conditions (in the Condition 1 column) require
	\begin{equation*}
		A = C + D \eqtext{and} Ce^{ika} + De^{-ika} = Ge^{-\kappa a}
	\end{equation*}
	The continuous differentiability conditions require 
	\begin{equation*}
		A\kappa = ik(C-D) \eqtext{and} ik(Ce^{ika} - De^{-ika}) = - \kappa Ge^{-\kappa a}
	\end{equation*}
	
	\item We could then write the four equations in a $ 4 \cross 4 $ coefficient matrix
	\begin{equation*}
		\begin{bmatrix}
			\cdots \\
			\cdots \\
			\cdots \\
			\cdots 
		\end{bmatrix}
		\begin{bmatrix}
			A\\
			B\\
			C\\
			D
		\end{bmatrix}
		 = 
		 \begin{bmatrix}
		 	0\\
		 	0\\
		 	0\\
		 	0
		 \end{bmatrix}
	\end{equation*}
	To proceed, we would require the matrix's determinant be zero for a unique solution.  The determinant of the coefficient matrix is a function of $ \kappa $ and $ k $, which are in turn functions of energy. We then view the matrix's determinant as a function of energy and try to find its zeros. Each zero is an energy eigenvalue of the particle in a finite potential well. However, this involves solving the above system of four equations for the four unknowns $ A $, $ B $, $ C $ and $ D $. That's tedious! We will stop here and solve the same problem more elegantly in the next exercise. But first, we'll need some theoretical machinery.
	
	
\end{itemize}

\subsubsection{Theory: Wavefunctions of a Particle in an Even Potential} \label{qmv:sss:even-odd}
 \textbf{Theorem:} The eigenfunctions of a particle in an even potential are either even or odd.
 
\begin{itemize}
	\item First, recall the superpositio principle: if two eigenfunctions $ \psi_{1} $ and $ \psi_{2} $ have the same eigenvalue $ E $, than any linear combination of $ \psi_{1} $ and $ \psi_{2} $ is also an eigenfunction with eigenvalue $ E $. In equation form, if $ H\psi_{1}(x) = E \psi_{1}(x) $ and $ H\psi_{2}(x) = E \psi_{2}(x) $ then
	\begin{equation*}
		H\left(\alpha \psi_{1}(x) + \beta \psi_{2}(x)\right) = E \left(\alpha \psi_{1}(x) + \beta \psi_{2}(x)\right)
	\end{equation*}
	We'll use the superposition principle later in the proof when considering degenerate states.

	\item To prove the even/odd theorem for particles in an even potential $ V(x) = V(-x) $, we start with the stationary \Schro equation
	\begin{equation*}
		H\psi(x) = E \psi(x)
	\end{equation*}
	We make the parity transformation $ x \to -x $ and note the Hamiltonian is invariant under parity transformation if $ V $ is even, since $ \pdv{}{(-x)} = - \pdv{}{x} $, and $ \pdv[2]{}{(-x)} = \pdv[2]{}{x} $. Under the transformation $ x \to -x $, the \Schro equation reads
	\begin{equation*}
		H\psi(-x) = E\psi(-x)
	\end{equation*}
	This means that if $ \psi(x) $ is an eigenfunction of $ H $ for the energy eigenvalue $ E $, then $ \psi(-x) $ is also an eigenfunction for the same energy eigenvalue.
	
	\item Next, two options: either the eigenvalue $ E $ is degenerate or not.
	
	If $ E $ is not degenerate, then $ \psi(-x) $ and  $\psi(x) $ are equal up to a constant phase factor. In other words, if $ E $ is not degenerate and $ V $ is even, then $ \psi(x) $ and $ \psi(-x) $ are linearly dependent. In equation form,
	\begin{equation*}
		 \psi(x) = e^{i\alpha}\psi(-x) = e^{2i\alpha}\psi(x) \implies e^{2i\alpha} = 1 \implies e^{i\alpha} = \pm 1
	\end{equation*}
	If $ e^{i\alpha} = 1 $, then $ \psi $ is even, and if $ e^{i\alpha} = - 1 $, then $ \psi $ is odd. There are no other options. In other words, the eigenfunctions corresponding to the non-degenerate states of a particle in an even potential are either even or odd, as we wanted to show.
	
	\item Next, if $ E $ is degenerate, then $ \psi(x) $ and $ \psi(-x) $ are by definition linearly independent. By the superposition principle, we can create two more linear combinations of $ \psi(x) $ and $ \psi(-x) $: a sum and a difference, e.g.
	\begin{equation*}
		\psi_{+}(x) = \psi(x) + \psi(-x) \eqtext{and} \psi_{-}(x) = \psi(x) - \psi(-x) 
	\end{equation*}
	Note that, by construction, $ \psi_{+} $ is even and $ \psi_{-} $ is odd. In other words, even though $ \psi_{1} $ and $ \psi_{2} $ may not be even or odd themselves, we can always combine the two into a valid eigenfunction that is either even or odd.
	
	\item The general takeaway is: if our problem's potential has reflection symmetry about the origin, we can a priori search for only even or odd functions, because we know there exists a basis of the surrounding Hilbert space formed of only odd and even eigenfunctions.
\end{itemize}


\subsubsection{Finite Potential Well Take 2}
\textit{Continued from the previous problem: find the energy eigenvalues of the bound states of a particle with energy $ E $ in a finite potential well of depth $ V_{0} > 0 $ and width $ a $.}
\begin{itemize}
	\item Here's how to proceed: First, note the problem has reflection symmetry if we place the center of the well at the origin. The well then spans from $ x = -\frac{a}{2} $ to $ x = \frac{a}{2} $. In this case $ V(x) = V(-x) $, i.e. the potential is an even function of $ x $. 
	
	Why is this useful? It reduces the number of wave functions we have to find by one. Namely, if the eigenfunctions are even, then $ \psi_{3} $ is a copy of $ \psi_{1} $. If the eigenfunctions are odd, then $ \psi_{3} = - \psi_{1} $. In both cases, we only need to find $ \psi_{1} $. 
	
	We then only need to solve the problem on half of the real axis.
	

		
	\item First, assuming the solution is an even function. Reusing results from the earlier treatment of the finite potential well, for region 3 we have
	\begin{equation*}
		\psi_{3} = Ge^{-\kappa x} \eqtext{where} \kappa^{2} = \frac{2mE_{0}}{\hbar^{2}}
	\end{equation*}
	and for region 2, inside the well, the even wavefunctions take the form
	\begin{equation*}
		\psi_{2} = A \cos(kx) \eqtext{where} k^{2} = \frac{2m(V_{0} - E_{0})}{\hbar^{2}}
	\end{equation*}
	A few notes: we switched from plane waves to sinusoidal functions, where are better suited to odd/even symmetry. And we dropped the $B\sin(kx)$ term and kept only the cosine because we're solving for an even function a priori.
	
	For region 1, because we're searching for even functions, the result is the same as for region 3:
	\begin{equation*}
		\psi_{1} = G e^{\kappa x}
	\end{equation*}
	
	\item If we assume an odd solution, we have
	\begin{equation*}
		\psi_{3}(x) = G e^{-\kappa x} \qquad \psi_{2}(x) = B \sin (kx) \qquad \psi_{1}(x) = -Ge^{\kappa x}
	\end{equation*}
	
	\item On to boundary conditions. Because an even or odd function will have the same behavior (up to a minus sign for odd functions) at both region boundaries, we only need to consider one region; we'll consider $ x = \frac{a}{2} $. The boundary conditions are
	\begin{equation*}
		\psi_{2}\left(\frac{a}{2}\right) = \psi_{3}\left(\frac{a}{2}\right) \eqtext{and} \pdv{\psi_{2}}{x}\left(\frac{a}{2}\right) = \pdv{\psi_{3}}{x}\left(\frac{a}{2}\right) 
	\end{equation*}
	
	\item For an even solution, the boundary conditions read:
	\begin{equation*}
		A \cos\left(k\frac{a}{2}\right) = Ge^{-\frac{\kappa a}{2}} \eqtext{and} -kA\sin(k\frac{a}{2}) = - \kappa Ge^{-\frac{\kappa a}{2}}
	\end{equation*}
	Next, a trick: divide the equations and cancel like terms to get
	\begin{equation*}
		k \tan (k\frac{a}{2}) = \kappa 
	\end{equation*}
	
	\item For an odd solution, the boundary conditions read:
	\begin{equation*}
		B \sin \left(k\frac{a}{2}\right) = Ge^{-\frac{\kappa a}{2}} \eqtext{and} kB\cos(k\frac{a}{2}) = -\kappa Ge^{-\frac{\kappa a}{2}}
	\end{equation*}
	Dividing the equations and cancel like terms gives
	\begin{equation*}
		k \cot (k\frac{a}{2}) = -\kappa 
	\end{equation*}
	
	\item The solutions of the two equations
	\begin{equation*}
		\tan (\frac{ka}{2}) = \frac{\kappa}{k}  \eqtext{and}  \cot (\frac{ka}{2}) = -\frac{\kappa}{k} 
	\end{equation*}
	will give the energy eigenvalues of the even and odd states, respectively. 
	
	These are transcendental equations. They don't have analytic solutions, and we'll have to solve them graphically. First, we introduce the dimensionless variable $ u = k a $. We then express $ \kappa $ in terms of $ u $ using
	\begin{equation*}
		\kappa^{2} + k^{2} = \kappa^{2} + \frac{u^{2}}{a^{2}}  = \frac{2mV_{0}}{\hbar^{2}}
	\end{equation*}
	Alternatively, to work in dimensionless quantities, we could define $ u_{0}^{2} = \frac{2mV_{0}a^{2}}{\hbar^{2}} $ which leads to
	\begin{equation*}
		\kappa^{2} = \frac{u_{0}^{2} - u^{2}}{a^{2}}
	\end{equation*}
	
	\item In terms of $ u $ and $ u_{0} $, the two transcendental equations become
	\begin{equation*}
		\tan(\frac{u}{2}) = \frac{\sqrt{u_{0}^{2} - u^{2}}}{u} = \sqrt{\frac{u_{0}^{2}}{u^{2}} - 1} \eqtext{and} \cot(\frac{u}{2}) = -\sqrt{\frac{u_{0}^{2}}{u^{2}} - 1}
	\end{equation*}
	We then plot both sides of the equations and look for values of $ u $ where the left side equals the right side. These values of $ u $ give the energy eigenvalues, which are the solution to our problem.
	
	Finally, some notes:
	\begin{itemize}
		\item The right sides of the equations are defined only for $ u \leq u_{0} $ and diverge as $ u \to 0 $. 
		
		\item As $ u $ increases, $ k $ increases, $ E $ becomes more positive, and states become less bound. The ground state occurs at the smallest value of $ u $. 
		
		
		\item The number of bound states increases as $ u_{0} $ increases. This is achieved by increasing $ V_{0} $ (well depth), $ a $ (well width), or $ m $ (particle mass).  A finite potential well always has at least one bound state, near $ u = 0 $. 
	\end{itemize}
	
	

\end{itemize}



\subsection{Second Exercise Set}

\subsubsection{Bound States in a Delta Potential Well Version 1}
\textit{Find the energies and wave functions of the bound states of a quantum particle of mass $ m $ in a delta function potential well by reusing the results from a finite potential well}. 
\begin{itemize}
	\item We will reuse our results from the previous problem set by interpreting a delta potential as a finite potential well in the limit 
	\begin{equation*}
		a \to 0, \qquad V_{0} \to \infty \eqtext{and} aV_{0} = \text{constant} \equiv \lambda 
	\end{equation*}
	where then write the potential as $ V(x) = - \lambda \delta(x) $. 
	
	\item Recall from the previous exercise set that even bound states in a finite potential well of width $ a $ and depth $ V_{0} $ obey
	\begin{equation*}
		\tan \frac{u}{2} = \sqrt{\left(\frac{u_{0}}{u}\right)^{2} -1} \eqtext{where} u_{0}^{2} = \frac{2mV_{0}a^{2}}{\hbar^{2}} \eqtext{and} u = ak
	\end{equation*}
	The wave numbers $ k $ and $ \kappa $ inside and outside the well are
	\begin{equation*}
		k = \sqrt{\frac{2m(V_{0}- E_{0})}{\hbar^{2}}} \eqtext{and} \kappa = \sqrt{\frac{2mE_{0}}{\hbar^{2}}}
	\end{equation*}
	
	\item The limit $ a \to 0 $ forces $ u_{0} \to 0 $. In the limit $ u_{0} \to 0 $, we expect at most one, even bound state.	For small $ u $ and $ u_{0} $, we expect $ u $ and $ u_{0} $ to be very close, so we write
	\begin{equation*}
		u = u_{0} - \epsilon \qquad \text{where } \epsilon \ll 1
	\end{equation*}
	We continue with a Taylor expansion approximation of the even bound state equation. To first order, the tangent function is
	\begin{equation*}
		\tan \frac{u}{2} = \tan \frac{u_{0} + \epsilon}{2} \approx \frac{u_{0} + \epsilon}{2} + \dots 
	\end{equation*}
	while the square root is
	\begin{equation*}
		\sqrt{\left(\frac{u_{0}}{u}\right)^{2} -1} = \sqrt{\left(\frac{u_{0}}{u_{0} + \epsilon}\right)^{2} -1} = \sqrt{\left(1 - \frac{\epsilon}{u_{0}}\right)^{-2} -1} \approx \sqrt{2\frac{\epsilon}{u_{0}}}
	\end{equation*}
	
	
	\item With the approximations, the original even bound state equation becomes
	\begin{equation*}
		\frac{u_{0} + \epsilon}{2} = \sqrt{2\frac{\epsilon}{u_{0}}}
	\end{equation*}
	We square both sides and take only the leading $ u_{0}^{2} $ term from $ (u_{0} + \epsilon)^{2} $ to get
	\begin{equation*}
		\frac{(u_{0} + \epsilon)^{2}}{4} \approx \frac{u_{0}^{2}}{4} = 2 \frac{\epsilon}{u_{0}} \implies \epsilon = \left(\frac{u_{0}}{2}\right)^{3}
	\end{equation*}
	Next, we solve for $ u $ in terms of $ u_{0} $:
	\begin{equation*}
		u = u_{0} - \epsilon = u_{0} - \left(\frac{u_{0}}{2}\right)^{3}
	\end{equation*}
	
	\item We then use the equation for $ k $ to solve for $ E $ in terms of $ u_{0} $:
	\begin{equation*}
		k = \frac{u}{a} = \sqrt{\frac{2m(V_{0}- E_{0})}{\hbar^{2}}} \implies E_{0} = V_{0} - \frac{\hbar^{2}u^{2}}{2ma^{2}} = V_{0} - \frac{\hbar^{2}}{2ma^{2}}\left[u_{0} - \left(\frac{u_{0}}{2}\right)^{3}\right]^{2}
	\end{equation*}
	Multiplying out and dropping the small terms of order $ u_{0}^{6} $ gives
	\begin{equation*}
		E_{0} = V_{0} - \frac{\hbar^{2}}{2ma^{2}}\left(u_{0}^{2} - \frac{u_{0}^{4}}{4}\right)
	\end{equation*}
	We then substitute in the expression $ u_{0}^{2} = \frac{2mV_{0}a^{2}}{\hbar^{2}} $, which simplifies things to
	\begin{equation*}
		E_{0} = \frac{ma^{2}V_{0}^{2}}{2\hbar^{2}} = \frac{m\lambda^{2}}{2\hbar^{2}}
	\end{equation*}
	where the last equality uses $ \lambda = a V_{0} $. This is the result for the bound state's energy. 
	
	\item We find the corresponding wave function with the plane-wave ansatz
	\begin{equation*}
		\psi(x) =
		\begin{cases}
			A e^{\kappa x} & x < 0\\
			B e^{-\kappa x} & x > 0
		\end{cases}
		\eqtext{where} \kappa = \sqrt{\frac{2mE_{0}}{\hbar^{2}}} = \frac{m\lambda}{\hbar^{2}}
	\end{equation*}
	Because the wave function is even, $ A = B $, allowing us to write $ \psi = Ae^{-\kappa \abs{x}} $. we find the coefficient $ A $ from the normalization condition
	\begin{equation*}
		1 \equiv \int \abs{\psi(x)}^{2} \diff x = A^{2} \int_{-\infty}^{\infty} e^{-2\kappa \abs{x}} \diff x
	\end{equation*}
	Because $ \psi $ is even, we can integrate over only half the real line and double the result:
	\begin{equation*}
		1 = 2A^{2} \int_{0}^{\infty} e^{-2\kappa x} \diff x = - \frac{A^{2}}{\kappa} \eval{e^{-2\kappa x}}_{0}^{\infty} = \frac{A^{2}}{\kappa} \implies A^{2} = \kappa
	\end{equation*}
	The wave function is thus
	\begin{equation*}
		\psi(x) = \sqrt{\kappa} e^{-\kappa \abs{x}} \eqtext{where} \kappa = \frac{m\lambda}{\hbar^{2}}
	\end{equation*}
	
\end{itemize}

\subsubsection{Bound States in a Delta Potential Take 2}
\textit{Find the energies and wave functions of the bound states of a quantum particle of mass $ m $ in a delta function potential well using a plane wave ansatz and appropriate boundary conditions}. 
\begin{itemize}
	\item Write the potential well in the form $ V(x) = - \lambda \delta (x) $. The stationary \Schro equation for the potential reads
	\begin{equation*}
		- \frac{\hbar^{2}}{2m}\pdv[2]{\psi}{x} - \lambda \delta(x) \psi = E\psi
	\end{equation*}
	We find the boundary condition on the derivative $ \psi' $ by integrating the \Schro equation over a small region $ [-\epsilon, \epsilon] $. 
	\begin{equation*}
		-\frac{\hbar^{2}}{2m} \eval{\pdv{\psi}{x}}_{-\epsilon}^{\epsilon} - \lambda \int_{-\epsilon}^{\epsilon} \delta(x) \psi(x)\diff x = E \int_{-\epsilon}^{\epsilon}\psi(x) \diff x
	\end{equation*}
	In the limit $ \epsilon \to 0 $, this becomes
	\begin{equation*}
		-\frac{\hbar^{2}}{2m} \left[\psi'(0_{+}) - \psi'(0_{-})\right] - \lambda \psi(0) = 0
	\end{equation*}
	where $ \psi'(0_{+}) $ and $ \psi'(0_{-}) $ denote $ \psi $'s derivatives from the right and left, respectively. The appropriate boundary condition $ \psi'(x) $ are thus
	\begin{equation*}
		\psi'(0_{+}) - \psi'(0_{-}) = -\frac{2m\lambda\psi(0)}{\hbar^{2}}
	\end{equation*}
	
	
	\item We construct the wavefunction with a plane-wave ansatz:
	\begin{equation*}
		\psi(x) =
		\begin{cases}
			A e^{\kappa x} & x < 0\\
			B e^{-\kappa x} & x > 0
		\end{cases}
	\end{equation*}
	As boundary conditions, we require that $ \psi $ is continuous and that $ \psi' $ obey the earlier condition $ \psi'(0_{+}) - \psi'(0_{-}) = \frac{2m\lambda\psi(0)}{\hbar^{2}} $. Applying the continuity condition at $ x = 0 $ gives
	\begin{equation*}
		A e^{\kappa \cdot 0} = B e^{-\kappa \cdot 0} \implies A = B
	\end{equation*}
	Applying the condition on the derivatives (and using $ A = B $) gives
	\begin{equation*}
		-\kappa A^{-\kappa \cdot 0} -\kappa A^{\kappa \cdot 0} = -\frac{2m\lambda}{\hbar^{2}} \psi(0) = - \frac{2m\lambda }{\hbar^{2}} Ae^{\kappa \cdot  0} \implies \kappa = \frac{m\lambda}{\hbar^{2}}
	\end{equation*}
	The wave function is thus
	\begin{equation*}
		\psi(x) = A e^{-\kappa \abs{x}} \eqtext{where} \kappa = \frac{m\lambda}{\hbar^{2}}
	\end{equation*}

	
	\item We can find the bound state's energy from
	\begin{equation*}
		\kappa = \sqrt{\frac{2mE_{0}}{\hbar^{2}}} \implies E_{0} = \frac{m\lambda^{2}}{2\hbar^{2}}
	\end{equation*}
	which matches the result from the previous problem. To find the wave function, we just need the value of $ A $, which we find with the usual normalization condition
	\begin{equation*}
		1 \equiv \int \abs{\psi(x)}^{2} \diff x = A^{2} \int_{-\infty}^{\infty} e^{-2\kappa \abs{x}} \diff x = 2A^{2} \int_{0}^{\infty} e^{-2\kappa x} \diff x \implies A^{2} = \kappa
	\end{equation*}
	The wave function is thus
	\begin{equation*}
		\psi(x) = \sqrt{\kappa} e^{-\kappa \abs{x}} \eqtext{where} \kappa = \frac{m\lambda}{\hbar^{2}},
	\end{equation*}
	in agreement with the result from the previous problem. 
	 
\end{itemize}

\subsubsection{Theory: Scattering}
\begin{itemize}
	\item The basic scattering problem involves a particle with energy $ E $ and two regions of the $ x $ axis with potentials $ V_{1} $ and $ V_{3} $ respectively,  where $ E > V_{1}, V_{3} $. Both energies and potentials are positive quantities. Because $ E > V_{1}, V_{3} $, the particle is free in the regions of $ V_{1} $ and $ V_{2} $.
	
	Near the origin, between regions $ 1 $ and $ 3 $, the particle encounters a small potential barrier where $ V(x) > E $; the exact form of $ V(x) $ is not important for our purposes. We call this region $ 3 $. 
	
	\item The general ansatz solutions in regions $ 1 $ and $ 3 $ are
	\begin{equation*}
		\psi_{1} = A_{1} e^{ik_{1}x} + B_{1}e^{-ik_{1}x} \eqtext{and} \psi_{3} = A_{3} e^{-ik_{2}x} + B_{3}e^{ik_{2}x}
	\end{equation*}
	The terms with $ A $ coefficients represent movement toward the potential barrier 
	
	\item In region 2, we don't know $ V(x) $, so we have to be more general. Because $ \psi_{2} $ comes from a second-order linear differential equation (i.e. the \Schro equation), its general form is a linear combination of two linearly independent functions, e.g.
	\begin{equation*}
		\psi_{2} = C f(x) + D g(x)
	\end{equation*}
	where $ f $ and $ g $ are linearly independent solutions of the \Schro equation in region $ 2 $. 
	
	\item Because $ E > V_{1}, V_{3} $, the states in regions 1 and 3 are free, meaning the particle's Hamiltonian has a continuous spectrum of energy eigenvalues. As a result, energy eigenvalues aren't particularly useful for characterizing the problem. 
	
	Instead, for unbound situations with a potential barrier, we describe the problem in terms of transmissivity $ T $ and reflectivity $ R $, which describe the probabilities of the scattered particle passing through and reflecting from the barrier, respectively.
\end{itemize}

\textbf{Probability Current} 
\begin{itemize}

	\item For scattering problems with $ T $ and $ R $, we work in terms of probability current
	\begin{equation*}
		j(x) = \frac{\hbar}{2mi}\left[\psi^{*}(x)\psi'(x) - \psi^{'^{*}}(x)\psi(x)\right] = \frac{\hbar}{m} \Im \left\{\psi^{*}\psi'(x)\right\}
	\end{equation*}
	where $ \psi^{*} $ and $ \psi' $ denotes the complex conjugate and derivative of $ \psi $, respectively.
	
	\item Substituting in the region 1 ansatz $ \psi_{1} = A_{1} e^{ik_{1}x} + B_{1}e^{-ik_{1}x}  $  gives the probability current in region 1:
	\begin{align*}
		j_{1} &= \frac{\hbar}{m}\Im \left\{A_{1}A_{1}^{*}ik_{1} - B_{1}B_{1}^{*}ik_{1} + B_{1}^{*}A_{1}ik_{1}e^{2ik_{1}x} - B_{1}A_{1}^{*}ik_{1}e^{-2ik_{1}x}\right\}\\
		&=\frac{\hbar k_{1}}{m}(A_{1}A_{1}^{*} - B_{1}B_{1}^{*}) \equiv v_{1}(A_{1}A_{1}^{*} - B_{1}B_{1}^{*}) =  v_{1}(\abs{A}^{2} - \abs{B}^{2})
	\end{align*}
	Noting that $ \frac{\hbar k_{1}}{m} $ has units of velocity, we've defined the constant $ v_{1} \equiv \frac{\hbar k_{1}}{m} $. 
	
	The procedure for $ j_{3} $ in region 3 is analogous. The result is
	\begin{equation*}
		j_{3} = v_{3}(B_{3}B_{3}^{*} - A_{3}A_{3}^{*}) = v_{3}(\abs{B}_{3}^{3} - \abs{A}_{3}^{3}) \eqtext{where} v_{3} \equiv \frac{\hbar k_{3}}{m}
	\end{equation*}

	
	\item Next, we run into a slight problem: the plane waves in regions 1 and 3 can't be normalized. They oscillate! Instead, we normalize $ \psi_{1} $ and $ \psi_{3} $ per unit ``probability velocity''. We redefine 
	\begin{equation*}
		\tilde{\psi}_{1} = \frac{A_{1}}{\sqrt{v_{1}}} e^{ik_{1}x} + \frac{B_{1}}{\sqrt{v_{1}}}e^{-ik_{1}x} \eqtext{and} \tilde{\psi}_{3} = \frac{A_{3}}{\sqrt{v_{3}}} e^{-ik_{3}x} + \frac{B_{3}}{\sqrt{v_{3}}}e^{ik_{3}x}
	\end{equation*}
	The corresponding probability currents, using the normalized $ \tilde{\psi}_{1} $ and $ \tilde{\psi}_{3} $ are
	\begin{align*}
		&\tilde{j}_{1}(x) = A_{1}^{*}A_{1} - B_{1}^{*}B_{1} = \abs{A_{1}}^{2} - \abs{B_{1}}^{2}\\
		&\tilde{j}_{3}(x) = B_{3}^{*}B_{3} - A_{3}^{*}A_{3} = \abs{B_{3}}^{2} - \abs{A_{3}}^{2}
	\end{align*}
	\textit{As a general rule, we always normalize plane waves with the probability velocity $ \frac{1}{\sqrt{v}} $ where $ v = \frac{hk}{m} $}.
	
	\item The next step in the scattering problem is formulating four boundary conditions on $ \psi $ requiring continuity and continuous differentiability at the two boundary regions between regions 1 and 2 and between regions 2 and 3.
	
	We end up with 4 linearly independent equations for six unknown coefficients. Our plan is to eliminate $ C $ and $ D $ and express $ B_{1} $ and $ B_{3} $ in terms of $ A_{1} $ and $ A_{3} $. The amplitudes $ A_{1} $ and $ A_{3} $ of the waves incident on the potential barrier thus parameterize our problem. Informally, all this means is that if we know the wavefunction of the incident particle (by specifying the incident amplitudes $ A_{1}, A_{3} $), we can solve the scattering problem by finding the reflected amplitudes $ B_{1}, B_{3} $. In general, it is best practice to parameterize a scattering problem with the \textit{incident} amplitudes $ A_{1} $ and $ A_{3} $. 
	
	In any case, we end up with a matrix equation
	\begin{equation*}
		\begin{bmatrix}
			B_{1}\\
			B_{3}
		\end{bmatrix}
		= 
		\mat{S}
		\begin{bmatrix}
			A_{1}\\
			A_{3}
		\end{bmatrix}
		\eqtext{or more concisely} \vec{B} = \mat{S} \vec{A}
	\end{equation*}
	where $ \mat{S} $ is called the \textit{scattering matrix}, in our case a $ 2 \cross 2 $ matrix. By convention, we parameterize a $ 2 \cross 2 $ scattering matrix in terms of the parameters $ r $ and $ t $:
	\begin{equation*}
		\mat{S} = 
		\begin{bmatrix}
			r & \tilde{t}\\
			t & \tilde{r}
		\end{bmatrix}
	\end{equation*} 
\end{itemize}

\textbf{Probability Conservation}
\begin{itemize}
	\item Some identities:
	\begin{equation*}
		T = \abs{t}^{2} \quad R = \abs{r}^{2} \eqtext{and} 		\tilde{T} = \abs{\tilde{t}}^{2} \quad \tilde{R} = \abs{\tilde{r}}^{2}
	\end{equation*}
	The identities $ T + R = 1 $ and $ \tilde{T} + \tilde{R} = 1 $ imply probability conservation, i.e. the total incident and reflected probabilities sum to one. 
	
	\item In general, the incident current is the sum of the two squares of the incidence amplitudes $ A_{1} $ and $ A_{3} $, while the reflected current is the sum of the reflected amplitudes $ B_{1} $ and $ B_{3} $, i.e.
	\begin{equation*}
		j_{\text{in}} = \abs{A_{1}}^{2} + \abs{A_{3}}^{2} \eqtext{and} j_{\text{ref}} = \abs{B_{1}}^{2} + \abs{B_{3}}^{2}
	\end{equation*}
	In terms of the coefficient vector $ \vec{A} $, the incident probability current is
	\begin{equation*}
		j_{\text{in}} = A_{1}A_{1}^{*} + A_{3}A_{3}^{*} = \big[A_{1}^{*}, A_{3}^{*}\big]
		\begin{bmatrix}
			A_{1}\\
			A_{3}
		\end{bmatrix}
		= \vec{A}^{\dagger}\vec{A}
	\end{equation*}
	An analogous procedure with the reflected amplitudes gives $ j_{\text{out}} = \vec{B}^{\dagger}\vec{B} $. 
	
	
	\item Conservation of probability requires $ j_{\text{in}} = j_{\text{ref}} $ or $ \vec{A}^{\dagger}\vec{A} = \vec{B}^{\dagger}\vec{B} $. Combining the scattering matrix equation $ \vec{B} = \mat{S}\vec{A} $ with the requirement $ \vec{A}^{\dagger}\vec{A} = \vec{B}^{\dagger}\vec{B} $ implies
	\begin{equation*}
		\vec{A}^{\dagger}\vec{A} \equiv \vec{B}^{\dagger}\vec{B} = (\vec{A}^{\dagger}\mat{S}^{\dagger})(\mat{S}\vec{A}) \implies \vec{S}^{\dagger}\mat{S} = \mat{I}
	\end{equation*}
	In other words, the scattering matrix $ \mat{S} $ must be unitary to conserve probability in scattering problems
\end{itemize}

\subsubsection{Scattering Off a Delta Potential}
\textit{Analyze a quantum particle scattering off of a delta function potential.}
\begin{itemize}	
 	\item We consider a particle of energy $ E $ scattering off the potential $ V(x) = \lambda \delta(x) $. We'll divide the problem into two separate cases. First, we'll assume the particle is incident on the potential barrier only from the left, so the incident amplitude vector reads $ \vec{A} = (1, 0) $. In this case, the scattering matrix equation reads
	\begin{equation*}
		\vec{B} = \mat{S} \vec{A} = 
		\begin{bmatrix}
			r & \tilde{t}\\
			t & \tilde{r}
		\end{bmatrix}
		\begin{bmatrix}
			1\\
			0
		\end{bmatrix}
		= 
		\begin{bmatrix}
			r\\
			t
		\end{bmatrix}
	\end{equation*}
	
	\item Similarly, if we assume the particle is incident only from the right, i.e. $ A = (0, 1) $,  the scattering equation reads
	\begin{equation*}
		\vec{B} = \mat{S} \vec{A} = 
		\begin{bmatrix}
			r & \tilde{t}\\
			t & \tilde{r}
		\end{bmatrix}
		\begin{bmatrix}
			0\\
			1
		\end{bmatrix}
		= 
		\begin{bmatrix}
			\tilde{t}\\
			\tilde{r}
		\end{bmatrix}
	\end{equation*}
		
	\item First, for $ \vec{A} = (1, 0) $ and $ \vec{B} = (r, t) $, the wave functions in region 1 and 3 are
	\begin{align*}
		&\psi_{1}(x) = \frac{A_{1}}{\sqrt{v}}e^{ikx} + \frac{B_{1}}{\sqrt{v}} e^{-ikx} = \frac{e^{ikx}}{\sqrt{v}} + \frac{r}{\sqrt{v}} e^{-ikx}\\
		& \psi_{3} = \frac{A_{3}}{\sqrt{v}} e^{-ikx} + \frac{B_{3}}{\sqrt{v}} e^{ikx} = 0 +  \frac{t}{\sqrt{v}} e^{ikx}
	\end{align*}
	Note that because the potential is the same on both sides of the delta function, $ k_{1} = k_{3} \equiv k$ and $ v_{1} = v_{3} \equiv v $.
	
	\item On to boundary conditions. Continuity between regions 1 and 3 requires
	\begin{equation*}
		\psi_{1}(0) = \psi_{3}(0) \implies 1 + r = t
	\end{equation*} 
	For the the boundary conditions on the derivative $ \psi' $, we reuse the earlier differentiability condition $ \psi'(0_{+}) - \psi'(0_{-}) = \frac{2m\lambda\psi(0)}{\hbar^{2}} $ from the previous problem involving bound states in a delta potential. Changing the sign of of $ \lambda $ because the delta function in a scattering problem points upward, and changing notation from $ \psi'_{\pm} $ to $ \psi'_{1,3} $the differentiability condition becomes
	\begin{equation*}
		\psi_{3}'(0) - \psi_{1}'(0) = \frac{2m\lambda}{\hbar^{2}} \psi(0) \implies ik(t + r -1) = \frac{2m\lambda}{\hbar^{2}} t
	\end{equation*}
	Substituting in the earlier continuity requirement $ t = 1 + r $ gives
	\begin{equation*}
		2ikr = \frac{2m\lambda}{\hbar^{2}} (1 + r) \implies r = -\frac{i\alpha}{k + i\alpha} \eqtext{where} \alpha = \frac{m\lambda}{\hbar^{2}}
	\end{equation*}
	The expression for the parameter $ t $ is then
	\begin{equation*}
		t = 1 + r = 1 - \frac{i\alpha}{k + i\alpha} = \frac{k}{k + i\alpha}
	\end{equation*}
	
	\item We would then find $ \tilde{r} $ and $ \tilde{t} $ using an analogous procedure with the incidence vector $ \vec{A} = (0, 1) $. It turns out (exercise left to the reader) that the results are the same:
	\begin{equation*}
		\tilde{r} = -\frac{i\alpha}{k + i\alpha}  \eqtext{and} \tilde{t} = \frac{k}{k + i\alpha}
	\end{equation*}
	
	The probability matrix can then be written
	\begin{equation*}
		\mat{S} = \frac{1}{k + i \alpha} 
		\begin{bmatrix}
			- i \alpha & k\\
			k & - i \alpha
		\end{bmatrix} 
		\eqtext{where}
		\alpha = \frac{m\lambda}{\hbar^{2}}
	\end{equation*}
\end{itemize}
\textbf{On the Problem's Symmetry:} A few notes on why the scattering matrix for the delta potential has only two independent parameters, i.e. why $ \tilde{t} = t $ and $ \tilde{r} = r $.
\begin{itemize}
	\item  Start by noting that the wave functions $ \psi_{1,3} $ in regions 1 and 3 solve the stationary \Schro equation
	\begin{equation*}
		H \psi = E \psi \eqtext{where} H = -\frac{\hbar^{2}}{m}\pdv[2]{}{x} + V(x)
	\end{equation*}
	We then take the \Schro equation's complex conjugate to get
	\begin{equation*}
		H \psi^{*} = E\psi^{*}
	\end{equation*}
	In other words, if $ \psi $ is a wave function for the energy eigenvalue $ E $, then so is $ \psi^{*} $. This holds in general for any real Hamiltonian. 
	
	\item In our specific problem in regions 1 and 3, the conjugate wave function reads
	\begin{equation*}
		\psi_{1}^{*} = \frac{A_{1}^{*}}{\sqrt{v}}e^{-ikx} e + \frac{B_{1}^{*}}{\sqrt{v}}e^{ikx} \eqtext{and} \psi_{3}^{*} = \frac{A_{3}^{*}}{\sqrt{v}}e^{ikx} e + \frac{B_{3}^{*}}{\sqrt{v}}e^{ikx}
	\end{equation*}
	Recall $ k_{1} = k_{3} = k $ and $ v_{1} = v_{3} = v $.
	
	\item Conjugation effectively switches the role of the incident and reflected waves: the waves with $ B $ coefficients are now incident and waves with $ A $ coefficients reflected. The equation linking the incident and reflected waves becomes
	\begin{equation*}
		\begin{bmatrix}
			A_{1}^{*}\\
			A_{3}^{*} 
		\end{bmatrix}
		= 
		\mat{S}
		\begin{bmatrix}
			B_{1}^{*}\\
			B_{3}^{*}
		\end{bmatrix}
		\eqtext{or more concisely} \vec{A}^{*} = \mat{S} \vec{B}^{*}
	\end{equation*}
	Recall the original equation, before conjugation, was $ \vec{B} = \mat{S} \vec{A} $ and note that the scattering matrix $ \mat{S} $ is the same, since the potential is invariant under conjugation.
	
	\item Remember probability conservation requires that $ \mat{S} $ be unitary, i.e. $ \mat{S}^{\dagger}\mat{S} = \mat{I} $. With this in mind, multiply the original equation $ \vec{B} = \mat{S} \vec{A} $ from the left by $ \mat{S}^{\dagger} $, and then take the complex conjugate of the equation, which gives
	\begin{equation*}
		\mat{S}^{\dagger}\mat{B} = \mat{A} \implies \mat{A}^{*} = \mat{S}^{T} \mat{B}^{*}
	\end{equation*}
	Substituting the result $ \mat{A}^{*} = \mat{S}^{T} \mat{B}^{*} $ into the conjugate equation $ \vec{A}^{*} = \mat{S} \vec{B}^{*} $ gives
	\begin{equation*}
		\mat{S}^{T} \mat{B}^{*} = \mat{S} \vec{B}^{*}
	\end{equation*}
	meaning that $ \mat{S} $ is symmetric for scattering off a delta potential. This symmetry is the reason why $ t = \tilde{t} $ in the delta function scattering matrix. Formally, this is a consequence of the problem's Hamiltonian being invariant under time reversal. 

	\item Next, why $ r = \tilde{r} $. This is a consequence of the problem's reflection symmetry. Start again with the \Schro equation:
	\begin{equation*}
		H \psi(x) = E \psi(x)
	\end{equation*}
	The parity transformation $ x \to -x $ (recall $ H $ is invariant under parity) gives:
	\begin{equation*}
		H\psi(-x) = E\psi(-x)
	\end{equation*}
	The parity-transformed wave functions for regions 1 and 3 are
	\begin{equation*}
		\psi_{1}(-x) = \frac{A_{1}}{\sqrt{v}} e^{-ikx} + \frac{B_{1}}{\sqrt{v}}e^{ikx} \eqtext{and} \psi_{3}(-x) = \frac{A_{3}}{\sqrt{v}} e^{ikx} + \frac{B_{3}}{\sqrt{v}}e^{-ikx}
	\end{equation*}
	The roles of the incident and reflected waves are mixed up under parity: $ \psi_{1}(-x) $ now refers to the region of $ x > 0 $ (right of the delta function), and $ \psi_{3}(-x) $ to the region of $ x < 0 $. The equation linking the incident and reflected waves becomes
	\begin{equation*}
		\begin{bmatrix}
			B_{3}\\
			B_{1} 
		\end{bmatrix}
		= 
		\mat{S}
		\begin{bmatrix}
			A_{3}\\
			A_{1}
		\end{bmatrix}
		\qquad (\text{after reflection})
	\end{equation*}
	Recall the original equation, before parity transformation, was
	\begin{equation*}
		\begin{bmatrix}
			B_{1}\\
			B_{3} 
		\end{bmatrix}
		= 
		\mat{S}
		\begin{bmatrix}
			A_{1}\\
			A_{3}
		\end{bmatrix}
		\qquad (\text{before reflection})
	\end{equation*}
	
	\item We can get the reflected equation from the original one by multiplying the original equation by the first Pauli spin matrix $ \sigma_{x} = 
	\begin{bmatrix}
		0 & 1\\
		1 & 0
	\end{bmatrix}$. The reflected equation is
	\begin{equation*}
		\sigma_{x}\vec{B} = \mat{S} \sigma_{x}\vec{A} \implies \vec{B} = \sigma_{x} \mat{S} \sigma_{x}\vec{A}
	\end{equation*}
	Substituting the expression for $ \vec{B} $ into the original equation $ \vec{B} = \mat{S} \vec{A} $ gives
	\begin{equation*}
		\sigma_{x} \mat{S} \sigma_{x}\vec{A} = \mat{S} \vec{A} \implies \mat{S} = \sigma_{x} \mat{S} \sigma_{x}
	\end{equation*}
	The relationship $ \mat{S} = \sigma_{x} \mat{S} \sigma_{x} $ holds in general for any even Hamiltonian. Applied to our parameterization of $ \mat{S} $, we have
	\begin{equation*}
		\mat{S} = \sigma_{x} \mat{S} \sigma_{x} \iff
		\begin{bmatrix}
			r & \tilde{t}\\
			t & \tilde{r}
		\end{bmatrix}
		= \sigma_{x}
		\begin{bmatrix}
			r & \tilde{t}\\
			t & \tilde{r}
		\end{bmatrix}
		\sigma_{x}
		=
		\begin{bmatrix}
			\tilde{r} & t\\
			\tilde{t} & r
		\end{bmatrix}
	\end{equation*}
	The result is $ r = \tilde{r} $ and $ t = \tilde{t} $. This accounts for both of the symmetries in our delta function scattering matrix! So invariance under parity transformation is a powerful symmetry: it reduces the number of independent elements in the scattering matrix by two, even under in the absence of time reversal symmetry.
	
	
\end{itemize}

\subsection{Third Exercise Set} 

\subsubsection{Theory: Uncertainty Product of Observable Quantities}
\begin{itemize}
	\item We are interested in finding an expression for the uncertainty in the product $ \Delta A \Delta B $ of two arbitrary observable quantities $ A $ and $ B $. We start by assigning both $ A $ and $ B $ a corresponding Hermitian operator (Hermitian because $ A $ and $ B $ are observable). The operators are
	\begin{equation*}
		A = A^{\dagger} \eqtext{and} B = B^{\dagger}
	\end{equation*}
	
	\item By definition, the uncertainty in $ A $ is
	\begin{equation*}
		(\Delta A)^{2} = \expval{A^{2}} - \expval{A}^{2} = \expval{(A - \expval{A})} \equiv \big\langle \tilde{A}^{2} \big\rangle
	\end{equation*}
	where we've defined $ \tilde{A} = A - \expval{A}I $. Here $ \expval{A} $ is a scalar and $ I $ is the identity operator. 
	
	\item First, the definition of an operator's expectation value and some review of bra-ket notation.
	\begin{equation*}
		\ev{A} = \int \psi^{*} A \psi \diff x \equiv \bra{\psi}A\ket{\psi} = \braket{\psi}{A\psi}
	\end{equation*}
	Because $ A $ is Hermitian, $ \braket{\psi}{A\psi} = \braket{A\psi}{\psi} $. This is a special case of the more general adjoint relationship $ \braket{A\psi}{\psi} = \braket{\psi}{A^{*}\psi} $ with $ A = A^{*} $ because $ A $ is Hermitian. 
	
	\item The expectation value of a Hermitian operator is real. The classic proof reads
	\begin{equation*}
		\ev{A} \equiv \braket{\psi}{A\psi} = \braket{A^{*}\psi}{\psi} = \braket{A\psi}{\psi} = \braket{\psi}{A\psi}^{*} \equiv \langle A \rangle^{*} \implies \langle A \rangle \in \mathbb{R}
	\end{equation*}
	
	\item In general, the sum of two Hermitian operators $ A = A^{\dagger} $ and $ B = B^{\dagger} $ is
	\begin{equation*}
		(A + B)^{\dagger} = A^{\dagger} + B^{\dagger} = A + B
	\end{equation*}
	So the sum of two Hermitian operators is a Hermitian operator. If we return to $ \tilde{A} = A - \expval{A}I  $ it follows that $ \tilde{A}^{\dagger} = \tilde{A} $ since both $ A $ and $ I $ are Hermitian.
	
	\item We return to the product $ \Delta A \Delta B $. First, we square everything, since uncertainty is expressed as $ (\Delta A)^{2} $. 
	\begin{align*}
		(\Delta A \Delta B)^{2} &= \big\langle \tilde{A}^{2} \big\rangle \big\langle \tilde{B}^{2} \big\rangle = \bra{\psi}\tilde{A}^{2}\ket{\psi} \bra{\psi}\tilde{B}^{2}\ket{\psi} = \braket{\tilde{A}\psi}{\tilde{A}\psi}\braket{\tilde{B}\psi}{\tilde{B}\psi}\\
		&= \norm{\tilde{A}\psi}^{2}\norm{\tilde{B}\psi}^{2}
	\end{align*}
	The last equality occurs in the Cauchy-Schwartz inequality:
	\begin{equation*}
		\norm{\tilde{A}\psi}^{2}\norm{\tilde{B}\psi}^{2} \geq \abs{\braket{\tilde{A}\psi}{\tilde{B}\psi}}^{2} = \abs{\braket{\psi}{\tilde{A}\tilde{B}\psi}}^{2}
	\end{equation*}
	
	\item Next, some more manipulations of the last result:
	\begin{equation*}
		 \abs{\bra{\psi}\tilde{A}\tilde{B}\ket{\psi}}^{2} = \abs{\bra{\psi}\tfrac{1}{2}\big(\tilde{A}\tilde{B} - \tilde{B}\tilde{A} + \tilde{A}\tilde{B} + \tilde{B}\tilde{A}\big)\ket{\psi} }^{2}
	\end{equation*}
	We introduce two quantities: the commutator and anti-commutator. They're written
	\begin{equation*}
		\big[\tilde{A}, \tilde{B}\big] = \tilde{A}\tilde{B} - \tilde{B}\tilde{A} \eqtext{and} \big\{\tilde{A}, \tilde{B}\big\} = \tilde{A}\tilde{B} + \tilde{B}\tilde{A}
	\end{equation*} 
\end{itemize}

\textbf{Intermezzo: Some Properties of Commutators}
\begin{itemize}
	\item The anti-commutator of two Hermitian operators is a Hermitian operator
	\begin{align*}
		\big\{A, B\big\}^{\dagger} &= (AB + BA)^{\dagger} = (AB)^{\dagger} + (BA)^{\dagger} = B^{\dagger}A^{\dagger} + A^{\dagger}B^{\dagger}\\
		&=AB + BA = \big\{A, B\big\}
	\end{align*}
	
	\item The commutator of two Hermitian operators is anti-Hermitian
	\begin{align*}
		\big[A, B\big]^{\dagger} &= (AB - BA)^{\dagger} = (AB)^{\dagger} - (BA)^{\dagger} = B^{\dagger}A^{\dagger} - A^{\dagger}B^{\dagger}\\
		&= - (AB - BA) = - \big[A, B\big]
	\end{align*}
	
	\item Finally, the expectation value of an anti-Hermitian operator $ A^{\dagger} = - A $ is
	\begin{equation*}
		\langle A \rangle = \braket{\psi}{A\psi} = \braket{A^{*}\psi}{\psi} = \braket{-A\psi}{\psi} = - \braket{A\psi}{\psi} = - \braket{\psi}{A\psi}^{*} = - \langle A \rangle^{*}
	\end{equation*}
	The result implies $ \expval{A} $ is a purely imaginary number if $ A $ is anti-Hermitian.
\end{itemize}

\textbf{Back to the Uncertainty Principle}
\begin{itemize}
	\item Specifically, back to where we left off with
	\begin{align*}
		(\Delta A \Delta B)^{2} &= \cdots = \norm{\tilde{A}\psi}^{2}\norm{\tilde{B}\psi}^{2} \geq \abs{\braket{\tilde{A}\psi}{\tilde{B}\psi}}^{2} = \cdots \\
		& = \abs{\bra{\psi}\tfrac{1}{2}\big[\tilde{A}, \tilde{B}\big] + \tfrac{1}{2}\big\{ \tilde{A}, \tilde{B}\big\}\ket{\psi} }^{2} = \abs{\left\langle \tfrac{1}{2}\big[\tilde{A}, \tilde{B}\big] + \tfrac{1}{2}\big\{ \tilde{A}, \tilde{B}\big\} \right\rangle}^{2}\\
		&= \frac{1}{4}\left(\abs{\big\langle \big[\tilde{A}, \tilde{B}\big] \big\rangle}^{2} + \abs{\big\langle \big\{\tilde{A}, \tilde{B}\big\} \big\rangle}^{2}\right) 
	\end{align*}
	In last parentheses we have a sum of two positive quantities, so we can drop the anti-commutator if we write
	\begin{equation*}
		\frac{1}{4}\left(\abs{\big\langle \big[\tilde{A}, \tilde{B}\big] \big\rangle}^{2} + \abs{\big\langle \big\{\tilde{A}, \tilde{B}\big\} \big\rangle}^{2}\right)  \geq \frac{1}{4}\abs{\big\langle \big[\tilde{A}, \tilde{B}\big] \big\rangle}^{2} = \left(\frac{1}{2}\abs{\big\langle [A, B] \big\rangle}\right)^{2}
	\end{equation*}
	The last equality uses the identity $ \big[\tilde{A}, \tilde{B}\big] = [A, B] $, which follows from  some basic algebra and the definitions $ \tilde{A} = A - \langle A \rangle I $ and $ \tilde{B} = B - \langle B \rangle I $:
	\begin{equation*}
		\big[\tilde{A}, \tilde{B}\big] = \big [A - \langle A \rangle I, B - \langle B \rangle I \big ] = \ldots = AB - BA = [A, B]
	\end{equation*}
	
	\item Okay, so here's the entire derivation so far in one place. Note the two inequalities.
	\begin{align*}
		(\Delta A \Delta B)^{2} &= \big\langle \tilde{A}^{2} \big\rangle \big\langle \tilde{B}^{2} \big\rangle = \bra{\psi}\tilde{A}^{2}\ket{\psi} \bra{\psi}\tilde{B}^{2}\ket{\psi} = \braket{\tilde{A}\psi}{\tilde{A}\psi}\braket{\tilde{B}\psi}{\tilde{B}\psi}\\
		&= \norm{\tilde{A}\psi}^{2}\norm{\tilde{B}\psi}^{2} \geq \abs{\braket{\tilde{A}\psi}{\tilde{B}\psi}}^{2} = \abs{\braket{\psi}{\tilde{A}\tilde{B}\psi}}^{2}\\
		& = \abs{\bra{\psi}\tfrac{1}{2}\big(\tilde{A}\tilde{B} - \tilde{B}\tilde{A} + \tilde{A}\tilde{B} + \tilde{B}\tilde{A}\big)\ket{\psi} }^{2} \equiv  \abs{\bra{\psi}\tfrac{1}{2}\big[\tilde{A}, \tilde{B}\big] + \tfrac{1}{2}\big\{ \tilde{A}, \tilde{B}\big\}\ket{\psi} }^{2} \\
		& = \abs{\left\langle \tfrac{1}{2}\big[\tilde{A}, \tilde{B}\big] + \tfrac{1}{2}\big\{ \tilde{A}, \tilde{B}\big\} \right\rangle}^{2} = \frac{1}{4}\left(\abs{\big\langle \big[\tilde{A}, \tilde{B}\big] \big\rangle}^{2} + \abs{\big\langle \big\{\tilde{A}, \tilde{B}\big\} \big\rangle}^{2}\right) \\
		& \geq \frac{1}{4}\abs{\ev{[A, B]}}^{2} = \left(\frac{1}{2}\abs{\ev{[A, B]}}\right)^{2}
	\end{align*}
	
	\item Now we apply the result specifically to $ x $ and $ p $, where $ x = x $, $ p = -i\hbar \pdv{}{x} $ and $ [x, p] = i \hbar $. The result is
	\begin{equation*}
		(\Delta x \Delta p)^{2} \geq \left(\tfrac{1}{2}\abs{\langle [x, p] \rangle}\right)^{2} = \left(\tfrac{1}{2}\abs{\langle i \hbar \rangle}\right)^{2} = \left(\tfrac{1}{2}\abs{i\hbar}\right)^{2} = \left(\tfrac{\hbar}{2}\right)^{2} \implies \Delta x \Delta p \geq \frac{\hbar}{2}
	\end{equation*}

\end{itemize}

\subsubsection{Wave Function Minimizing the Uncertainty Product}
\textit{Find all wave functions with the minimum position-momentum uncertainty product allowed by the Heisenberg uncertainty principle, i.e. find all wave functions for which $ \Delta x \Delta p = \frac{\hbar}{2} $}.
\begin{itemize}
	\item To solve this problem, we need a wavefunction for which both inequalities in the above theory section are strict equalities. First, the Cauchy-Schwartz inequality is an equality for two linearly dependent vectors.
	\begin{equation*}
		\norm{\tilde{A}\psi}^{2}\norm{\tilde{B}\psi}^{2} = \abs{\braket{\tilde{A}\psi}{\tilde{B}\psi}}^{2} \quad \text{if} \quad \tilde{A}\psi = \alpha \tilde{B}\psi, \qquad \alpha \in \mathbb{C}
	\end{equation*}
	The second inequality is an equality if 
	\begin{equation*}
		\big\langle \big\{\tilde{A}, \tilde{B}\big\} \big\rangle = 0
	\end{equation*}
	
	\item We have two conditions:
	\begin{equation*}
		\ket{\tilde{A}\psi} = \alpha \ket{\tilde{B}\psi} \eqtext{and} \big\langle \big\{\tilde{A}, \tilde{B}\big\} \big\rangle = 0
	\end{equation*}
	We start with the second condition and perform some manipulations... 
	\begin{align*}
		0 &\equiv \evb{\big\{\tilde{A}, \tilde{B}\big\}} = \bra{\psi}\tilde{A}\tilde{B} + \tilde{B} \tilde{A} \ket{\psi} = \bra{\psi}\tilde{A}\tilde{B} \ket{\psi} + \bra{\psi}\tilde{B} \tilde{A} \ket{\psi}\\
		&= \braket{\tilde{A}\psi}{\tilde{B}\psi} + \braket{\tilde{B}\psi}{\tilde{A}\psi} = 0
	\end{align*}
	And then substitute in the Cauchy-Schwartz condition...
	\begin{align*}
		0 &= \braket{\tilde{A}\psi}{\tilde{B}\psi} + \braket{\tilde{B}\psi}{\tilde{A}\psi} = \braket{\alpha \tilde{B}\psi}{\tilde{B}\psi} + \braket{\tilde{B}\psi}{\alpha \tilde{B}\psi} \\
		& = \alpha^{*}\braket{ \tilde{B}\psi}{\tilde{B}\psi} + \alpha\braket{\tilde{B}\psi}{\tilde{B}\psi} = (\alpha^{*} + \alpha)\braket{\tilde{B}\psi}{\tilde{B}\psi} = 0
	\end{align*}
	Mathematically, the equality holds if either of the two product terms equal zero. But the bra-ket term is $ \braket{\tilde{B}\psi}{\tilde{B}\psi} = \big \langle \tilde{B}^{2} \big \rangle = (\Delta B)^{2}$, and this term being zero would imply zero uncertainty in $ B $, which implies infinite uncertainty in $ A $. We reject this option as non-physical, so we're left with $ (\alpha^{*} + \alpha) = 0 $, meaning $ \alpha $ is a purely imaginary number. To make this requirement explicit, we write $ \alpha = i c $ where $ c \in \mathbb{R} $. The Cauchy-Schwartz condition then reads 
	\begin{equation*}
		\ket{\tilde{A}\psi} = i c \ket{\tilde{B}\psi}, \qquad c \in \mathbb{R}
	\end{equation*}
	Substituting in the definition $ \tilde{A} = A - \expval{A}I $ gives
	\begin{equation*}
		\ket{A\psi} - \langle A \rangle\ket{\psi} = ic\ket{B\psi} - ic\langle B \rangle\ket{\psi}
	\end{equation*}
	
	\item Any solutions $ \psi $ to this equation will satisfy the equality
	\begin{equation*}
		  \Delta A \Delta B = \frac{1}{2}\abs{\big\langle [A, B] \big\rangle}
	\end{equation*}
	For the specific case $ A \to x $ and $ B \to p $ where $ p \to  - i \hbar \pdv{}{x} $ and $ \ket{\psi} = \psi(x) $, the equation reads
	\begin{equation*}
		x \psi - \expval{x} \psi = \hbar c \pdv{\psi}{x} - ic \expval{p} \psi
	\end{equation*}
\end{itemize}


\subsection{Fourth Exercise Set}

\subsubsection{Wave Function Minimizing the Uncertainty Product (continued)}
\textit{Continued from the previous exercise set...}
\begin{itemize}
	\item \textit{Review of last exercise set}: We started with two Hermitian operators $ A  $ and $ B $ and showed
	\begin{equation*}
		\Delta A \Delta B \geq \frac{1}{2}\abs{\langle [A, B] \rangle}
	\end{equation*}
	An equality $ = $ replaces the inequality $ \geq $ if
	\begin{equation*}
		\ev{\{\tilde{A}, \tilde{B}} = 0 \eqtext{and} \tilde{A}\ket{\psi} = \alpha \tilde{B}\ket{\psi}
	\end{equation*}
	where $ \tilde{A} = A - \ev{A}$, $ \tilde{B} = B - \ev{B}$ and $ \alpha = ic $ where $ c \in \mathbb{R} $ is real constant.
	
	In the concrete momentum-position case, the minimum uncertainty condition reads
	\begin{equation*}
		x \psi(x) - \expval{x} \psi = \hbar c \psi'(x) - ic \expval{p} \psi
	\end{equation*}
	The wave functions $ \psi $ solving this equation will minimize the product $ \Delta x \Delta p $. 
	
	\item Rearranging the equation for $ \psi' $ gives
	\begin{equation*}
		\psi'(x) = \left(\frac{x - \ev{x}}{c\hbar} + \frac{i\ev{p}}{\hbar}\right)\psi(x)
	\end{equation*}
	Next, we separate variables and integrate:
	\begin{equation*}
		\frac{\diff \psi}{\psi} = \frac{x - \ev{x}}{c \hbar} + \frac{i\ev{p}}{\hbar} \implies \ln \psi = \frac{(x - \ev{x})^{2}}{2c \hbar} + \frac{i\ev{p}}{\hbar}x + \lambda
	\end{equation*}
	Solving for $ x $ gives
	\begin{equation*}
		\psi(x) = e^{\lambda}\exp(\frac{(x - \ev{x})^{2}}{2c\hbar})e^{-i\frac{\ev{p}}{\hbar}x}
	\end{equation*}
	
	\item Now we just have to normalize the wavefunction:
	\begin{equation*}
		\int_{-\infty}^{\infty} \abs{\psi(x)}^{2} \diff x \equiv 1 = \abs{e^{\lambda}}^{2} \int_{-\infty}^{\infty}\exp(\frac{(x - \ev{x})^{2}}{2c\hbar})\diff x
	\end{equation*}
	Note that $ c $ must be negative for the integral to converge. To make this requirement explicit, we'll write
	\begin{equation*}
		1 \equiv  \abs{e^{\lambda}}^{2} \int_{-\infty}^{\infty}\exp(-\frac{(x - \ev{x})^{2}}{2\sigma^{2}})\diff x
	\end{equation*}
	where we introduce $ \sigma $ to match the form of a Gauss bell curve, which then implies
	\begin{equation*}
		\abs{e^{\lambda}}^{2} = \frac{1}{\sqrt{2\pi \sigma^{2}}}
	\end{equation*}
	The final result for $ \psi(x) $ is
	\begin{equation*}
		\psi(x) = \frac{1}{\sqrt[4]{2\pi \sigma^{2}}} \exp(\frac{(x - \ev{x})^{2}}{4 \sigma^{2}})e^{-i\frac{\ev{p}}{\hbar}x}
	\end{equation*}
	These functions are called \textit{Gaussian wave packets}. This concludes the problem: the functions minimizing the product $ \Delta x \Delta p $ are Gaussian wave packets. 
	
	As a final note, the $ e^{-i\frac{\ev{p}}{\hbar}x} $ term is a plane wave, with wavelength
	\begin{equation*}
		\frac{\ev{p}}{\hbar} \lambda = 2\pi \implies \lambda = \frac{h}{\ev{p}}
	\end{equation*}
	
\end{itemize}


\subsubsection{Theory: Time Evolution of a Wave Function}
\begin{itemize}
	\item We find the time evolution of a wave function by solving the \Schro equation
	\begin{equation*}
		H\psi(x, t) = i\hbar \pdv{t}\psi(x, t)
	\end{equation*}
	One option is to solve the stationary \Schro equation
	\begin{equation*}
		H \psi_{n}(x) = E_{n}\psi_{n}(x)
	\end{equation*}
	and expand the initial state $ \psi(x, 0) $ in terms of the basis functions $ \psi_{n} $ solving the stationary \Schro equation, i.e. writing $ \psi(x, 0) $ as
	\begin{equation*}
		\psi(x, 0) = \sum_{n}c_{n}\psi_{n}(x)
	\end{equation*}
	\item We then find the time evolution by adding a time-dependent phase factor to the eigenfunction expansion
	\begin{equation*}
		\psi(x, t) = \sum_{n}c_{n}\psi_{n}(x)e^{-i\frac{E_{n}}{\hbar}t}
	\end{equation*}
	In Dirac bra-ket notation, the stationary \Schro equation and eigenfunction expansion of the initial state read
	\begin{equation*}
		H\ket{n} = E_{n}\ket{n} \eqtext{and} \ket{\psi, 0} = \sum_{n}c_{n}\ket{n} 
	\end{equation*}
	and the time evolution reads
	\begin{equation*}
		\ket{\psi, t} = \sum_{n}c_{n} e^{-i\frac{E_{n}}{\hbar}t} \ket{n}
	\end{equation*}
	The time evolution depends on the potential $ V(x) $ we're working in.
\end{itemize}

\subsubsection{Theory: Time-Dependent Expectation Values and Operators}

\begin{itemize}
	\item Consider an operator $ A $. A function of the operator is defined in terms of the function's Taylor series:
	\begin{equation*}
		f(A) = \sum_{n} \frac{1}{\sqrt{N!}}f^{(n)}(A)A^{N}
	\end{equation*}

	\item Next, consider an arbitrary observable $ A = A^{\dagger} $. We then ask what is the expectation value $ \ev{A, t} $ of $ A $ at time $ t $? We can find the wave function $ \ket{\psi, t} $ with
	\begin{equation*}
		\ket{\psi, t} = \sum_{n} c_{n}e^{-i \frac{E_{n}}{\hbar}t}\ket{n}
	\end{equation*}
	We'll now show that we get the same result by acting on the initial state $ \ket{\psi, 0} $ with the time evolution operator, i.e. we will prove the equality
	\begin{equation*}
		\ket{\psi, t} \equiv \sum_{n} c_{n}e^{-i \frac{E_{n}}{\hbar}t}\ket{n} = e^{-i\frac{H}{\hbar}t}\ket{\psi, 0}
	\end{equation*}
	
	\item To show this, we first expand $ \ket{\psi, 0} $ in terms of its eigenstates and bring the operator inside the sum.
	\begin{equation*}
		 e^{-i\frac{H}{\hbar}t}\ket{\psi, 0} =  e^{-i\frac{H}{\hbar}t}\sum_{n}c_{n}\ket{n} = \sum_{n}c_{n}e^{-i\frac{H}{\hbar}t}\ket{n}
	\end{equation*}
	We write the exponent of the Hamiltonian operator in terms of the exponential function's Taylor series:
	\begin{equation*}
		e^{-i\frac{H}{\hbar}t}\ket{\psi, 0}  = \sum_{n}c_{n} \left[\sum_{m}\frac{1}{m!}\left (-\frac{it}{\hbar}\right )^{m}H^{m}\ket{n}\right]
	\end{equation*}
	
	\item First, we'll tackle the term $ H^{m}\ket{n} $, recalling that $ \ket{n} $ are eigenfunctions of $ H $:
	\begin{equation*}
		H^{m}\ket{n} = H^{m-1}\left(H\ket{n}\right) = H^{m-1}\left(E_{n}\ket{n}\right) = \cdots = E_{n}^{m}\ket{n}
	\end{equation*}
	This step is important---it converts the operator $ H $ to the scalar values $ E_{n} $. We then have
	\begin{equation*}
		e^{-i\frac{H}{\hbar}t}\ket{\psi, 0} = \sum_{n}c_{n} \left[\sum_{m}\frac{1}{m!}\left (-\frac{it}{\hbar}\right )^{m}E_{n}^{m}\right]\ket{n} = \sum_{n}c_{n}e^{-i\frac{E_{n}}{\hbar}t}\ket{n}
	\end{equation*}
	This completes the proof that
	\begin{equation*}
		\ket{\psi, t} = \sum_{n} c_{n}e^{-i \frac{E_{n}}{\hbar}t}\ket{n} = e^{-i\frac{H}{\hbar}t}\ket{\psi, 0}
	\end{equation*} 
	In other words, instead of finding a time evolution by expanding an initial state $ \ket{\psi, 0} $ in terms of basis functions, we can act directly on the initial state with the time evolution operator.
\end{itemize}

\textbf{Time-Dependent Expectation Values}
\begin{itemize}
	
	\item Next, we return to the expectation value $ \ev{A, t} $:
	\begin{equation*}
		\ev{A, t} \equiv \bra{\psi, t} A \ket{\psi, t}
	\end{equation*}
	We've just shown the ket term can be found with the time evolution operator
	\begin{equation*}
		\ket{\psi, t} = \tev \ket{\psi, 0}
	\end{equation*}
	We find the bra term by taking the complex conjugate of the ket term:
	\begin{equation*}
		\bra{\psi, t} = \bra{\psi, 0}\left(\tev\right)^{\dagger} = \bra{\psi, 0}\tevp
	\end{equation*}
	Note that the $ \ket{\psi, 0} $ ket term is reversed under complex conjugation! We then have
	\begin{equation*}
		\ev{A, t} = \bra{\psi, 0}\tevp A \tev \ket{\psi, 0} \equiv  \bra{\psi, 0} A(t) \ket{\psi, 0}
	\end{equation*}
	where we've defined $ A(t) = \tevp A \tev  $ for shorthand.
	
	\item The above result is useful: we have a new way to find a time-dependent expectation value. If we are given an initial state $ \ket{\psi, 0} $, we can use the time evolution operator to get
	\begin{equation*}
		\ev{A, t} = \bra{\psi, 0}\tevp A \tev \ket{\psi, 0} \equiv  \bra{\psi, 0}
	\end{equation*}
	In other words, we don't need to find the time evolution of the wave function $ \ket{\psi, t} $. This is convenient, since finding $ \ket{\psi, t} $ is often tedious.
	
	\item Finally, some vocabulary. Finding $ \ket{A, t} $ via time evolution of the wave function, i.e. 
	\begin{equation*}
		\ev{A, t} = \bra{\psi, t} A \ket{\psi, t}
	\end{equation*}
	is called the \textit{\Schro approach}. Finding $ \ket{A, t} $ via time evolution of the $ A $ operator, i.e. 
	\begin{equation*}
		\ev{A, t} = \bra{\psi, 0}\tevp A \tev \ket{\psi, 0} = \bra{\psi, 0} A(t) \ket{\psi, 0}
	\end{equation*}
	is called the \textit{Heisenberg approach}. 
\end{itemize}
\textbf{Theory: Time Evolution of an Operator}
\begin{itemize}
	\item Next, we ask how to find the time evolution $ A(t) $ of an operator $ A $? To do this, we solve the differential equation
	\begin{equation*}
		\dv{t}A(t) = \dv{t}\left[\tevp A \tev \right] = \left(\tfrac{i}{\hbar}H\right)\tevp A \tev + \tevp A\left(-i\tfrac{H}{\hbar}\tev\right)
	\end{equation*}
	This is found with the Taylor series definition of an operator $ A $. In both terms, we have the product of the Hamiltonian $ H $ with the time evolution operator. These operators commute, so we can switch their order of multiplication and factor to get
	\begin{equation*}
		\dv{t}A(t) = \tevp \left(\frac{i}{\hbar}HA - \frac{i}{\hbar}AH\right) \tev = \tevp \frac{i}{\hbar}[H, A]\tev \equiv \frac{i}{\hbar}[H, A](t)
	\end{equation*}
	So, we find $ A(t) $ by solving the differential equation
	\begin{equation*}
		\dv{t}A(t) = \frac{i}{\hbar}[H, A](t)
	\end{equation*}
	
	\item One more useful identity: consider two operators $ A $ and $ B $. We're interested in the time evolution of their product $ AB $: 
	\begin{align*}
		(AB)(t) &= \tevp AB \tev = \tevp A I B \tev\\
		&=\tevp A \tev \tevp B \tev = A(t)B(t)
	\end{align*}

\end{itemize}


\subsubsection{Time Evolution of the Gaussian Wave Packet}
\textit{Given a Gaussian wave function $ \psi(x, 0) $ and the time-independent Hamiltonian $ H = \frac{p^{2}}{2m} + V(x) $, find the initial wavefunction's time evolution $ \psi(x, t) $.}

\begin{itemize}
	\item We'll work in the potential $ V(x) = 0$. Because the basis functions of a free particle are continuous, and $ n $ is traditionally used to index discrete quantities, we'll index the basis functions with $ k $. For a particle in a constant potential, the eigenfunctions are plane waves. We have
	\begin{equation*}
		\psi_{k}(x) = \frac{e^{ikx}}{\sqrt{2\pi}} \eqtext{and} E_{k} = \frac{\hbar^{2}k^{2}}{2m}
	\end{equation*}
	Note the normalization of the plane wave with $ \sqrt{2\pi} $. The factor $ \frac{1}{\sqrt{2\pi}} $ is chosen so that a product of two basis functions produces a delta function:
	\begin{equation*}
		\braket{k}{\tilde{k}} \equiv \int \psi_{k}^{*}(x)\psi_{\tilde{k}}(x)\diff x = \frac{1}{2\pi} \int e^{i(\tilde{k}-k)x}\diff x \equiv \delta(\tilde{k} - k)
	\end{equation*}
	
	\item First, an overview: To perform the time evolution, we first expand the initial state $ \psi(x, 0) $ in terms of the basis functions $ \psi_{k} $
	\begin{equation*}
		\psi(x, 0) = \int  c(k)\frac{e^{ikx}}{\sqrt{2\pi}} \diff k
	\end{equation*}
	Note that we use integration instead of summation because the basis functions are continuous and not discrete. The above expansion is a Fourier transform of $ c(k) $ from the $ k $ to the $ x $ domain, so $ c(k) $ is found with the inverse Fourier transform
	\begin{equation*}
		c(k) = \int \psi(x, 0)\frac{e^{-ikx}}{\sqrt{2\pi}}\diff x 
	\end{equation*}
	We would then find the time evolution with
	\begin{equation*}
		\psi(x, t) = \int c(k)e^{-i\frac{E_{k}}{\hbar}t}\frac{e^{ikx}}{\sqrt{2\pi}} \diff k
	\end{equation*}
	Again, integration replaces summation.
	
	\item In the end, we'll be more interested in the observables $ x $ and $ p $ than the actual wave function. For example the expectation values of $ x $ and $ p $ at time $ t $, written
	\begin{equation*}
		\ev{x, t} \equiv \bra{\psi, t}x\ket{\psi, t} \eqtext{and} \ev{p, t} \equiv \bra{\psi, t}p\ket{\psi, t}
	\end{equation*}
	Likewise, we'll be interested in the uncertainties
	\begin{equation*}
		\Delta x(t) = \sqrt{\ev{x^{2}, t} - \ev{x, t}^{2}} \eqtext{and} \Delta p(t) = \sqrt{\ev{p^{2}, t} - \ev{p, t}^{2}}
	\end{equation*}
	\textit{Note:} Directly performing the above eigenfunction expansion and time evolution by solving the integrals is a tedious mathematical exercise. We'll take a slight detour, and introduce some machinery that solves the problem in a more physically elegant way.
\end{itemize}

\textbf{Theory: Commutator Properties}
\begin{itemize}
	\item First, a distributive property: $ [AB, C] = A[B, C] + [A, C]B $.
	
	\item And second: $ [\lambda A, B] = \lambda [A, B] $
	
	\item And  finally: $ [B, A] = -[A, B] $
\end{itemize}

\textbf{Back to the Time Evolution of the Gaussian Wave Packet}
\begin{itemize}
	\item We now have the formalism we need to easily find the expectation values
	\begin{equation*}
		\ev{x, t} \equiv \bra{\psi, t}x\ket{\psi, t} \eqtext{and} \ev{p, t} \equiv \bra{\psi, t}p\ket{\psi, t}
	\end{equation*}
	for a Gaussian wave packet with the simple Hamiltonian $ H = \frac{p^{2}}{2m} $. Using the Heisenberg approach, we'll first find the time evolution of the operators $ x $ and $ p $, then find the expectation values with
	\begin{equation*}
		\ev{A, t} = \bra{\psi, 0} A(t) \ket{\psi, 0}
	\end{equation*}
	
	\item First, the equation for the operator $ x(t) $:
	\begin{equation*}
		\dv{t}x(t) = \frac{i}{\hbar}[H, x](t) = \frac{i}{\hbar}\left [\frac{p^{2}}{2m}, x\right ](t)
	\end{equation*}
	Writing $ p^{2} = pp $, applying basic commutator properties and recalling the result $ [x, p] = i \hbar $ gives
	\begin{equation*}
		\dv{t}x(t) = \frac{i}{2m\hbar}\left(p[p, x] + [p, x]p\right)(t) = \frac{i}{2m\hbar}\left(-pi\hbar -i\hbar p\right)(t) = \frac{p(t)}{m}
	\end{equation*}
	Second, the differential for the operator $ p(t) $, noting that $ [p^{2}, p] = 0 $, is
	\begin{equation*}
		\dv{p}(t) = \frac{i}{\hbar}\left[H, p\right](t) = \frac{i}{\hbar}\left[\frac{p^{2}}{2m}, p\right](t) = 0
	\end{equation*}
	The general solution is a constant: $ p(t) = p_{0} $. We need an initial condition to find a solution specific to our problem, which we get from general expression
	\begin{equation*}
		A(t)\big |_{t = 0} = e^{i\frac{H}{\hbar}\cdot 0}Ae^{-i\frac{H}{\hbar}\cdot 0} = A
	\end{equation*}
	In our case, $ p(0) = p $, which implies $ p(t) = p$. In other words, the momentum operator stays the same with time; it is always the usual
	\begin{equation*}
		p = -i\hbar \pdv{x}
	\end{equation*}
	for all time $ t $. Next, with $ p(t) $ known, we solve the equation for $ x(t) $:
	\begin{equation*}
		\dv{x} = \frac{p(t)}{m} = \frac{p}{m} \implies x(t) = \frac{p}{m}t + x_{0}
	\end{equation*}
	With the initial condition $ x(0) = x $, we now have the expression for the time evolution of the operator $ x(t) $
	\begin{equation*}
		x(t) = \frac{p}{m}t + x \to -i\frac{\hbar}{m}t\pdv{x} + x
	\end{equation*}
	
	\item With $ x(t) $ and $ p(t) $ known, we can find the expectation values using
	\begin{equation*}
		\ev{A, t} = \bra{\psi, 0} A(t) \ket{\psi, 0}
	\end{equation*}
	We start with momentum:
	\begin{equation*}
		\ev{p, t} = \bra{\psi, 0} p(t) \ket{\psi, 0} = \bra{\psi, 0} p \ket{\psi, 0} \equiv \ev{p, 0} = \ev{p}
	\end{equation*}
	In other words, because $ p(t) = p $ is constant, we can just find the initial expectation value $ \ev{p, 0} $ using the initial wave function. This is the same $ \ev{p} $ term in the exponent of the plane wave term in the Gaussian wave packet. 
	
	Next, the expectation value of position. Inserting $ x(t) $  and splitting the bra-ket into two parts gives
	\begin{align*}
		\ev{x, t} &= \bra{\psi, 0} x(t) \ket{\psi, 0} = \bra{\psi, 0} \frac{p}{m}t + x \ket{\psi, 0} \\
		&= \frac{t}{m}\bra{\psi, 0} p \ket{\psi, 0} + \bra{\psi, 0} x \ket{\psi, 0} = \frac{t}{m}\ev{p, 0} + \ev{x, 0}
	\end{align*}
	These are the same  $ \ev{x} $ and $ \ev{p} $ term in the exponents of the initial the Gaussian wave packet. 
	
	\item Next, we want to find the uncertainties
	\begin{equation*}
		\Delta x(t) = \sqrt{\ev{x^{2}, t} - \ev{x, t}^{2}} \eqtext{and} \Delta p(t) = \sqrt{\ev{p^{2}, t} - \ev{p, t}^{2}}
	\end{equation*}
	It remains to find the the time evolution of the operators $ p^{2} $ and $ x^{2} $ and then the expectation values $ \ev{p^{2}, t} $ and $ \ev{x^{2}, t} $. We start with the operator $ p^{2}(t) $. 
	\begin{equation*}
		\ev{p^{2}, t} = \bra{\psi, 0} p^{2}(t) \ket{\psi, 0} = \bra{\psi, 0} \big[p(t)\big]^{2} \ket{\psi, 0} = \bra{\psi, 0} p^{2} \ket{\psi, 0}
	\end{equation*}
	In other words, $ \ev{p^{2}, t} $ is the expectation value of the time-independent operator $ p^{2} $. 
	
	Next, the evolution of $ x(t) $. Using $ x^{2}(t) = \big[x(t)\big]^{2} $, substituting in the definition of $ x(t) $, and splitting up the expectation value into three terms gives
	\begin{align*}
		\ev{x^{2}, t} &= \bra{\psi, 0} x^{2}(t) \ket{\psi, 0} =  \bra{\psi, 0} \big[x(t)\big]^{2} \ket{\psi, 0} = \bra{\psi, 0}\left(\frac{p}{m}t + x\right)^{2} \ket{\psi, 0}\\
		&= \bra{\psi, 0}\left(\frac{p^{2}t^{2}}{m^{2}} + \frac{t}{m}(px + xp) + x^{2}\right)\ket{\psi, 0}\\
		&= \frac{t^{2}}{m^{2}}\bra{\psi, 0} p^{2} \ket{\psi, 0} + \frac{t}{m}\bra{\psi, 0} px + xp \ket{\psi, 0} + \bra{\psi, 0} x^{2} \ket{\psi, 0}
	\end{align*}
	We've now succeeded in expressing the time-dependent expectation values of $ x, x^{2}, p $ and $ p^{2} $ in terms of quantities that appear in the initial state, namely the exponent parameters $ \ev{x} $ and $ \ev{p} $. 
	
	\item From the beginning of this problem, recall the initial wave function is
	\begin{equation*}
		\psi(x, 0) = \frac{1}{\sqrt[4]{2\pi \sigma^{2}}} \exp(\frac{(x - \ev{x})^{2}}{4 \sigma^{2}})e^{-i\frac{\ev{p}}{\hbar}x}
	\end{equation*}
	The associated probability density is 
	\begin{equation*}
		\rho(x, t) = \frac{1}{\sqrt{2\pi \sigma^{2}}} \exp(\frac{(x - \ev{x})^{2}}{2 \sigma^{2}})
	\end{equation*}
	The expectation values of $ x $ and $ p $ are simply
	\begin{equation*}
		\bra{\psi, 0} x \ket{\psi, 0} = \ev{x} \eqtext{and} \bra{\psi, 0} p \ket{\psi, 0} = \ev{p}
	\end{equation*}
	By definition, the initial uncertainty in $ x $ is
	\begin{equation*}
		\Delta x(0) = \sqrt{\ev{x^{2}, 0} - \ev{x, 0}^{2}}
	\end{equation*}
	There is a shortcut: for a Gaussian wave packet, the uncertainty is simply the wave packet's standard deviation $ \sigma $. We can take advantage of this relationship to easily find $ \ev{x^{2}, 0} $:
	\begin{equation*}
		\Delta x(0) = \sqrt{\ev{x^{2}, 0} - \ev{x, 0}^{2}} = \sigma \implies \ev{x^{2}, 0} = \sigma^{2} + \ev{x, 0}^{2}
	\end{equation*}
	
	\item Another shortcut: instead of the definition, we find the uncertainty in $ p $ using the uncertainty principle, which for a Gaussian wave packet is the equality
	\begin{equation*}
		\Delta x \Delta p = \frac{\hbar}{2} \implies \Delta p(0) = \frac{\hbar}{2\Delta x(0)} = \frac{\hbar}{2\sigma}
	\end{equation*}
	With $ \Delta p(0) $ in hand, we can find $ \ev{p^{2}, 0} $ with
	\begin{equation*}
		\Delta p(0) = \sqrt{\ev{p^{2}, 0} - \ev{p, 0}^{2}} = \frac{\hbar}{2\sigma} \implies \ev{p^{2}, 0} = \frac{\hbar^{2}}{4\sigma^{2}} + \ev{p, 0}^{2}
	\end{equation*}
	
	\item The last piece needed to find $ \ev{x^{2}, t} $ is the quantity $ \bra{\psi, 0} px + xp \ket{\psi, 0}  $. To find this, we'll use the relationship $ px = p^{\dagger}x^{\dagger} = (xp)^{\dagger} $. In general,
	\begin{equation*}
		\evb{A^{\dagger}} = \bbraket{\psi}{A^{\dagger}\psi} = \braket{A\psi}{\psi} = \braket{\psi}{A\psi}^{*} = \ev{A}^{*}
	\end{equation*}
	which implies $ \ev{A + A^{\dagger}} = \ev{A} + \ev{A}^{*} = 2 \Re \ev{A} $. The expression $  \bra{\psi, 0} px + xp \ket{\psi, 0}  $ then simplifies to
	\begin{equation*}
		 \bra{\psi, 0} px + xp \ket{\psi, 0}  = 2 \Re \bra{\psi, 0}xp \ket{\psi, 0} 
	\end{equation*}
	\textit{We ran out of time at this point. The problem is completed in the next exercise set.}
	
\end{itemize}


\subsection{Fifth Exercise Set}

\subsubsection{Time Evolution of a Gaussian Wave Packet (continued)}
\begin{itemize}
	\item In the last exercise set, we wanted to find the uncertainties
	\begin{equation*}
		\Delta x(t) = \sqrt{\ev{x^{2}, t} - \ev{x, t}^{2}} \eqtext{and} \Delta p(t) = \sqrt{\ev{p^{2}, t} - \ev{p, t}^{2}}
	\end{equation*}
	We approached finding the time evolution of the operators $ x(t) $ and $ p(t) $ using the Heisenberg approach. We left off with the following operator expressions:
	\begin{equation*}
		p(t) = p \eqtext{and} x(t) = \frac{pt}{m} + x
	\end{equation*}
	For expected momentum values, we found
	\begin{equation*}
		\ev{p, t} = \ev{p, 0} \eqtext{and} \ev{p^{2}, t} = \ev{p^{2}, 0}
	\end{equation*}
	For expected position values, we found
	\begin{align*}
		&\ev{x, t} = \frac{t}{m} \ev{p, 0} + \ev{x, 0}\\
		&\ev{x^{2}, t} = \frac{t^{2}}{m^{2}}\bra{\psi, 0} p^{2} \ket{\psi, 0} + \frac{t}{m}\bra{\psi, 0} px + xp \ket{\psi, 0} + \bra{\psi, 0} x^{2} \ket{\psi, 0}
	\end{align*}
	We found nearly all of the initial expectation values in terms of the parameters $ \ev{x}, \ev{p} $ and $ \sigma $ in the wave packet. The result were:
	\begin{align*}
		&\ev{p, 0} = \ev{p} \qquad \ev{x, 0} = \ev{x}\\
		&\ev{x^{2}, 0} = \sigma^{2} + \ev{x}^{2} \qquad \ev{p^{2}, 0} = \left(\frac{\hbar}{2\sigma}\right)^{2} + \ev{p}^{2}
	\end{align*}
	The only remaining expectation value is $ \ev{px + xp, 0} $, which we showed to be
	\begin{equation*}
		\ev{xp + px, 0} = 2\Re \big[\ev{xp, 0}\big]
	\end{equation*}
	We find the expectation value by definition, using the wave function:
	\begin{align*}
		\ev{xp + px, 0} &= 2\Re \big[\ev{xp, 0}\big] = 2\Re \int_{-\infty}^{\infty}\psi^{*}(x, 0)x\left[-i\hbar \dv{x}\right]\psi(x, 0) \diff x\\
		&= 2 \Re \int_{-\infty}^{\infty} \psi^{*}(x, 0) \cdot x \cdot (-i\hbar)\dv{x}\left[\frac{1}{\sqrt[4]{2\pi \sigma^{2}}}e^{-\frac{(x - \ev{x})^{2}}{4\sigma^{2}}}e^{i\frac{\ev{p}}{\hbar}x}\right]  \diff x\\
		&=2 \int_{-\infty}^{\infty} \psi^{*}(x, 0)x \ev{p} \psi(x, 0) \diff x = 2 \ev{p}\ev{x}
	\end{align*}
	Note that the imaginary portion of the derivative in the middle line disappears when taking the real component.
	
	\item We now have everything we need to find the uncertainties $ \Delta x $ and $ \Delta p $. Starting with $ \Delta p $, we have:
	\begin{equation*}
		\big[\Delta p(t)\big]^{2} = \ev{p^{2}, t} - \ev{p, t}^{2} =  \left(\frac{\hbar}{2\sigma}\right)^{2} + \ev{p}^{2} - \ev{p}^{2} = \left(\frac{\hbar}{2\sigma}\right)^{2}
	\end{equation*}
	For position, the uncertainty $ \Delta x $ is
	\begin{align*}
		\big[\Delta x(t)\big]^{2} &= \ev{x^{2}, t} - \ev{x, t}^{2} = \frac{t^{2}}{m^{2}}\ev{p^{2}, 0} + \frac{t}{m} \ev{px + xp, 0} + \ev{x^{2}, 0} - \left( \frac{t}{m} \ev{p, 0} + \ev{x, 0} \right)^{2}\\
		&=\frac{t^{2}}{m^{2}}\left[\ev{p}^{2} + \left(\frac{\hbar}{2\sigma}\right)^{2}\right] + \frac{t}{m}2\ev{p}\ev{x} + \sigma^{2} + \ev{x}^{2} - \frac{t^{2}}{m^{2}}\ev{p}^{2} - 2\frac{t}{m}\ev{p}\ev{x} - \ev{x}^{2}\\
		&= \sigma^{2} + \left(\frac{\hbar t}{2m\sigma}\right)^{2}
	\end{align*}
	The product in the two uncertainties is 
	\begin{equation*}
		\Delta x(t) \Delta p(t) = \left(\frac{\hbar}{2\sigma}\right)^{2}\left(\sigma^{2} + \left(\frac{\hbar t}{2m\sigma}\right)^{2}\right) = \frac{\hbar}{2}\sqrt{1 + \left(\frac{\hbar t}{2m\sigma^{2}}\right)^{2}}
	\end{equation*}
	Note that the product in uncertainties starts at the initial value $ \frac{\hbar}{2} $ and increases with time. This immediately implies that the time evolution $ \psi(x, t > 0) $ of the initial Gaussian wave packet $ \psi(x, 0) $ is no longer a Gaussian wave packet. It couldn't be---it has an uncertainty product greater $ \Delta x \Delta p > \frac{\hbar}{2} $, while Gaussian wave packets are by definition constructed to have $ \Delta x \Delta p = \frac{\hbar}{2} $. 
\end{itemize}

\subsubsection{Theory: Quantum Harmonic Oscillator}
\begin{itemize}
	\item The Hamiltonian of a particle of mass $ m $ in a harmonic oscillator reads
	\begin{equation*}
		H = \frac{p^{2}}{2m} + \frac{kx^{2}}{2} = \frac{p^{2}}{2m} + \frac{m\omega}{2}x^{2}, \qquad \omega = \sqrt{\frac{k}{m}}
	\end{equation*}
	We analyze the harmonic oscillator using the annihilation and creation operators. The annihilation operator $ a $ is
	\begin{equation*}
		a = \frac{1}{\sqrt{2}}\left(\frac{x}{x_{0}} + i\frac{p}{p_{0}}\right) \eqtext{where} x_{0} = \sqrt{\frac{\hbar}{m\omega}}, \quad p_{0} = \frac{\hbar}{x_{0}}
	\end{equation*}
	while the creation operator, equal to the adjoint of $ a $, is
	\begin{equation*}
		a^{\dagger} = \frac{1}{\sqrt{2}}\left(\frac{x}{x_{0}} - i\frac{p}{p_{0}}\right)
	\end{equation*}
	The annihilation and creation operators don't commute---their commutator is 
	\begin{equation*}
		\big[a, a^{\dagger}\big] = 1
	\end{equation*}
	Adding and subtracting the two operators give expressions for $ x $ and $ p $
	\begin{equation*}
		x = \frac{x_{0}}{\sqrt{2}}(a + a^{\dagger}) \eqtext{and} p = \frac{p_{0}}{\sqrt{2}i}(a - a^{\dagger})
	\end{equation*}
	
	\item In terms of $ a $ and $ a^{\dagger} $, the harmonic oscillator's Hamiltonian reads
	\begin{equation*}
		H = \hbar \omega\left (a^{\dagger}a + \frac{1}{2}\right )
	\end{equation*}
	The Hamiltonian's eigenstates are indexed by $ n = 0, 1, 2, \ldots $ and read
	\begin{equation*}
		H \ket{n} = \hbar \omega \left(n + \frac{1}{2}\right)\ket{n}, \quad n = 0, 1, 2, \ldots
	\end{equation*}
	The annihilation and creation operators act on the oscillator's eigenstates as follows:
	\begin{equation*}
		a\ket{n} = \sqrt{n}\ket{n-1} \eqtext{and} a^{\dagger} \ket{n} = \sqrt{n + 1} \ket{n+1}
	\end{equation*}
	Note the operator equality $ a^{\dagger}a \ket{n} = n \ket{n}$---in other words, acting on an eigenstate $ \ket{n} $  with the operator $ a^{\dagger}a $ reveals the state's index $ n $. 
\end{itemize}

\textbf{Theory: Ehrenfest Theorem}\\
In our case (for a harmonic oscillator), the theorem reads
\begin{equation*}
	\dv{t}\ev{x, t} = \frac{\ev{p, t}}{m} \eqtext{and} \dv{t}\ev{p, t} = \ev{-\dv{x}V(x)} = -k\ev{x, t}
\end{equation*}


\subsubsection{Time Evolution of a Particle in a Harmonic Oscillator}
\textit{Consider a particle in a harmonic potential with the initial eigenfunction}
\begin{equation*}
	\ket{\psi, 0} = \frac{1}{\sqrt{2}}\ket{0} + \frac{1}{\sqrt{2}}\ket{1}
\end{equation*}
\textit{Compute the wavefunction's time evolution $ \ket{\psi, t} $ the time-dependent expectation values $ \ev{x, t} $ and $ \ev{p, t} $ and use this to determine the validity of the Ehrenfest theorem. Finally, determine the product of uncertainties $ \Delta x(t) \Delta p(t) $}.

\begin{itemize}
	\item First, we find the wavefunction's time evolution. This is relatively simple, since the initial wavefunction is a linear combination of the Hamiltonian's eigenstates. We just have to add the time-dependent phase factors $ e^{-i\frac{E_{n}}{\hbar}t} $. Substituting in the energies for a particle in a harmonic oscillator, the result is
	\begin{equation*}
		\ket{\psi, t} = \frac{1}{\sqrt{2}} e^{-i\frac{E_{0}}{\hbar}t}\ket{0} + \frac{1}{\sqrt{2}} e^{-i\frac{E_{1}}{\hbar}t}\ket{1}  =  \frac{1}{\sqrt{2}} e^{-i\frac{\omega}{2}t}\ket{0} + \frac{1}{\sqrt{2}} e^{-i\frac{3\omega}{2}t}\ket{1}
	\end{equation*}
	
	\item Next, working with $ x $ in terms of the annihilation and creation operators, we find the expectation value $ \ev{x} $ as
	\begin{equation*}
		\ev{x} = \frac{x_{0}}{\sqrt{2}}\ev{a + a^{\dagger}} = \frac{x_{0}}{\sqrt{2}}\left(\ev{a} + \ev{a}^{*}\right) =  \sqrt{2}x_{0} \Re \ev{a}
	\end{equation*}
	Following similar lines for $ \ev{p} $, we have
	\begin{equation*}
		\ev{p} = \frac{p_{0}}{\sqrt{2}i}\ev{a - a^{\dagger}} = \frac{p_{0}}{\sqrt{2}i}\left(\ev{a} - \ev{a}^{*}\right) = \sqrt{2}p_{0}\Im \ev{a}
	\end{equation*}
	These two results are useful: they show that by finding the expectation value $ \ev{a} $ we also determine the values of $ \ev{x} $ and $ \ev{p} $. Naturally, the next step is to find $ \ev{a} $ (we'll find the time-dependent form)
	\begin{equation*}
		\ev{a, t} = \bra{\psi, t}a\ket{\psi, t} = \bra{\psi, t}\left(\frac{1}{\sqrt{2}}e^{-i\frac{\omega}{2}t}a \ket{0} + \frac{1}{\sqrt{2}}e^{-i\frac{3\omega}{2}t}a \ket{1}\right)
	\end{equation*}
	The annihilation operator eliminates the ground state, i.e. $ a \ket{0} = 0 $ and turns the first state into the ground state, i.e. $ a \ket{1} = \ket{0} $. The expression for $ \ev{a, t} $ becomes
	\begin{align*}
		\ev{a, t} &= \bra{\psi, t}\frac{1}{\sqrt{2}}e^{-i\frac{3\omega}{2}t}\ket{0} = \left(\frac{1}{\sqrt{2}}e^{i\frac{\omega}{2}t}\bra{0} + \frac{1}{\sqrt{2}}e^{i\frac{3\omega}{2}t}\bra{1}\right) \frac{1}{\sqrt{2}}e^{-i\frac{3\omega}{2}t}\ket{0}\\
		&=\frac{1}{2}e^{-i\omega t} 
	\end{align*}
	where the last equality makes use of the eigenstates' orthogonality. With $ \ev{a, t} $ known, we can now find the expectation values of position and momentum These are
	\begin{equation*}
		\ev{x, t} = \sqrt{2}x_{0}\Re\ev{a, t} = \frac{x_{0}}{\sqrt{2}}\cos \omega t \eqtext{and} \ev{p, t} = \sqrt{2}p_{0}\Im\ev{a, t} = - \frac{p_{0}}{\sqrt{2}}\sin \omega t
	\end{equation*}
	
	\item Next, we confirm the validity of the Ehrenfest theorem.
	\begin{equation*}
		\dv{t}\ev{x, t} = \dv{t}\left( \frac{x_{0}}{\sqrt{2}}\cos \omega t\right) = - 		\frac{\omega x_{0}}{\sqrt{2}}\sin \omega \stackrel{?}{=} \frac{\ev{p, t}}{m} = - \frac{p_{0}}{\sqrt{2}}\sin \omega t
	\end{equation*}
	Comparing the equalities, canceling like terms and inserting the definition of $ p_{0} $ and $ \omega $, we have 
	\begin{equation*}
		 \omega x_{0} \stackrel{?}{=}\frac{p_{0}}{m} = \frac{\hbar}{x_{0}m} \implies \omega \stackrel{?}{=} \frac{h}{mx_{0}^{2}} = \frac{\hbar}{m}\frac{m \omega}{\hbar} = \omega
	\end{equation*}
	which satisfies the first part of the Ehrenfest theorem. To confirm the second part of the theorem, we compute
	\begin{equation*}
		\dv{t}\left(-\frac{p_{0}}{\sqrt{2}}\sin \omega t\right) = -\frac{p_{0}\omega}{\sqrt{2}}\cos \omega t\stackrel{?}{=} - k \ev{x, t}
	\end{equation*}
	The equality reduces to
	\begin{equation*}
		p_{0}\omega \stackrel{?}{=} kx_{0} \implies \frac{\hbar}{x_{0}}\omega = m \omega^{2}x_{0} \implies x_{0}^{2} \stackrel{?}{=} \frac{\hbar}{m \omega}
	\end{equation*}
	The last equality leads to $ \omega = \omega $, already shown above when confirming the first part of the Ehrenfest theorem.
	
	\item Finally, we compute the product $ \Delta x(t) \Delta p(t) $. By definition,
	\begin{equation*}
		\Delta x(t) = \sqrt{\ev{x^{2}, t} - \ev{x, t}^{2}} \eqtext{and} \Delta p(t) = \sqrt{\ev{p^{2}, t} - \ev{p, t}^{2}}
	\end{equation*}
	First, we express $ \ev{x} $ in terms of the annihilation operator $ a $:
	\begin{align*}
		\ev{x^{2}} &= \ev{\left[\frac{x_{0}}{\sqrt{2}}(a + a^{\dagger})\right]^{2}} = \frac{x_{0}^{2}}{2}\ev{a^{2} + aa^{\dagger} + a^{\dagger}a + a^{\dagger^{2}}}\\
		&= \frac{x_{0}^{2}}{2}\ev{a^{2} + 2a^{\dagger}a + a^{\dagger^{2}}+1}
	\end{align*}
	Where the last equality uses the identity $ \big[a, a^{\dagger}\big] = 1 \implies aa^{\dagger} = 1 + a^{\dagger}a $. Continuing on, we have
	\begin{equation*}
		\ev{x^{2}} = \frac{x_{0}^{2}}{2}\left(2\evb{a^{\dagger}a} + \ev{a^{2}}+ \evb{a^{\dagger^{2}}}+1\right) = x_{0}^{2}\left(\Re\ev{a^{2}} + \evb{a^{\dagger}a} + \tfrac{1}{2}\right)
	\end{equation*}
	Next, we express $ \ev{p^{2}} $ in terms of $ a $ with a similar procedure:
	\begin{align*}
		\ev{p^{2}} &= \left(\frac{p_{0}}{\sqrt{2}i}\right)^{2}\ev{(a - a^{\dagger})^{2}} = -\frac{p_{0}}{2}\ev{a^{2}- aa^{\dagger} - a^{\dagger}a + a^{\dagger^{2}}}\\
		& = -\frac{p_{0}}{2} \ev{a^{2} - 2a^{\dagger}a -1 + a^{\dagger^{2}}} = p_{0}^{2}\left(-\Re \ev{a^{2}} + \evb{a^{\dagger}a} + \tfrac{1}{2}\right)
	\end{align*}
	\item Next, we find the expectation value $ \ev{a^{2}, t} $:
	\begin{equation*}
		\ev{a^{2}, t} = \bra{\psi, t}\left(\frac{1}{\sqrt{2}}e^{-i\frac{\omega}{2}t}a^{2}\ket{0} + \frac{1}{\sqrt{2}}e^{-i\frac{3\omega}{2}t}a^{2}\ket{1} \right) 
	\end{equation*}
	Brief intermezzo to note that
	\begin{equation*}
		a^{2}\ket{0} = a\left(a\ket{0}\right) = a \cdot 0 = 0 \eqtext{and} a^{2}\ket{1} = a\left(a\ket{1}\right) = a\ket{0} = 0
	\end{equation*}
	With these identities in hand, we have
	\begin{equation*}
		\ev{a^{2}, t} = \bra{\psi, t} \cdot 0 = 0
	\end{equation*}
	
	\item One more expectation value to go: $ \ev{a^{\dagger}a, t} $
	\begin{align*}
		\evb{a^{\dagger}a, t} &=  \bra{\psi, t}\left(\frac{1}{\sqrt{2}}e^{-i\frac{\omega}{2}t}a^{\dagger}a\ket{0} + \frac{1}{\sqrt{2}}e^{-i\frac{3\omega}{2}t}a^{\dagger}a\ket{1} \right) = \bra{\psi, t} \frac{1}{\sqrt{2}}e^{-i\frac{3\omega}{2}t} \ket{1}\\
		&=\left(\frac{1}{\sqrt{2}}e^{i\frac{\omega}{2}t}\bra{0} + \frac{1}{\sqrt{2}}e^{i\frac{3\omega}{2}t}\bra{1}\right)\frac{1}{\sqrt{2}}e^{-i\frac{3\omega}{2}t} \ket{1}  = \frac{1}{2}
	\end{align*}
	The derivation uses the identity $ a^{\dagger}a \ket{n} = n \ket{n} $ and the eigenstates' orthogonality.
	
	\item We now have everything we need to find the product of uncertainties in $ x $ and $ p $. Putting the pieces together, we have
	\begin{align*}
		&\ev{x^{2}, t} =  x_{0}^{2}\left(\Re\ev{a^{2}} + \evb{a^{\dagger}a} + \tfrac{1}{2}\right) = x_{0}^{2}\left(0 + \tfrac{1}{2} + \tfrac{1}{2}\right) = x_{0}^{2}\\
		&\ev{p^{2}, t} = p_{0}^{2}\left(-\Re \ev{a^{2}} + \evb{a^{\dagger}a} + \tfrac{1}{2}\right) = p_{0}^{2}\left(0 + \ev{a^{\dagger}a} + \tfrac{1}{2} \right) = p_{0}^{2}\\
		&\ev{x, t} = \sqrt{2}x_{0}\Re\ev{a, t} = \frac{x_{0}}{\sqrt{2}}\cos \omega t \\
		&\ev{p, t} = \sqrt{2}p_{0}\Im\ev{a, t} = - \frac{p_{0}}{\sqrt{2}}\sin \omega t
	\end{align*}
	The uncertainties $ \Delta x(t) $ and $ \Delta p $ are then
	\begin{align*}
		& \big[\Delta x(t)\big]^{2} = \ev{x^{2}, t} - \ev{x}^{2} = x_{0}^{2} - \frac{x_{0}^{2}}{2}\cos^{2} \omega t = x_{0}^{2}\left(1 - \frac{\cos^{2}\omega t}{2}\right)\\
		& \big[\Delta p(t)\big]^{2} = \ev{p^{2}, t} - \ev{p}^{2} = p_{0}^{2} - \frac{p_{0}^{2}}{2}\sin^{2} \omega t = p_{0}^{2}\left(1 - \frac{\sin^{2}\omega t}{2}\right)
	\end{align*}
	The product in uncertainties is
	\begin{align*}
		\Delta x(t) \Delta p(t) &= x_{0}p_{0} \sqrt{\left(1 - \frac{\cos^{2}\omega t}{2}\right)\left(1 - \frac{\sin^{2}\omega t}{2}\right)}\\
		&=\hbar \sqrt{\frac{1}{2} + \frac{1}{4}\sin^{2}\omega t \cos^{2}\omega t  }  = \hbar \sqrt{\frac{1}{2} +  \frac{1}{16}\sin^{2}2\omega t}
	\end{align*}
	In other words, the product of uncertainties oscillates in time between a minimum value of $ \frac{\hbar}{\sqrt{2}} $ to a maximum value of $ \frac{3\hbar}{4} $. 

\end{itemize}
\textbf{Take Two, Using the Heisenberg Approach}
\begin{itemize}
	\item We start with an expression for $ \ev{x, t} $, using the Heisenberg approach
	\begin{equation*}
		\ev{x, t} = \sqrt{2}x_{0} \Re \bra{\psi, 0}a(t) \ket{\psi, 0}
	\end{equation*}
	We start with the equation for the operator $ a(t) $: 
	\begin{equation*}
		\dot{a}(t) = \frac{i}{\hbar}[H, a](t)
	\end{equation*}
	Making use of $ \big[a, a^{\dagger}\big] = 1 $ and $ \big[ a^{\dagger}, a\big] = -1 $, the commutator $ [H, a] $ is
	\begin{equation*}
		[H, a] = [\hbar \omega (a^{\dagger}a + \tfrac{1}{2}), a] = \hbar \omega \big[a^{\dagger}a, a\big] = \hbar \omega \left([a^{\dagger}, a]a + a^{\dagger}[a, a]\right) = -\hbar \omega a
	\end{equation*}
	and the equation for $ a(t) $ reads
	\begin{align*}
		&\dot{a}(t) = -i \omega a(t) \implies \frac{\diff a}{a} = -i\omega \diff t \implies \ln a(t) = -i\omega t + C\\
		&a(t) = De^{-i\omega t}
	\end{align*}
	We find the constant $ D $ with the initial condition $ a(0) = a $, giving the final solution 
	\begin{equation*}
		a(t) = ae^{-i\omega t}
	\end{equation*}
	Inserting $ a(t) $ into the expression $ \ev{x, t} = \sqrt{2}x_{0} \Re \bra{\psi, 0}a(t) \ket{\psi, 0} $ gives
	\begin{equation*}
		\ev{x, t} = \sqrt{2}x_{0} \Re \bra{\psi, 0}ae^{-i\omega t} \ket{\psi, 0} = \sqrt{2}x_{0} \Re \left[e^{-i\omega t} \bra{\psi, 0}a \ket{\psi, 0}\right]
	\end{equation*}
	This general result holds for any initial state $ \ket{\psi, 0} $ of a particle in a harmonic potential. For our specific initial state, the expression reads
	\begin{equation*}
		\bra{\psi, 0}a \ket{\psi, 0} = 	\bra{\psi, 0} \left(\frac{1}{\sqrt{2}}a \ket{0} + \frac{1}{\sqrt{2}}a\ket{1} \right) \ket{\psi, 0}  =	\bra{\psi, 0} \frac{1}{\sqrt{2}} \ket{0} = \frac{1}{2}
	\end{equation*}
	The result for $ \ev{x, t} $ then reads
	\begin{align*}
		\ev{x, t} &= \sqrt{2}x_{0} \Re \left[e^{-i\omega t} \bra{\psi, 0}a \ket{\psi, 0}\right] = \sqrt{2}x_{0} \Re \left[\frac{1}{2} e^{-i\omega t}\right]\\
		&=\frac{x_{0}}{\sqrt{2}}\cos \omega t
	\end{align*}
	which matches the result from the earlier \Schro approach. 
\end{itemize}

\subsection{Sixth Exercise Set}

\subsubsection{Theory: Coherent States of the Quantum Harmonic Oscillator}
\begin{itemize}
	\item The annihilation operator's eigenstates are called \textit{coherent states} of the quantum harmonic oscillator's Hamiltonian. Coherent states  $ \ket{\psi} $ of a QHO satisfy the eigenvalue equation
	\begin{equation*}
		a \ket{\psi} = \lambda \ket{\psi}, \qquad \lambda \in \mathbb{C}
	\end{equation*}
	Recall that $ a $ is not Hermitian, so the eigenvalue $ \lambda $ is in general complex. By convention, we make the potentially complex nature of $ \lambda $ explicit by writing 
	\begin{equation*}
		a \ket{z} = z \ket{z}
	\end{equation*}
	Where $ \ket{z} $ is just a new notation for the coherent eigenstate and $ z $ is the corresponding eigenvalue.
	
	\item The next step is to find the coherent states' time evolution $ \ket{z, t} $. One way to do this is to expand the coherent state in the QHO eigenstate basis $ \ket{n} $ in the form
	\begin{equation*}
		\ket{z} = \sum_{n} c_{n} \ket{n}
	\end{equation*}
	Inserting this expression for $ \ket{z} $ in to the eigenvalue equation $ a \ket{z} = z \ket{z} $ gives
	\begin{equation*}
		a \ket{z} = z \ket{z} \implies  \sum_{n} c_{n} a \ket{n} = \sum_{n} c_{n} z \ket{n}
	\end{equation*}
	Substituting in the annihilation operator's action  $ a \ket{n} = \sqrt{n}\ket{n-1} $ on the QHO eigenstates $ \ket{n} $ leads to
	\begin{equation*}
		 \sum_{n=1}^{\infty} c_{n} \sqrt{n} \ket{n - 1} =  \sum_{n=0}^{\infty} c_{n} z \ket{n}
	\end{equation*}
	Note that $ n $ starts at $ 1 $ in the left sum because the annihilation operator eliminates the ground state $ \ket{0} $. Keeping in mind the orthogonality of the eigenstates with different $ n $, the above equality only holds if the coefficients of each $ \ket{n} $ term in the left and right sums are equal, i.e.
	\begin{equation*}
		c_{n+1} \sqrt{n+1} = c_{n}z \implies c_{n+1} = \frac{z}{\sqrt{n+1}}c_{n}
	\end{equation*}
	This is a recursive relation between the coefficients $ c_{n} $ of the eigenstate expansion of the coherent states. We can recognize the general form from the pattern in the first few terms:
	\begin{align*}
		n &= 0 \implies c_{1} = c_{0}z\\
		n &= 1 \implies c_{2} = c_{1}\frac{z}{\sqrt{2}} = c_{0}\frac{z^{2}}{\sqrt{1 \cdot 2}}\\[-4mm]
		&{}\ \, \vdots\\[-4mm]
		c_{n} &= \frac{z^{n}}{\sqrt{n!}}c_{0}
	\end{align*}
	As long as we know $ c_{0} $, we can find all $ c_{n} $ with the above expression. Returning to the expansion of the coherent $ \ket{z} $, we have
	\begin{equation*}
		\ket{z} = \sum_{n}c_{n} \ket{n} = c_{0} \sum_{n} \frac{z^{n}}{\sqrt{n!}}\ket{n}
	\end{equation*}
	
	\item We find $ c_{0} $ by requiring the coherent states are normalized:
	\begin{equation*}
		1 \equiv \braket{z}{z} = \left(c_{0}^{*} \sum_{n} \frac{z^{*^{n}}}{\sqrt{n!}}\bra{n}\right)\left(c_{0} \sum_{m} \frac{z^{m}}{\sqrt{m!}}\ket{m}\right)
	\end{equation*}
	We only have to evaluate one sum, since orthogonality of the QHO eigenstates means $ \braket{n}{m} = \delta_{nm} $. We then have
	\begin{equation*}
		1 \equiv \braket{z}{z} = \abs{c_{0}}^{2} \sum_{n}\frac{z^{*^{n}}z^{n}}{n!} = \abs{c_{0}}^{2}\sum_{n}\frac{\abs{z}^{2n}}{n!} = \abs{c_{0}}^{2}e^{\abs{z}^{2}} \equiv 1
	\end{equation*}
	Solving the last equality for $ c_{0} $  gives $ c_{0} = e^{-\frac{\abs{z}^{2}}{2}} $. We now have everything we need for the eigenfunction expansion of the coherent states. Putting the pieces together gives
	\begin{equation*}
		\ket{z} =  \sum_{n}c_{n} \ket{n} = c_{0} \sum_{n} \frac{z^{n}}{\sqrt{n!}}\ket{n} = e^{-\frac{\abs{z}^{2}}{2}} \sum_{n}\frac{z^{n}}{\sqrt{n!}} \ket{n}
	\end{equation*}
	
	\item We now consider another way to write the coherent states $ \ket{z} $ using creation operator's action on the QHO eigenstates:
	\begin{align*}
		a^{\dagger} \ket{0} &= \ket{1} \implies \ket{1} = a^{\dagger}\ket{0}\\
		a^{\dagger \ket{1}} &= \sqrt{2}\ket{2} \implies \ket{2} = \frac{a^{\dagger}\ket{1}}{\sqrt{2}} = \frac{\big(a^{\dagger}\big)^{2}}{\sqrt{1 \cdot 2}} \ket{0}\\[-4mm]
		&\ \, \vdots \\[-4mm]
		\ket{n} &= \frac{\big(a^{\dagger}\big)^{n}}{\sqrt{n!}} \ket{0}
	\end{align*} 
	Substituting in the expression for the QHO eigenstate $ \ket{n} $ into the expansion of the coherent states $ \ket{z} $ gives
	\begin{equation*}
		\ket{z} = \sum_{n}c_{n}\ket{n} = \sum_{n}\frac{z^{n}c_{0}}{\sqrt{n!}} \frac{\big(a^{\dagger}\big)^{n}}{\sqrt{n!}} \ket{0} = e^{-\frac{\abs{z}^{2}}{2}} \sum_{n} \frac{z^{n}\big(a^{\dagger}\big)^{n}}{n!} \ket{0} =  e^{-\frac{\abs{z}^{2}}{2}}  e^{za^{\dagger}} \ket{0}
	\end{equation*}
	In other words, the coherent states $ \ket{z} $ and ground state $ \ket{0} $ are related by the exponential operator $ e^{za^{\dagger}} $ via
	\begin{equation*}
		\ket{z} =  e^{-\frac{\abs{z}^{2}}{2}}  e^{za^{\dagger}} \ket{0}
	\end{equation*}
	
	\item Next, we will find the time evolution $ \ket{z, t} $ of the coherent states. This is
	\begin{equation*}
		\ket{z, t} = e^{-i\frac{E_{n}}{\hbar}t} \ket{z} = e^{-\frac{\abs{z}^{2}}{2}} \sum_{n}\frac{z^{n}}{\sqrt{n!}} \left(e^{-i\omega (n + \frac{1}{2})t}\right) \ket{n} 
	\end{equation*}
	where we have substituted in the QHO's energy eigenvalues $ E_{n} = \hbar\omega \big(n + \frac{1}{2}\big) $. Some rearranging of $ \ket{z, t} $ leads to
	\begin{equation*}
		\ket{z, t} = e^{-i\frac{\omega}{2}t}e^{-\frac{\abs{z}^{2}}{2}}\sum_{n}\frac{z^{n}e^{-i\omega n t}}{\sqrt{n!}}\ket{n} = e^{-i\frac{\omega}{2}t}e^{-\frac{\abs{z}^{2}}{2}} \sum_{n} \frac{(ze^{-i\omega t})^{n}}{\sqrt{n!}} \ket{n}
	\end{equation*}
	Next, a slight trick. Using $ \abs{ze^{-i\omega t}} = \abs{z}\abs{e^{-i\omega t}} = \abs{z}$, we re-write the coefficient $ e^{-\frac{\abs{z}^{2}}{2}} $ to get
	\begin{equation*}
		\ket{z, t} =  e^{-i\frac{\omega}{2}t}e^{-\frac{\abs{ze^{-i\omega t}}^{2}}{2}} \sum_{n} \frac{(ze^{-i\omega t})^{n}}{\sqrt{n!}} \ket{n}
	\end{equation*}
	Except for the factor $ e^{-i\frac{\omega}{2}t} $, this expression has the same form as the earlier result
	\begin{equation*}
		\ket{z} = e^{-\frac{\abs{z}^{2}}{2}} \sum_{n}\frac{z^{n}}{\sqrt{n!}} \ket{n}
	\end{equation*}
	with $ z $ replaced by $ z e^{-i\omega t} $. We use this relationship to write
	\begin{equation*}
		\ket{z, t} = e^{-i \frac{\omega}{2}t} \ket{z e^{-i\omega t}}
	\end{equation*}
	
	\item Finally, an approach to finding the time evolution $ \ket{z, t} $ in the Heisenberg picture. We write $ \ket{z, t} $ in terms of the time evolution operator and use the earlier relationship between $ \ket{z} $ and $ \ket{0} $ via the creation operator $ a^{\dagger} $ to get
	\begin{equation*}
		\ket{z, t} = \tev \ket{z} = \tev\left( e^{-\frac{\abs{z}^{2}}{2}}e^{za^{\dagger}}\ket{0}\right) = e^{-\frac{\abs{z}^{2}}{2}}\tev e^{za^{\dagger}}\tevp \tev \ket{0}
	\end{equation*}
	The three terms $ \tev e^{za^{\dagger}} \tevp $, with the exponent written as a Taylor series, are
	\begin{align*}
		\tev e^{za^{\dagger}} \tevp &= \tev \left(\sum_{n}\frac{(za^{\dagger})^{n}}{n!}\right)\tevp = \sum_{n} \frac{z^{n}}{n!}\tev (a^{\dagger})^{n} \tevp\\
		&= \sum_{n}\frac{z^{n}}{n!}\left[\tev a^{\dagger}\tevp \tev a^{\dagger}\tevp \cdots \tev a^{\dagger}\tevp\right]\\
		&=\sum_{n}\frac{z^{n}}{n!}\left(\tev a^{\dagger}\tevp\right)^{n}
	\end{align*}
	Recall that in the Heisenberg approach the time evolution of an operator $ \mathcal{O} $ reads $  \mathcal{O}(t) = \tevp  \mathcal{O} \tev$. Applied to our above expression (note the reversed roles of the time evolution operators), we see
	\begin{equation*}
		\tev e^{za^{\dagger}} \tevp = \sum_{n}\frac{z^{n}}{n!}\big(a^{\dagger}(-t)\big)^{n} = e^{za^{\dagger}(-t)}
	\end{equation*}
	The initial expression for $ \ket{z, t} $ in the Heisenberg picture then simplifies to
	\begin{equation*}
		\ket{z, t} = e^{-\frac{\abs{z}^{2}}{2}}  e^{za^{\dagger}(-t)} \tev \ket{0} = e^{-\frac{\abs{z}^{2}}{2}}  e^{za^{\dagger}(-t)} e^{-i\frac{\omega}{2}t}\ket{0}
	\end{equation*}
	
	\item Next, we find an expression for $ a^{\dagger}(-t) $. In the Heisenberg approach, this is
	\begin{equation*}
		a^{\dagger}(-t) = \tev a^{\dagger} \tevp = \left[\tev a \tevp\right]^{\dagger} = \big[a(-t)\big]^{\dagger}
	\end{equation*}
	Using the relationship $ a(t) = ae^{-i\omega t} $ from the previous exercise set, we finally have
	\begin{equation*}
		a^{\dagger}(-t) = \big[a(-t)\big]^{\dagger} = \left[ae^{i\omega t}\right]^{\dagger} = a^{\dagger}e^{-i\omega t}
	\end{equation*}
	Substituting the expression for $  a^{\dagger}(-t)  $ into the time evolution $ \ket{z, t} $ to get
	\begin{equation*}
		\ket{z, t} = e^{-\frac{\abs{z}^{2}}{2}}  e^{ze^{-i\omega t}a^{\dagger}} e^{-i\frac{\omega}{2}t}\ket{0} =  e^{-i\frac{\omega}{2}t} e^{-\frac{\abs{ze^{-i\omega t}}^{2}}{2}} e^{ze^{-i\omega t}a^{\dagger}}\ket{0}
	\end{equation*}
	Recall that, like before in the \Schro approach, the equality $ \abs{z}^{2} = \abs{ze^{-i\omega t}}^{2}$ allows us to introduce the phase factor $ e^{-i\omega t} $ into the exponent of $ e^{-\frac{\abs{z}^{2}}{2}} $. Note the similarity between this last result for $ \ket{z, t} $ to the initial expression 
	\begin{equation*}
		\ket{z, t} = \tev e^{-\frac{\abs{z}^{2}}{2}}e^{za^{\dagger}}\ket{0}
	\end{equation*}
	Aside from the factor $ e^{-i\frac{\omega}{2}t} $, the expressions are the same, just with $ z $ shifted to $ ze^{-i\omega t} $. This allows us to write
	\begin{equation*}
		\ket{z, t} =  e^{-i\frac{\omega}{2}t} e^{-\frac{\abs{ze^{-i\omega t}}^{2}}{2}} e^{ze^{-i\omega t}a^{\dagger}}\ket{0} = e^{-i\frac{\omega}{2}t}\ket{ze^{-i\omega t}}
	\end{equation*}
	in agreement with the earlier result using the \Schro approach. 
	
	\item Next, we want to get a better sense for the behavior of the wave function $ \ket{z, t} $. From the last exercise set, we know the following expressions for any state of quantum harmonic oscillator:
	\begin{align*}
		&\ev{x} = \sqrt{2}x_{0} \Re \ev{a} && \ev{p} = \sqrt{2} p_{0} \Im \ev{a}\\
		&\ev{x^{2}} = x_{0}^{2}\big(\evb{a^{\dagger}a} + \Re \ev{a^{2}} \tfrac{1}{2}\big) && \ev{p^{2}} = p_{0}^{2}\big(\evb{a^{\dagger}a} - \Re \ev{a^{2}} \tfrac{1}{2}\big)
	\end{align*}
	Next, using the eigenvalue equation $ a \ket{z} = z \ket{z} $ for coherent states, we have
	\begin{equation*}
		\bra{z}(a^{\dagger})^{n}a^{m}\ket{z} = \braket{a^{n}z}{a^{m}z} = \braket{z^{n}z}{z^{m}z} = z^{*^{n}}z^{m}
	\end{equation*}
	We will use this expression to evaluate the expectation values of $ x $ and $ p $ above. Note the difference between $ z $ as an eigenvalue and $ \ket{z} $ as a coherent state.
	
	\item Next, using the just-derived identity $ \bra{z}(a^{\dagger})^{n}a^{m}\ket{z} = z^{*^{n}}z^{m} $, the expectation value $ \ev{a} $ is
	\begin{equation*}
		\ev{a} = \ev{1\cdot a} = \ev{(a^{*})^{0}a} = z^{*^{0}}z^{1} = 1 \cdot z^{1} = z
	\end{equation*}
	Using $ \ev{a} = z $, the expectation values of $ x $ and $ p $ are
	\begin{equation*}
		\ev{x} = \sqrt{2} x_{0}\Re z \eqtext{and} \ev{p} = \sqrt{2}p_{0}\Im z
	\end{equation*}
	To find $ \ev{x^{2}} $ and $ \ev{p^{2}} $, we first have to find $ \ev{a^{\dagger}a} $ and $ \ev{a^{2}} $. These are
	\begin{equation*}
		\evb{a^{\dagger}a} = \abs{z}^{2} \eqtext{and} \ev{a^{2}} = z^{2}
	\end{equation*}
	$ \ev{x^{2}} $ and $ \ev{p^{2}} $ are then
	\begin{equation*}
		\ev{x^{2}} = x_{0}^{2} \left(\abs{z}^{2} + \Re z^{2} + \tfrac{1}{2}\right) \eqtext{and} \ev{p^{2}} = p_{0}^{2}\left(\abs{z}^{2} - \Re z^{2} + \tfrac{1}{2}\right)
	\end{equation*}
	
	\item Next, using the  general complex number identity $ \Re z^{2} = \frac{z^{2}+z^{*^{2}}}{2}  $, we write
	\begin{equation*}
		\abs{z}^{2} + \Re z^{2} = \abs{z}^{2} + \frac{z^{2}+z^{*^{2}}}{2} = \frac{1}{2}\big(z + z^{*}\big)^{2} = \frac{1}{2}(2\Re z)^{2} = 2 \Re^{2}z
	\end{equation*}
	which, substituted into $ \ev{x^{2}} $, gives
	\begin{equation*}
		\ev{x^{2}} = x_{0}^{2} \left(\abs{z}^{2} + \Re z^{2} + \tfrac{1}{2}\right) = x_{0}^{2}\left(2 \Re^{2}z + \tfrac{1}{2}\right)
	\end{equation*}
	a similar procedure for $ \ev{p^{2}} $ gives
	\begin{equation*}
		\ev{p^{2}} = p_{0}^{2}\left[-\tfrac{1}{2}\big(z-z^{*}\big) + \tfrac{1}{2}\right] = p_{0}^{2}\left(2 \Im^{2}z + \tfrac{1}{2}\right)
	\end{equation*}
	
	\item Next, the uncertainties $ \Delta x $ and $ \Delta p $ are
	\begin{align*}
		&\big(\Delta x\big)^{2} = \ev{x^{2}} - \ev{x}^{2} = x_{0}^{2}\left(2 \Re^{2}z + \tfrac{1}{2}\right) - \left(\sqrt{2}x_{0}\Re z\right)^{2} = \frac{x_{0}^{2}}{2}\\
		&\big(\Delta p\big)^{2} = \ev{p^{2}} - \ev{p}^{2} = p_{0}^{2}\left(\tfrac{1}{2} + 2 \Im^{2}z\right) - \left(\sqrt{2}p_{0}\Im z\right)^{2} = \frac{p_{0}^{2}}{2}
	\end{align*}
	The product of uncertainties, recalling the definition $ p_{0} = \frac{\hbar}{x_{0}} $, is 
	\begin{equation*}
		\Delta x \Delta p = \sqrt{\frac{x_{0}^{2}}{2}\frac{p_{0}^{2}}{2}} = \frac{x_{0}p_{0}}{2} = \frac{\hbar}{2}
	\end{equation*}
	Note that the product of uncertainties takes the minimum possible value $ \frac{\hbar}{2} $, meaning a coherent state $ \ket{z} $ of the QHO must be a Gaussian wave packet. 
	
	\item Recall the general form of a Gaussian wave packet is
	\begin{equation*}
		\psi(x) = \frac{1}{\sqrt[4]{2\pi\sigma^{2}}}\exp(-\frac{(x-\ev{x})^{2}}{4\sigma^{2}})e^{i \frac{\ev{p}}{\hbar}x}
	\end{equation*}
	For the coherent state $ \ket{z} $, substituting in the values of $ \ev{x} $, $ \ev{p} $ and $ \sigma^{2} \equiv \ev{x^{2}} $, the Gaussian wave packet reads
	\begin{equation*}
		\psi_{z}(x) = \frac{1}{\sqrt[4]{\pi x_{0}^{2}}}\exp\left[-\frac{\left(x-\sqrt{2}x_{0}\Re z\right)^{2}}{2x_{0}^{2}}\right]e^{i \frac{\sqrt{2}p_{0}\Im z}{\hbar}x}
	\end{equation*}
	
	\item Finally, we will examine two more properties of the coherent states of a QHO: the expectation values of the Hamiltonian $ H $. First, recall the Hamiltonian can be written in terms of $ a $ and $ a^{\dagger} $ as
	\begin{equation*}
		H = \hbar \omega\left(a^{\dagger}a + \tfrac{1}{2}\right)
	\end{equation*}
	We evaluate this with the help of the earlier identity $ 		\bra{z}(a^{\dagger})^{n}a^{m}\ket{z} = z^{*^{n}}z^{m} $. Applied to $ a^{\dagger}a $, we have
	\begin{equation*}
		\ev{H} = \frac{\hbar \omega}{2} + \hbar \omega \evb{a^{\dagger}a} = \frac{\hbar \omega}{2} + \hbar \omega z^{*}z = \frac{\hbar \omega}{2} + \hbar \omega \abs{z}^{2}
	\end{equation*}
	For the expectation value $ \ev{H^{2}} $ we first write $ H $ in terms of $ a  $ and $ a^{\dagger} $: 
	\begin{equation*}
		H^{2} = \hbar^{2} \omega^{2}\left(a^{\dagger}aa^{\dagger}a + a^{\dagger}a + \tfrac{1}{4}\right)
	\end{equation*}
	To simplify $ a^{\dagger}aa^{\dagger}a $ we use the commutator identity
	\begin{equation*}
		\big[a^{\dagger}, a\big] = -1 \implies aa^{\dagger} = 1 + a^{\dagger}a
	\end{equation*}
	Substituting $ aa^{\dagger} = 1 + a^{\dagger}a $  into $ H^{2} $ and an intermediate step of algebra gives
	\begin{equation*}
		H^{2} = \hbar^{2} \omega^{2}\left(a^{\dagger^{2}}a^{2} + 2a^{\dagger}a + \tfrac{1}{4}\right)
	\end{equation*}
	We again use the earlier identity $ 		\bra{z}(a^{\dagger})^{n}a^{m}\ket{z} = z^{*^{n}}z^{m} $ to get
	\begin{equation*}
		\ev{H^{2}} = \hbar^{2} \omega^{2} \left(z^{*^{2}}z^{2} + 2z^{*}z + \tfrac{1}{4}\right) = \hbar^{2} \omega^{2} \left(\abs{z}^{4} + 2\abs{z}^{2} + \tfrac{1}{4}\right)
	\end{equation*}
	 energy uncertainty is
	\begin{align*}
		\big(\Delta H\big)^{2} &= \ev{H^{2}} - \ev{H}^{2} = \hbar^{2} \omega^{2} \left(\abs{z}^{4} + 2\abs{z}^{2} + \tfrac{1}{4}\right) - \left(\frac{\hbar \omega}{2} + \hbar \omega \abs{z}^{2}\right)^{2}\\
		&= \hbar^{2}\omega^{2}\abs{z}^{2} \implies \Delta H = \hbar \omega \abs{z}
	\end{align*}
	
	\item Next, note the ratio
	\begin{equation*}
		\frac{\Delta H}{\ev{H}} = \frac{\hbar \omega \abs{z}}{\hbar \omega \big(\abs{z}^{2} + \tfrac{1}{2}\big)} \approx \frac{1}{\abs{z}}, \quad \abs{z} \gg 1 \quad \implies \quad \lim_{\abs{z} \to \infty} \frac{\Delta H}{\ev{H}} = 0
	\end{equation*}
	In other words, the relative uncertainty in energy $ \frac{\Delta H}{\ev{H}} $ approaches zero for large $ \abs{z} $. 
	
	We want a better understanding of what  $ \abs{z} \gg 1 $ means. To do this, we first examine the earlier expressions for a QHO coherent state:
	\begin{equation*}
		\ev{x} = \sqrt{2}x_{0}\Re z \eqtext{and} \ev{x, t} = \sqrt{2}x_{0}\Re \left\{ze^{-i\omega t}\right\}
	\end{equation*}
	If we write the complex number $ z $ in the polar form $ z = \abs{z}e^{i\delta} $, $ \ev{x, t}  $ becomes
	\begin{equation*}
		\ev{x, t}  =  \sqrt{2}x_{0}\Re \left\{ze^{i\delta -i\omega t}\right\} = \sqrt{2}x_{0}\abs{z}\cos(\omega t - \delta  )
	\end{equation*}
	In other words, large $ \abs{z} $ means a large amplitude of oscillation in the time-dependent expectation value $ \ev{x, t} $. 
	
\end{itemize}

\subsubsection{Harmonic Oscillator in an Electric Field}
\textit{Consider a particle of mass $ m $ and charge $ q $ at the equilibrium position $ x_{0} $ of a spring with spring constant $ k $ constrained to oscillate along the $ x $ axis. At time $ t = 0 $, we turn on an external electric field $ \mathcal{E} $ in the positive $ x $ direction. Solve for the particle's motion using quantum mechanics. }

\begin{itemize}
	\item First, we find the classical solution with Newton's law to get a feel for the solution. Newton's law reads:
	\begin{equation*}
		m\ddot{x} = -k x + q \mathcal{E}
	\end{equation*}
	Turning the field exerts a force on the particle in the $ x $ direction, moving the equilibrium position to $ \tilde{x}_{0} = x_{0} + x_{1} > x_{0} $. The particle starts at the far left amplitude $ x_{0} $ and oscillates about the new equilibrium position $ \tilde{x}_{0} $ with amplitude $ x_{1} $. 
	
	Placing the origin at $ x_{0} \equiv 0 $, the initial conditions are $ x(0) = 0 $ and $ \dot{x}(0) = 0 $. The solution is
	\begin{equation*}
		x(t) = x_{1}(1 - \cos \omega t) \eqtext{where} \omega = \sqrt{\frac{k}{m}}, \quad x_{1} = \frac{q\mathcal{E}}{k}
	\end{equation*}
	
	\item Next, the quantum mechanical picture. The particle's Hamiltonian is
	\begin{equation*}
	H(t) = 
		\begin{cases}
			\frac{p^{2}}{2m} + \frac{1}{2}kx^{2} & t < 0\\
			\frac{p^{2}}{2m} + \frac{1}{2}kx^{2} - q\mathcal{E}x & t > 0
		\end{cases}
	\end{equation*}
	Note that turning on the field adds the potential energy term $ - q\mathcal{E}x  $ to the initial Hamiltonian. 
	
	\textit{Notation:} all quantities for $ t > 0 $, after the field is turned on, will be written with a tilde. 
	
	\item In the classical picture, the particle takes the initial position $ x(0) = 0 $. This doesn't carry over in quantum mechanics---specifying an exact position violates the uncertainty principle. Instead, we place the particle in the harmonic oscillator's ground state: $ \ket{\psi, 0} = \ket{0} $ where $ H\ket{0} = \frac{1}{2}\hbar \omega \ket{0} $. Our goal will be to find the time-dependent wave function $ \ket{\psi, t} $ and then compute the position expectation value $ \ev{x, t} $. 
	
	\item Let's begin! First, we expand the electric field Hamiltonian to a perfect square
	\begin{equation*}
		\tilde{H} = \frac{p^{2}}{2m} + \frac{k}{2}\left(x - \frac{e\mathcal{E}}{k}\right)^{2} - \frac{1}{2}k\left(\frac{q\mathcal{E}}{k}\right)^{2} = \frac{p^{2}}{2m} + \frac{k}{2}\left(x - x_{1}\right)^{2} - \frac{1}{2}kx_{1}^{2}
	\end{equation*}
	Where we have substituted in the amplitude $ x_{1} = \frac{q\mathcal{E}}{k} $ from the classical solution. Next, we denote the post-field potential
	\begin{equation*}
		\tilde{V}(x) = \frac{k}{2}\left(x - x_{1}\right)^{2} - \frac{1}{2}kx_{1}^{2}
	\end{equation*}
	Note that while the pre-field potential $ V(x) = \frac{1}{2}kx^{2} $ has its minimum at $ (0, 0) $, the post-field potential $ \tilde{V}(x) $'s minimum is shifted to $ \big(x_{1}, - \frac{1}{2}kx_{1}^{2}\big) $. With this shift of the equilibrium position in mind, we introduce new coordinates
	\begin{equation*}
		\tilde{x} = x - x_{1} \eqtext{and} \tilde{p} = - i\hbar
 		\dv{\tilde{x}} = -i \hbar \dv{x} = p
 	\end{equation*}
 	The Hamiltonian $ \tilde{H} $ then reads
 	\begin{equation*}
 		\tilde{H} = \frac{\tilde{p}^{2}}{2m} + \frac{1}{2}k\tilde{x}^{2} - \frac{1}{2}kx_{1}^{2}
 	\end{equation*}
 	
 	\item The Hamiltonian's shifted annihilation operator is
 	\begin{equation*}
 		\tilde{a} = \frac{1}{\sqrt{2}}\left(\frac{\tilde{x}}{x_{0}} + i\frac{\tilde{p}}{p_{0}}\right) 
 	\end{equation*}
 	where $ x_{0} = \sqrt{\frac{\hbar}{m\omega}}$ and $ p_{0} = \frac{\hbar}{x_{0}} $. The difference between $ \tilde{a} $  and the unshifted $ a $ is
 	\begin{equation*}
 		\tilde{a} - a = -\frac{x_{1}}{\sqrt{2}x_{0}} \implies \tilde{a} = a -\frac{x_{1}}{\sqrt{2}x_{0}}
 	\end{equation*}
 	
 	\item Recall the annihilation operator actions on the quantum harmonic oscillator's eigenstates as $ a \ket{n} = \sqrt{n} \ket{n-1} $ and $ a \ket{0} = 0 $. In our case, the shifted annihilation operator $ \tilde{a} $ acts on our problem's initial state $ \ket{\psi, 0} = \ket{0} $ as
 	\begin{equation*}
 		\tilde{a}\ket{\psi, 0} = \left(a -\frac{x_{1}}{\sqrt{2}x_{0}}\right)\ket{0} = 0 - \frac{x_{1}}{\sqrt{2}x_{0}} \ket{0} \implies \tilde{a}\ket{\psi, 0} = - \frac{x_{1}}{\sqrt{2}x_{0}} \ket{\psi, 0}
 	\end{equation*}
 	In other words, our initial state $ \ket{\psi, 0} $ is an eigenstate of the shifted annihilation operator $ \tilde{a} $ with the eigenvalue $  - \frac{x_{1}}{\sqrt{2}x_{0}} $. This means the initial state is a coherent state of the annihilation operator $ \tilde{a} $, so we can use the results from the theory section on coherent states.
 	
 	\item From the theory section, an coherent state $ \ket{\psi, 0} $ satisfying $ a \ket{\psi, 0} = z \ket{\psi, 0} $ with eigenvalue $ z $ evolves in time as
 	\begin{equation*}
		\ket{\psi, t} = e^{-\frac{\omega}{2}t}\ket{ze^{-i\omega t}}
 	\end{equation*}
	where the eigenvalue $ z $ changes with time as $ 	z(t) = ze^{-i\omega t} $. Meanwhile, the position expectation value is
	\begin{equation*}
		\ev{x} = \sqrt{2} x_{0}\Re z
	\end{equation*}
	In our case, the time-dependent expectation value of the shifted position $ \tilde{x} $ is thus
	\begin{equation*}
		\ev{\tilde{x}, t} = \sqrt{2}x_{0}\Re z(t) = \sqrt{2}x_{0}\Re \left\{- \frac{x_{1}}{\sqrt{2}x_{0}}e^{-i\omega t}\right\} = - x_{1} \cos \omega t
	\end{equation*}
	The unshifted position is $ x = x_{1} + \tilde{x} $, which implies
	\begin{equation*}
		\ev{x, t} = x_{1} - x_{1}\cos \omega t = x_{1}(1 - \cos \omega t)
	\end{equation*}
	in agreement with the classical result $ x(t) = x_{1}(1 - \cos \omega t) $. 
\end{itemize}


\subsection{Seventh Exercise Set}

\subsubsection{Theory: Two-Dimensional Harmonic Oscillator}
\begin{itemize}
	\item We generalize the harmonic oscillator to two dimensions by introducing the vector operators
	\begin{equation*}
		\vec{r} = (x, y) \eqtext{and} \vec{p} = (p_{x}, p_{y}) = \left(-i\hbar \pdv{x}, -i \hbar \pdv{y}\right) = -i\hbar \grad
	\end{equation*}
	We write the oscillator's Hamiltonian as
	\begin{equation*}
		H = \frac{\vec{p}^{2}}{2m} + \frac{1}{2}k_{x}x^{2} + \frac{1}{2}k_{y}y^{2} = \frac{p_{x}^{2}}{2m} + \frac{1}{2}k_{x}x^{2} + \frac{p_{y}^{2}}{2m} + \frac{1}{2}k_{y}y^{2} \equiv H_{x} + H_{y}
	\end{equation*}
	In other words, we can write the two-dimensional Hamiltonian as the sum of two one-dimensional Hamiltonians corresponding to motion in the $ x $ and $ y $ directions. 
	
	\item We want to solve the stationary \Schro equation
	\begin{equation*}
		H \psi(x, y) = E\psi(x, y)
	\end{equation*} 
	The equation can be solved with separation of variables because the two-dimensional Hamiltonian can be decomposed into the sum of one-dimensional $ x $ and $ y $ Hamiltonians. We make this separation explicit by defining
	\begin{align*}
		&H_{x}\psi_{n_{x}} = E_{n_{x}}\psi_{n_{x}}(x) \eqtext{where} E_{n_{x}} = \hbar \omega_{x}\big(n_{x} + \tfrac{1}{2}\big), \quad \omega_{x} = \sqrt{\frac{k_{x}}{m}}\\
		&H_{y}\psi_{n_{y}} = E_{n_{y}}\psi_{n_{y}}(y) \eqtext{where} E_{n_{y}} = \hbar \omega_{y}\big(n_{y} + \tfrac{1}{2}\big), \quad \omega_{y} = \sqrt{\frac{k_{y}}{m}}
	\end{align*}
	for $ n_{x}, n_{y} = 0, 1, 2, \ldots $ and then writing
	\begin{equation*}
		H\psi(x,y) = E\psi(x, y) \to H\psi_{n_{x}}(x)\psi_{n_{y}}(y) = (E_{n_{x}} + E_{n_{y}})\psi_{n_{x}}(x)\psi_{n_{y}}(y)
	\end{equation*}
	
	\item In terms of the annihilation and creation operators, the Hamiltonian reads
	\begin{equation*}
		H = H_{x} + H_{y} = \hbar \omega_{x}\big(a_{x}^{\dagger}a_{x} + \tfrac{1}{2}\big) + \hbar \omega_{y}\big(a_{y}^{\dagger}a_{y} + \tfrac{1}{2}\big)
	\end{equation*}
	where the annihilation and creation operators are defined as
	\begin{align*}
		&a_{x} = \frac{1}{\sqrt{2}}\left(\frac{x}{x_{0}} + i \frac{p_{x}}{p_{0_{x}}}\right) \eqtext{where} x_{0} = \sqrt{\frac{\hbar}{m\omega_{x}}}, \quad p_{0_{x}} = \frac{\hbar}{x_{0}}\\
		&a_{y} = \frac{1}{\sqrt{2}}\left(\frac{y}{y_{0}} + i \frac{p_{y}}{p_{0_{y}}}\right) \eqtext{where} y_{0} = \sqrt{\frac{\hbar}{m\omega_{y}}}, \quad p_{0_{y}} = \frac{\hbar}{y_{0}}
	\end{align*}
	With the annihilation and creation operators defined, we write
	\begin{equation*}
		H_{x} \ket{n_{x}} = \hbar \omega_{x} \big(n_{x} + \tfrac{1}{2}\big) \ket{n_{x}} \eqtext{and} H_{y} \ket{n_{y}} = \hbar \omega_{y} \big(n_{y} + \tfrac{1}{2}\big) \ket{n_{y}}
	\end{equation*}
	And for the two-dimensional Hamiltonian we write separation of variables as
	\begin{equation*}
		H\ket{n_{x}} \ket{n_{y}} = \left[\hbar \omega_{x} \big(n_{x} + \tfrac{1}{2}\big) + \hbar \omega_{y} \big(n_{y} + \tfrac{1}{2}\big)\right] \ket{n_{x}} \ket{n_{y}}
	\end{equation*}
	A slightly shorter notation for the same expression reads
	\begin{equation*}
		H\ket{n_{x}n_{y}} = \left[\hbar \omega_{x} \big(n_{x} + \tfrac{1}{2}\big) + \hbar \omega_{y} \big(n_{y} + \tfrac{1}{2}\big)\right] \ket{n_{x}n_{y}}
	\end{equation*}
\end{itemize}	
	\textbf{A Few Special Cases}
\begin{itemize}
	\item Consider the degenerate case with $ k_{x} > 0 $ and $ k_{y} = 0 $. In this case the $ y $ Hamiltonian has only a kinetic term:
	\begin{equation*}
		H_{x} = \frac{p_{x}^{2}}{2m} + \frac{1}{2}k_{x}x^{2} \eqtext{and} H_{y} = \frac{p_{y}^{2}}{2m}
	\end{equation*}
	In this case the $ y $ Hamiltonian's eigenfunctions are simply plane waves:
	\begin{equation*}
		H_{y}e^{i\kappa_{y}y} = \frac{\hbar^{2}\kappa_{y}^{2}}{2m}e^{i\kappa_{y}y} \eqtext{or} H_{y}\ket{\kappa_{y}} = \frac{\hbar^{2}\kappa_{y}^{2}}{2m}\ket{\kappa_{y}}
	\end{equation*}
	We would then solve the eigenvalue equation
	\begin{equation*}
		H\ket{n_{x}\kappa_{y}} = \left[\hbar \omega_{2}\big(n_{x} + \tfrac{1}{2}\big) + \frac{\hbar^{2}\kappa_{y}^{2}}{2m}\right]\ket{n_{x}\kappa_{y}}
	\end{equation*}
	
	\item Next, if both spring constants are zero with $ k_{x} = k_{y} = 0 $ (i.e. a free particle in two dimensions) we have the purely kinetic Hamiltonian $ H = \frac{\vec{p}^{2}}{2m} $. Both the $ x $ and $ y $ eigenfunctions are plane waves
	\begin{equation*}
		H_{x}e^{i\kappa_{x}x} = \frac{\hbar^{2}\kappa_{x}^{2}}{2m}e^{i\kappa_{x}x} \eqtext{and} H_{y}e^{i\kappa_{y}y} = \frac{\hbar^{2}\kappa_{y}^{2}}{2m}e^{i\kappa_{y}y}
	\end{equation*}
	and we solve the equation 
	\begin{equation*}
		H\ket{\kappa_{x}\kappa_{y}} = \left[\frac{\hbar^{2}\kappa_{x}^{2}}{2m} + \frac{\hbar^{2}\kappa_{y}^{2}}{2m}\right]\ket{\kappa_{x}\kappa_{y}} \eqtext{or} H\ket{\vec{\kappa}} = \frac{\hbar^{2}\vec{\kappa}^{2}}{2m} = \ket{\vec{\kappa}}
	\end{equation*}
	where $ \vec{\kappa} = (\kappa_{x}, \kappa_{y}) $.
	
	\item Finally, we consider the case $ k_{x} = k_{y} \equiv k > 0 $ when both spring constants are equal. The potential then reads
	\begin{equation*}
		V(\vec{r}) = \frac{1}{2}k(x^{2} + y^{2}) = \frac{1}{2}kr^{2}
	\end{equation*}
	Note that the potential depends only on the distance $ r $ from the origin; such an oscillator is called \textit{isotropic}. 
	
	Because $ k_{x} = k_{y} \equiv k $ we have $ \omega_{x} = \omega_{y} \equiv \omega = \sqrt{\frac{k}{m}}$. The stationary \Schro then reads
	\begin{equation*}
		H\ket{n_{x}n_{y}} = \hbar \omega (n_{x} + n_{y} + 1)\ket{n_{x}n_{y}}
	\end{equation*}
	The system's lowest possible energy occurs for $ n_{x} = n_{y} = 0 $, where the stationary \Schro equation reads $ H\ket{00} = \hbar \omega \ket{00} $. This is the ground state, and the energy $ E_{00} = \hbar \omega $ is called the zero-point energy. 
	
	The first two excited states are
	\begin{equation*}
		H\ket{10} = \hbar \omega \ket{10} \eqtext{and} H\ket{01} = \hbar \omega \ket{01}
	\end{equation*}
	Note that the first excited states is doubly degenerate---two linearly independent eigenfunctions $ \ket{10} $ and $ \ket{01} $ have the same energy. In general, the $ n $th excited state of a 2D isotropic harmonic oscillator has degeneracy $ n +1 $. 
\end{itemize}

\textbf{Theory: The $ z $ Component of Angular Momentum}
\begin{itemize}
	\item Eigenstates $ \ket{\psi} $ of the z component of angular momentum operator $ L_{z} $ satisfy
	\begin{equation*}
		L_{z}\ket{\psi} = \lambda \ket{\psi}
	\end{equation*}
	The operator $ L_{z} $ can be written
	\begin{equation*}
		L_{z} = xp_{y} - y p_{x} = - \hbar \pdv{\phi}
	\end{equation*}
	where $ \phi $ is the azimuthal angle in the spherical coordinate system. Using the definition $ L_{z} = - \hbar \pdv{\phi} $ in spherical coordinates, the eigenvalue equation in coordinate notation reads
	\begin{equation*}
		-i\hbar \psi'(\phi) = \lambda \psi(\phi)
	\end{equation*}
	Separating variables and integrating the equation gives
	\begin{equation*}
		\ln \psi = \frac{i\lambda}{\hbar} \phi + C \implies \psi(\phi) = \tilde{C}e^{i\frac{\lambda}{\hbar}\phi}
	\end{equation*}
	To satisfy periodicity over a full rotation of $ 2\pi $, we require $ \psi(\phi + 2\pi) = \psi(\phi) $, which implies the quantization
	\begin{equation*}
		\frac{\lambda}{\hbar} = m; \qquad m \in \mathbb{Z} \implies \psi(\phi) = \tilde{C}e^{im\phi}
	\end{equation*}
	We find the integration constant $ \tilde{C} $ with the normalization condition
	\begin{equation*}
		1 \equiv \int_{0}^{2\pi}\psi^{*}(\phi)\psi(\phi)\diff \phi = 2\pi \abs{\tilde{C}}^{2} \implies \tilde{C} = \frac{1}{\sqrt{2\pi}}
	\end{equation*}
	The eigenfunctions of the angular momentum operator $ L_{z} $ are thus
	\begin{equation*}
		\psi_{m}(\phi) = \frac{1}{\sqrt{2\pi}}e^{im\phi}, \qquad m \in \mathbb{Z}
	\end{equation*}
	In Dirac notation, the eigenfunctions are written simply $ \ket{m} $, where the reference to the angular momentum operator is usually clear from context. 
	
	Using the relationship $ \lambda = h m $, the eigenvalue equation in Dirac notation reads
	\begin{equation*}
		L_{z}\ket{\psi} = m \hbar \ket{\psi}
	\end{equation*}
	
	
\end{itemize}

\subsubsection{Two-Dimensional Isotropic Harmonic Oscillator} \label{qmv:sss:2dqho}
\textit{Consider a two-dimensional isotropic harmonic oscillator. Within the subspace of energy eigenstates with energy $ E = 2\hbar \omega $, find those states that are also eigenstates of the $ z $-component of angular momentum $ L_{z} $.}
\begin{itemize}
	\item The energy $ E = 2\hbar \omega $ corresponds to the isotropic oscillator's first two excited states $ \ket{10} $ and $ \ket{01} $. These states have degeneracy two, meaning the subspace is spanned by two linearly independent states. The subspace is formed of all normalized linear combinations of $ \ket{01} $ and $ \ket{10} $, i.e. all $ \ket{\psi} $ for which
	\begin{equation*}
		\ket{\psi} = \alpha \ket{10} + \beta \ket{01}, \qquad \alpha, \beta \in \mathbb{C}, \quad \abs{\alpha}^{2} + \abs{\beta}^{2} = 1
	\end{equation*}
	The Hamiltonian acts on $ \ket{\psi} $ as
	\begin{align*}
		H \ket{\psi} &= \alpha H \ket{10} + \beta H \ket{01} = \alpha 2\hbar \omega \ket{10} + \beta 2\hbar \omega \ket{01}\\
		&=2\hbar \omega \big(\alpha \ket{10} + \beta \ket{01}\big) = 2\hbar \omega \ket{\psi}
	\end{align*}
	Evidently, $ \psi $ is an eigenfunction of $ H $ with energy eigenvalue $ 2\hbar \omega $.	We are interested in $ \psi $ that are also eigenfunctions of $ L_{z} $, which must satisfy the eigenvalue equation
	\begin{equation*}
		L_{z}\ket{\psi} = m \hbar \ket{\psi}
	\end{equation*}
	
	\item It is possible to find functions that are simultaneously eigenfunctions of two operators if the two operators commute. Applied to our problem, if we show that $ H $ and $ L_{z} $ commute, we can be sure there exist functions that are eigenfunctions of both $ H $ and $ L_{z} $. In other words, we want to show our problem is solvable by proving $ \big[H, L_{z}\big] = 0 $. We will first write the Hamiltonian in polar coordinates:
	\begin{equation*}
		H = \frac{\vec{p}^{2}}{2m} + \frac{1}{2}kr^{2} = -\frac{\hbar^{2}}{2m} \laplacian + \frac{1}{2}kr^{2} = -\frac{\hbar^{2}}{2m}\left [\frac{1}{r}\pdv{r}\left(r\pdv{r}\right) + \frac{1}{r^{2}}\pdv[2]{}{\phi}\right ] + \frac{1}{2}kr^{2}
	\end{equation*}
	Using the definition of $ L_{z} $ in polar coordinates, the commutator reads
	\begin{align*}
		\big[H, L_{z}\big] &= \left[ -\frac{\hbar^{2}}{2m}\left [\frac{1}{r}\pdv{r}\left(r\pdv{r}\right) + \frac{1}{r^{2}}\pdv[2]{}{\phi}\right ] + \frac{1}{2}kr^{2}, -i\hbar \pdv{\phi}\right]\\
		&=\left[-\frac{\hbar^{2}}{2mr^{2}}\pdv[2]{}{\phi}, -i\hbar \pdv{\phi}\right] = 0
	\end{align*}
	The entire proof rests on the commutativity of second derivatives, i.e. 
	\begin{equation*}
		\pdv{}{\phi}{r} = \pdv{}{r}{\phi} \eqtext{and} \pdv[2]{}{\phi} \pdv{\phi} =  \pdv{\phi} \pdv[2]{}{\phi}
	\end{equation*} 
	The derivatives with respect to $ \phi $ then cancel the $ r $-dependent terms in the Hamiltonian. All we did here is show that eigenfunctions solving our problem exist in the first place by showing $ H $ and $ L_{z} $ commute.
	
	\item To actually solve the problem, we will take both a heuristic and a formal approach. We start with a heuristic approach. From the introductory theory section, the eigenfunctions solving $ H \ket{10} = 2\hbar \omega \ket{10}$ and $ H \ket{01} = 2\hbar \omega \ket{01}$ can be written in the separated form
	\begin{equation*}
		\psi_{10}(x, y) = \psi_{1}(x)\psi_{0}(y) \eqtext{and} \psi_{01}(x, y) = \psi_{0}(x)\psi_{1}(y)
	\end{equation*}
%	
%	\begin{equation*}
%		H = \frac{p_{x}^{2}}{2m} \frac{1}{2}kx^{2}
%	\end{equation*}
	Next, recall the annihilation operator action on the ground state produces
	\begin{equation*}
		a \ket{0} = 0 \ket{0}
	\end{equation*}
	In other words, $ \ket{0} $ is an eigenstate of the annihilation operator (i.e. a coherent state) with eigenvalue $ z = 0 $. From the previous exercise set, we know that the eigenfunctions of coherent states are Gaussian wave packets. If $ z = 0 $, then $ \ev{x} = 0 $ and $ \ev{p} = 0 $, and the wavefunction would read
	\begin{equation*}
		\psi_{0}(x) = \frac{1}{\sqrt[4]{\pi x_{0}^{2}}}e^{-\frac{x^{2}}{2x_{0}^{2}}}
	\end{equation*}

	\item We can get an expression for the first excited state $ \ket{1} $ with the creation operator $ a^{\dagger}\ket{0} = \ket{1} $. In the coordinate representation of the operator, this reads
	\begin{align*}
		\psi_{1}(x) &= a^{\dagger}\psi_{0}(x) = \frac{1}{\sqrt{2}}\left(\frac{x}{x_{0}}-i\frac{p}{p_{0}}\right)\psi_{0}(x)  = \frac{1}{\sqrt{2}}\left(\frac{x}{x_{0}}-\frac{\hbar}{p_{0}}\dv{x}\right)\psi_{0}(x) \\
		& = \frac{1}{\sqrt{2}}\left(\frac{x}{x_{0}}-x_{0}\dv{x}\right)\psi_{0}(x)
	\end{align*}
	Applied to the Gaussian wave packet $ \psi_{0}(x) $, we have
	\begin{align*}
		\psi_{1}(x) &= \frac{1}{\sqrt{2}}\frac{x}{x_{0}}\psi_{0}(x) - \frac{x_{0}}{\sqrt{2}}\dv{x}\left[\frac{1}{\sqrt[4]{\pi x_{0}^{2}}}e^{-\frac{x^{2}}{2x_{0}^{2}}}\right] = \frac{1}{\sqrt{2}}\frac{x}{x_{0}}\psi_{0}(x) + \frac{x_{0}}{\sqrt{2}}\frac{x}{x_{0}^{2}}\psi_{0}(x)\\
		&=\frac{\sqrt{2}}{x_{0}}x\psi_{0}(x)
	\end{align*}
	We can then write the states $ \psi_{10} $ and $ \psi_{01} $ as
	\begin{align*}
		\psi_{10}(x, y) &= \psi_{1}(x)\psi_{0}(y) = \frac{\sqrt{2}}{x_{0}}x\psi_{0}(x)\psi_{0}(y) = \frac{\sqrt{2}}{x_{0}} \frac{x}{\sqrt{\pi x_{0}^{2}}}e^{-\frac{x^{2}}{2x_{0}^{2}}} e^{-\frac{y^{2}}{2x_{0}^{2}}}\\
		&=\frac{\sqrt{2}}{x_{0}}\frac{x}{\sqrt{\pi x_{0}^{2}}} e^{-\frac{r^{2}}{2x_{0}^{2}}} = \frac{\sqrt{2}r \cos \phi}{x_{0}\sqrt{\pi x_{0}^{2}}}e^{-\frac{r^{2}}{2x_{0}^{2}}}
	\end{align*}
	and, analogously, 
	\begin{equation*}
		\psi_{01}(x, y) = \psi_{0}(x)\psi_{1}(y) = \frac{\sqrt{2}r \sin \phi}{x_{0}\sqrt{\pi x_{0}^{2}}}e^{-\frac{r^{2}}{2x_{0}^{2}}}
	\end{equation*}
	\textit{We ran out of time at this point; the problem is continued in the eight exercise set.}
	
\end{itemize}

\subsection{Eight Exercise Set}

\subsubsection{Two-Dimensional Isotropic Harmonic Oscillator (continued)}
We left off in the previous exercise set having found the harmonic oscillator's states $ \psi_{10}(x,y) $ and $ \psi_{01}(x, y) $; these were
\begin{equation*}
	\psi_{10}(x, y) = \frac{\sqrt{2}r \cos \phi}{x_{0}\sqrt{\pi x_{0}^{2}}}e^{-\frac{r^{2}}{2x_{0}^{2}}} \eqtext{and} \psi_{01}(x, y) = \frac{\sqrt{2}r \sin \phi}{x_{0}\sqrt{\pi x_{0}^{2}}}e^{-\frac{r^{2}}{2x_{0}^{2}}}
\end{equation*}
These are the two linearly independent states spanning the isotropic harmonic oscillator's subspace of eigenstates with energy $ E = 2\hbar \omega $. Our next step is to find the linear combinations of $ \psi_{10} $ and $ \psi_{01} $ that are also eigenstates of the operator $ L_{z} $. 
	
\vspace{2mm}
\begin{itemize}
	\item Recall that the eigenfunctions of $ L_{z} $ are 
	\begin{equation*}
		\psi_{m}(\phi) = \frac{1}{\sqrt{2\pi}}e^{im\phi}, \qquad m \in \mathbb{Z}
	\end{equation*}
	Recall also the identities $ \cos \phi + i \sin \phi = e^{i\phi} $ and $ \cos \phi - i \sin \phi = e^{-i\phi} $. 
	
	\item Comparing these identities to the definitions of $ \psi_{10} $, $ \psi_{01} $ and $ \psi_{m}(\phi) $, we can construct the $ L_{z} $ eigenstate with $ m = 1 $ via
	\begin{equation*}
		\ket{m=1} = \frac{1}{\sqrt{2}}\big(\ket{10} + i\ket{01}\big)
	\end{equation*}
	where the $ \frac{1}{\sqrt{2}} $ term ensures the state is normalized. To confirm the state $ \ket{m=1} $ is normalized, note that
	\begin{align*}
		\braket{m=1}{m=1} &= \frac{1}{2}\big(\bra{10} - i\bra{01}\big)\big(\ket{10} + i\ket{01}\big)\\
		&= \frac{1}{2}\big(\braket{10}{10} - i \braket{01}{10} + i\braket{10}{01} + \braket{01}{01}\big)\\
		&=\frac{1}{2}\big(1 -i + i + 1\big) = 1
	\end{align*}
	Finally, we construct the state with $ m = -1 $ with
	\begin{equation*}
		\ket{m=-1} = \frac{1}{\sqrt{2}} \big(\ket{10} - i \ket{01}\big)
	\end{equation*}
	
\end{itemize}

\textbf{Formal Approach}
\begin{itemize}
	\item Consider an eigenstate $ \ket{\psi} $ that is both an eigenstate of $ H $ with $ E = 2\hbar \omega $ and an eigenstate of $ L_{z} $. This state must satisfy
	\begin{equation*}
		\ket{\psi} = \alpha \ket{10} + \beta \ket{01} \eqtext{and} L_{z}\ket{\psi} = \lambda \ket{\psi}.
	\end{equation*}
	First, we write the 2D Hamiltonian $ H $ in terms of the creation and annihilation operators:
	\begin{align*}
		H = \hbar \omega_{x}\big(a_{x}^{\dagger}a_{x} + \tfrac{1}{2}\big) + \hbar \omega_{y}\big(a_{y}^{\dagger}a_{y} + \tfrac{1}{2}\big) \equiv H_{x} + H_{y}
	\end{align*}

	\item For the isotropic oscillator with $ \omega_{x} $ = $ \omega_{y} $, this simplifies to
	\begin{equation*}
		H = \hbar \omega \big(a_{x}^{\dagger}a_{x} + a_{y}^{\dagger}a_{y} + 1\big)
	\end{equation*}
	More so, both the constants $ x_{0} $, $ y_{0} $ and $ p_{0_{x}} $, $ p_{0_{y}} $ are equal for the $ x $ and $ y $ annihilation and creation operators; we have
	\begin{equation*}
		a_{x} = \frac{1}{\sqrt{2}}\left(\frac{x}{x_{0}} + i\frac{p_{x}}{p_{0}}\right) \eqtext{and} a_{y} = \frac{1}{\sqrt{2}}\left(\frac{y}{x_{0}} + i\frac{p_{y}}{p_{0}}\right)
	\end{equation*}
	where $ x_{0} = \sqrt{\frac{\hbar}{m \omega}} $ and $ p_{0} = \frac{\hbar}{x_{0}} $. 
	
	\item The angular momentum operator is $ L_{z} = x p_{y} - y p_{x} $; in terms of the annihilation and creation operators this becomes
	\begin{align*}
		L_{z} &= \frac{x_{0}}{\sqrt{2}}\big(a_{x} + a_{x}^{\dagger}\big)\cdot \frac{p_{0}}{\sqrt{2}i}\big(a_{y} - a_{y}^{\dagger}\big) - \frac{x_{0}}{\sqrt{2}}\big(a_{y} + a_{y}^{\dagger}\big)\cdot \frac{p_{0}}{\sqrt{2}i}\big(a_{x} - a_{x}^{\dagger}\big)\\
		&=\frac{x_{0}p_{0}}{2i}\left[\big(a_{x}+a_{x}^{\dagger}\big)\big(a_{y}-a_{y}^{\dagger}\big) - \big(a_{y}+a_{y}^{\dagger}\big)\big(a_{x}-a_{x}^{\dagger}\big)\right]
	\end{align*}
	Applying $ x_{0}p_{0} = \hbar $ and multiplying out the terms in parentheses and combining like terms (recall $ \big[a_{x}, a_{y}\big] = \big[a_{x}^{\dagger}, a_{y}^{\dagger}\big] =  \big[a_{x}^{\dagger}, a_{y}\big] = 0$) simplifies the expression for $ L_{z} $  to
	\begin{equation*}
		L_{z} = \frac{\hbar}{2i}\big(2a_{x}^{\dagger}a_{y} - 2a_{y}^{\dagger}a_{x}\big) = \frac{\hbar}{i}\big(a_{x}^{\dagger}a_{y} - a_{y}^{\dagger}a_{x}\big)
	\end{equation*}
	
	\item Next, using the just-derived expression for $ L_{z} $ in terms of $ a_{x,y} $ and $ a_{x,y}^{\dagger} $, we investigate the action of $ L_{z} $ on our desired state $ \ket{\psi} $; we have
	\begin{equation*}
		L_{z}\ket{\psi} = \alpha L_{z}\ket{10} + \beta L_{z} \ket{01} =  \frac{\hbar}{i}\alpha\big(a_{x}^{\dagger}a_{y} - a_{x}a_{y}^{\dagger}\big)\ket{10} +  \frac{\hbar}{i}\beta\big(a_{x}^{\dagger}a_{y} - a_{x}a_{y}^{\dagger}\big)\ket{01}
	\end{equation*}
	Using the identities $ a\ket{0} = 0 $ and $ a\ket{1} = \ket{0} $, we see that $ a_{x}^{\dagger}a_{y} \ket{10} = 0 $---the $ a_{y} $ operator acts on the zero $ y $ component of $ \ket{10} $ to produce zero. Analogously, $ a_{x}a_{y}^{\dagger} \ket{01} = 0 $, where $ a_{x} $ acts on the zero $ x $ component $ of \ket{01} $ to produce zero. We're left with
	\begin{equation*}
		L_{z}\ket{\psi} = -\frac{\hbar}{i}\alpha a_{x}\ket{1}a_{y}^{\dagger}\ket{0} + \frac{\hbar}{i}\beta a_{x}^{\dagger}\ket{0}a_{y}\ket{1}
	\end{equation*}
	Remember $ a_{x} $ and $ a_{y} $ act only on their respective components of $ \ket{01} $ and $ \ket{10} $, which can be factored into $ \ket{0}\ket{1} $ and $ \ket{1}\ket{0} $. Finally, using the identities $ a^{\dagger}\ket{0} = \ket{1} $ and $ a^{\dagger}\ket{1} = \sqrt{2}\ket{2} $, $ L_{z}\ket{\psi} $ simplifies further to
	\begin{equation*}
		L_{z}\ket{\psi} = -\frac{\hbar}{i}\alpha\ket{0}\ket{1} + \frac{\hbar}{i}\beta \ket{1}\ket{0} = \frac{\hbar}{i}\big(-\alpha \ket{01} + \beta \ket{10}\big)
	\end{equation*}
	
	\item To be an eigenstate of $ L_{z} $, $ \ket{\psi} $ must satisfy the eigenvalue equation $ L_{z}\ket{\psi} = \lambda \ket{\psi}  $. Using our just-derived expression for $ L_{z}\ket{\psi}  $, the eigenvalue equation reads
	\begin{equation*}
		L_{z}\ket{\psi} = \lambda \ket{\psi} \implies \frac{\hbar}{i}\big(-\alpha \ket{01} + \beta \ket{10}\big) \equiv \lambda \big(\alpha \ket{10} + \beta \ket{01}\big)
	\end{equation*}
	Multiplying (scalar product on the Hilbert space) the equation from the left by $ \bra{10} $ and applying the orthonormality of $ \ket{00} $ and $ \ket{10} $ leaves
	\begin{equation*}
		\frac{\hbar}{i}\beta = \lambda \alpha,
	\end{equation*}
	while multiplying the equation from the left by $ \bra{01} $ produces
	\begin{equation*}
		-\frac{\hbar}{i}\alpha = \lambda \beta
	\end{equation*}
	In matrix form, these two equations form a simple eigenvalue problem:
	\begin{equation*}
		\begin{bmatrix}
			0 & \frac{\hbar}{i}\\
			-\frac{\hbar}{i} & 0
		\end{bmatrix}
		\begin{bmatrix}
			\alpha\\
			\beta
		\end{bmatrix}
		= \lambda
		\begin{bmatrix}
			\alpha\\
			\beta
		\end{bmatrix}
	\end{equation*}
	We solve the problem by finding the zeros of the characteristic polynomial:
	\begin{equation*}
		\det 
		\begin{bmatrix}
			-\lambda & \frac{\hbar}{i}\\
			-\frac{\hbar}{i} & -\lambda
		\end{bmatrix} \equiv 0 \implies \lambda^{2} - \hbar^{2} = 0 \implies \lambda = \pm \hbar
	\end{equation*}
	Recall $ L_{z} $'s eigenvalues are $ \lambda = m \hbar $, so we have  $ \lambda = \hbar m = \pm \hbar \implies m = \pm 1$ (we had found the same solutions $ m = \pm 1 $ in the earlier heuristic approach). 
	
	\item Substituting the $ m = 1 \implies \lambda = \hbar $ solution into the matrix equation gives
	\begin{equation*}
		\begin{bmatrix}
			-\hbar & \frac{\hbar}{i}\\
			-\frac{\hbar}{i} & -\hbar
		\end{bmatrix}
		\begin{bmatrix}
			\alpha\\
			\beta
		\end{bmatrix}
		= 0 \implies \beta = i \alpha
	\end{equation*}
	Substituting the $ m = 1 $ result $ \beta = i \alpha $ into the general linear combination $ \ket{\psi} = \alpha \ket{10} + \beta \ket{01} $ produces
	\begin{equation*}
		\ket{m=1} = \alpha \ket{10} + (i\alpha)\ket{01} = \alpha \big(\ket{10} + i \ket{01}\big)
	\end{equation*}
	The normalization condition requires $ \alpha = \frac{1}{\sqrt{2}} $, which gives
	\begin{equation*}
		\ket{m=1} = \frac{1}{\sqrt{2}}\big(\ket{10} + i \ket{01}\big)
	\end{equation*}
	which agrees with the $ m = 1 $ solution in the heuristic approach.
	
	\item Substituting the $ m = - 1 \implies \lambda = -\hbar $ solution into the matrix equation gives
	\begin{equation*}
		\begin{bmatrix}
			+\hbar & \frac{\hbar}{i}\\
			-\frac{\hbar}{i} & +\hbar
		\end{bmatrix}
		\begin{bmatrix}
			\alpha\\
			\beta
		\end{bmatrix}
		= 0 \implies \beta = - i \alpha
	\end{equation*}
	Analogously to the $ m = 1 $ case, substituting the $ m = -1 $ result $ \beta = -i \alpha $ into the general linear combination $ \ket{\psi} = \alpha \ket{10} + \beta \ket{01} $ produces
	\begin{equation*}
		\ket{m=-1} = \alpha \ket{10} + (-i\alpha)\ket{01} = \alpha \big(\ket{10} - i \ket{01}\big)
	\end{equation*}
	The normalization condition requires $ \alpha = \frac{1}{\sqrt{2}} $, which gives
	\begin{equation*}
		\ket{m=-1} = \frac{1}{\sqrt{2}}\big(\ket{10} - i \ket{01}\big)
	\end{equation*}
	which agrees with the $ m = - 1 $ solution in the heuristic approach.
	
	\item The final solution for the eigenstates of $ H $ with energy $ 2\hbar \omega $ that are also eigenstates of $ L_{z} $ is thus
	\begin{align*}
		&\ket{m=1} = \frac{1}{\sqrt{2}}\big(\ket{10} + i \ket{01}\big)\\
		&\ket{m=-1} = \frac{1}{\sqrt{2}}\big(\ket{10} - i \ket{01}\big)
	\end{align*}
\end{itemize}
\textbf{Why This Result is Useful}\\
\begin{itemize}
	\item Next, we ask why we would be interested in finding states that are simultaneously eigenstates of two operators (e.g. both $ H $ and $ L_{z} $). As an example, consider a 2D isotropic harmonic oscillator in an external magnetic field $ \vec{B} $. Its Hamiltonian is
	\begin{equation*}
		H = H_{0} - \vec{\mu} \cdot \vec{B}
	\end{equation*}
	where $ H_{0} $ is the Hamiltonian of a 2D isotropic harmonic oscillator without a magnetic field and $ \vec{\mu} $ is the particle's magnetic moment. The magnetic moment is proportional to the angular momentum, i.e. $ \vec{\mu} = \gamma \vec{L} $, where $ \gamma $ is a constant proportionality factor.
	
	\item Assume the magnetic field points in the $ z $ direction (i.e. $ \vec{B} = B \uvec{z} $) in which case the Hamiltonian simplifies to
	\begin{equation*}
		H = H_{0} - \gamma B L_{z}
	\end{equation*}
	In this case, the states that are simultaneously eigenstates of both $ H_{0} $ and $ L_{z} $ will also be eigenstates of the Hamiltonian $ H = H_{0} - \gamma B L_{z}$, which is useful for analyzing particles in  a external magnetic field. 
	
	For example, using our earlier solutions $ \ket{m = \pm 1} $, we have the eigenvalue equation
	\begin{align*}
		H \ket{m = \pm 1} &= H_{0}\ket{m = \pm 1} - \gamma B L_{z} \ket{m = \pm 1} \\
		& = 2\hbar \omega \ket{m = \pm 1} - \gamma B (\pm 1 \cdot \hbar)\ket{m = \pm 1} \\
		&= (2\hbar \omega \pm \gamma B\hbar)\ket{m = \pm 1}
	\end{align*}
	In other words, $ \ket{m = \pm 1} $ are indeed eigenstates of $ H $, with eigenvalues $ (2\hbar \omega \pm \gamma B\hbar) $.
\end{itemize}


\subsubsection{Larmor Precession}
\textit{Analyze the motion of a quantum-mechanical particle with magnetic moment $ \vec{\mu} $ and angular momentum quantum number $ l = 1 $ in an external magnetic field $ \vec{B} = B\uvec{z} $, where $ \vec{\mu} $ forms an initial angle $ \theta $ with $ \vec{B} $ at $ t = 0 $.}

\begin{itemize}
	\item We consider a particle in an external magnetic field $ \vec{B} = B\uvec{z} $ whose magnetic moment $ \vec{\mu} $ makes an initial angle $ \theta $ with the magnetic field. The particle's Hamiltonian is
	\begin{equation*}
		H = - \m \cdot \vec{B} = - \gamma \vec{L} \cdot \vec{B} = - \gamma B L_{z}
	\end{equation*}
	Recall the values of angular momentum are quantized. In general, a quantum particle with angular momentum quantum number $ l = 1 $ exists in a $ 2l + 1 $ dimensional Hilbert space with basis $ \ket{lm} $, where $ m \in \{-l, -l+1, \ldots, l-1, l\}  $. In our case $ l = 1 $, meaning $ m \in \{-1, 0, 1\} $.
	
	\item In Cartesian coordinates, the angular momentum operator is $ \vec{L} = (L_{x}, L_{y}, L_{z}) $. The operator $ L^{2} $ acts on the state $ \ket{lm} $ as $ L^{2}\ket{lm} = h^{2}l(l+1) \ket{lm}$. The operator $ L_{z} $ acts on $ \ket{lm} $ as $ L_{z} \ket{lm} = \hbar m \ket{lm} $. In other words, the basis $ \ket{lm} $ is the basis of states that are eigenstates of the operator $ L^{2} $ with eigenvalue $ h^{2}l(l+1) $ and eigenstates of the operator $ L_{z} $ with eigenvalue $ \hbar m $. 
	
	In the coordinate wave function representation, the states $ \ket{lm} $ are the spherical harmonics
	\begin{equation*}
		\ket{lm} = Y_{lm}(\phi, \theta)
	\end{equation*}
	The $ \phi $ component of $ Y_{lm} $ is proportional to $ \frac{e^{iml}}{\sqrt{2\pi}} $. 
	
	\item We return to the Hamiltonian of a particle with a magnetic moment in an external magnetic field: $ H = -\gamma BL_{z} $. For a particle with $ l = 1 $ (and thus magnitude of angular momentum $ L^{2} = \hbar^{2}l (l+1) = 2\hbar^{2} $), the Hamiltonian's eigenstates $ \ket{\psi} $ occurs in a $ 2l + 1 = 3 $ dimensional Hilbert space. In the $ \ket{lm} $ basis, the general expression for $ \ket{\psi} $ is thus the linear combination
	\begin{equation*}
		\ket{\psi} = a \ket{11} + b \ket{10} + c \ket{1 -1}
	\end{equation*}
	where $ l = 1 $ and $ m = 1, 0, -1 $. 
	
	\item At $ t = 0 $, the particle's magnetic moment forms a polar angle $ \theta $ with the magnetic field $ \vec{B} = B \uvec{z} $. Our first step will be finding an appropriate expression for this initial condition in the language of quantum mechanics.
\end{itemize}

\textbf{Finding the Initial State}
\begin{itemize}	
	\item In general, if some state $ \ket{\psi} $ is an eigenstate of the operator $ \vec{L}\cdot \uvec{e} $, (i.e. the projection of angular momentum $ \vec{L} $ in the direction $ \uvec{e} $), and the operator acts on $ \psi $ as 
	\begin{equation*}
		\vec{L}\cdot \uvec{e} \ket{\psi} = \hbar l \ket{\psi},
	\end{equation*}
 	then we say the state $ \ket{\psi} $'s angular momentum points in the direction $ \uvec{e} $.
	
	Back to the initial condition. We write $ \vec{L}\cdot\uvec{e} \ket{\psi, 0} = \hbar \ket{\psi, 0} $ where $ \uvec{e} $ points in the initial direction of the magnetic moment $ \m $. If we assume the magnitude moment initially lies in the $ x, z $ plane with $ \phi = 0 $, the unit vector $ \uvec{e} $, in spherical coordinates, reads
	\begin{equation*}
		\uvec{e} = (\sin \theta, 0, \cos \theta)
	\end{equation*}
	To summarize, the quantum mechanical way of saying the particle's magnetic moment forms an initial angle $ \theta $ with the magnetic field $ \vec{B} = B \uvec{z} $ is
	\begin{equation*}
		\vec{L}\cdot\uvec{e} \ket{\psi, 0} = \hbar \ket{\psi, 0}
	\end{equation*}
	where $ \ket{\psi, 0} $ is the particle's initial wave function and $ \uvec{e} = (\sin \theta, 0, \cos \theta) $. 
	
	\item To find $ \ket{\psi, 0} $, we need to find the constants $ a, b, c $ in the linear combination $ \ket{\psi} = a \ket{11} + b \ket{10} + c \ket{1 -1} $. Inserting $ \uvec{e} $ into the condition $ \vec{L}\cdot\uvec{e} \ket{\psi, 0} = \hbar \ket{\psi, 0} $ gives
	\begin{equation*}
		(L_{x}\sin \theta + L_{z}\cos \theta)\ket{\psi, 0} = \hbar \ket{\psi, 0}
	\end{equation*}
	Substituting in the linear combination $ \ket{\psi} = a \ket{11} + b \ket{10} + c \ket{1 -1} $ and rearranging gives
	\begin{equation*}
		(L_{x}\sin \theta + L_{z}\cos \theta - h)\big(a \ket{11} + b\ket{10} + c\ket{1-1}\big) = 0
	\end{equation*}
	
\end{itemize}

\textbf{Theoretical Interlude: Action of $ L_{x, y} $ on $ \ket{ml} $}
\begin{itemize}
	\item Recall the eigenvalue equation $ L_{z} \ket{lm} = \hbar m \ket{lm} $ for the operator $ L_{z} $. We now ask how $ L_{x} $ and $ L_{y} $ act on the states $ \ket{lm} $. To do this, we introduce the new operators
	\begin{equation*}
		L_{+} \equiv L_{x} + i L_{y} \eqtext{and} L_{-} \equiv L_{+}^{\dagger} = L_{x} - i L_{y}
	\end{equation*}
	In terms of $ L_{+} $ and $ L_{-} $, $ L_{x} $ and $ L_{y} $ read
	\begin{equation*}
		L_{x} = \frac{L_{+} + L_{-}}{2} \eqtext{and} L_{y} = \frac{L_{+} - L_{-}}{2i}
	\end{equation*}
	The plan is to find out how $ L_{+} $ and $ L_{-} $ act on $ \ket{lm} $, and then reconstruct the action of $ L_{x} $ and $ L_{y} $ on $ \ket{lm} $ using the relationship between $ L_{+, -} $ and $ L_{x, y} $. 
	
	\item Without proof (or e.g. see the lecture notes), $ L_{+} $ acts on $ \ket{lm} $ as
	\begin{align*}
		&L_{+}\ket{lm} = \hbar \sqrt{l (l+1) - m(m+1)} \ket{l, m+1} \\
		&L_{-}\ket{lm} = \hbar \sqrt{l (l+1) - m(m-1)} \ket{l, m-1} 
	\end{align*}
	
	\item In our case (working with a particle with $ l = 1 $ and thus $ m \in \{-1, 0, 1\} $), we have $ L_{+}\ket{11} = 0 $ (nominally this would create a state with $ m = 2 $, outside the range of allowed $ m $). In general, $ L_{+}\ket{l, m=l} = 0 $, since $ m $  cannot increase beyond $ l $. 
	
	Next, $ L_{+}\ket{10} = \sqrt{2}\hbar \ket{11} $ and $ L_{+}\ket{1 -1} = \sqrt{2}\hbar \ket{10} $.
	
	Meanwhile, $ L_{-} $ produces $ L_{-}\ket{11} = \sqrt{2}\hbar \ket{10} $, $ L_{-}\ket{10} = \sqrt{2}\hbar \ket{1-1} $ and $ L_{-}\ket{1-1} = 0 $, since $ m $ cannot decrease below $ l = 01 $. In general, $ L_{+}\ket{l, m=-l} = 0 $, since $ m $  cannot decrease below $ -l $. 
	
\end{itemize}

\textbf{Back to Finding the Initial State}
\begin{itemize}
	\item We left off with
	\begin{equation*}
		(L_{x}\sin \theta + L_{z}\cos \theta - h)\big(a \ket{11} + b\ket{10} + c\ket{1-1}\big) = 0
	\end{equation*}
	Writing $ L_{x, y} $ in terms of $ L_{+,-} $ and substituting the just-derived action of $ L_{+,-} $ on $ \ket{11}, \ket{10} $ and $ \ket{1-1} $ gives
	\begin{align*}
		0 &= \left(\frac{L_{+}+L_{-}}{2}\sin \theta + L_{z}\cos \theta - h\right)\big(a \ket{11} + b\ket{10} + c\ket{1-1}\big)\\
		&=a\left(\frac{\sqrt{2}\hbar}{2}\ket{10}\sin \theta + \hbar \cos \theta \ket{11} - h\ket{11}\right) \\
		&{} \quad + b\left(\frac{\sqrt{2}\hbar}{2}\ket{11}\sin \theta + \frac{\sqrt{2}\hbar}{2}\sin \theta\ket{1-1} - \hbar\ket{10}\right)\\
		&{} \quad + c\left(\frac{\sqrt{2}\hbar}{2}\ket{10}\sin \theta -\hbar \cos \theta\ket{1-1} - \hbar\ket{1-1}\right)
	\end{align*}
	Notice that this equation now involves only scalar values; all operators are gone.
	
	\item Next, we find the constants $ a, b $ and $ c $. First, divide through by $ \hbar $, which cancels out from each equation. Next, multiplying the above equations by $ \bra{11} $ and applying orthonormality of the states $ \ket{11} $, $ \ket{10} $, $ \ket{1-1} $, we have
	\begin{equation*}
		a  \cos \theta - a  + \frac{b}{\sqrt{2}} \sin \theta = 0
	\end{equation*}
	Next, multiplying the equation by $ \ket{10} $ gives
	\begin{equation*}
		\frac{a}{\sqrt{2}}\sin \theta - b  + \frac{c}{\sqrt{2}}\sin \theta = 0
	\end{equation*}
	Finally, multiplying the equation by $ \ket{1-1} $ gives
	\begin{equation*}
		\frac{b}{\sqrt{2}} \sin \theta - c \cos \theta - c = 0
	\end{equation*}
	
	\item We've found a system of three equations for the three unknowns $ a $, $ b $ and $ c $. Recall from e.g. introductory linear algebra that because the system of equations is homogeneous (the right side of each equation is zero), the system has a solution only up to a free parameter. 
	
	Solving the first equation for $ a $ in terms of $ b $ gives
	\begin{equation*}
		a(\cos \theta - 1) + \frac{b}{\sqrt{2}} \sin \theta = 0 \implies a = \frac{b\sin \theta}{\sqrt{2}(1 - \cos \theta)}
	\end{equation*}
	From the third equation, we get $ c $ in terms of $ b $:
	\begin{equation*}
		\frac{b}{\sqrt{2}}\sin \theta - c(1 + \cos \theta) = 0 \implies c = \frac{b\sin \theta}{\sqrt{2}(1 + \cos \theta)}
	\end{equation*}
	
	\item The solution is easier to find with $ \sin \theta  $ and $ \cos \theta $ written in terms of double angle identities, which produce
	\begin{equation*}
		 a = \frac{b}{\sqrt{2}
		 }\cot \frac{\theta}{2} \eqtext{and}  c = \frac{b}{\sqrt{2}}\tan \frac{\theta}{2} 
	\end{equation*}
	
	\item With $ a $ and $ c $ known in terms of the free parameter $ b $, the initial condition on $ \ket{\psi, 0} $ reads
	\begin{equation*}
		\ket{\psi, 0} = b\left(\frac{1}{\sqrt{2}}\cot \frac{\theta}{2}\ket{11} + \ket{10} + \frac{1}{\sqrt{2}}\tan \frac{\theta}{2}\ket{1-1}  \right)
	\end{equation*}
	We find $ b $ from the normalization condition, which, with the help of some trigonometric identities, reads
	\begin{align*}
		\braket{\psi, 0}{\psi, 0} \equiv 1 &= \abs{b}^{2}\left(\frac{1}{2}\cot^{2}\frac{\theta}{2} + 1 + \frac{1}{2}\tan^{2}\frac{\theta}{2} \right) = \abs{b}^{2}\left(\frac{\cos^{4}\frac{\theta}{2} + 2 \cos^{2}\frac{\theta}{2}\sin^{2}\frac{\theta}{2} + \sin^{4}\frac{\theta}{2}}{2\sin^{2}\frac{\theta}{2}\cos^{2}\frac{\theta}{2}}\right)\\
		&=\abs{b}^{2}\frac{\big(\cos^{2}\frac{\theta}{2} + \sin^{2}\frac{\theta}{2}\big)^{2}}{2 \sin^{2}\frac{\theta}{2} \cos^{2}\frac{\theta}{2}}  = \frac{\abs{b}^{2}}{2 \sin^{2}\frac{\theta}{2} \cos^{2}\frac{\theta}{2}} \equiv 1
	\end{align*}
	Because of the $ \abs{b}^{2} $, $ b $ is mathematically determined only up to a constant phase factor $ e^{i\phi} $ of magnitude $ 1 $; if we make the simple choice $ e^{i\phi} = 1 $, the normalization condition gives
	\begin{equation*}
		b = \sqrt{2}\sin \frac{\theta}{2} \cos \frac{\theta}{2}
	\end{equation*}
	
	\item Substituting $ b = \sqrt{2}\sin \frac{\theta}{2} \cos \frac{\theta}{2} $ into the expression for $ \ket{\psi, 0} $ gives the desired result
	\begin{equation*}
		\ket{\psi, 0} = \cos^{2} \frac{\theta}{2} \ket{11} + \sqrt{2}\sin \frac{\theta}{2} \cos \frac{\theta}{2} \ket{10} + \sin^{2}\frac{\theta}{2} \ket{1 -1}
	\end{equation*}
	To summarize: precisely this state $ \ket{\psi, 0} $ satisfies the initial condition that a particle's magnitude moment $ \m $ makes an angle $ \theta $ with an external magnetic field $ \vec{B} = B \uvec{z} $. 
\end{itemize}

\textbf{Time Evolution of the Initial State}
\begin{itemize}
	\item With the initial state $ \ket{\psi, 0} $ known, the next step is to find the time-dependent wave function $ \ket{\psi, t} $ for a particle with magnetic moment $ \m $ in an external magnetic field. We'll find the time evolution in the \Schro picture using the particle's Hamiltonian $ H = -\gamma BL_{z}  $. 
	
	\item We'll first solve the stationary \Schro equation $ H \ket{\psi} = E \ket{\psi} $ for the basis functions $ \ket{11} $, $ \ket{10} $ and $ \ket{1-1} $; this gives
	\begin{align*}
		&H \ket{11} = - \gamma BL_{z}\ket{11} = -\gamma B (1\cdot \hbar) \ket{11} = -\gamma B \hbar \ket{11}\\
		&H\ket{10} = - \gamma BL_{z}\ket{10} = -\gamma B (0\cdot \hbar) \ket{10} = 0 \ket{10}\\
		&H \ket{1-1} = - \gamma BL_{z}\ket{1-1} = -\gamma B (-1\cdot \hbar) \ket{1-1} = \gamma B \hbar \ket{1-1}
	\end{align*}
	
	\item Using the energy eigenvalues $ E_{11} = -\gamma B \hbar $, $ E_{10} = 0 $ and $ E_{1-1} = \gamma B \hbar $, the time-evolved wave function $ \ket{\psi, t} $ is then
	\begin{align*}
		\ket{\psi, t} &= \cos^{2} \frac{\theta}{2} e^{-\frac{i(-\gamma B\hbar)}{\hbar}t}\ket{11} + \sqrt{2}\sin \frac{\theta}{2} \cos \frac{\theta}{2} e^{-\frac{i\cdot 0}{\hbar}t}\ket{10} + \sin^{2}\frac{\theta}{2} e^{-\frac{i\gamma B\hbar}{\hbar}t}\ket{1 -1}\\
		&=\cos^{2} \frac{\theta}{2} e^{i\gamma B t}\ket{11} + \sqrt{2}\sin \frac{\theta}{2} \cos \frac{\theta}{2} \ket{10} + \sin^{2}\frac{\theta}{2} e^{-\gamma B t}\ket{1 -1}\\
		&=\cos^{2} \frac{\theta}{2} e^{i \omega_{L} t}\ket{11} + \sqrt{2}\sin \frac{\theta}{2} \cos \frac{\theta}{2} \ket{10} + \sin^{2}\frac{\theta}{2} e^{-\omega_{L} t}\ket{1 -1}
	\end{align*}
	where in the last line we've defined the \textit{Larmor frequency} $ \omega_{L} \equiv \gamma B $. 	The time evolution is relatively simple to find because the initial state $ \ket{\psi, 0} $ was already written in the basis $ \ket{11} $, $ \ket{10} $, $ \ket{1-1} $. 
	
	\item Next, using the wave function $ \ket{\psi, t} $, we will find the expectation value $ \ev{\m, t} $ of the particle's magnetic moment at time $ t $, which is related to angular momentum $ \vec{L} $ via
	\begin{equation*}
		\ev{\m, t} = \gamma \ev{L, t} = \gamma
		\begin{bmatrix}
			\ev{L_{x}, t}\\
			\ev{L_{y}, t}\\
			\ev{L_{z}, t}
		\end{bmatrix}
	\end{equation*}
	We'll start by finding $ L_{z} $, using the general definition of an expectation value:
	\begin{align*}
		\ev{L_{z}, t} = \bra{\psi, t}L_{z}\ket{\psi, t} &= \left(\cos^{2} \frac{\theta}{2} e^{-i \omega_{L} t}\bra{11} + \sqrt{2}\sin \frac{\theta}{2} \cos \frac{\theta}{2} \bra{10} + \sin^{2}\frac{\theta}{2} e^{\omega_{L} t}\bra{1 -1}\right) \\
		&\cdot L_{z}\left(\cos^{2} \frac{\theta}{2} e^{i \omega_{L} t}\hbar\ket{11} + 0 - \sin^{2}\frac{\theta}{2} e^{-\omega_{L} t}\hbar\ket{1 -1}\right)
	\end{align*}
	where the operator $ L_{z} $ acts on the basis states $ \ket{11} $, $ \ket{10} $ and $ \ket{1-1} $ to produce the eigenvalues $ \hbar, 0 $ and $ -\hbar $. Multiplying out the terms and applying the orthonormality of the basis states, followed by some trigonometric identities, leads to the considerably simpler expression
	\begin{align*}
		\ev{L_{z}, t} &= \hbar \cos^{4}\frac{\theta}{2} - \hbar \sin^{4}\frac{\theta}{2} = \hbar\left(\cos^{2}\frac{\theta}{2} +  \sin^{2}\frac{\theta}{2}\right)\left(\cos^{2}\frac{\theta}{2} -  \sin^{2}\frac{\theta}{2}\right)\\
		&=\hbar\cdot (1) \cdot (\cos \theta) = \hbar \cos \theta
	\end{align*}
	In other words, the $ z $ component of angular momentum $ L_{z} $ is constant!
	
	\textit{We ran out of time at this point and continued in the ninth exercise set}
	
\end{itemize}

\subsection{Ninth Exercise Set}
\subsubsection{Larmor Precession (continued)}
\textit{Analyze the motion of a quantum-mechanical particle with magnetic moment $ \mu $ and angular momentum quantum number $ l = 1 $ in an external magnetic field $ \vec{B} = B\uvec{z} $, where $ \mu $ forms an initial angle $ \theta $ with $ \vec{B} $ at $ t = 0 $.}
\begin{itemize}
	\item In the last exercise set we found the particle's time-dependent wave function
	\begin{equation*}
		\ket{\psi, t} =\cos^{2} \frac{\theta}{2} e^{i \omega_{L} t}\ket{11} + \sqrt{2}\sin \frac{\theta}{2} \cos \frac{\theta}{2} \ket{10} + \sin^{2}\frac{\theta}{2} e^{-\omega_{L} t}\ket{1 -1}
	\end{equation*}
	where $ \omega_{L} \equiv \gamma B $ is the Larmor frequency. We left off with using $ \ket{\psi, t} $ to find the expectation value $ \ev{L_{z}, t} $, which turned out to be the constant quantity $ \ket{L_{z}, t} = \hbar \cos \theta $. Next, we will use $ \ket{\psi, t} $ to find $ L_{x} $ and $ L_{y} $, which we will use to find the particle's magnetic moment via $ \ket{\m, t} = \gamma \big(\ev{L_{x}, t}, \ev{L_{y}, t}, \ev{L_{z}, t}\big) $.
	
	\item It will be easiest to find $ \ev{L_{x}, t} $ and $ \ev{L_{y}, t} $ indirectly, in terms of the operators $ L_{+} $ and $ L_{-} $; recall these are related by 
	\begin{align*}
		& L_{+} = L_{x} + iL_{y} \eqtext{and} L_{-} = L_{x} - i L_{y}\\
		& L_{x} = \frac{L_{+}+L_{-}}{2} \eqtext{and} L_{y} = \frac{L_{+} - iL_{-}}{2i}
	\end{align*}
	It  follows that  $ \ev{L_{x}, t} $ and $ \ev{L_{y}, t} $ can be found via
	\begin{equation*}
		\ev{L_{x}, t} = \frac{1}{2}\big(\ev{L_{+}, t} + \ev{L_{-}, t} \big) \eqtext{and} \ev{L_{y}, t} = \frac{1}{2i}\big(\ev{L_{+}, t} - \ev{L_{-}, t} \big)
	\end{equation*}
	In fact, $ \ev{L_{-}, t} = \ev{L_{+}, t}^{*} $ is the complex conjugate of  $ \ev{L_{+}, t} $, so we only need to find $ \ev{L_{+}, t} $, from which we can find $ \ev{L_{-}, t} $ using the general identity $ \ev{\mathcal{O}^{\dagger}} = \ev{\mathcal{O}}^{*} $. We then have
	\begin{align*}
		& \ev{L_{x}, t} = \frac{1}{2}\big(\ev{L_{+}, t} + \ev{L_{+}, t}^{*} \big) = \Re \ev{L_{+}, t}\\
		& \ev{L_{y}, t} = \frac{1}{2i}\big(\ev{L_{+}, t} - \ev{L_{+}, t}^{*} \big) = \Im \ev{L_{+}, t}
	\end{align*}
	
	\item We now find $ \ev{L_{+}, t} $ using the definition of the expectation value (we'll use the identities $ L_{+}\ket{1, -1} = \sqrt{2}\hbar \ket{10} $, $ L_{+}\ket{10} = \sqrt{2}\hbar \ket{11} $, and $ L_{+}\ket{11} = 0 $). The expectation value $ \ev{L_{+}, t} $ is then:
	\begin{align*}
		\ev{L_{+}, t} &= \bra{\psi, t} L_{+}\ket{\psi, t} = \bra{\psi, t} \left(2 \hbar \sin \frac{\theta}{2} \cos \frac{\theta}{2}\ket{11} + \sqrt{2}\hbar \sin^{2}\frac{\theta}{2}e^{-i\omega_{L}t}\ket{10}\right)\\
		&=\left(\cos^{2}\frac{\theta}{2} e^{-i\omega_{L}t}\right)\cdot \left(2\hbar \sin\frac{\theta}{2}\cos\frac{\theta}{2}\right) + \left(\sqrt{2}\sin \frac{\theta}{2}\cos \frac{\theta}{2}\right)\left(\sqrt{2}\hbar\sin^{2}\frac{\theta}{2}e^{-i\omega_{L}t}\right)\\
		&=2\hbar\cos\frac{\theta}{2}\sin\frac{\theta}{2}\left(\cos^{2}\frac{\theta}{2} + \sin^{2}\frac{\theta}{2}\right)e^{-i\omega_{L}t}= \hbar \sin\theta e^{-i\omega_{L}t}
	\end{align*}
	The angular momentum components $ \ev{L_{x}, t} $ and $ \ev{L_{y}, t} $ are then
	\begin{align*}
		&\ev{L_{x}, t} = \Re \ev{L_{+}, t} = \hbar \sin \theta \cos( \omega_{L}t)\\
		& \ev{L_{y}, t} = \Im \ev{L_{+}, t} = \hbar \sin \theta \sin( \omega_{L}t)
	\end{align*}
	In one place, the components of angular momentum are
	\begin{equation*}
		\ev{L_{x}, t} = \hbar \sin \theta \cos( \omega_{L}t) \qquad 	\ev{L_{y}, t} = \hbar \sin \theta \sin( \omega_{L}t) \qquad 
		\ev{L_{z}, t} = \hbar \cos \theta
	\end{equation*}
	In other words, analogously to the classical picture, the expectation values $ \ev{L_{x}, t} $ and $ \ev{L_{y}, t} $ precess around the direction of the external magnetic field $ \vec{B} = B \uvec{z} $ with the Larmor frequency $ \omega_{L} = \gamma B $. 
	
	\item Recall that an physical measurement (observation) generally disturbs quantum mechanical systems. With this issue in mind, we'll find what happens with an observation of $ L_{z} $  at the time $ t $. 
	
\end{itemize}
\textbf{Theoretical Interlude: Observations in Quantum Mechanics}
\begin{itemize}
	\item We make an observation of a physical quantity in quantum mechanics as follows. First, expand the relevant system's wave function in the basis consisting of the eigenfunctions of the operator corresponding to the quantity being measured (e.g. to measure a system's $ L_{z} $, expand the system wave function in the $ L_{z} $ basis $ \ket{lm} $. ) 
	
	\item The possible outcomes of the observation are the discrete eigenvalues of the operator corresponding to the quantity being measured. 
	
	When the wavefunction is a linear combination of multiple eigenstates, each of the states' corresponding eigenvalues is a possible outcome, and the probability of each eigenvalue being the outcome is the squared absolute value of the corresponding eigenstate's coefficient.
	
	\item Finally, immediately after an observation yielding a given eigenvalue, the system's wavefunction assumes (``collapses into'') the eigenfunction corresponding to the measured eigenvalue.
\end{itemize}

\textbf{Back to the Observation of $ L_{z} $}
\begin{itemize}
	\item Our particle's wave function $ \ket{\psi, t} $ is already expanded in $ L_{z} $ basis $ \ket{lm} $; recall the wave function is 
	\begin{equation*}
		\ket{\psi, t} =\cos^{2} \frac{\theta}{2} e^{i \omega_{L} t}\ket{11} + \sqrt{2}\sin \frac{\theta}{2} \cos \frac{\theta}{2} \ket{10} + \sin^{2}\frac{\theta}{2} e^{-\omega_{L} t}\ket{1 -1}
	\end{equation*}
	
	\item Next, we consider the possible outcome of the observation of $ L_{z} $. Our wavefunction is a combination of three states $ \ket{11} $, $ \ket{10} $ and $ \ket{1-1} $; the corresponding $ L_{z} $ eigenvalues of these states are $ \hbar $, $ 0 $ and $ -\hbar $, and the corresponding probabilities are the squared absolute values of the corresponding eigenstate's coefficients. Table \ref{qmv:table:larmor-Lz} summarizes the eigenstates, possible outcomes, and corresponding probabilities.
	\begin{table}
	\centering 
	\begin{tabular}{c|c|c}
		Eigenstate & Outcome & Probability \\
		\hline {\rule{0pt}{2.6ex}} \hspace{-7pt} 
		$ \ket{11} $ & $ \hbar $  & $ \abs{\cos^{2}\frac{\theta}{2}e^{-i\omega_{L}t}} = \cos^{4}\frac{\theta}{2} $\\[1mm]
		$ \ket{10} $ & 0 & $ 2 \cos^{2}\frac{\theta}{2}\sin^{2}\frac{\theta}{2} $\\[1mm]
		$ \ket{1-1} $ & $ -\hbar $  & $ \abs{\sin^{2}\frac{\theta}{2}e^{-i\omega_{L}t}} = \sin^{4}\frac{\theta}{2} $
	\end{tabular}
	\caption{Ingredients to consider in a measurement of an $ l=1 $ Larmor-precessing particle's angular momentum $ L_{z} $. }
	\label{qmv:table:larmor-Lz}
	\end{table}
	
	\item Because of wavefunction collapse to the measured eigenvalue's corresponding eigenfunction, any measurement of $ L_{z} $ would cause the particle's eigenfunction to stop precessing at a polar angle $ \theta $ about the magnetic field $ \vec{B} = B\uvec{z} $ in agreement with classical Larmor precession.
	
	For example, measuring $ L_{z} = \hbar $ would cause the particle to assume the eigenfunction $ \ket{11} $, which directly points in the direction of the magnetic field and $ \uvec{z} $ axis. 
	
	The lesson here is that even though the classical and quantum-mechanical results for a particle with magnetic moment $ \mu $ in an external magnetic field both display Larmor precession about the $ \uvec{B} $ direction, any observation of the quantum-mechanical observation of the system breaks this agreement because of wave function collapse.
	
\end{itemize}

% This problem introduces spin operators (with spin 1/2 operator)
% whereas previous problems used orbital angular momentum operators
% We'll get practice with a wavefunction that exists both in position
% and spin angular momentum space at onces
\subsubsection{Rashba Coupling}
\textit{Consider a particle in the two-dimensional $ x, y $ plane with magnitude of spin $ S = \frac{1}{2} $ and Hamiltonian}
\begin{equation*}
	H = \frac{p^{2}}{2m} + \lambda (p_{x}S_{y} - p_{y}S_{x})
\end{equation*}
\textit{where $ \vec{p} = (p_{x}, p_{y}) $ and $ \vec{S} = (S_{x}, S_{y}, S_{z}) $ are the momentum and spin operators and $ \lambda $ is a constant.\footnote{The term $ \lambda (p_{x}S_{y} - p_{y}S_{x}) $ is called the \textit{Rashba coupling term}, which gives this problem its name.} Find the Hamiltonian $ H $'s eigenfunctions and eigenvalues.}

\vspace{2mm}
\textbf{Spin and Momentum States}
\begin{itemize}
	\item The Hamiltonian $ H $ acts on states in the combined Hilbert space 
	$ \H = \H_{p}\otimes \H_{s} $ where $ \H_{p} $ is the momentum Hilbert space and $ \H_{s} $ is the spin Hilbert space. Analogously, the states in $ \H $ are $ \ket{\psi} = \ket{\psi_{p}} \otimes \ket{\psi_{s}}$. 
	
	\item Since we're working with states with spin magnitude $ S = \frac{1}{2} $ and thus $ M \in  \big\{-\tfrac{1}{2}, \tfrac{1}{2}\big\} $, the spin wavefunction $ \psi_{s} $ is the linear combination
	\begin{equation*}
		\ket{\psi_{s}} = \alpha \ket{\frac{1}{2}\frac{1}{2}} + \beta \ket{\frac{1}{2}-\frac{1}{2}}
	\end{equation*}
	where $ \ket{SN_{s}} $ is the basis of the spin operator $ S^{2} $---$ S $ is the spin quantum number and $ M_{s} $ is the quantum number corresponding to the projection of spin on the $ z $ axis. The spin operator $ S^{2} $ acts on these basis states to produce
	\begin{align*}
		&S^{2} \ket{\frac{1}{2}\frac{1}{2}} = \hbar^{2} \frac{1}{2}\left(\frac{1}{2} + 1\right ) \ket{\frac{1}{2}\frac{1}{2}} = \hbar^{2} \frac{3}{4} \ket{\frac{1}{2}\frac{1}{2}}\\
		& S^{2} \ket{\frac{1}{2}-\frac{1}{2}} = \hbar^{2} \frac{1}{2}\left (\frac{1}{2} + 1\right ) \ket{\frac{1}{2}-\frac{1}{2}} = \hbar^{2} \frac{3}{4} \ket{\frac{1}{2}-\frac{1}{2}}
	\end{align*}
	Meanwhile, the operator $ S_{z} $ acts on the basis states to produce
	\begin{equation*}
		S_{z} \ket{\frac{1}{2}\frac{1}{2}} = \frac{\hbar}{2} \ket{\frac{1}{2}\frac{1}{2}} \eqtext{and} S_{z} \ket{\frac{1}{2}-\frac{1}{2}} = -\frac{\hbar}{2} \ket{\frac{1}{2}-\frac{1}{2}}
	\end{equation*}
	When working with particles with spin $ S = \frac{1}{2} $, we usually denote the states $  \ket{\frac{1}{2}\frac{1}{2}}  $ and $  \ket{\frac{1}{2}-\frac{1}{2}}  $ with $ \ket{\ua} $ and $ \ket{\da} $, respectively. In this notation, the spin wavefunction is
	\begin{equation*}
		\ket{\psi_{s}} = \alpha \ket{\ua} + \beta \ket{\da}
	\end{equation*}
	In our case, the spin Hilbert space $ \H_{s} $ is two-dimensional, since it consists of all linear combinations of the two linearly independent states $ \ket{\ua} $ and $ \ket{\da} $. 
	
	\item Next, on to the momentum states $ \ket{\psi_{p}} $, which correspond to the kinetic energy operator. The eigenstates of the kinetic energy operator are plane waves of the form $ e^{i\vec{k}\cdot \vec{r}} $. Because the wave vectors $ \vec{k} $ are continuously distributed and $ \vec{k} $ generates a unique set of eigenvalues, the position space $ \H_{p} $ is infinitely dimensional.
\end{itemize}

\textbf{Finding Eigenfunctions and and Eigenvalues}
\begin{itemize}
	
	\item To find the Hamiltonian's eigenfunctions and eigenvalues, we need to solve the stationary \Schro equation
	\begin{equation*}
		H \ket{\psi} = E \ket{\psi}
	\end{equation*}
	First, to make the rest of the problem easier, we will show that $ H $ commutes with the operators $ p_{x} $ and $ p_{y} $. First, we have
	\begin{equation*}
		[H, p_{x}] = \left[\frac{p_{x}^{2} + p_{y}^{2}}{2m} + \lambda (p_{x}S_{y} - p_{y}S_{x}), p_{x}\right]
	\end{equation*}
	The operators $ p_{x}^{2} $ and $ p_{x} $ commute, as do $ p_{y}^{2} $ and $ p_{x} $, which takes care of the first term. Next, we consider the Rashba coupling term $ (p_{x}S_{y} - p_{y}S_{x}) $. Because the $ S_{y, x} $ operators act on the spin Hilbert space $ \H_{s} $ and $ p_{x} $ acts on the independent momentum Hilbert space $ \H_{p} $, and because $ p_{x} $ commutes with both $ p_{x} $ and $ p_{y}$, the operator $ p_{x} $ also commutes with the Rashba term $ (p_{x}S_{y} - p_{y}S_{x}) $. It follows that
	\begin{equation*}
		[H, p_{x}] = 0
	\end{equation*}
	We can show $ [H, p_{y}] = 0 $ with an analogous procedure.
	
	\item Next, we will make use of the commutators $ [H, p_{x}] = 0  $ and $ [H, p_{y}] = 0  $. Recall that if two operators commute, it is possible to find eigenfunctions that are simultaneously eigenfunctions of both operators (see e.g. the 2D harmonic oscillator problem \ref{qmv:sss:2dqho}). In our case, because $ \vec{p} = (p_{x}, p_{y})$ and $ H $ commute, it is possible to find such functions that are simultaneously eigenfunctions of both operators. In other words, instead of finding $ H $'s eigenfunctions, we can search for $ \vec{p} $'s eigenfunctions instead. 
	
	\item $ \vec{p} $'s eigenfunctions correspond to the momentum states $ \ket{\psi_{p}} $. We want to solve the eigenvalue equation
	\begin{equation*}
		\vec{p}\ket{\psi_{p}} = a \ket{\psi_{p}} \qquad \text{where } \vec{p} = -i\hbar \nabla
	\end{equation*}
	I've used $ a $ instead of $ \lambda $ to denote the eigenvalue to avoid confusion with the Rashba coupling parameter $ \lambda $. Recall the momentum eigenfunctions are plane waves of the form $ e^{i\vec{k}\cdot \vec{r}} $, for which the eigenvalue equation, in the coordinate wavefunction representation, reads
	\begin{equation*}
		\vec{p} e^{i\vec{k}\cdot \vec{r}} = -i\hbar (i \vec{k}) e^{i\vec{k}\cdot \vec{r}} = \hbar \vec{k}e^{i\vec{k}\cdot \vec{r}}
	\end{equation*}
	In Dirac notation, the equation reads
	\begin{equation*}
		\vec{p}\ket{\vec{k}} = \hbar \vec{k} \ket{\vec{k}} 
	\end{equation*}
	where the eigenstate $ \ket{\k} $ corresponds to the wavefunction $ e^{i\vec{k}\cdot \vec{r}} $ and the eigenvalue is $ \hbar \vec{k} = \hbar(k_{x}, k_{y}) $.
	
	\item Returning the stationary \Schro equation and using $ \ket{\psi_{p}} = \ket{\k} $ we have
	\begin{equation*}
		H\ket{\psi} = H\big(\ket{\psi_{p}} \otimes \ket{\psi_{s}}\big) = H\big(\ket{\k} \otimes \ket{\psi_{s}}\big) = E \big(\ket{\k}\otimes \ket{\psi_{s}}\big)
	\end{equation*}
	Again, the replacement of $ \ket{\psi_{p}}$ with $ \k $ in the \Schro equation is possible only because $ H $ and $ \vec{p} $ commute. We have thus reduced our problem to finding spin wavefunctions $ \ket{\psi_{s}} $. 
	
	\textit{Notation}: I practice, we drop the tensor product symbol $ \otimes $; in this convention the above stationary \Schro reads
	\begin{equation*}
		H\big(\ket{\k} \ket{\psi_{s}}\big) = E \big(\ket{\k} \ket{\psi_{s}}\big)
	\end{equation*}
	
	\item Next, substituting the Hamiltonian $ H $ into the equation $ H\big(\ket{\k} \ket{\psi_{s}}\big) = E \big(\ket{\k} \ket{\psi_{s}}\big) $ and noting that each operator in the Hamiltonian acts either only on the momentum function $ \ket{\k} $ or only on the spin function $ \ket{\psi_{s}} $, we have
	\begin{align*}
		H\big(\ket{\k} \ket{\psi_{s}}\big) &= \left[\frac{p^{2}}{2m} + \lambda (p_{x}S_{y} - p_{y}S_{x})\right]\big(\ket{\k} \ket{\psi_{s}}\big) \\
		& = \left(\frac{p^{2}}{2m}\ket{\k}\right)\ket{\psi_{s}} + \lambda \big(p_{x}\ket{\k} S_{y}\ket{\psi_{s}} - p_{y}\ket{\k} S_{x}\ket{\psi_{s}}\big) \\
		&=\frac{\hbar^{2}k^{2}}{2m}\ket{\k}\ket{\psi_{s}} + \lambda \hbar k_{x}\ket{\k}S_{y}\ket{\psi_{s}} - \lambda \hbar k_{y}\ket{\k}S_{x}\ket{\psi_{s}}\\
		&\equiv E\ket{\k}\ket{\psi_{s}}
	\end{align*}
	Next, to eliminate $ \ket{\k} $ we multiply the equation from the left by $ \bra{\k} $ to get
	\begin{equation*}
		\frac{\hbar^{2}k^{2}}{2m}\ket{\psi_{s}} + \lambda \hbar (k_{x}S_{y} - k_{y}S_{x})\ket{\psi_{s}} = E\ket{\psi_{s}}
	\end{equation*}
	We're now left with an equation containing only the spin wavefunction $ \ket{\psi_{s}} $. 
\end{itemize}

\textbf{Theoretical Interlude}
\begin{itemize}

	\item Recall that for a particle with spin $ S = \frac{1}{2} $, the function $ \ket{\psi_{s}} $ is an element of the two-dimensional spin Hilbert space $ \H_{s} $ and can thus be written as the linear combination
	\begin{equation*}
		\ket{\psi_{s}} = \alpha \ket{\ua} + \beta \ket{\da}
	\end{equation*}

	\item Just like it is more convenient to the orbital angular momentum components $ L_{x} $ and $ L_{y} $ in terms of the operators $ L_{+} $ and $ L_{-} $, it is best to analyze $ S_{x} $ and $ S_{y} $ in terms of the analogously defined operators $ S_{+} $ and $ S_{-} $, which read
	\begin{align*}
		& S_{+} = S_{x} + iS_{y} \eqtext{and} S_{-} = S_{x} - i S_{y}\\
		& S_{x} = \frac{S_{+}+S_{-}}{2} \eqtext{and} S_{y} = \frac{S_{+}-S_{-}}{2i}
	\end{align*}
	The operators $ S_{+} $ and $ S_{-} $ act on the spin basis states $ \ket{sm} $ to produce
	\begin{align*}
		& S_{+} \ket{sm} = \hbar \sqrt{s(s+1) - m(m+1)}\ket{s, m+1}\\
		& S_{-} \ket{sm} = \hbar \sqrt{s(s+1) - m(m-1)}\ket{s, m-1}
	\end{align*}
	
\end{itemize}

\textbf{Back to Our Problem}
\begin{itemize}
	\item  First, some useful intermediate results: $ S_{+}\ket{\ua} = S_{+}\ket{\tfrac{1}{2} \tfrac{1}{2}} = 0 $ ($ m $ cannot increase beyond $ s = \frac{1}{2} $), $ S_{+}\ket{\da} = S_{+}\ket{\tfrac{1}{2} -\tfrac{1}{2}} = \hbar \ket{\ua} $, $ S_{-}\ket{\ua} = S_{-}\ket{\tfrac{1}{2} \tfrac{1}{2}} = \hbar \ket{\da} $ and $ S_{-}\ket{\da} = S_{-}\ket{\tfrac{1}{2}- \tfrac{1}{2}} = 0 $ ($ m $ cannot increase below $ -s = -\frac{1}{2} $). 

	\item In terms of $ S_{+} $ and $ S_{-} $ and using the above intermediate results, $ S_{x} $ and $ S_{y} $ act on $ \ket{\psi_{s}} $ to produce
	\begin{align*}
		&S_{x}\ket{\psi_{s}} = \frac{S_{+}+S_{-}}{2} \big(\alpha \ket{\ua} + \beta \ket{\da}\big) = \frac{\hbar}{2} \big(\alpha \ket{\da} + \beta \ket{\ua}\big)\\
		&S_{y}\ket{\psi_{s}} = \frac{S_{+}-S_{-}}{2i} \big(\alpha \ket{\ua} + \beta \ket{\da}\big) = \frac{\hbar}{2i} \big(-\alpha \ket{\da} + \beta \ket{\ua}\big)
	\end{align*} 
	
	\item We can now evaluate the earlier equation 
	\begin{equation*}
		\frac{\hbar^{2}k^{2}}{2m}\ket{\psi_{s}} + \lambda \hbar (k_{x}S_{y} - k_{y}S_{x})\ket{\psi_{s}} = E\ket{\psi_{s}}
	\end{equation*}
	Using the just-derived action of $ S_{x} $ and $ S_{y} $ act on $ \ket{\psi_{s}} $, we have
	\begin{equation*}
		\frac{\hbar^{2}k^{2}}{2m}\big(\alpha \ket{\da} + \beta \ket{\ua}\big)+ \frac{\lambda k_{x} \hbar^{2}}{2i} \big(-\alpha \ket{\da} + \beta \ket{\ua}\big) - \frac{\lambda k_{y} \hbar^{2}}{2} \big(\alpha \ket{\da} + \beta \ket{\ua}\big) = E\big(\alpha \ket{\da} + \beta \ket{\ua}\big)
	\end{equation*}
	Note that this equation contains only scalar values and the two linearly independent states $ \ket{\da} $ and $ \ket{\ua} $---all operators are gone from the equation. 
	
	\item Multiplying the equation from the left by $ \bra{\ua} $ and applying the orthonormality of $ \ket{\da} $ and $ \ket{\ua} $ produces
	\begin{equation*}
		\frac{\hbar^{2}k^{2}}{2m} \alpha + \frac{\lambda \hbar^{2}k_{x}}{2i} \beta - \frac{\lambda \hbar^{2}k_{y}}{2} \beta = E \alpha
	\end{equation*}
	while multiplying the equation from the left by $ \bra{\da} $ produces
	\begin{equation*}
		\frac{\hbar^{2}k^{2}}{2m} \beta - \frac{\lambda \hbar^{2}k_{x}}{2i} \beta - \frac{\lambda \hbar^{2}k_{y}}{2} \alpha = E \beta
	\end{equation*}
	We have a system of two equations for the two unknown coefficients $ \alpha $ and $ \beta $; in matrix form this system reads
	\begin{equation*}
		\begin{bmatrix}
		\frac{\hbar^{2}k^{2}}{2m} & \frac{\lambda \hbar^{2}}{2i}(k_{x}-ik_{y}) \\
		-\frac{\lambda \hbar^{2}}{2i}(k_{x}+ik_{y}) & \frac{\hbar^{2}k^{2}}{2m}
		\end{bmatrix}
		\begin{bmatrix}
			\alpha\\
			\beta
		\end{bmatrix}
		= E
		\begin{bmatrix}
			\alpha\\
			\beta
		\end{bmatrix}
	\end{equation*}
	which is an ($ 2 \cross 2 $) eigenvalue problem.
	
	\item Before tackling the eigenvalue problem, we'll write the 2D wave vector $ \vec{k} = (k_{x}, k_{y}) $ in polar coordinates:
	\begin{equation*}
		k_{x} + ik_{y} = ke^{i\phi} \eqtext{and} k_{x} - ik_{y} = ke^{-i\phi}
	\end{equation*}
	With $ \k $ written in polar coordinates, the eigenvalue equation reads
	\begin{equation*}
		\begin{bmatrix}
		\frac{\hbar^{2}k^{2}}{2m} & \frac{\lambda \hbar^{2}}{2i}ke^{-i\phi} \\[1mm]
		-\frac{\lambda \hbar^{2}}{2i}ke^{i\phi} & \frac{\hbar^{2}k^{2}}{2m}
		\end{bmatrix}
		\begin{bmatrix}
			\alpha\\
			\beta
		\end{bmatrix}
		= E
		\begin{bmatrix}
			\alpha\\
			\beta
		\end{bmatrix}
	\end{equation*}
	We find the energy eigenvalues from the zeros of the characteristic polynomial
	\begin{equation*}
		p(E) = \det 
		\begin{bmatrix}
		\frac{\hbar^{2}k^{2}}{2m} - E & \frac{\lambda \hbar^{2}}{2i}ke^{-i\phi} \\[1mm]
		-\frac{\lambda \hbar^{2}}{2i}ke^{i\phi} & \frac{\hbar^{2}k^{2}}{2m} - E
		\end{bmatrix}
		= \left( \frac{\hbar^{2}k^{2}}{2m} - E\right)^{2} - \left(\frac{\lambda \hbar^{2}k^{2}}{2}\right)^{2} 
	\end{equation*}	
	The polynomial's two zeros are
	\begin{equation*}
		E_{+,-} = \frac{\hbar^{2}k^{2}}{2m} \pm \frac{\lambda \hbar^{2}k}{2}
	\end{equation*}
	Note that the case $ \lambda = 0 $, which corresponds to zero coupling, recovers the free-particle energy $ E = \frac{\hbar^{2}k^{2}}{2m} $. In this case we have energy degeneracy $ 2 $ for each $ \k $, since both energy eigenvalues $ E_{+,-} $ are equal for a given value of $ k $.
	
	For $ \lambda \neq 0 $, in the presence of Rashba coupling, the degeneracy is broken, since both energy eigenvalues $ E_{\pm} $ are different; shifted up or down from the free particle energy by the quantity $ \frac{\lambda \hbar^{2}k}{2} $.
	
%	\item To analyze the energy eigenvalues with $ \lambda \neq 0 $ in the presence of Rashba coupling, we first write $ E $ as a complete square:
%	\begin{equation*}
%		E_{\pm} = \frac{h^{2}}{2m}\left(k \pm \frac{m\lambda}{2}\right)^{2} - \frac{m\hbar^{2}\lambda^{2}}{8}
%	\end{equation*}
%	The nonzero coupling coefficient breaks the twofold degeneracy of a free particle, since both energy eigenvalues $ E_{\pm} $ are different.

	\item Next, we consider the eigenstates. In the degenerate case $ \lambda = 0 $, we have
	\begin{equation*}
		H \ket{\k} \big(\alpha \ket{\ua} + \beta \ket{\da}\big) = \frac{\hbar^{2}k^{2}}{2m}\big(\alpha \ket{\ua} + \beta \ket{\da}\big)
	\end{equation*}
	for each $ \alpha $ and $ \beta $. In other words, when $ \lambda = 0 $, any linear combination $ \ket{\psi_{s}} = \big(\alpha \ket{\ua} + \beta \ket{\da}\big) $ is an eigenstate of the Hamiltonian with the energy eigenvalue $  \frac{\hbar^{2}k^{2}}{2m} $.
	
	\item When $ \lambda \neq 0 $, only two unique linear combination of $ \ket{\ua} $ and $ \ket{\da} $ will be eigenstates of the Hamiltonian; we find these states by finding the eigenvectors of the earlier eigenvalue problem
	\begin{equation*}
		\begin{bmatrix}
		\frac{\hbar^{2}k^{2}}{2m} - E & \frac{\lambda \hbar^{2}}{2i}ke^{-i\phi} \\[1mm]
		-\frac{\lambda \hbar^{2}}{2i}ke^{i\phi} & \frac{\hbar^{2}k^{2}}{2m} - E
		\end{bmatrix}
		\begin{bmatrix}
			\alpha\\
			\beta
		\end{bmatrix}
		= 0
	\end{equation*}
	Substituting in the two energy eigenvalues $ E_{\pm} = \frac{\hbar^{2}k^{2}}{2m} \pm \frac{\lambda \hbar^{2}k}{2} $ gives
	\begin{equation*}
		\begin{bmatrix}
		\mp \frac{\lambda \hbar^{2}k}{2}  & \frac{\lambda \hbar^{2}}{2i}ke^{-i\phi} \\[1mm]
		\frac{\lambda \hbar^{2}}{2i}ke^{i\phi} & \mp \frac{\lambda \hbar^{2}k}{2} 
		\end{bmatrix}
		\begin{bmatrix}
			\alpha\\
			\beta
		\end{bmatrix}
		= 0
	\end{equation*}
	Multiplying the matrices leads to the equation
	\begin{equation*}
		\mp \frac{\lambda \hbar^{2}k}{2}\alpha + \frac{\lambda \hbar^{2}k}{2i} e^{-i\phi} \beta = 0 \implies \beta = \pm \alpha i e^{i\phi}
	\end{equation*}
	The two eigenvectors are thus
	\begin{equation*}
		\begin{bmatrix}
			\alpha\\
			\beta
		\end{bmatrix}
		= 
		\alpha 
		\begin{bmatrix}
			1 \\
			\pm ie^{i\phi}
		\end{bmatrix}
		\eqtext{or, when normalized,}
		\begin{bmatrix}
			\alpha\\
			\beta
		\end{bmatrix}
		= 
		\frac{1}{\sqrt{2}} 
		\begin{bmatrix}
			1 \\
			\pm ie^{i\phi}
		\end{bmatrix}
	\end{equation*}
	The corresponding eigenfunctions for the eigenvalues $ E_{\pm} $ are thus
	\begin{equation*}
		\ket{\psi_{+}} = \ket{\k}\frac{\ket{\ua} + ie^{i\phi}\ket{\da}}{\sqrt{2}} \eqtext{and} \ket{\psi_{-}} =  \ket{\k}\frac{\ket{\ua} - ie^{i\phi}\ket{\da}}{\sqrt{2}}
	\end{equation*}
	Next, we will analyze the just-derived wavefunctions.
\end{itemize}

\textbf{Theoretical Interlude}
\begin{itemize}
	\item If the projection $ \vec{S} \cdot \uvec{e}$ of a particle's spin $ \vec{S} $ in the direction $ \uvec{e} $ acts on the spin particle's wavefunction $ \ket{\psi_{s}} $ to produce $  \vec{S} \cdot \uvec{e} \ket{\psi_{s}} = \frac{\hbar}{2}\ket{\psi_{s}} $, then we say the particle's spin points in the direction $ \uvec{e} $. 
	
	\item If we write $ \uvec{e} $ in spherical coordinates as 
	\begin{equation*}
		\uvec{e} = \big(\cos \varphi \sin \theta, \sin \varphi \sin \theta, \cos \theta\big),
	\end{equation*}
	then the equation $  \vec{S} \cdot \uvec{e} \ket{\psi_{s}} = \frac{\hbar}{2}\ket{\psi_{s}} $ has the solution 
	\begin{equation*}
		\ket{\psi_{s}} = \cos \frac{\theta}{2} \ket{\ua} + \sin \frac{\theta}{2} e^{i\varphi} \ket{\da}
	\end{equation*}
	In other words, if we know a particle's spin wavefunction $ \ket{\psi_{s}} $ and can deduce the values of $ \varphi $ and $ \theta $ by comparing the particle's wavefunction to the above equation, we can determine the spatial orientation $ \uvec{e} = \big(\cos \varphi \sin \theta, \sin \varphi \sin \theta, \cos \theta\big) $  of the particle's spin.
	
\end{itemize}

\textbf{Back to Our Problem}
\begin{itemize}
	\item In our case, the particle has the spin wavefunctions
	\begin{equation*}
		\ket{\psi_{s_{\pm}}} = \frac{1}{\sqrt{2}}\ket{\ua} \pm \frac{1}{\sqrt{2}} ie^{i\phi}\ket{\da} =  \frac{1}{\sqrt{2}}\ket{\ua} + \frac{1}{\sqrt{2}} e^{i(\phi \pm \frac{\pi}{2})}\ket{\da}
	\end{equation*} 
	By comparing $ \ket{\psi_{s_{\pm}}} $ to the above general expression for a spin wave function
	\begin{equation*}
		 \ket{\psi_{s}} = \cos \frac{\theta}{2} \ket{\ua} + \sin \frac{\theta}{2} e^{i\varphi} \ket{\da}
	\end{equation*}
	we see that our particle has polar angle $ \theta = \frac{\pi}{2} $ (since $ \theta = \frac{\pi}{2} \implies \cos \frac{\theta}{2} = \cos \frac{\pi}{4} = \frac{1}{\sqrt{2}} $ reproduces the $ \ket{\ua} $ coefficient $ \frac{1}{\sqrt{2}} $) and azimuthal angle $ \varphi = \phi \pm \frac{\pi}{2} $, where $ \phi $ is the angle in the phase term $ e^{i\phi} $ ($ \phi $ was the azimuthal angle in the polar-coordinate representation of the wave vector $ \k = (k, \phi) $). 
	
	In both cases, the particle's spin is perpendicular to wave vector $ \vec{k} $. 
\end{itemize}


\subsection{Tenth Exercise Set}

\subsubsection{Rashba Coupling with Pauli Spin Matrices}
\textit{Use the Pauli spin matrices to find the energy eigenvalues and eigenfunctions of a particle in the two-dimensional $ x, y $ plane with magnitude of spin $ S = \frac{1}{2} $ and Hamiltonian}
\begin{equation*}
	H = \frac{p^{2}}{2m} + \lambda (p_{x}S_{y} - p_{y}S_{x})
\end{equation*}
\textit{where $ \vec{p} = (p_{x}, p_{y}) $ and $ \vec{S} = (S_{x}, S_{y}, S_{z}) $ are the momentum and spin operators and $ \lambda $ is a constant.}


\vspace{2mm}
\textbf{Quick Review of Previous Solution}
\begin{itemize}
	\item In the ninth exercise set, we solved this same problem without using spin matrices. For a particle with spin $ S = \frac{1}{2} $, the spin wavefunctions occur in a 2D spin Hilbert space and take the general form
	\begin{equation*}
		\ket{\psi_{s}} = \alpha \ket{\ua} + \beta \ket{\da}
	\end{equation*}
	
	We then showed the commutation relation $ [H, \vec{p}] = 0 $ which allowed us to make the wavefunction factorization
	\begin{equation*}
		\ket{\psi} = \ket{\vec{k}}\ket{\psi_{s}}
	\end{equation*}
	We substituted this factorization in the \Schro equation $ H \ket{\psi} = E \ket{\psi} $ and ended up with the ($ 2 \cross 2 $) eigenvalue problem
	\begin{equation*}
		\begin{bmatrix}
		\frac{\hbar^{2}k^{2}}{2m} & \frac{\lambda \hbar^{2}}{2i}(k_{x}-ik_{y}) \\
		-\frac{\lambda \hbar^{2}}{2i}(k_{x}+ik_{y}) & \frac{\hbar^{2}k^{2}}{2m}
		\end{bmatrix}
		\begin{bmatrix}
			\alpha\\
			\beta
		\end{bmatrix}
		= E
		\begin{bmatrix}
			\alpha\\
			\beta
		\end{bmatrix}
	\end{equation*}
	which we solved for the Hamiltonian's energy eigenvalues and eigenfunctions.
\end{itemize}

\textbf{Solution Using Spin Matrices}
\begin{itemize}
	\item  Today we will use the Pauli matrix representation of the spin operator, which is
	\begin{equation*}
		\vec{S} = \frac{\hbar}{2}\vec{\sigma}
	\end{equation*}
	where $ \vec{\sigma} = (\sigma_{x}, \sigma_{y}, \sigma_{z})$; $ \sigma_{x}$, $\sigma_{y}$, and $ \sigma_{z} $ are called the \textit{Pauli spin matrices}. In the standard $ \ket{\ua}$ $\ket{\da} $ basis, spin matrices are
	\begin{equation*}
		\sigma_{x} = 
		\begin{bmatrix}
			0 & 1\\
			1 & 0
		\end{bmatrix}
		\qquad
		\sigma_{y} = 
		\begin{bmatrix}
			0 & -i\\
			i & 0
		\end{bmatrix}
		\qquad
		\sigma_{z} = 
		\begin{bmatrix}
			1 & 0\\
			0 & -i
		\end{bmatrix}
	\end{equation*}
	Recall our problem's spin wavefunctions took the general form $ \ket{\psi_{s}} = \alpha \ket{\ua} + \beta \ket{\da} $. When working with Pauli matrices, we represent the wavefunction with the vector $ [\alpha, \beta]^{T} $, which we call a \textit{spinor}.
	
	\item In terms of the spin matrices, the Hamiltonian reads
	\begin{equation*}
		H = \frac{p^{2}}{2m} + \lambda \frac{\hbar}{2}(p_{x}\sigma_{x} - p_{y}\sigma_{x})
	\end{equation*} 
	and the wavefunction $  \ket{\psi} = \ket{\vec{k}}\ket{\psi_{s}} $ is, in the coordinate representation,
	\begin{equation*}
		\psi = e^{i\vec{k}\cdot \vec{r}} 
		\begin{bmatrix}
		\alpha\\
		\beta
		\end{bmatrix}
	\end{equation*}
	The stationary \Schro equation $ H \psi = E \psi $ reads
	\begin{equation*}
		H \psi = \frac{\hbar^{2}k^{2}}{2m} e^{i\k \cdot \vec{r}}
		\begin{bmatrix}
			\alpha\\
			\beta
		\end{bmatrix}
		+ \frac{\lambda \hbar}{2}\left(\hbar k_{x}\sigma_{y} - \hbar k_{y}\sigma_{x}\right)
		e^{i\k \cdot \vec{r}}
		\begin{bmatrix}
			\alpha\\
			\beta
		\end{bmatrix}
		\equiv E \psi = E e^{i\k \cdot \vec{r}}
		\begin{bmatrix}
			\alpha\\
			\beta
		\end{bmatrix}
	\end{equation*}
	If we cancel $ e^{i\k \cdot \vec{r}} $ from both sides of the equation, we end up with
	\begin{equation*}
		\frac{\hbar^{2}k^{2}}{2m}
		\begin{bmatrix}
			\alpha\\
			\beta
		\end{bmatrix} + 
		\frac{\lambda\hbar^{2}}{2}	
		\left[k_{x}\sigma_{y} - k_{y}\sigma_{x}\right]
		\begin{bmatrix}
			\alpha\\
			\beta
		\end{bmatrix}
		 = E
		\begin{bmatrix}
			\alpha\\
			\beta
		\end{bmatrix}
	\end{equation*}
	
	\item If we insert the definitions of the Pauli matrices $ \sigma_{y} $ and $ \sigma_{x} $ and multiply out the matrices $ \sigma_{y} $ and $ \sigma_{x} $ with the spinor $ \big[\alpha, \beta\big]^{T} $, we end up with the matrix equation
	\begin{equation*}
		\begin{bmatrix}
			\frac{\hbar^{2}k^{2}}{2m} & \frac{\lambda \hbar}{2i}(k_{x} - ik_{y})\\
			-\frac{\lambda \hbar}{2i}(k_{x} + ik_{y}) & \frac{\hbar^{2}k^{2}}{2m}
		\end{bmatrix}
		\begin{bmatrix}
			\alpha\\
			\beta
		\end{bmatrix}
		= 
		E
		\begin{bmatrix}
			\alpha\\
			\beta
		\end{bmatrix}
	\end{equation*}
	This is exactly the same $ 2 \cross 2 $ eigenvalue problem as in the previous exercise set. The procedure from here forward is same as in the previous problem---we would solve the eigenvalue problem for the \Ham's energy eigenvalues and eigenfunctions as before.
	
	The lesson is that when working with particles with $ S = \frac{1}{2} $, we are able to use the Pauli spin matrix representation of the spin operator to derive the same eigenvalue problem as in the previous Hilbert space approach.
\end{itemize}

\subsubsection{Theory: Time Reversal Symmetry}
\begin{itemize}
	\item A problem is symmetric under time reversal if the problem's Hamiltonian $ H $ obeys $ [H, \T] = 0 $ where $ \T $ is time reversal operator. The time reversal operator is anti-unitary, i.e.
	\begin{equation*}
		\braket{\T\psi_{1}}{\T\psi_{2}} = \braket{\psi_{1}}{\psi_{2}}^{*}
	\end{equation*}
	where $ * $ denotes complex conjugation.
	
	\item From linear algebra, recall that a unitary operator $ U $ preserves the inner product, i.e.
	\begin{equation*}
		\braket{U\psi_{1}}{U\psi_{2}} = \braket{\psi_{1}}{\psi_{2}} 
	\end{equation*}
	If we move $ U $ from the ket to the bra term, the equality reads
	\begin{equation*}
		\bbraket{U^{\dagger}U\psi_{1}}{\psi_{2}} = \braket{\psi_{1}}{\psi_{2}} 
	\end{equation*}
	which implies a unitary operator must satisfy $ U^{\dagger}U = I $.
	
	\item We now introduce the complex conjugation operator $ K: \psi \mapsto \psi^{*} $. We will now show that if $ \T $ is written as the product of a unitary operator $ U $ and the conjugation operator $ K $, then $ \T $ is anti-unitary:
	\begin{align*}
		\braket{\T\psi_{1}}{\T\psi_{2}} &= \braket{UK\psi_{1}}{UK\psi_{2}} = \bbraket{UU^{\dagger}K\psi_{1}}{K\psi_{2}}\\
		&= \braket{K\psi_{1}}{K\psi_{2}} = \int (K\psi_{1})^{*} (K\psi_{2})\diff V = \int (\psi_{1}^{*})^{*}\psi_{2}^{*}\diff V\\
		&= \int \psi_{2}^{*}\psi_{1}\diff V = \braket{\psi_{2}}{\psi_{1}} = \braket{\psi_{1}}{\psi_{2}}^{*}
	\end{align*}
	where results in the anti-unitary identity 
	\begin{equation*}
		\braket{\T\psi_{1}}{\T\psi_{2}} = \braket{\psi_{1}}{\psi_{2}}^{*}
	\end{equation*}
	
	\item Finally a theorem: for spin $ 1/2 $ particles, the time-reversal operator takes the form
	\begin{equation*}
		\T = i\sigma_{y}K
	\end{equation*}
	In this case (comparing to the general form $ \T = UK $) we have $ U = \i \sigma_{y} $. We can show that $ \T $ is anti-unitary by proving that $ U = i \sigma_{y} $ is unitary. The proof reads:
	\begin{equation*}
		U_{\dagger}U = \big[\sigma_{y}^{\dagger} i \sigma_{y}\big] = \sigma_{y} (-i) i \sigma_{y} = \sigma_{y}^{2} = I
	\end{equation*}
	Since $ U = i \sigma_{y} $ is indeed unitary, $ \T = UK $ is anti-unitary.
\end{itemize}
	
	
	
	
\subsubsection{Tine-Reversal Symmetry and Rashba Coupling}
\textit{Analyze the Rashba-coupled Hamiltonian from the previous two problems,}
\begin{equation*}
	H = \frac{p^{2}}{2m} + \frac{\lambda\hbar}{2} (p_{x}\sigma_{y} - p_{y}\sigma_{x}),
\end{equation*}
\textit{using the formalism of time-reversal symmetry for a particle with spin $ S = \frac{1}{2} $}.

\begin{itemize}	
	\item First, we will show the problem's Hamiltonian is invariant under time reversal, i.e. $ [H, \T] = 0 $. We can rewrite the commutation condition in the form $ H\T = \T H $ and multiply by $ \T^{-1} $ from the left to get
	\begin{equation*}
		H = \T H \T^{-1}
	\end{equation*}
	We will show $ H $ and $ \T $ commute by proving $ H = \T H \T^{-1} $.
	
	\item Recall from the theory section that for particles with spin $ S = \frac{1}{2} $, the time reversal operator is $ \T = i \sigma_{y} K $, where $ \sigma_{y} $ is the second Pauli spin matrix and $ K $ is the complex conjugation operator. Substituting $ \T = i \sigma_{y} K $ into the commutation condition gives
	\begin{equation*}
		\T H \T^{-1} = (i\sigma_{y}K)H(K^{-1}\sigma_{y}^{-1}i^{-1})
	\end{equation*}
	We simplify this expression by noting that $ K^{2} = I \implies K^{-1} = K$;  $ \sigma_{y} = \sigma_{y}^{-1} $; and $ i^{-1} = -i $, which results in
	\begin{align*}
		\T H \T^{-1} &= (i\sigma_{y}K)H(K\sigma_{y}(-i)) = i \sigma_{y} H^{*} K (K\sigma_{y}(-i)) \\
		&= i \sigma_{y} H^{\dagger} KK \sigma_{y}(-i) = i \sigma_{y}H^{*}\sigma_{y}(-i) \\
		&= \sigma_{y}H^{*} \sigma_{y}
	\end{align*} 
	Substituting in the Rashba-coupled \Ham $ H $ gives
	\begin{align*}
		\T H\T^{-1} &= \sigma_{y} \left[\frac{p^{2}}{2m} + \frac{\lambda\hbar}{2} (p_{x}\sigma_{y} - p_{y}\sigma_{x})\right]^{*}\sigma_{y} \\
		& = \sigma_{y}\left[\frac{p^{2}}{2m} + \lambda \frac{\hbar}{2}\left((-p_{x})(-\sigma_{y}) - (-p_{y})(\sigma_{x}) \right)\right]\sigma_{y}
	\end{align*}
	where we have used $ (p^{2})^{*} = p^{2} $; $ p_{x,y}^{*} = -p_{x,y} $; $ \sigma_{y}^{*} = -\sigma_{y} $ and $ \sigma_{x}^{*} = \sigma_{x} $. Multiplying out the above expression and applying $ \sigma_{y}^{2} = I $ and $ \sigma_{x}\sigma_{y} = -\sigma_{y}\sigma_{x} $ gives
	\begin{align*}
		\T H\T^{-1} & = \frac{p^{2}}{2m}\sigma_{y}^{2} + \frac{\lambda\hbar}{2}\left(p_{x}\sigma_{y}^{3} + p_{y}\sigma_{y}\sigma_{x}\sigma_{y}\right) = \frac{p^{2}}{2m} + \frac{\lambda\hbar}{2}\left(p_{x}\sigma_{y} + p_{y}(-\sigma_{x}\sigma_{y})\sigma_{y}\right)\\
		&= \frac{p^{2}}{2m} + \frac{\lambda\hbar}{2} \left(p_{x}\sigma_{y} - p_{y}\sigma_{x}\right) = H
	\end{align*}
	Because $ \T H\T^{-1} = \T$, $ H $ is invariant under time reversal.
	
	\item We will know make use of our Hamiltonian $ H $'s time invariance. We start with the stationary \Schro equation $ H \ket{\psi} = E \ket{\psi} $, apply $ \T $ to $ \ket{\psi} $ on both sides to get  $ H \T\ket{\psi} = E \T\ket{\psi} $, and use the commutativity of $ H $ and $ \T $ to get
	\begin{equation*}
		H \T \ket{\psi} = \T H \ket{\psi} = \T E \ket{\psi} = E \T \ket{\psi}
	\end{equation*}
	In other words, both $ \ket{\psi} $ and $ \T\ket{\psi} $ are eigenfunctions of $ H $. 
	
	\item Next, we consider the projection of $ \ket{\psi} $ onto $ \ket{\T \psi} $, i.e. $ \braket{\psi}{\T\psi} $. Applying the $ \T $'s anti-unitarity gives
	\begin{equation*}
		\braket{\psi}{\T\psi} = \braket{\T\psi}{\T(\T\psi)}^{*} = \braket{\T\psi}{\T^{2}\psi}^{*}
	\end{equation*}
	We find $ \T^{2} $ using the spin $ 1/2 $ identity $ \T = i \sigma_{y}K $:
	\begin{equation*}
		\T^{2} = i \sigma_{y}K i\sigma_{y}K = i\sigma_{y}(-i)(-\sigma_{y})K^{2} = -\sigma_{y} I = - I
	\end{equation*}
	Substituting $ \T^{2} = - I $ into the inner product $ \braket{\psi}{\T\psi} $ gives
	\begin{equation*}
		\braket{\psi}{\T\psi} = \braket{\T\psi}{\T^{2}\psi}^{*} = \braket{\T\psi}{-\psi}^{*} = -\braket{\T\psi}{\psi}^{*} = - \braket{\psi}{\T\psi}
	\end{equation*}
	which implies $ \braket{\psi}{\T\psi} = 0 $. In other words, the projection  $ \ket{\psi} $ onto $ \ket{\T \psi} $ is zero, meaning $ \ket{\psi} $ and $ \ket{\psi} $ are orthogonal and thus linearly independent.
	
	
	\item To summarize: For a spin $ 1/2 $ particle (which has $ \T^{2} = -I $) whose Hamiltonian is invariant under time reversal, if $ \ket{\psi} $ is a solution of the stationary \Schro equation
	\begin{equation*}
		H \ket{\psi} = E\ket{\psi}
	\end{equation*}
	then the wavefunction $ \T\ket{\psi} $ also solves the stationary \Schro equation with the same energy eigenvalue, and $ \ket{\psi} $ is orthogonal to $ \T \ket{\psi} $. 
	
	This means every eigenstate of a $ \T $-invariant spin $ 1/2 $ Hamiltonian has degeneracy of at least two, since we have two linearly independent solutions $ \ket{\psi} $ and $ \T \ket{\psi} $ for each energy eigenvalue. This result is called \textit{Kramers degeneracy}, and $ (\ket{\psi}, \T\ket{\psi}) $ are called a \textit{Kramers pair. }

	\item Next, referring to the solutions from the previous two problem, we will identify the Kramer's pairs in the energy eigenstates of the Rasbha-coupled Hamiltonian. Recall that for a given $ \k $, the \Ham has energy eigenvalues
	\begin{equation*}
		E_{\pm} = \frac{\hbar^{2}k^{2}}{2m} \pm \frac{\lambda\hbar^{2}k}{2},
	\end{equation*}
	with corresponding eigenfunctions
	\begin{equation*}
		\ket{\psi_{\pm}} = \frac{\ket{\k}}{\sqrt{2}}\left(\ket{\ua} \pm ie^{i\phi}\ket{\da}\right)
	\end{equation*}
	where we wrote the wave vector $ \k $ in polar coordinates as $ \k = (k, \phi) $. 
	
	\item We consider the solution $ \psi_{+} $. Theory predicts that the Kramer's pair $ \T \ket{\psi_{+}} $ is also an energy eigenstate with the same eigenvalue and is orthogonal to $ \ket{\psi_{+}} $---we'll see if this is the case. Writing $ \ket{\k} $ in the coordinate wavefunction representation and working in terms of spinors, the Kramer's pair $ \T \ket{\psi_{+}} $ is
	\begin{align*}
		\T \ket{\psi_{+}} & = \T \left[\frac{\ket{\k}}{\sqrt{2}}\left(\ket{\ua} + ie^{i\phi}\ket{\da}\right) \right]= (i \sigma_{y}K)e^{i\k\cdot \vec{r}} 
		\begin{bmatrix}
			\alpha\\
			\beta
		\end{bmatrix}
		= 
		i 
		\begin{bmatrix}
			0 & -i\\
			i & 0
		\end{bmatrix}
		e^{-i\k\cdot \vec{r}} 
		\begin{bmatrix}
			\alpha^{*}\\
			\beta^{*}
		\end{bmatrix}
		\\
		&= 
		e^{-i\k\cdot \vec{r}} 
		\begin{bmatrix}
			0 & 1\\
			-1 & 0
		\end{bmatrix}
		\begin{bmatrix}
			\alpha^{*}\\
			\beta^{*}
		\end{bmatrix}
		 = e^{-i\k\cdot \vec{r}} 
		\begin{bmatrix}
			\beta^{*}\\
			-\alpha^{*}
		\end{bmatrix}
	\end{align*}
	Returning to Dirac notation and noting that $ \alpha = \frac{1}{\sqrt{2}} $ and $ \beta = \frac{ie^{i\phi}}{\sqrt{2}} $, we have
	\begin{align*}
		\T \ket{\psi_{+}} &= \ket{-\k}  \left(\beta^{*} \ket{\ua} - \alpha^{*}\ket{\da}\right) = \ket{-\k} \left[\frac{-ie^{-i\phi}}{\sqrt{2}}\ket{\ua} - \frac{1}{\sqrt{2}}\ket{\da}\right] \\
		&= -ie^{-i\phi}\ket{-\k} \frac{\ket{\ua} - i e^{i\phi}\ket{\da}}{\sqrt{2}}
	\end{align*}
	The phase factor $ -ie^{-i\phi} $ has magnitude one; since a wavefunction is determined only up to a constant phase factor of magnitude one, the above is equivalent to
	\begin{align*}
		\T \ket{\psi_{+}} &= \ket{-\k} \frac{\ket{\ua} - i e^{i\phi}\ket{\da}}{\sqrt{2}}\\
		&=\ket{-\k} \frac{\ket{\ua} + i e^{i(\phi + \pi)}\ket{\da}}{\sqrt{2}}
	\end{align*}
	where the second line uses the identity $ -i = ie^{i\pi} $. Recall the original eigenstate $ \ket{\psi_{+}} $ has a phase angle $ \phi $, corresponding to the direction of $ \k $ and spin up. It's Kramer pair $ \T\ket{\psi_{+}} $ has phase angle $ \phi + \pi $, corresponding to the direction $ -\k $ and spin down. 
\end{itemize}
	
\subsubsection{Scattering on a Spin-Dependent Delta Function in 1D}
\textit{Consider a spin-dependent scattering problem with two particles: particle 1 with spin $ S_{1} = \frac{1}{2} $ in the state $ \ket{\ua} $ and particle $ 2 $ with spin $ S_{2} = 1 $ in the state $ \ket{10} $. The particles have the Hamiltonian}
\begin{equation*}
	H = \frac{p_{1}^{2}}{2m} - \frac{\lambda}{\hbar^{2}}\vec{S}_{1}\cdot \vec{S}_{2}\delta(x)
\end{equation*}
\textit{Particle $ 2 $ is fixed at the origin at $ x = 0 $ and particle $ 1 $ approaches and hits particle $ 2 $ from the region $ x \to -\infty $. Determine the particle's spins after the collision.}


\begin{itemize}
	\item First, we'll establish the problem's Hilbert space and choose an appropriate basis. The total Hilbert space is $ \H = \H_{p} \otimes \H_{1} \otimes \H_{2} $. $ \H_{p} $ is the momentum space of the first particle and $ \H_{1,2} $  are the spin spaces of the first and second particles, respectively. Note that the second particle's Hilbert space doesn't have a momentum component because particle 2 is fixed at the origin and doesn't move.
	
	The first particle has spin $ S = \frac{1}{2} $, so its spin Hilbert space $ \H_{1} $ is two-dimensional, and we will use the standard basis $ \ket{\ua} $ and $ \ket{\da} $. The second particle has spin $ S = 1 $ and thus a three-dimensional space; we'll use the basis functions$ \ket{11} $, $ \ket{10} $ and $ \ket{1-1} $.
	
	\item Next, we determine a basis for the combined spin space $ \H_{1} \otimes \H_{2} $. There are two good options:
	\begin{enumerate}
		\item A product basis, which uses commutativity of $ S_{1}^{2} $, $ S_{1z} $, $ S_{2}^{2} $, and $ S_{2z} $, which implies the existence of eigenfunctions that are simultaneously eigenfunctions of all four operators. The product basis consists of the states 
		\begin{equation*}
			\big\{\ket{\ua}\ket{11},\ \ket{\ua}\ket{10},\ \ket{\ua}\ket{1-1},\ \ket{\da}\ket{11},\ \ket{\da}\ket{10},\ \ket{\da}\ket{1-1}   \big\}
		\end{equation*}
		This set is just all possible combinations of the products of the basis functions of the individual spin spaces $ \H_{1} $ and $ \H_{2} $.
		
		\item The other possible basis is the total angular momentum basis, which works in terms of the total spin operator $ \vec{S} = \vec{S}_{1} + \vec{S}_{2} $. This basis uses commutativity of $ S^{2} $, $ S_{z} $, $ S_{1}^{2} $, and $ S_{2}^{2} $.
			
		In general, the total spin operator obeys $ \abs{S_{1} - S_{2}} \leq S \leq S_{1} + S_{2} $. In our case with $ S_{1} = \frac{1}{2} $  and $ S_{2} = 1 $, the above relationship implies $ S \in \big\{ \frac{1}{2}, \frac{3}{2} \big\} $.
			
		In our case the good spin basis would be
		\begin{equation*}
			\left\{ \ket{\tfrac{3}{2}, \tfrac{3}{2} \tfrac{1}{2} 1},\  \ket{\tfrac{3}{2}, \tfrac{1}{2} \tfrac{1}{2} 1},\  \ket{\tfrac{3}{2}, -\tfrac{1}{2} \tfrac{1}{2} 1} \, \ket{\tfrac{3}{2}, -\tfrac{3}{2} \tfrac{1}{2} 1},\ \ket{\tfrac{1}{2}, \tfrac{1}{2} \tfrac{1}{2} 1},\  \ket{\tfrac{1}{2}, -\tfrac{1}{2} \tfrac{1}{2} 1}  \right\}
		\end{equation*}
		By convention, because $ S_{1} = \frac{1}{2} $ and $ S_{2} = 1 $ remain fixed throughout the problem, we drop the last two terms $ \tfrac{1}{2} 1 $ of each basis state and write the basis functions as
		\begin{equation*}
			\left\{ \ket{\tfrac{3}{2}, \tfrac{3}{2} },\  \ket{\tfrac{3}{2}, \tfrac{1}{2} },\  \ket{\tfrac{3}{2}, -\tfrac{1}{2} } \, \ket{\tfrac{3}{2}, -\tfrac{3}{2} },\ \ket{\tfrac{1}{2}, \tfrac{1}{2} },\  \ket{\tfrac{1}{2}, -\tfrac{1}{2}}  \right\}
		\end{equation*}
				
	\end{enumerate}
	\textit{We ran out of time at this point and continue the problem in the next exercise set.}	
\end{itemize}



\subsection{Eleventh Exercise Set}

\subsubsection{Scattering on a Spin-Dependent Delta Function (continued)}
\textit{Consider a spin-dependent scattering problem with two particles: particle 1 with spin $ S_{1} = 1/2 $ in the state $ \ket{\ua} $ and particle $ 2 $ with spin $ S_{2} = 1 $ in the state $ \ket{10} $. The particles have the Hamiltonian}
\begin{equation*}
	H = \frac{p_{1}^{2}}{2m} - \frac{\lambda}{\hbar^{2}}\vec{S}_{1}\cdot \vec{S}_{2}\delta(x)
\end{equation*}
\textit{Particle $ 2 $ is fixed at the origin at $ x = 0 $ and particle $ 1 $ approaches and hits particle $ 2 $ from the region $ x \to -\infty $. Determine the particle's spins after the collision.}


\begin{itemize}
	\item Review from the last exercise set: we had just begun the problem, and established the two possible bases to describe the problem---the product basis and the total angular momentum basis.
	
	\item Next we'll review the problem of scattering in a spinless delta potential (from the second exercise set) where the Hamiltonian is
	\begin{equation*}
		H = \frac{p^{2}}{2m} + \lambda \delta (x)
	\end{equation*}
	We describe free scattering states with energy $ E > 0 $ with the scattering matrix
	\begin{equation*}
		\mat{S} = 
		\begin{bmatrix}
			r & t'\\
			t & r'
		\end{bmatrix}
		 = 
		 \frac{1}{k + i \kappa}
		 \begin{bmatrix}
		 	- i\kappa & k\\
		 	k	& - i\kappa
		 \end{bmatrix}
	\end{equation*}
	If we send a particle in towards the delta potential from the left, the particle is partly reflected and partly transmitted, according to
	\begin{equation*}
		\psi(x < 0) = e^{ikx} + re^{-ikx} \eqtext{and} \psi(x>0) te^{ikx}
	\end{equation*}
	Recall that the scattering matrix $ \mat{S} $ is unitary and thus obeys $ \mat{S}^{\dagger}\mat{S} = \mat{I} $. Finally, recall the coefficient parameters obey $ \abs{t}^{2} + \abs{r}^{2} = T + R = 1 $, where $ T $ and $ R $ are the probability of transmission and reflection, respectively.
	
	\item From the last exercise set, recall the system's Hilbert space is
	\begin{equation*}
		\H = \H_{p} \otimes \H_{1} \otimes \H_{2}
	\end{equation*}
	where the combined spin Hilbert space $ \H_{1} \otimes \H_{2} $ is six-dimensional.
	
	We identified two possible bases for use with our problem: The first is a product basis using the commutativity of $ S_{1}^{2} $, $ S_{z_{1}} $, $ S_{2}^{2} $ and $ S_{z_{2}} $. 
	
	Nominally, the states in this basis are written $ \ket{S_{1}m_{1}S_{2}m_{2}} $, but because the particle spins $ S_{1} $ and $ S_{2} $ are fixed at $ 1/2 $ and $ 1 $, respectively, we adopt a shorthand convention and write the states simply as $ \ket{m_{1}m_{2}} $, with $ S_{1} = 1/2 $ and $ S_{2} = 1 $ implicit.
	
	\item The second basis, called the total angular momentum basis, uses the commutativity of $ S_{2} $, $ S_{z} $, $ S_{1}^{2} $ and $ S_{2}^{2} $. Recall total spin is the vector sum $ \vec{S} = \vec{S}_{1} + \vec{S}_{2} $.  We write the states in this basis as
	\begin{equation*}
		\ket{SS_{1}S_{2}m} \eqtext{or, in shorthand,} \ket{Sm}
	\end{equation*}
	Again, by convention, we leave out the $ S_{1} $ and $ S_{2} $ for conciseness because their values are fixed at $ S_{1} = 1/2 $ and $ S_{2} = 1 $, respectively.
	
	We transform between the bases using the \textit{Clebsch-Gordan coefficients}.
\end{itemize}
\textbf{End of Review, Start of New Material}
\begin{itemize}
	\item Recall the Hamiltonian for our spin-dependent scattering problem is
	\begin{equation*}
		H = \frac{p_{1}^{2}}{2m} - \frac{\lambda}{\hbar^{2}}\vec{S}_{1} \cdot \vec{S}_{2}\delta (x_{1})
	\end{equation*}
	First, we'll rewrite the dot product using the total spin operator identity
	\begin{equation*}
		\vec{S} = \vec{S}_{1} + \vec{S}_{2} \implies S^{2} = S_{1}^{2} + 2\vec{S}_{1}\vec{S}_{2} + S_{2}^{2},
	\end{equation*}
	which implies 
	\begin{equation*}
		\vec{S}_{1}\cdot \vec{S}_{2} = \frac{S^{2} -S_{1}^{2} - S_{2}^{2}}{2}
	\end{equation*}
	Substituting this expression for $ \vec{S}_{1}\cdot \vec{S}_{2} $ into the Hamiltonian gives
	\begin{equation*}
		H = \frac{p_{1}^{2}}{2m} -  \frac{\lambda}{2\hbar^{2}}(S^{2} -S_{1}^{2} - S_{2}^{2})\delta(x)
	\end{equation*}
	
	\item Next note that the \Ham $ H $ commutes with the spin operators:
	\begin{equation*}
		[H, S^{2}] = [H, S_{1}^{2}] = [H, S_{2}^{2}] = [H, S_{z}] = 0
	\end{equation*}
	Because $ H $ commutes with all of the spin basis operators, we can find eigenfunctions that are eigenfunctions of both $ H $ and all of the spin operators simultaneously.
	
	\item Next, we solve the stationary \Schro equation:
	\begin{equation*}
		H \ket{\psi} = E\ket{\psi}
	\end{equation*}
	Because $ H $ and the spin operators commute, we can factor the system's wavefunction into a momentum and spin portion of the form $ \ket{\psi} = \ket{\psi_{1}} \otimes \ket{Sm} $. This factorization gives
	\begin{align*}
		H \ket{\psi_{1}} \otimes \ket{Sm} &= \left(\frac{p_{1}^{2}}{2m}\ket{\psi_{1}}\right)\otimes \ket{Sm} - \frac{\lambda}{2\hbar^{2}} \delta (x_{1})\ket{\psi_{1}}\otimes (S^{2} -S_{1}^{2} - S_{2}^{2}) \ket{Sm}\\
		&= E \ket{\psi_{1}}\otimes \ket{Sm}
	\end{align*}
	We stress that the factorization $ \ket{\psi} = \ket{\psi_{1}} \otimes \ket{Sm} $ is possible only because $ H $ commutes with each spin operator.
	
	\item The spin operators $ S $, $ S_{1} $ and $ S_{2} $ then act on their corresponding eigenstates to give
	\begin{align*}
		H \ket{\psi_{1}} \otimes \ket{Sm} &= \left(\frac{p_{1}^{2}}{2m}\ket{\psi_{1}}\right)\otimes \ket{Sm} - \frac{\lambda}{2\hbar^{2}} \delta (x_{1})\ket{\psi_{1}}\otimes \big[\hbar^{2}S(S+1) \\
		&{} \qquad  - \hbar^{2}S_{1}(S_{1} + 1) - \hbar^{2}S_{2}(S_{2} + 1)\big] \ket{Sm} \\
		&= E \ket{\psi_{1}}\otimes \ket{Sm}
	\end{align*}
	Conveniently, $ \ket{Sm} $ cancels from both sides of the equation. Substituting in $ S_{1} = 1/2 $ and $ S_{2} = 1 $ produces the purely momentum problem
	\begin{equation*}
		\left(\frac{p_{1}^{2}}{2m} - \frac{\lambda \delta(x)}{2}\big[S(S+1) - \frac{3}{4} - 2\big]\right)\ket{\psi_{1}} = E \ket{\psi_{1}}
	\end{equation*}
	where $ \ket{\psi_{1}} $ is the first particle's momentum wavefunction. Note that this equation depends only on the size $ S $ of the total spin, not on the $ z $ components. For our problem with $ S_{1} = 1/2 $ and $ S_{2} = 1 $, the identity $ \abs{S_{1} - S_{2}} \leq S \leq S_{1} + S_{2} $ means there are only two possible values for $ S $; these are $ S = 1/2 $ and $ S = 3/2 $. 
	
	\item For $ S = 3/2 $ we have
	\begin{equation*}
		\left[\frac{p_{1}^{2}}{2m} - \frac{\lambda \delta(x)}{2}\right]\ket{\psi_{1}} = E \ket{\psi_{1}}
	\end{equation*}
	For $ S = 1/2 $ we have
	\begin{equation*}
		\left[\frac{p_{1}^{2}}{2m} + \lambda \delta(x)\right]\ket{\psi_{1}} = E \ket{\psi_{1}}
	\end{equation*}
	In other words, using the commutation of $ H $ and the spin operators, we have transformed our problem to a problem in only the momentum Hilbert space. All spin dependence is gone; the eigenvalues depend only on the delta function parameter $ \lambda $. 
	
	\item A delta function potential has a bound state only for a downward-pointing delta function, which occurs if the delta function's coefficient is negative. Looking at the above equations for $ S = 1/2$ and $ S = 3/2 $, we see we have a bound state only for $ S = 3/2 $, where the $ \delta(x) $ term has a negative coefficient. For $ S = 1/2 $, the $ \delta $ function has a positive coefficient, and their is no bound state.
	
	\item For conciseness, we define the constants 
	\begin{equation*}
		\lambda_{3/2} = \frac{\lambda}{2} \eqtext{and} \lambda_{1/2} = - \lambda
	\end{equation*}
	The $ S = 3/2 $ and $ S = 1/2 $ eigenvalue equations involving $ \ket{\psi_{1}} $ then read
		\begin{equation*}
			\frac{p_{1}^{2}}{2m} - \lambda_{3/2}\delta(x) = H_{3/2} \eqtext{and} \frac{p_{1}^{2}}{2m} - \lambda_{1/2}\delta(x) = H_{1/2} 
		\end{equation*}
		
	\item Recall (e.g. from the second exercise set) that a bound state in a delta potential $ V(x) = - \lambda \delta(x) $ has the wavefunction
	\begin{equation*}
		 \psi_{0}(x) = \sqrt{\kappa} e^{-\kappa \abs{x}}, \qquad \text{where } \kappa = \frac{m\lambda}{\hbar^{2}}
	\end{equation*}
	and corresponding energy eigenvalue $  E_{0} = \frac{m\lambda^{2}}{2\hbar^{2}} $.
	
	
	\item For the $ S = 3/2 $ problem, which has a bound state, the quantity $ \kappa $ is
	\begin{equation*}
		\kappa_{3/2} = \frac{M\lambda_{3/2}}{\hbar^{2}} = \frac{M\lambda}{2\hbar^{2}},
	\end{equation*}
	and the corresponding bound eigenfunction is
	\begin{equation*}
		\ket{\psi_{0}^{M}} = \sqrt{\kappa_{3/2}}e^{-\kappa_{3/2}\abs{x}} \ket{\tfrac{3}{2}\tfrac{1}{2}}
	\end{equation*}
	where we have substituted in $ M = \frac{1}{2} $, which comes from $ M = m_{1} + m_{2} = \frac{1}{2} + 0 = \frac{1}{2} $.
	
	This state is four-times degenerate because four linearly independent eigenfunctions (one each for $ M \in \big[-\frac{3}{2}, -\frac{1}{2}, \frac{1}{2}, \frac{3}{2}\big] $) all have the same energy eigenvalue $ E_{0} = \frac{M\lambda_{3/2}^{2}}{2\hbar^{2}} $. 
	
	\item \textit{Side Note}: Technically, we are guilty of a slight abuse of notation. Namely, we've used both coordinate and Dirac notation when writing the wavefunction
	\begin{equation*}
		\ket{\psi_{0}^{M}} = \sqrt{\kappa_{3/2}}e^{-\kappa_{3/2}\abs{x}} \ket{\tfrac{3}{2}\tfrac{1}{2}}
	\end{equation*}
	To resolve this, for the rest of the problem we define 
	\begin{equation*}
		\psi(x)\ket{SM} \equiv \left[\int \psi(x) \ket{x} \diff x \right] \ket{SM}
	\end{equation*}
	
	\item Having discussed the single bound state for $ S = 3/2 $, we now consider the free scattering states. Recall that for a particle incident on the origin from the left, after scattering, the wavefunction on $ x \in (-\infty, 0) $ (to the left of the delta potential) takes the general form:
	\begin{equation*}
		\ket{\psi_{-}} = \left(e^{ik x} + re^{-i\kappa x}\right)\ket{SM},
	\end{equation*}
	This ansatz contains the incident wave $ e^{ikx} $ and the reflected wave $ re^{-ikx} $. 
	
	The wavefunction on $ x \in (0, \infty)  $ (to the right of the delta potential) takes the form
	\begin{equation*}
		\ket{\psi_{+}} = t e^{ikx}\ket{SM}
	\end{equation*}
	where $ te^{ikx} $ is the transmitted wave.
	
	\item For our problem (reusing the results from the delta function scattering problem in the second exercise set), the scattering matrix is
	\begin{equation*}
		\mat{S}_{S} = 
		\begin{bmatrix}
			r_{S} & t_{S}\\
			t_{S} & r_{S}
		\end{bmatrix}
		= 
		\frac{1}{k + i \kappa_{S}}
		\begin{bmatrix}
			-i\kappa_{S} & k\\
			k & -i \kappa_{S}
		\end{bmatrix}
	\end{equation*}
	where we have introduced a subscript $ _{S} $ to make the dependence of $ r $ and $ t $ on the value of the total spin $ S $ explicit. The possible values of $ \kappa_{S} $ for $ S \in \{1/2, 3/2\} $ are
	\begin{equation*}
		\kappa_{3/2} \equiv \frac{m\lambda_{3/2}}{\hbar^{2}} = \frac{m\lambda}{2\hbar^{2}} \eqtext{and} \kappa_{1/2} \equiv \frac{m\lambda_{1/2}}{\hbar^{2}} = - \frac{m\lambda}{\hbar^{2}}
	\end{equation*}
	
	\item For our scattering problem---involving a particle incident from the left---the reflected and transmitted eigenfunctions for $ S \in \{1/2, 3/2\} $, namely
	\begin{align*}
		&\ket{\psi^{(1/2)}_{-}} = \left(e^{ik x} + r_{1/2}e^{-i\kappa x}\right)\ket{\tfrac{1}{2}\tfrac{1}{2}} \quad \ket{\psi^{(1/2)}_{+}} = t_{1/2} e^{ikx}\ket{\tfrac{1}{2}\tfrac{1}{2}}\\
		&\ket{\psi^{(3/2)}_{-}} = \left(e^{ik x} + r_{3/2}e^{-i\kappa x}\right)\ket{\tfrac{3}{2}\tfrac{1}{2}} \quad \ket{\psi^{(3/2)}_{+}} = t_{3/2} e^{ikx}\ket{\tfrac{3}{2}\tfrac{1}{2}}
	\end{align*}
% Why isn't k dependent on S?	
%	\begin{align*}
%		&\ket{\psi^{(1/2)}_{-}} = \left(e^{ik_{1/2} x} + r_{1/2}e^{-i\kappa x}\right)\ket{\tfrac{1}{2}\tfrac{1}{2}} \quad \ket{\psi^{(1/2)}_{+}} = t_{1/2} e^{ik_{1/2}x}\ket{\tfrac{1}{2}\tfrac{1}{2}}\\
%		&\ket{\psi^{(3/2)}_{-}} = \left(e^{ik_{3/2} x} + r_{3/2}e^{-i\kappa x}\right)\ket{\tfrac{3}{2}\tfrac{1}{2}} \quad \ket{\psi^{(3/2)}_{+}} = t_{3/2} e^{ik_{3/2}x}\ket{\tfrac{3}{2}\tfrac{1}{2}}
%	\end{align*}
	form a complete basis of the momentum Hilbert space of free scattering states. In the remainder of the problem, we will use these basis states to construct the initial and final scattering states in our specific problem. Again, recall that each basis state contains $ M = 1/2 $, since the total $ z $-component of spin is $ M = m_{1} + m_{2} = \frac{1}{2} + 0  = \frac{1}{2}$.
	
	\item Just to review what the problem asks for: particle 1, in state $ \ket{\ua} $, is incident from the left on particle 2, which is fixed at the origin and in state $ \ket{0} $, and we are interested in the scattered spin states of the two particles.
	
	The incident part of the wavefunction takes the form
	\begin{equation*}
		\ket{\psi_{\text{in}}} = e^{ikx} \ket{\ua} \ket{0}
	\end{equation*}
	Note that this wavefunction is written in the product basis---it is the product of the first particle's spin state $ \ket{\ua} $ and the second particle's spin state $ \ket{0} $. However, the above eigenfunctions $ \bket{\psi^{(S)}_{-}} $ and $ \bket{\psi^{(S)}_{+}} $ spanning the Hilbert space of free scattering are written in the total angular momentum basis.
	
	At this point, we need a way to transform the initial state from the product basis to the total angular momentum basis---we make the transformation using the Clebsch-Gordan (CG) coefficients.
\end{itemize}	

\begin{figure}[hbtb!]
\centering
\includegraphics[width=0.75\linewidth]{cg-coefficients}
\caption{The Clebsch-Gordan coefficients for two particles with spins $ S_{1} = 1/2 $ and $ S_{2} = 1 $.}
\label{fig:cg}
\end{figure}
	
	
\textbf{Using the Clebsch-Gordan Coefficients}	
\begin{itemize}
	\item First, using a table of CG coefficients, find the sub-table whose heading has the correct combination $ S_{1} \cross S_{2} $ of spin numbers for each particle. In our case, our particles have spins $ S_{1} = 1/2 $ and $ S_{2} = 1 $, so we use the $ 1 \cross 1/2 $ table, shown in Figure \ref{fig:cg} (note that the order of $ S_{1} $ and $ S_{2} $ is not important in this step.
	
	\item We start with the initial state $ \ket{\ua}\ket{0} \equiv \ket{1/2}\ket{0} $, which is written in the product basis. In the CG table, we find the row containing $ 0 $ and $ +1/2 $. The row immediately to the right contains the numbers $ 2/3 $ and $ -1/3 $---these are coefficients. Each coefficient has an implicit square root---for example $ -1/3 $ means $ -\sqrt{1/3} $---but the square roots are not written for conciseness. 
	
	For each coefficient, in this case $ 2/3 $ and $ -1/3 $, we find the column in the box immediately above. For $ 2/3 $, the column above is $ 3/2, +1/2 $, and for the coefficient $ -1/3 $, the column above is $ 1/2, +1/2 $. The columns represent states in the total angular momentum basis---the top row, in this case $ 3/2 $ and $ 1/2 $, represents values of $ S $, and the bottom row, in this case $ +1/2 $ and $ +1/2 $, represents values of $ M $. Put together, each column is a basis state $ \ket{SM} $.

	We assemble the transformation between the product and total angular momentum basis as follows:
	\begin{equation*}
		\ket{\ua} \ket{0} \equiv \ket{\tfrac{1}{2}}\ket{0} \to \sqrt{\tfrac{2}{3}} \ket{\tfrac{3}{2}\tfrac{1}{2}} - \tfrac{1}{\sqrt{3}}\ket{\tfrac{1}{2}\tfrac{1}{2}}
	\end{equation*}
	Using the above transformation of $ \ket{\ua}\ket{0} $, the initial incident wavefunction is written in the total angular momentum basis as
	\begin{equation*}
		\ket{\psi_{\text{in}}} = e^{ikx}\ket{\ua} \ket{0} = e^{ikx}\left(\sqrt{\tfrac{2}{3}} \ket{\tfrac{3}{2}\tfrac{1}{2}} - \sqrt{\tfrac{1}{3}}\ket{\tfrac{1}{2}\tfrac{1}{2}}\right)
	\end{equation*}
	
	\item Recall the basis states on the region $ x < 0 $ are
	\begin{align*}
		&\ket{\psi_{-}^{(1/2)}} = \left(e^{ikx} + r_{1/2}e^{-ikx}\right)\ket{\frac{1}{2}\frac{1}{2}}\\
		& \ket{\psi_{-}^{(3/2)}} = \left(e^{ikx} + r_{3/2}e^{-ikx}\right)\ket{\frac{3}{2}\frac{1}{2}},
	\end{align*}
	while the second set of basis states, for the region $ x > 0 $, are
	\begin{align*}
		&\ket{\psi_{+}^{(1/2)}} =  t_{1/2}e^{ikx}\ket{\frac{1}{2}\frac{1}{2}} \eqtext{and}\ket{\psi_{+}^{(3/2)}} = t_{3/2}e^{ikx}\ket{\frac{3}{2}\frac{1}{2}}
	\end{align*}
	
	\item Our next step is to construct our specific scattering problem's wavefunctions on the regions $ x < 0 $ and $ x > 0 $ using the using the above basis functions. 
	
	To do this, we first note that the incident state $ \ket{\psi_{\text{in}}} $ contains the state $ \ket{\tfrac{3}{2}\tfrac{1}{2}} $ with coefficient $ \sqrt{\tfrac{2}{3}} $, and the state $ \ket{\tfrac{1}{2}\tfrac{1}{2}} $ with coefficient $ -\sqrt{\tfrac{1}{3}} $. We thus construct the wavefunction $ \ket{\psi_{-}} $, which describes the particle on the region $ x < 0 $, from a linear combination of the basis state $ \bket{\psi_{-}^{(3/2)}} $ (which contains $ \ket{\tfrac{3}{2}\tfrac{1}{2}} $) weighted by $  \sqrt{\tfrac{2}{3}}  $, and the basis state $ \bket{\psi_{-}^{(1/2)}} $ (which contains $ \ket{\tfrac{1}{2}\tfrac{1}{2}}  $ ) weighted by $ -\sqrt{\tfrac{1}{3}}  $. The result is 
	\begin{equation*}
		\ket{\psi_{-}} = \sqrt{\frac{2}{3}}\left(e^{ikx} + r_{3/2}e^{-ikx}\right)\ket{\frac{3}{2}\frac{1}{2}} - \sqrt{\frac{1}{3}}\left(e^{ikx} + r_{1/2}e^{-ikx}\right)\ket{\frac{1}{2}\frac{1}{2}}
	\end{equation*}
	Similarly, we construct $ \ket{\psi_{\text{+}}} $, which describes our scattering problem on the region $ x > 0 $, via
	\begin{equation*}
		\ket{\psi_{+}} = \sqrt{\frac{2}{3}}\left(t_{3/2}e^{ikx}\ket{\frac{3}{2}\frac{1}{2}}\right) - \sqrt{\frac{1}{3}}\left(t_{1/2}e^{ikx}\ket{\frac{1}{2}\frac{1}{2}} \right)
	\end{equation*}
	Recognizing the expression for $ \ket{\psi_{\text{in}}} $ with $ \ket{\psi_{i}} $ and factoring out the common exponential factors gives
	\begin{align*}
		&\ket{\psi_{-}}= e^{ikx}\ket{\ua}\ket{0} + e^{-ikx}\left( \sqrt{\frac{2}{3}} r_{3/2}\ket{\frac{3}{2}\frac{1}{2}} - \sqrt{\frac{1}{3}} r_{1/2}\ket{\frac{1}{2}\frac{1}{2}} \right)\\
		&\ket{\psi_{+}} = 	e^{ikx}\left(\sqrt{\frac{2}{3}}t_{3/2}\ket{\frac{3}{2}\frac{1}{2}} - \sqrt{\frac{1}{3}}t_{1/2}\ket{\frac{1}{2}\frac{1}{2}}\right)
	\end{align*}
	Technically, these two wavefunctions complete describe our scattering problem. The $ e^{ikx}\ket{\ua}\ket{0} $ term in $ \ket{\psi_{-}} $ encodes the incident wave $ \ket{\psi_{\text{in}}} $, the remaining terms in $ \ket{\psi_{-}} $ encode the reflected scattered states, and the terms in $ \ket{\psi_{+}} $ encode the transmitted scattered states.
	
	\item However, $ e^{ikx}\ket{\ua}\ket{0} $ is written in the product basis and the other terms are written in the total angular momentum basis. For consistency, we will now transform the total angular momentum terms $ \ket{\frac{3}{2}\frac{1}{2}}  $ and $ \ket{\frac{1}{2}\frac{1}{2}} $ from the total angular momentum basis to the product bases. Again, we make the transformation with the CG coefficients.
	
	We start with the state $ \ket{\frac{3}{2}\frac{1}{2}} $. In the CG table, we find the column containing $ 3/2 $ and $ +1/2 $, which correspond to $ S $ and $ M $ in the total angular momentum picture. The column below, in this case $ 1/3 $ and $ 2/3 $, contains the coefficients needed for the transformation to the product basis. The row to the left of each coefficient ($ +1 $, $ -1/2 $ for the coefficient $ 1/3 $ and $ 0 $, $ +1/2 $ for the coefficient $ 2/3 $) represents the corresponding states in the product basis; each coefficient applies to its corresponding state. The transformation of $ \ket{\frac{3}{2}\frac{1}{2}} $ to the product basis reads
	\begin{equation*}
		\ket{\frac{3}{2}\frac{1}{2}}  \to \sqrt{\frac{1}{3}}\ket{\da}\ket{1} +  \sqrt{\frac{2}{3}}\ket{\ua}\ket{0} 
	\end{equation*}
	Analogously, the transformation of $ \ket{\frac{1}{2}\frac{1}{2}} $ to the product basis reads
	\begin{equation*}
		\ket{\frac{1}{2}\frac{1}{2}}  \to \sqrt{\frac{2}{3}}\ket{\da}\ket{1} - \sqrt{\frac{1}{3}}\ket{\ua}\ket{0} 
	\end{equation*}
	
	\item Substituting in the product basis representations of $ \ket{\frac{3}{2}\frac{1}{2}} $ and $ \ket{\frac{1}{2}\frac{1}{2}} $ into the state $ \ket{\psi_{-}} $ gives
	\begin{align*}
		\ket{\psi_{-}} = e^{ikx}\ket{\ua}\ket{0} + e^{-ikx} & \Bigg[\sqrt{\frac{2}{3}}r_{3/2}\left(\sqrt{\frac{1}{3}}\ket{\da}\ket{1} +  \sqrt{\frac{2}{3}}\ket{\ua}\ket{0}\right) \\
		& - \sqrt{\frac{1}{3}}r_{1/2}\left( \sqrt{\frac{2}{3}}\ket{\da}\ket{1} - \sqrt{\frac{1}{3}}\ket{\ua}\ket{0} \right)\Bigg]
	\end{align*}
	The state $ \ket{\psi_{-}}  $ is now fully transformed back to the product basis. 
	
	Similarly, the product basis representation of $ \ket{\psi_{+}} $ is
	\begin{align*}
		\ket{\psi_{+}} =  e^{ikx}& \Bigg[\sqrt{\frac{2}{3}}t_{3/2}\left(\sqrt{\frac{1}{3}}\ket{\da}\ket{1} +  \sqrt{\frac{2}{3}}\ket{\ua}\ket{0}\right) \\
		&- \sqrt{\frac{1}{3}}t_{1/2}\left( \sqrt{\frac{2}{3}}\ket{\da}\ket{1} - \sqrt{\frac{1}{3}}\ket{\ua}\ket{0} \right)\Bigg]
	\end{align*}
	
	\item Next, we combine like terms in $ \ket{\psi_{-}} $ to get
	\begin{align*}
		\ket{\psi_{-}} &= e^{ikx}\ket{\ua}\ket{0} + e^{-ikx}\left[\left(\frac{\sqrt{2}}{3}r_{3/2} - \frac{\sqrt{2}}{3}r_{1/2}\right)\ket{\da}\ket{1} + \left(\frac{2}{3}r_{3/2} + \frac{1}{3}r_{1/2}\right)\ket{\ua}\ket{0}\right]\\
		&\equiv e^{ikx}\ket{\ua}\ket{0} + e^{-ikx}\big(r_{\da 1}\ket{\da}\ket{1} + r_{\ua 0}\ket{\ua}\ket{0}\big)
	\end{align*}
	where we have defined the probability amplitudes $ r_{\da 1} $ and $ r_{\ua 0} $, which represent, respectively, the probability of the first particle reflecting in the state $ \ket{\da} $ and the second particle reflecting in the state $ \ket{1} $; and the probability of the first particle reflecting in the state $ \ket{\ua} $ and the second particle reflecting in the state $ \ket{0} $. 
	
	
	Similarly, combining like terms in $ \ket{\psi_{+}} $ gives 
	\begin{align*}
		\ket{\psi_{+}} &= e^{ikx}\left[\left(\frac{\sqrt{2}}{3}t_{3/2} - \frac{\sqrt{2}}{3}t_{1/2}\right)\ket{\da}\ket{1} + \left(\frac{2}{3}t_{3/2} + \frac{1}{3}t_{1/2}\right)\ket{\ua}\ket{0}\right]\\
		& \equiv e^{ikx} \big( t_{\da 1}\ket{\da}\ket{1} + t_{\ua 0}\ket{\ua}\ket{0} \big)
	\end{align*}
	Here $ t_{\da 1} $ and $ t_{\ua 0} $ represent, respectively, the probability of the first particle transmitting in the state $ \ket{\da} $ and the second particle transmitting in the state $ \ket{1} $; and the probability of the first particle transmitting in the state $ \ket{\ua} $ and the second particle transmitting in the state $ \ket{0} $.
	
	\item Evidently, their are four possible outcomes: the incident particle can either reflect or transmit; and the system's spin configuration can either flip (from $ \ket{\ua}\ket{0} $ to $ \ket{\da}\ket{1} $) or remain the same. The probability for a given process comes from the squared amplitude of the corresponding $ r $ or $ t $ coefficient.
	
	For example, the probability for reflection with a flipped spin configuration
	\begin{equation*}
		R_{\da 1 } = \abs{r_{\da 1}}^{2} = \abs{\frac{\sqrt{2}}{3}r_{3/2} - \frac{\sqrt{2}}{3}r_{1/2} }^{2}
	\end{equation*}
	
	\item Finally, we will show the problem obeys conservation of total probability, i.e.
	\begin{equation*}
		P_{\text{tot}} \equiv R_{\da 1} + R_{\ua 0} + T_{\da 1} + R_{\ua 0} = 1
	\end{equation*}
	We substitute in the values of the probability amplitudes to get
	\begin{align*}
		P_{\text{tot}} &= \abs{\frac{\sqrt{2}}{3}r_{3/2} - \frac{\sqrt{2}}{3}r_{1/2} }^{2} + \abs{\frac{2}{3}r_{3/2} + \frac{1}{3}r_{1/2}}^{2} + \abs{\frac{\sqrt{2}}{3}t_{3/2} - \frac{\sqrt{2}}{3}t_{1/2} }^{2} + \abs{\frac{2}{3}t_{3/2} + \frac{1}{3}t_{1/2}}^{2}\\
		& = \frac{2}{9}\abs{r_{3/2}}^{2} + \frac{2}{9}\abs{r_{1/2}}^{2}  - \frac{2}{9} 2 \Re \big[r^{*}_{3/2}r_{1/2}\big] + \frac{4}{9}\abs{r_{3/2}}^{2} + \frac{1}{9}\abs{r_{1/2}}^{2} + \frac{2}{9} 2 \Re \big[r^{*}_{3/2}r_{1/2}\big]  \\ 
		& {}\quad + \frac{2}{9}\abs{t_{3/2}}^{2} + \frac{2}{9}\abs{t_{1/2}}^{2}  - \frac{2}{9} 2 \Re \big[t^{*}_{3/2}t_{1/2}\big] + \frac{4}{9}\abs{t_{3/2}}^{2} + \frac{1}{9}\abs{t_{1/2}}^{2} + \frac{2}{9} 2 \Re \big[t^{*}_{3/2}t_{1/2}\big] \\
		& = \frac{2}{3}\left(\abs{r_{3/2}}^{2} + \abs{t_{3/2}}^{2}\right) + \frac{1}{3}\left(\abs{r_{1/2}}^{2} + \abs{t_{1/2}}^{2}\right) 
	\end{align*}
	Next, note that the $ r $ and $ t $ terms are precisely the elements of the scattering matrices
	\begin{equation*}
		\mat{S}_{1/2} = 
		\begin{bmatrix}
			r_{1/2} & t_{1/2}\\
			t_{1/2} & r_{1/2}
		\end{bmatrix}
		\eqtext{and}
		\mat{S}_{3/2} = 
			\begin{bmatrix}
				r_{3/2} & t_{3/2}\\
				t_{3/2} & r_{3/2}
			\end{bmatrix}
	\end{equation*}
	Since every scattering matrix is unitary, i.e. $ \mat{S}^{\dagger}\mat{S} = \mat{I} $, it follows that 
	\begin{equation*}
		 \left(\abs{r_{3/2}}^{2} + \abs{t_{3/2}}^{2}\right) = 1  \eqtext{and}
		 \left(\abs{r_{1/2}}^{2} + \abs{t_{1/2}}^{2}\right) = 1
	\end{equation*}
 	Substituting these results into the expression for $ P_{\text{tot}} $ gives
	\begin{equation*}
		P_{\text{tot}} = \frac{2}{3}\left(\abs{r_{3/2}}^{2} + \abs{t_{3/2}}^{2}\right) + \frac{1}{3}\left(\abs{r_{1/2}}^{2} + \abs{t_{1/2}}^{2}\right) = \frac{2}{3}\cdot 1 +  \frac{1}{3}\cdot 1 = 1
	\end{equation*}
	In other words, because $ P_{\text{tot}} = 1 $, our scattering problem obeys conservation of probability, as it must.


	
\end{itemize}


\subsection{Twelfth Exercise Set}

\subsubsection{Theory: Non-Degenerate Perturbation Theory}

\begin{itemize}
	\item Consider a \Ham $ H $ with known eigenfunctions $ \psi_{n} $ and energy non-degenerate eigenvalues $ E_{n} $ satisfying the stationary \Schro
	\begin{equation*}
		H \ket{n} = E_{n} \ket{n}
	\end{equation*}
	We then add a small perturbation term $ H' $ to the $ H $ to get the perturbed \Ham
	\begin{equation*}
		\t{H} = H + H'
	\end{equation*}
	
	\item In this case, to second order in perturbation theory, the energy eigenvalues of the perturbed Hamiltonian are
	\begin{equation*}
		\t{E}_{n} = E_{n} + \bra{n}H'\ket{n} + \sum_{m\neq n}\frac{\abs{\bra{m}H'\ket{n}}^{2}}{E_{n}-E_{m}},
	\end{equation*}
	while the corrected eigenfunction $ \ket{n} $ are
	\begin{equation*}
		\ket{\t{n}} = \ket{n} + \sum_{m\neq n}\frac{\abs{\bra{m}H'\ket{n}}^{2}}{E_{n}-E_{m}} \ket{m}
	\end{equation*}
	For both eigenvalues and eigenfunctions, we generally take only the first nonzero (non-trivial) term in the perturbation expansion (e.g. if the first-order correction is non-zero, we would stop there, without finding the second-order correction).

\end{itemize}

\subsubsection{QHO with a Quartic Perturbation}
\textit{Use perturbation theory to estimate the energy eigenvalues of the perturbed Hamiltonian}
\begin{equation*}
	\t{H} = \frac{p^{2}}{2m} + \frac{1}{2}kx^{2} + \lambda x^{4}, \qquad \lambda > 0,
\end{equation*}
\textit{which contains the quartic perturbation term $ \lambda x^{4} $.}

\begin{itemize}
	
	\item First, we identify the unperturbed Hamiltonian: the familiar harmonic oscillator
	\begin{equation*}
		H = \frac{p^{2}}{2m} + \frac{1}{2}kx^{2},
	\end{equation*}
	with eigenstates $ \ket{n} $ and eigenvalues $ E_{n} $ obeying
	\begin{equation*}
		H \ket{n} = E_{n} \ket{n}, \qquad E_{n} = \hbar \omega \big(n + \tfrac{1}{2}\big)
	\end{equation*}
	
	\item The perturbation term is $ H' = \lambda x^{4} $. To first order, the corrected energy of the perturbed \Ham $ \t{H} $ is
	\begin{equation*}
		\t{E}_{n} = E_{n} + \threebraket{n}{\lambda x^{4}}{n} = E_{n} + \lambda \threebraket{n}{x^{4}}{n}
	\end{equation*}
	Next, we evaluate the expectation value matrix element $ \threebraket{n}{x^{4}}{n} $. We will work in terms of the annihilation and creation operators. Nominally, $ x^{4} $ takes the form
	\begin{equation*}
		x^{4} = \frac{x_{0}^{4}}{4}(a+a^{\dagger})^{4} 
	\end{equation*}
	However, since $ a $ and $ a^{\dagger} $ don't commute, $ (a+a^{\dagger})^{4} $ would have 16 terms if multiplied out.  To avoid dealing with 16 terms, we make two $ x $ act on the $ \bra{n} $ term and two on the $ \ket{n} $ term as follows:
	\begin{equation*}
		\threebraket{n}{x^{4}}{n} = \threebraket{x^{2}n}{x^{2}}{n}
	\end{equation*}
	We can factor $ x^{4} $ and move it between $ \bra{n} $ and $ \ket{n} $ because $ x $ is Hermitian.
	
	\item In terms of $ a $ and $ a^{\dagger} $, the operator $ x^{2} $ reads
	\begin{equation*}
		x^{2} = \frac{x_{0}^{2}}{2}(a+a^{\dagger})^{2} = \frac{x_{0}^{2}}{2}(a^{2} + 2a^{\dagger}a + a^{2} + 1)
	\end{equation*}
	where we have used the commutator identity $ \big[a, a^{\dagger}\big] = 1 $. Using this expression for $ x^{2} $, we now assemble the matrix element $ \threebraket{x^{2}n}{x^{2}}{n} $ in pieces. First, we have
	\begin{align*}
		 x^{2} \ket{n} &= \frac{x_{0}^{2}}{2}(a^{2} + 2a^{\dagger}a + a^{2} + 1)\ket{n} \\
		&= \frac{x_{0}^{2}}{2}\big[\sqrt{n}\sqrt{n-1}\ket{n-2} + 2\sqrt{n}\sqrt{n}\ket{n} + \sqrt{n+1}\sqrt{n+2}\ket{n+2} + \ket{n}\big]\\
		& = \frac{x_{0}^{2}}{2}\big[\sqrt{n(n-1)}\ket{n-2}+(2n+1)\ket{n}+\sqrt{(n+1)(n+2)}\ket{n+2}\big]
	\end{align*}
	Since the coefficients in $ x^{2} \ket{n} $ are real, making complex conjugation redundant, we have $ \bra{x^{2}n} = x^{2} \ket{n} $. Using orthonormality of the states $ \ket{n} $ produces
	\begin{align*}
		\threebraket{x^{2}n}{x^{2}}{n} &= \frac{x_{0}^{4}}{4}\big[n(n-1) + (2n+1)^{2} + (n+1)(n+2)\big]\\
		&= \frac{x_{0}^{4}}{4}\big[6n^{2} + 6n + 3\big]
	\end{align*}
	
	\item Using the just-calculated matrix element $ \threebraket{x^{2}n}{x^{2}}{n} = \threebraket{n}{x^{4}}{n} $, the perturbed \Ham's energy to first order in perturbation theory is
	\begin{equation*}
		\t{E}_{n} = E_{n} + \lambda \frac{3x_{0}^{4}}{4}(2n^{2} + 2n + 1)
	\end{equation*}
	We end our approximation here, since the first-order correction is nontrivial.
	
	Written out in full, the corrected energy eigenvalues are
	\begin{equation*}
		\t{E}_{n} = \hbar \omega\big(n + \tfrac{1}{2}\big) + \lambda \frac{3x_{0}^{4}}{4}(2n^{2} + 2n + 1)
	\end{equation*}
	Note that, unlike $ E_{n} $, the energies $ \t{E}_{n} $ are no longer equally spaced by $ \hbar \omega $.
\end{itemize}

\subsubsection{QHO with a Cubic Perturbation}
\textit{Use perturbation theory to estimate the energy eigenvalues of the perturbed Hamiltonian}
\begin{equation*}
	\t{H} = \frac{p^{2}}{2m} + \frac{1}{2}kx^{2} + \lambda x^{3}, \qquad \lambda > 0,
\end{equation*}
\textit{which contains the cubic perturbation term $ \lambda x^{3} $.}
\begin{itemize}
	\item As in the previous problem, the unperturbed Hamiltonian $ H $ is the familiar quantum harmonic oscillator
	\begin{equation*}
		H = \frac{p^{2}}{2m} + \frac{1}{2}kx^{2}
	\end{equation*}
	with the eigenvalue relation
	\begin{equation*}
		H\ket{n} = E_{n} \ket{n}, \qquad E_{n} = \hbar \omega \left(n + \tfrac{1}{2}\right)
	\end{equation*}
	
	\item The perturbation term is $ H' = \lambda x^{3} $. We also define the perturbed potential
	\begin{equation*}
		\t{V}(x) \equiv \frac{1}{2}kx^{2} + \lambda x^{3}
	\end{equation*}
	
	\item To first order, the perturbed \Ham's energy eigenvalues are
	\begin{equation*}
		\t{E}_{n} = E_{n} + \threebraket{n}{\lambda x^{3}}{n}
	\end{equation*}
	In the coordinate wavefunction representation the expectation value reads
	\begin{equation*}
		\threebraket{n}{\lambda x^{3}}{n} = \int_{-\infty}^{\infty}\psi_{n}^{*}\lambda x^{3}\psi_{n}\diff x = 0
	\end{equation*}
	The expectation value is zero; a short explanation follows. Note that $ V(x) = \frac{1}{2}kx^{2} $ is an even potential, the \Ham $ H $'s eigenfunctions are either symmetric or asymmetric (see e.g. \hyperref[qmv:sss:even-odd]{Subsubsection \ref{qmv:sss:even-odd}}).
	
	If $ \psi_{n}(x) $ is even, the integrand $ \psi_{n}^{*}\lambda x^{3}\psi_{n} $, being the product of an even, odd, and even function, is odd. Similarly, if $ \psi_{n}(x) $ is odd, the integrand is a product of three odd functions, and is thus still odd. In both cases we take the integral of an odd function over $ -\infty $ to $ \infty $---result is zero. 
	
	\item Because the first-order correction to $ \t{E}_{n} $ gives a trivial result, we move on to the second order \pert approximation
	\begin{equation*}
		\t{E}_{n} = E_{n} + \sum_{m \neq n} \frac{\abs{\threebraket{m}{H'}{n}}^{2}}{E_{n} - E_{m}}
	\end{equation*}
	The expectation value can be simplified to
	\begin{equation*}
		\threebraket{m}{H'}{n} = \threebraket{m}{\lambda x^{3}}{n} = \lambda \threebraket{xm}{x^{2}}{n}
	\end{equation*}
	As in the previous problem, we assemble the expectation value piece by piece. Reusing the previous problem's result of $ x^{2}\ket{n} $, the ket term is
	\begin{equation*}
		x^{2}\ket{n} = \frac{x_{0}^{2}}{2}\Big[\sqrt{n(n-1)}\ket{n-2}+(2n+1)\ket{n}+\sqrt{(n+1)(n+2)}\ket{n+2}\Big]
	\end{equation*}
	Meanwhile, we find the bra term with 
	\begin{align*}
		&x \ket{m} = \frac{x_{0}}{\sqrt{2}}(a + a^{\dagger})\ket{m} = \frac{x_{0}}{\sqrt{2}}\big[\sqrt{m}\ket{m-1} + \sqrt{m+1}\ket{m+1}\big] \implies \\
		&\bra{xm} = \frac{x_{0}}{\sqrt{2}}\big[\sqrt{m}\bra{m-1} + \sqrt{m+1}\bra{m+1}\big],
	\end{align*}
	where the real coefficients make complex conjugation redundant. Applying the orthonormality of the states $ \ket{n} $, the braket is thus
	\begin{align*}
		\threebraket{xm}{x^{2}}{n} = \frac{x_{0}^{3}}{\sqrt{8}}\Big[&\sqrt{m}\sqrt{n(n-1)} \delta_{m-1,n-2} + \sqrt{m}(2n+1)\delta_{m-1,n}\\
		& + \sqrt{m}\sqrt{(n+1)(n+2)}\delta_{m-1,n+2} + \sqrt{m+1}\sqrt{n(n-1)}\delta_{m+1,n-2}\\
		& + \sqrt{m+1}(2n+1)\delta_{m+1,n} + \sqrt{m+1}\sqrt{(n+1)(n+2)}\delta_{m+1,n+2} \Big]
	\end{align*}
	Re-shifting indexes on the Kronecker deltas (just for clarity, e.g. $ \delta_{m-1,n-2} \equiv \delta_{m, n-1} $ or $ \delta_{m+1, n-2} \equiv \delta_{m, n-3} $) gives
	\begin{align*}
		\threebraket{xm}{x^{2}}{n} = \frac{x_{0}^{3}}{\sqrt{8}}\Big[&\sqrt{m}\sqrt{n(n-1)} \delta_{m,n-1} + \sqrt{m}(2n+1)\delta_{m,n+1}\\
		& + \sqrt{m}\sqrt{(n+1)(n+2)}\delta_{m,n+3} + \sqrt{m+1}\sqrt{n(n-1)}\delta_{m,n-3}\\
		& + \sqrt{m+1}(2n+1)\delta_{m,n-1} + \sqrt{m+1}\sqrt{(n+1)(n+2)}\delta_{m,n+1} \Big]
	\end{align*}	
	Writing $ m $ in terms of $ n $ with reference to the $ \delta_{mn} $ (e.g. $ m \to n -1 $ for $ \delta_{m, n-1} $) gives
	\begin{align*}
			\threebraket{xm}{x^{2}}{n} = \frac{x_{0}^{3}}{\sqrt{8}} \Big[& \sqrt{n}(n-1) \delta_{m, n-1} + \sqrt{n+1}(2n+1)\delta_{m, n+1} \\
			& + \sqrt{(n+1)(n+2)(n+3)}\delta_{m, n+3}  + \sqrt{n(n-1)(n-2)}\delta_{m, n-3} \\
			& + \sqrt{n}(2n+1)\delta_{m, n-1} + (n+2)\sqrt{n+1}\delta_{m, n+1}\Big]
	\end{align*}
	Finally, combining like terms and putting the $ \delta_{mn} $ in order produces
	\begin{align*}
		\threebraket{xm}{x^{2}}{n} = \frac{x_{0}^{3}}{\sqrt{8}} \Big[&\sqrt{n(n-1)(n-2)}\delta_{m, n-3} + 3n\sqrt{n}\delta_{m, n-1}\\
		& + 3(n+1)\sqrt{n+1}\delta_{m, n+1} + \sqrt{(n+1)(n+2)(n+3)}\delta_{m, n+3}\Big]
	\end{align*}
	With $ \threebraket{xm}{x^{2}}{n} $ known, we just multiply by $ \lambda $ to find matrix element
	\begin{equation*}
		\threebraket{m}{H'}{n} = \lambda \threebraket{xm}{x^{2}}{n},
	\end{equation*}
 	needed to find the perturbed energy $ \t{E}_{n} $.
	
	\item Using the just-derived $ \threebraket{m}{H'}{n} $, the perturbed \Ham's energy $ \t{E}_{n} $ is thus
	\begin{align*}
		\t{E}_{n} = E_{n} + \sum_{m \neq n} \frac{\abs{\braket{m}{H'n}}^{2}}{E_{n} - E_{m}} = E_{n} &+ \frac{\lambda^{2} x_{0}^{6}}{8}\bigg(\frac{n(n-1)(n-2)}{E_{n}-E_{n-3}} + \frac{9n^{3}}{E_{n}-E_{n-1}} \\
		&+ \frac{9(n+1)^{3}}{E_{n} - E_{n+1}} + \frac{(n+1)(n+2)(n+3)}{E_{n} - E_{n+3}} \bigg)
	\end{align*}
	Note that, nominally, we must sum over all $ m \neq n $ to find $ \t{E}_{n} $. However, because of the Kronecker deltas in the matrix element $ \threebraket{m}{H'}{n} $, there are only four $ m $ that are not equal to $ n $ at a given value of $ n $. 
	
	Next, we substitute in the energy differences (e.g. $ E_{n} - E_{n-3} $) in the denominators, which are known from the unperturbed \Ham $ H $, where the energies are equally spaced by $ \hbar \omega $. Substituting in energies and factoring out $ \hbar \omega $ gives
	\begin{align*}
		\t{E}_{n} &= E_{n} + \frac{\lambda^{2} x_{0}^{6}}{24 \hbar \omega}\left[n(n-1)(n-2) + 27n^{3} - 27(n+1)^{3} - (n+1)(n+2)(n+3) \right]\\
		& = E_{n} + \frac{\lambda^{2} x_{0}^{6}}{24 \hbar \omega} \left(n^{3}-3n^{2} + 2n + 27n^{3} - 27n^{3} - 81n^{2} - 81n - 27 - n^{3} - 6n^{2} - 11n - 6\right)\\
		&=E_{n} - \frac{\lambda^{2} x_{0}^{6}}{24 \hbar \omega} \left(90n^{2} + 90n + 33\right)\\
		&=E_{n} - \frac{\lambda^{2} x_{0}^{6}}{8 \hbar \omega} \left(30n^{2} + 30n + 11\right)
	\end{align*}
	Note that the energy correction is negative---the perturbed energies $ \t{E}_{n} $ are lower than for the standard QHO energies $ E_{n} $.
	
	\item Next, we find the perturbed eigenfunctions $ \ket{\t{n}} $. From the theory section, the $ \ket{\t{n}} $ are defined as
	\begin{equation*}
		\ket{\t{n}} = \ket{n} + \sum_{m\neq n}\frac{\abs{\bra{m}H'\ket{n}}^{2}}{E_{n}-E_{m}} \ket{m}
	\end{equation*}
	which in our case, using the matrix element $ \threebraket{m}{H'}{n}  $, is
	\begin{align*}
		\ket{\t{n}} =
		\ket{n} &+ \frac{\lambda x_{0}^{3}}{\sqrt{8}}\Bigg[\frac{\sqrt{n(n_1)(n-2)}}{3\hbar \omega}\ket{n-3} + \frac{3n\sqrt{n}}{\hbar \omega}\ket{n-1} \\
		&- \frac{3(n+1)\sqrt{n+1}}{\hbar \omega}\ket{n+1} - \frac{\sqrt{(n+1)(n+2)(n+3)}}{3\hbar \omega}\ket{n+3}\Bigg]
	\end{align*}
	The perturbed ground state wavefunction $ \ket{\t{0}} $ is
	\begin{equation*}
		\ket{\t{0}} = \ket{0} + \frac{\lambda x_{0}^{3}}{3\sqrt{8}\hbar\omega}\left[-9\ket{1} - \sqrt{6}\ket{3}\right]
	\end{equation*}
	Note that we drop the $ \ket{n-3} $ and $ \ket{n-1} $ terms, since $ \ket{-3} $ and $ \ket{-1} $ don't exist.
	
	\item Finally, we find $ \threebraket{\t{0}}{x}{\t{0}} $, the expected value of position in the perturbed ground state. First, writing $ x $ in terms of the annihilation and creation operators, the ket term is
	\begin{align*}
		x\ket{\t{0}} &= \frac{x_{0}}{\sqrt{2}}(a + a^{\dagger})\left[ \ket{0} + \frac{\lambda x_{0}^{3}}{3\sqrt{8}\hbar\omega}\left(-9\ket{1} - \sqrt{6}\ket{3}\right)\right]\\
		&= \frac{x_{0}}{\sqrt{2}}\ket{1} + \frac{\lambda x_{0}^{4}}{12\hbar \omega} \left[-9 \ket{0} - \sqrt{6} \sqrt{3}\ket{2} + \ket{1} - 9 \sqrt{2}\ket{2} - \sqrt{6}\sqrt{4}\ket{4}\right]
	\end{align*}
	Next, using the orthonormality of the $ \ket{n} $ states, the full expectation value is
	\begin{equation*}
		\threebraket{\t{0}}{x}{\t{0}} = -\frac{\lambda x_{0}^{4}}{12 \hbar \omega}(9 + 9) = -\frac{3\lambda x_{0}^{4}}{2 \hbar \omega}
	\end{equation*}
	In other words, according to perturbation theory, the position expectation value in the state $ \ket{\t{0}} $ shifts left from the origin to the region of negative $ x $. 
	
%	Note that the wavefunction is not physically correct---we would expect the particle to fall to the infinite potential well which occurs at x \to -infinity (assuming lambda is positive) because of the cubic potential. That said, the particle is still in a local minimum at the origin, and it may not have enough energy to escape this minimum and reach x \to -\infty

% The perturbation approxation to the ground state is good assuming lambda is small, the local minimum is thus deep, and the chance for the particle to tunnel to x \to -\infty is very small.
	
\end{itemize}


\end{document}






