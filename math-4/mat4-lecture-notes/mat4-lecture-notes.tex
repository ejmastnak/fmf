\documentclass[11pt, a4paper]{article}
\usepackage[T1]{fontenc}
\usepackage{mwe}
\usepackage[margin=3.5cm]{geometry}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{esint} % various fancy integral symbols
\usepackage{bm} % for bold vectors in math mode
\usepackage{physics} % many useful physics commands
\usepackage[separate-uncertainty=true]{siunitx} % for scientific notation and units
\usepackage{xcolor}  % to color hyperref links
\usepackage[colorlinks = true, allcolors=blue]{hyperref}

\setlength{\parindent}{0pt} % to stop indenting new paragraphs
\newcommand{\eqtext}[1]{\qquad \text{#1} \qquad}

\newcommand{\diff}{\mathop{}\!\mathrm{d}} % differential

\renewcommand{\vec}[1]{\bm{#1}}
\newcommand{\uvec}[1]{\hat{\vec{#1}}}

\renewcommand{\div}{\nabla \cdot}
\renewcommand{\curl}{\nabla \cross}
\renewcommand{\grad}{\nabla}
\renewcommand{\laplacian}{\nabla^{2}}

\newcommand{\D}{\mathcal{D}} % shorthand for the complex region D
\newcommand{\R}{\mathbb{R}} % shorthand for the real numbers
\newcommand{\C}{\mathbb{C}} % shorthand for the complex numbers

\pdfinfo{
	/Title (Matematika 4 Lecture Notes)
	/Author (Elijan Mastnak)
	/Subject (Mathematics)
}


\begin{document}
\title{Matematika 4 Lecture Notes}
\author{Elijan Mastnak}
\date{2019-2020 Summer Semester}
\maketitle

\begin{center}
\textbf{About These Notes}
\end{center}
These are my lecture notes from course \textit{Matematika 4} (Mathematics 4), given to second-year physics students at the Faculty of Math and Physics in Ljubljana, Slovenia. The exact material herein is specific to the physics program at the University of Ljubljana, but the content is fairly standard for an undergraduate-level course covering complex analysis, Fourier analysis, and differential equations. I am making the notes publicly available in the hope that they might help others learning the same material.

\vspace{2mm}
\textit{Note}: For easier document navigation, the table of contents is ``clickable'', meaning you can jump directly to a section by clicking the section name in the table of contents.

\vspace{2mm}
\textit{On Authorship:} These lecture were given by Professor Bojan Magajna, who accordingly deserves credit for the content herein. I have merely typeset the notes and provided additional comments where I saw fit.

% If applicable: The lecture notes for the course (in Slovene) can be found as of \today \href{URL}{this website}.

\vspace{2mm}
\textit{Disclaimer:} Mistakes---both trivial typos and---are likely. Keep in mind that these are the notes of an undergraduate student in the process of learning the material himself---take what you read with a grain of salt. If you find mistakes and feel like telling me, by Github pull request, email or some other means, I'll be happy to hear from you, even for the most trivial of errors.



\tableofcontents

\newpage

\section{Complex Analysis}

\subsection{Introduction to the Complex Plane}

The complex numbers $ \C $ are points in the complex plane. I use the terms complex numbers and complex plane synonymously.

\subsubsection{Basic Properties of Functions from $ \R $ to $ \C $}
Let $ \gamma : [a, b] \subset \R \to \C $ be a function mapping from the real line to the complex plane. The function $ \gamma $ can be written in the form
\begin{equation*}
	\gamma(t) = \gamma_1(t) + i \gamma_2(t)
\end{equation*}
where $ \gamma_1, \gamma_2 : [a, b] \to \R $ are both real functions and $ i $ is the imaginary number.

\begin{enumerate}
	\item $ \gamma $ is continuous if $ \gamma_1 $ and $ \gamma_2 $ are both continuous.
	\item $ \gamma $ is (continuously) differentiable if $ \gamma_1 $ and $ \gamma_2 $ are both (continuously) differentiable. In this case,
	\begin{equation*}
		\gamma'(t) = \lim_{h \to 0} \frac{\gamma(t + h) - \gamma(t)}{h} = \gamma_1'(t) + i \gamma_2'(t)
	\end{equation*}
\end{enumerate}

\subsubsection{Definition: Piecewise Continuously Differentiable}
The function $ \gamma : [a, b] \subset \R \to \C $ is \textit{piecewise continuously differentiable} if the interval $ [a, b] $ can be divided into a finite set of disjoint sub-intervals $ I_1, I_2, \dots, I_n $ where $ [a, b] = I_1 \cup  I_2 \cup \dots \cup I_n $ such that $ \gamma $ is continuously differentiable on each sub-interval $ I_i $.

\subsubsection{Definitions: Path, Path-Connected Set and Region}
\begin{enumerate}
	\item A piecewise differentiable function $ \gamma : [a, b] \subset \R \to \C $ is called a \textit{path} in $ \C $.
	\item The open complex subset $ U \in \C $ is \textit{path-connected} if for all $ \alpha, \beta \in U $ there exists a path $ \gamma:[a, b] \to U $ such that
	\begin{equation*}
		\gamma(a) = \alpha \quad \text{and} \quad \gamma(b) = \beta
	\end{equation*}
	
	\item An open, path-connected subset of $ \C $ is called a \textit{region}.
\end{enumerate}

\subsubsection{Definition: The Expanded Complex Plane}
The expanded complex plane, denoted by $ \hat{\C} $, is the union of the complex plane and $ \infty $.
\begin{equation*}
	\hat{\C} = \C \cup \infty
\end{equation*}
Any distance infinitely far from the origin of the expanded complex plane has the value $ \infty $.

\subsection{Differentiability in Complex Analysis}

\subsubsection{Basics: Complex Differentiability}
\begin{itemize}
	\item Let $ U \subset \C $ be a region in the complex plane and let $ f : U \to \C $ be a complex function. The function $ f $ is \textit{complex-differentiable at the point $ z_0 \in \C $} if the difference quotient
	\begin{equation*}
	\lim_{h \to 0} \frac{f(z_0 + h) - f(z_0)}{h}
	\end{equation*} 
	exists at $ z_0 $. In this case, we define the derivative of $ f $ at $ z_0 $, denoted by $ f'(z_0) $, as
	\begin{align*}
	f'(z_0) = \lim_{h \to 0} \frac{f(z_0 + h) - f(z_0)}{h}
	\end{align*}
	
	\item The function $ f $ is \textit{complex-differentiable} if it is complex-differentiable for all $ z \in U$.
	
	\item The function $ f $ is called \textit{holomorphic} if it is complex-differentiable for all $ z \in U $.
\end{itemize}

\subsubsection{Basic Properties of Complex Differentiation}
Differentiation of complex functions behaves similarly to differentiation of real functions. Let $ U \subset \C $ be a region in the complex plane and let $ f, g : U \to \C $ be differentiable complex functions and let $ c \in \C $ be a constant. In this case:
\begin{align*}
	&(cf)' = cf' && (f \pm g)' = f' \pm g'\\
	&(fg)' = fg' + f'g && \left(\frac{f}{g}\right)'= \frac{f'g - fg'}{g^2}\\
	&(c)' = 0 & &\left(z^n\right)'= n z^{n-1}
\end{align*}

\subsubsection{Proposition: Convergence of Complex Power Series}
The complex power series $\displaystyle{ \sum_{k = 0}^{\infty} a_{k}z^{k}} $ is convergent if it satisfies the Cauchy criterion; that is, if for all $ \epsilon > 0 $ there exists $ M_0 \in \mathbb{N}$ such that
\begin{equation*}
	\abs{\sum_{k = n}^{m} a_k z^{k}} < \epsilon \qquad \text{for all } m \geq n \geq M_0
\end{equation*}

\subsubsection{Definition: Radius of Convergence of Complex Power Series}
Let $\displaystyle{\mathcal{S} = \sum_{k = 0}^{\infty} a_{k}(z - z_0)^{k}} $ be a complex power series centered at $ z_0 \in \C $. The radius of convergence $ R $ of $ \mathcal{S} $ is defined as
\begin{align*}
	R = \frac{1}{\limsup \sqrt[n]{\abs{a_n}}}
\end{align*}

\subsubsection{Theorem: Convergence In Terms of Radius of Convergence}
Let $\displaystyle{\mathcal{S} = \sum_{k = 0}^{\infty} a_{k}(z - z_0)^{k}} \vspace{0.5mm} $ be a complex power series with radius of convergence $ R $, and let $ D(z_0, R) \subset \C \vspace{1mm}$ be an open disk in the complex plane of radius $ R $ centered at $ z_0 $ given by $ \displaystyle{D(z_0, R) = \left\{ z \in \C; \ \abs{z - z_0} < R \right\}} $. In this case:
\begin{enumerate}
	\item $ \mathcal{S} $ converges absolutely for all $ z \in D(z_0, R) $, 
	\item $ \mathcal{S} $ diverges for all $ z \notin U $.
\end{enumerate}
Additionally, the function series $ \displaystyle{f(z) = \sum_{k = 0}^{\infty} a_{k}(z - z_0)^{k}} $ converges uniformly for all $ z \in  D(z_0, R)$.


\subsubsection{Differentiation of Complex Power Series}
Let $\displaystyle{\mathcal{S} = \sum_{k = 0}^{\infty} a_{k}(z - z_0)^{k}} $ be a complex power series with radius of convergence $ R $ and let $ f(z) $ be the function series
\begin{align*}
	f(z) = \mathcal{S}(z) = \sum_{k = 0}^{\infty} a_{k}(z - z_0)^{k}
\end{align*}
In this case, for all $ z \in D(z_0, R) $ (because $ \mathcal{S}(z) $'s uniform convergence allows us to differentiate term by term) we define $ f(z) $'s derivative $ f'(z) $ as
\begin{align*}
	&f'(z) = \sum_{k = 1}^{\infty}  k a_k (z - z_0)^{k-1}\\
	&f''(z) = \sum_{k = 2}^{\infty}  k (k-1) a_k (z - z_0)^{k-2}\\
	&\qquad \quad \quad \ \vdots\\
	&f^{(n)}(z) = \sum_{k = n}^{\infty}  k (k-1) \cdots (k - n - 1) (z - z_0)^{k-n}
\end{align*}


\subsubsection{Coefficients and Differentiability of Complex Function Series}
Let $\displaystyle{f(z) = \sum_{k = 0}^{\infty} a_{k}(z - z_0)^{k}} $ be a complex function series with radius of convergence $ R $. In this case, for all $ z \in D(z_0, R) $, $ f(z) $:
\begin{enumerate}
	\item $ f(z) $ is infinitely continuously differentiable in the complex sense
	\item The coefficients $ a_k  $ are defined by the relationship $ \displaystyle{	a_k = \frac{f^{(k)}(\alpha)}{k!}} $
\end{enumerate}

\subsubsection{Identity: Euler's Identity}
For all $ z \in \C $, the complex exponential, sine, and cosine functions are related by the identity
\begin{align*}
	e^{iz} = \cos z + i \sin z
\end{align*}

\subsubsection{Definitions: Complex Exponent, Sine and Cosine Functions}
\begin{enumerate}
	\item The complex exponential function $ e^{z} $, where $ z \in \C $, is defined in terms of complex function series as:
	\begin{align*}
		e^{z} = 1 + z + \frac{z^2}{2!} + \dots + \frac{z^{k}}{k!} + \dots = \sum_{k=0}^{\infty}\frac{z^{k}}{k!}
	\end{align*}
	For all $ z, w \in \C $, $ e^{z}e^{w} = e^{z + w} $.
	
	\item Using Euler's identity and the power series definition of the complex exponential function, we define the complex sine and cosine functions as:
	\begin{align*}
		&\sin z = \frac{e^{iz} - e^{-iz}}{2i} = z - \frac{z^3}{3!} + \frac{z^5}{5!} - \frac{z^7}{7!} \pm \dots =  \sum^{\infty}_{n=0} \frac{(-1)^n}{(2n+1)!} z^{2n+1}\\
		&\cos z = \frac{e^{iz} + e^{-iz}}{2} =  1 - \frac{z^2}{2!} + \frac{z^4}{4!} - \frac{z^6}{6!} \pm \dots =  \sum^{\infty}_{n=0} \frac{(-1)^n}{(2n)!} z^{2n}
	\end{align*}
	
	\item The complex hyperbolic sine and cosine functions are defined in terms of the complex sine and cosine functions as
	\begin{align*}
		&\sinh z = -i \sin (iz)  = z + \frac{z^3}{3!} + \frac{z^5}{5!} + \dots =  \sum^{\infty}_{n=0} \frac{z^{2n+1}}{(2n+1)!} \\
		&\cosh z = \cos (iz) = 1 + \frac{z^2}{2!} + \frac{z^4}{4!} + \dots =  \sum^{\infty}_{n=0} \frac{z^{2n}}{(2n)!} 
	\end{align*}
\end{enumerate}

\subsection{The Cauchy-Riemann Equations}
\subsubsection{Note: Complex Functions in Terms of Real Components}
Let $ U \subset \C $ be a region in $ \C $, let $ z \in \C $ be a complex number and let $ f: U \to \C $ be a complex function mapping $ z \mapsto f(z) $. We write $ f $ in terms of real components as
\begin{align*}
	f(z) = u(z) + i v(z)
\end{align*}
where $ u, v : U \to \R $ are real functions mapping from the complex plane to the real numbers. Typically, we go one step further and write $ z $ in terms of its real components as $ z = x + i y $ where $ x, y \in \R $. In this case, we re-define $ u(z) = u(x, y) $ and $ v(z) = v(x, y) $ as real functions of two variables, $ u, v: \R^2 \to \R $. In this case, we write $ f $ as
\begin{align*}
	&f(z) = u(x, y) + iv(x, y) \qquad \text{where} \qquad z = x + iy; \quad x, y \in \R
\end{align*}

\subsubsection{Definition: Cauchy-Riemann Equations}
The Cauchy-Riemann equations for two real, continuously differentiable functions $ u, v: \R^2 \to \R $ mapping $ (x, y) \mapsto u(x, y) $ and $ (x, y) \mapsto v(x, y) $ are
\begin{align*}
	&\pdv{}{x} u(x, y) = \pdv{}{y} v(x, y) && \pdv{}{x} v(x, y) = -\pdv{}{x}u(x, y)
\end{align*}
Note that two arbitrary functions $ u, v $ do not in general satisfy the Cauchy-Riemann equations and this definition is not saying they do; it just presents the definition of the equations. 

\subsubsection{Complex Differentiability and the Cauchy-Riemann Equations}
Let $ U \subset \C $ be a region in $ \C $, let $ f: U \to \C $ be a differentiable complex function, and let $ u, v: \R^2 \to \R $ be continuously differentiable real functions such that
\begin{align*}
	&f(z) = u(x, y) + iv(x, y) \qquad \text{where} \qquad z = x + iy; \quad x, y \in \R
\end{align*}
In this case, $ f $ is holomorphic if and only if $ u $ and $ v $ satisfy the Cauchy-Riemann equations
\begin{align*}
	&\pdv{}{x} u(x, y) = \pdv{}{y} v(x, y) && \pdv{}{x} v(x, y) = -\pdv{}{x}v(x, y)
\end{align*}

\subsubsection{Definition: Laplacian In the Real Plane}
Let $ u : U \subset \mathbb{R}^2 \to \mathbb{R} $ be a twice differentiable scalar function. The Laplacian of $ u $, denoted by $ \Delta f $ or $ \nabla^2 f $, is the scalar function
\begin{equation*}
	\Delta f = \div{(\grad{f})} = \pdv[2]{u}{x} + \pdv[2]{u}{y}
\end{equation*}

\subsubsection{Definition: Harmonic Functions}
Scalar functions whose Laplacian is zero are called harmonic functions. The twice-differentiable function $ u : U \subset \mathbb{R}^2 \to \mathbb{R} $ is harmonic on $ \R^2 $ if
\begin{equation*}
	\Delta u = 0 \qquad \text{(condition for harmonic functions)}
\end{equation*}

\subsubsection{Note: Components of a Holomorphic Function are Harmonic}
Let $ z \in \C $ be a complex number, let $ f: U \subset \C \to \C $ be a holomorphic function with continuously differentiable harmonic components $ u, v: \R^2 \to \R^2 $, written
\begin{align*}
	f(z) = u(x, y) + iv(x, y)
\end{align*}
where $ z = x + iy $. In this case, if $ f $ is holomorphic, both $ u $ and $ v $ are harmonic functions.

\textbf{Proof:} We prove the proposition for the real component $ u $; the proof for $ v $ is analogous. By definition, the Laplacian of $ u $ is
\begin{align*}
	\Delta u = \pdv[2]{u}{x} + \pdv[2]{u}{y} = \pdv{}{x}\left[\pdv{u}{x} \right] + \pdv{}{y}\left[\pdv{u}{y} \right]
\end{align*}
Because $ f $ is holomorphic, $ u $ and $ v $ satisfy the Cauchy-Riemann equations. Continuing from before, we use the Cauchy-Riemann equations to write
\begin{align*}
	\Delta u = \pdv{}{x}\left[\pdv{v}{y} \right] - \pdv{}{y}\left[\pdv{v}{x} \right] = \dfrac{\partial^2 v}{\partial x \partial y} - \dfrac{\partial^2 v}{\partial y \partial x} = 0 \implies \Delta u = 0
\end{align*}
The mixed partial derivatives are equal because we have assumed $ u $ and $ v $ are continuous.

\subsubsection{Proposition: Harmonic and Holomorphic Functions}
Let $  U \subset \C $ be an arbitrary subset of the complex plane and let $ u: U \to \R $ be a twice-continuously differentiable harmonic function.
\begin{enumerate}
	\item If $ u $ is the real component of some holomorphic function, then $ u $ must be harmonic. That is, $ u $ being harmonic is a necessary condition for $ u $ to be the real part of some holomorphic function.
	\item More so, if $ U $ is a \textit{connected} subset of $ C $, then $ u $ being harmonic becomes a sufficient condition for $ u $ to be the real part of some holomorphic function. That is, if $ U $ is connected and $ u $ is harmonic, there exists holomorphic function $ f : U \to \C $ of which $ u $ is the real part.
\end{enumerate}

\subsection{Integration of Complex Functions}

\subsubsection{Definition: Integral of the Complex Functions of a Real Variable}
Let $ I = [a, b] \subset \R $ be an interval on the real line and let $ f:I \to \C $ be a complex function. Let $ \mathcal{P} = \{a = x_0, x_1, \dots, x_i, \dots, x_n = b \} $ be a partition of the interval $ I $, let $ \Delta_i x = x_i - x_{i-1} $ be the $ i $th sub-interval of $ I $ and let $ \xi_i \in \Delta x_i$ be an element of the $ i $th sub-interval $ \Delta x_i $. If the sum
\begin{align*}
	\lim_{n \to \infty} \sum_{i}^{n}f(\xi_i) \Delta x_i
\end{align*}
converges to a complex number, we say that $ f $ is \textit{integrable} on $ I $ and define the integral of $ f $ on $ I $ as
\begin{align*}
	\int_{a}^{b} f(t) \diff t = \lim_{n \to \infty} \sum_{i}^{n}f(\xi_i) \Delta x_i
\end{align*}

\subsubsection{Integral of the Complex Functions of a Real Variable by Components}
Let $ I = [a, b] \subset \R $ be an interval on the real line and let $ f:I \to \C $ be a complex function with integrable real and imaginary components $ u, v : I \to \R $, respectively. In this case, the integral of $ f $ is defined as
\begin{align*}
	\int_{a}^{b} f(t) \diff t = \int_{a}^{b}u(t) \diff t + i\int_{a}^{b}v(t) \diff t
\end{align*}



\subsubsection{Proposition: Properties of Complex Integrals}
Let $ I = [a, b] \subset \R $ be an interval on the real line, let $ f, g:I \to \C $ be integrable complex functions, and let $ \alpha, \beta \in \C $ be constants. In this case
\begin{enumerate}
	\item $ \displaystyle{\int_{a}^{b}(\alpha f(t) + \beta g(t))\diff t = \alpha \int_{a}^{b} f(t) \diff t + \beta \int_{a}^{b} g(t) \diff t } $
	
	\item $ \displaystyle{\abs{\int_{a}^{b} f(t) \diff t } \leq \int_{a}^{b} \abs{f(t)} \diff t } $
\end{enumerate}

\subsubsection{Definition: Complex Line Integral}
Let $ I = [a, b] \subset \R $ be an interval on the real line, let $ \gamma: I \to \C $ be a path, let $ \Gamma = \{ \gamma(t) ; t \in [a, b] \} $ be the image of $ \gamma $ and let $ f: \Gamma \to \C $ be an integrable complex function. The line integral of $ f $ along the curve $ \Gamma $  is defined as
\begin{align*}
	\int_{\Gamma} f(z) \diff z = \int_{a}^{b}f(\gamma(t)) \dot{\gamma}(t) \diff t
\end{align*}
where $ \dot{\gamma}(t) = \dv{\gamma(t)}{t} $ denotes differentiation with respect to $ t $.

\subsubsection{Note: Component Form of a Complex Line Integral}
Let $ I = [a, b] \subset \R $ be an interval on the real line, let $ \gamma: I \to \C $ be a path, let $ \Gamma = \{ \gamma(t) ; t \in [a, b] \} $ be the image of $ \gamma $ and let $ f: \Gamma \to \C $ be an integrable complex function with the integrable components $ u, v : \Gamma \to \R $. If we write $ f $ in the form
\begin{align*}
	f(z) = u(x, y) + i v(x, y)
\end{align*}
where $ z = x + iy $ is a point on $ \Gamma $, we can equivalently write the line integral of $ f $ along $ \Gamma $ in terms of $ u $ and $ v $ as
\begin{align*}
	\int_{\Gamma} f(z) \diff z = \int_{\Gamma}(u \diff x - v \diff y) + i\int_{\Gamma}(v \diff x - u \diff y)
\end{align*}
where $  \int_{\Gamma}(u \diff x - v \diff y) $ and $ \int_{\Gamma}(v \diff x - u \diff y) $ are line integrals of the real functions $ u $ and $ v $.

\subsubsection{Proposition: Line Integral is Independent of Parameterization}
The definition of the line integral of a complex function is independent of the parametrization of the curve along which the integral is evaluated. 

In symbols, let $ \Gamma \subset \C $ be a complex curve and let $ f: \Gamma \to \C $ be an integrable complex function. More so, let $ I = [a, b] \subset \R $ and $ J =[\alpha, \beta] \subset \R  $ be intervals on the real line and let $ \gamma: I \to \Gamma $ and $ \psi: J \to \Gamma $ be two arbitrary parameterizations of the curve $ \Gamma $. In this case,
\begin{align*}
	\int_{a}^{b}f(\gamma(t)) \dot{\gamma}(t) \diff t = \int_{\alpha }^{\beta}f(\psi(t)) \dot{\psi}(t) \diff t
\end{align*}

\subsubsection{Proposition: Properties of Complex Line Integrals}
Let $ I = [a, b] \subset \R $ be an interval on the real line, let $ \gamma: I \to \C $ be a path, let $ \Gamma = \{ \gamma(t) ; t \in [a, b] \} $ be the image of $ \gamma $, let $ f, g: \Gamma \to \C $ be integrable complex functions, and let $ \alpha, \beta \in \C $ be constants. In this case
\begin{enumerate}
	\item $ \displaystyle{\int_{\Gamma}(\alpha f(z) + \beta g(z))\diff z = \alpha \int_{\Gamma} f(z) \diff z + \beta \int_{\Gamma} g(z) \diff z } $
	
	\item $ \displaystyle{\abs{\int_{\Gamma} f(z) \diff z } \leq \int_{\Gamma} \abs{f(z)} \diff s } $
\end{enumerate}
where $ \diff s = \abs{\diff z}$ denotes a line element of the curve $ \Gamma $.

\subsubsection{Note: Connected Combination of Two Curves}
The purpose of this note is two formalize the intuitive notion of piecing two curves together by placing the beginning of the second curve at the end of the first curve to form a single, connected curve.  Along these lines, let $ \gamma:[a, b] \to \C $ and $ \psi : [c, d] \to \C $ be two paths such that $ \gamma(b) = \psi(c) $; i.e. the end of the curve described by $ \gamma $ coincides with the beginning of the curve described by $ \psi $. In this case, we define a joint parametrization of $ \gamma \stackrel{\bullet}{+} \psi $ describing the entire joined curve with the relation
\[
(\gamma \stackrel{\bullet}{+} \psi)(t) = 
\begin{cases}
	\gamma(t); & t \in [a, b]\\
	\psi(t - b + c);	& t \in [b, b + d - c]
\end{cases}
\]
The rather complicated-looking choice of the time domain for $ \psi $ is made to ensure that $ \gamma(b) = \psi(c) $. 

For any complex function $ f : [\gamma \stackrel{\bullet}{+} \psi] \to \C $
\begin{align*}
	\int_{\gamma \stackrel{\bullet}{+} \psi} f(z) \diff z = \int_{\gamma}f(z)\diff z + \int_{\psi}f(z) \diff z
\end{align*}

\subsubsection{Note: Oppositely Parameterized Path}
Let $ \gamma : [a, b] \to \C $ be a path with image $ \Gamma $. We denote the oppositely parameterized path by $ \gamma_{-} $ and define it with the relation
\begin{align*}
	\gamma^{-}(t) = \gamma(-t); \quad t \in [-b, -a]
\end{align*}
Both paths have the same image (i.e. describe the same curve $ \Gamma $) but traverse the curve in opposite directions.

For any complex function $ f : [\gamma] \to \C $
\begin{align*}
	&\int_{\gamma} f(z) \diff z = - \int_{\gamma^{-}}f(z) \diff z\\
	&
\end{align*}

\subsubsection{Definition: Closed Path and Closed Curve}
Let $ \gamma : [a, b] \to \C $ be a path with image is the curve $ \Gamma \in \C$. If $ \gamma(a) = \gamma(b) $, then $\gamma$ is called a \textit{closed path} and $ \Gamma $ is a \textit{closed curve}. The line integral of a function along a closed curve is denoted by the symbol $ \oint $. For instance, the line integral of some function $ f $ along the closed curve $ \gamma $ is written:
\begin{align*}
	\oint_{\gamma} f(z) \diff z \qquad (\text{notation for closed line integral})
\end{align*}

\subsubsection{Fundamental Theorem of Calculus for Curve Integrals}
Let $ U \subset \C $ be a region in $ \C $, let $ \gamma : [a, b] \to U $ be a path mapping to $ U $, and let $ F:U \to \C $ be a holomorphic function. In this case
\begin{align*}
	\int_{\gamma} F'(z) \diff z = F\left(\gamma(b)\right) - F\left(\gamma(a)\right)
\end{align*}

\textbf{Proof: } Applying the definition of a complex line integral and then the chain rule gives
\begin{align*}
	\int_{\gamma} F'(z) \diff z = \int_{a}^{b} F'(\gamma(t)) \dot{\gamma(t)} \diff t = \int_{a}^{b}\dv{}{t} \big[F(\gamma(t))\big] \diff t = F\left(\gamma(b)\right) - F\left(\gamma(a)\right)
\end{align*}


\subsubsection{Implication: Integral Along a Closed Curve is Zero}
Let $ U \subset \C $ be a region in $ \C $, let $ \gamma : [a, b] \to U $ be a closed path mapping to $ U $ and let $ F:U \to \C $ be a holomorphic function. In this case
\begin{align*}
	\oint_{\gamma} F'(z) \diff z = 0 && (\gamma \text{ closed path})
\end{align*}

\subsubsection{Theorem}
Let $ U \subset \C $ be a region in $ \C $, let $ f: U \to \C $ be a continuous function such that
\begin{align*}
	\oint f(z) \diff z = 0
\end{align*}
for all closed paths $ \gamma : [a, b] \to U $. In this case, there exists holomorphic function $ F: U \to \C $ such that 
\begin{align*}
	F'(z) = f(z)
\end{align*}

\subsection{Winding Number and Cauchy's Theorem}

\subsubsection{Definition: Winding Number}
Let $ \gamma : [a, b] \to \C $ be closed path with corresponding closed curve $ \Gamma \subset \C $. The \textit{winding number} of the point $ z_0 \in \C \setminus \Gamma $ with respect to the closed curve $ \Gamma $, also called the index of $ z_0 $ with respect to $ \Gamma $ and denoted by $ \operatorname{Ind}_{\gamma}(z_0) $, is the number of times the curve $ \Gamma $ wraps around $ z_0 $ in the counterclockwise direction. The winding number is given by the formula
\begin{align*}
	\operatorname{Ind}_{\gamma}(z_0) = \frac{1}{2\pi i} \oint_{\gamma} \frac{\diff z}{z - z_0} = \frac{1}{2\pi i} \int_{a}^{b} \frac{\dot{\gamma}(t) \diff t}{\gamma(t) - z_0} 
\end{align*}

\subsubsection{Proposition: Properties of the Winding Number}
Let $ \gamma : [a, b] \to \C $ be closed path with corresponding closed curve $ \Gamma \subset \C $, let $ \Omega = \C \setminus \Gamma $ be the complement of $ \Gamma $ and define the point $ 	\operatorname{Ind}_{\gamma}(z_0) $. In this case:
\begin{enumerate}
	\item $ \displaystyle{	\operatorname{Ind}_{\gamma}(z_0)} $ is an integer number for all $ z_0 \in \Omega $.
	
	\item $ \displaystyle{	\operatorname{Ind}_{\gamma}(z_0)} $ has the same value for all $ z_0 $ in a given maximal connected component of $ \Omega $.
	
	\item $ \displaystyle{	\operatorname{Ind}_{\gamma}(z_0)} = 0$ if $ z_0 $ is in the unbounded component of $ \Omega $.
\end{enumerate}

\subsubsection{Cauchy's Theorem}
Let $ U \subset \C $ be a region in $ \C $, let $ f: U \to \C $ be a holomorphic function and let $ \gamma : [a, b] \to U $ be closed path that does not wind around any points in $ U $'s complement, i.e. $ 	\operatorname{Ind}_{\gamma}(z_0) = 0 \ \text{for all } z_0 \in \C \setminus U $. In this case
\begin{align*}
	\oint_{\gamma} f(z) \diff z = 0
\end{align*}

\textbf{Proof:} This proof is only for the special case in which $ f $ has the continuously differentiable components $ u, v: \R^2 \to \R $ and the curve $ [\gamma] $ does not cross over itself. We write $ f $ in terms of its components as
\begin{align*}
	&f(z) = u(x, y) + iv(x, y); && z = x + iy, \quad \diff z = \diff x + i \diff y
\end{align*}
Let $ \Gamma \subset U $ be the region bounded by the curve $ [\gamma] $. We split the complex line integral into real components and apply Green's formula on the region $ \Gamma $, followed by Cauchy's equations for $ u $ and $ v $ to get
\begin{align*}
	\oint_{\gamma} f(z) \diff z &= \oint_{\gamma}(u + iv)(\diff x + i \diff y)\\
	&= \oint_{\gamma} u \diff x - v \diff y + i\oint_{\gamma} v \diff z + u \diff y\\
	&=\iint_{\Gamma} (-v_x - u_y) \diff A + \iint_{\Gamma} (u_x - v_y) \diff A\\
	&=\iint_{\Gamma} (0) \diff A + \iint_{\Gamma} (0) \diff A = 0
\end{align*}
Because $ f $ is holomorphic $ u $ and $ v $ satisfy the Cauchy equations, so $ u_x = v_y $ and $ u_y = -v_x $. 

\subsubsection{Cauchy's Integral Formula}
Let $ U \subset \C $ be a region in $ \C $, let $ f: U \to \C $ be a holomorphic function, let $ \gamma : [a, b] \to U $ be closed path that does not wind around any points in $ U $'s complement, i.e. $ 	\operatorname{Ind}_{\gamma}(z) = 0 \ \text{for all } z \in \C \setminus U $, and let $ z_0 \in U \setminus [\gamma] $ be complex number in $ U $ that does not lie on the curve $ [\gamma] $. In this case
\begin{align*}
	\operatorname{Ind}_{\gamma}(z_0) f(z_0) = \frac{1}{2\pi i} \oint_{\gamma} \frac{f(z)}{z - z_0} \diff z
\end{align*}

\subsubsection{Note: Cauchy's Integral Formula on an Annulus}
On an annulus with outer radius $ R $ and inner radius $ r $, where the inner disk is bounded by $ \gamma_r $ and the outer disk by $ \gamma_R $, and where $ z_0 $ is a point in the annulus, Cauchy's integral formula reads
\begin{align*}
	f(z_0) = \frac{1}{2\pi i} \left[\oint_{\gamma_R} \frac{f(z)}{z - z_0} \diff z - \oint_{\gamma_r} \frac{f(z)}{z - z_0} \diff z \right]
\end{align*}

\subsubsection{Cauchy's Differentiation Formula}
Let $ U \subset \C $ be a region in $ \C $, let $ f: U \to \C $ be a holomorphic function, let $ \gamma : [a, b] \to U $ be closed path that does not wind around any points in $ U $'s complement, i.e. $ 	\operatorname{Ind}_{\gamma}(z) = 0 \ \text{for all } z \in \C \setminus U $, and let $ z_0 \in U \setminus [\gamma] $ be complex number in $ U $ that does not lie on the curve $ [\gamma] $. In this case
\begin{align*}
	\operatorname{Ind}_{\gamma}(z_0) f^{(n)}(z_0) = \frac{n!}{2\pi i} \oint_{\gamma} \frac{f(z)}{(z - z_0)^{n+1}} \diff z
\end{align*}

\subsubsection{Cauchy's Inequality For Derivatives}
Let $ U \subset \C $ be a region in $ \C $, let $ z_0 \in U $ be a point in $ U $, and let $ D(\omega, R) \subset U $ be an open disk of radius $ R $ centered at $ \omega $. Finally, let $ M \in \R^{+} $ be a constant and let $ f: U \to \C $ be a holomorphic function bounded on $ D $ such that $ \abs{f(z)} \leq M $ for all $ z \in D $. In this case
\begin{align*}
	\abs{f^{(n)}(z_0)} \leq \frac{M n!}{R^n}
\end{align*}

\subsubsection{Liouville's Theorem}
Let $ f : \C \to \C $ be a holomorphic function. If there exists constant $ M \in \R^{+} $ such that $ \abs{f(z)} \leq M $ for all $ z \in \C $, then $ f $ is a constant function. Equivalently, all non-constant holomorphic functions $ f : \C \to \C $ have unbounded images.

\subsubsection{Note: Fundamental Theorem of Algebra}
Every non-constant single-variable constant polynomial has at least one complex zero.

\subsection{Laurent Series}

\subsubsection{Definition: Laurent Series}
Let $ U \subset \C $ be a region, let $ z_0 \in \C $ be a complex number, let $ r, R \in \R^+ $ be positive real numbers such that $ R > r $, and let $ A \subset U $ be the open annulus centered at $ z_0 $ with outer and inner radii $ R $ and $ r $, respectively:
\begin{align*}
	A = \left\{ z \in \C; \  r < \abs{z - z_0} \leq R \right\}
\end{align*}
Finally, let the complex function $ f : U \to \C $ be holomorphic in a neighborhood of the annulus $ A $. In this case, for all $ z \in A $, $ f $'s \textit{Laurent series} about the point $ z_0 \in A $ is defined as
\begin{align*}
	f(z) = \sum_{-\infty}^{\infty} a_n (z - z_0)^{n}
\end{align*}
The coefficients $ a_n $ are defined in terms of the Cauchy integration formula on an annulus:
\[
	a_n = 
	\begin{cases}
		\displaystyle{\frac{1}{2\pi i} \oint_{\gamma_R} \frac{f(z)}{(z - z_0)^{n+1}}\diff z} & n \geq 0 \\[5.0mm]
		\displaystyle{	\frac{1}{2\pi i} \oint_{\gamma_r} \frac{f(z)}{(z - z_0)^{n+1}}\diff z} & n \leq 0
	\end{cases}
\]
The paths of integration $ \gamma_R $ and $ \gamma_r $ describe the positively oriented circles
\begin{align*}
	&y_R: \quad \left\{z \in \C; \ \abs{z - z_0} = R \right\}\\
	&y_r: \quad \, \left\{z \in \C; \ \abs{z - z_0} = r \right\}
\end{align*}
More generally, the coefficients $ a_n $ may be written
\begin{align*}
	a_n = \frac{1}{2\pi i} \oint_{\gamma} \frac{f(z)}{(z - z_0)^{n+1}}\diff z
\end{align*}
where the path of integration $ \gamma $ describes a positively oriented Jordan curve in the annulus $ A $ enclosing $ z_0 $.
 


\subsubsection{Principle and Regular Part of Laurent Series}
Let $ U \subset \C $ be a region, let $ z_0 \in \C $ be a complex number, let $ r, R \in \R^+ $ be positive real numbers such that $ R > r $, let $ A \subset U $ be the open annulus centered at $ z_0 $ with outer and inner radii $ R $ and $ r $. And let $ f : U \to \C $ be a holomorphic function in a neighborhood of the annulus $ A $ with Laurent series
\begin{align*}
	f(z) = \sum_{-\infty}^{\infty} a_n (z - z_0)^{n}
\end{align*}
In this case, the terms of $ f $'s Laurent series with positive degree, i.e. $ \displaystyle{\sum_{n=0}^{\infty} a_n (z - z_0)^{n}} $, are called the \textit{regular part} of the Laurent series. Meanwhile, the terms with negative degree, i.e. $ \displaystyle{	\sum_{n=-\infty}^{-1} a_n (z - z_0)^{n}} $, are called the \textit{principle part} of the Laurent series.

\subsubsection{Consequence: Existence of Taylor Series}
Let $ U \subset \C $ be a region, let $ z_0 \in \C $ be a complex number, let $ R \in \R^+ $ be a positive real number and let $ D(z_0, R) \subset U $ be an open disk centered at $ z_0 $. Finally, let the function $ f : U \to \C $ be a holomorphic in a neighborhood of $ D $. In this case, for all $ z \in D $, there exists a Taylor series for $ f $ about the point $ z_0 \in D $ that converges for all $ z \in D $:
\begin{align*}
	& f(z) = \sum_{n = 0}^{\infty}a_n (z-z_0)^n && a_n = \frac{1}{2\pi i} \oint_{\abs{z}=R} \frac{f(z)}{(z - z_0)^{n+1}} \diff z
\end{align*}
\textbf{Interpretation:} The expression for $ f $'s Taylor series is derived by applying $ f $'s Laurent series expansion to an annulus centered at $ z_0 $ with outer radius $ R $ and inner radius $ r \to 0 $. As $ r \to 0 $, the annulus converges to the disk $ D $, the principle part of $ f $'s Laurent series vanishes, only the regular part remains, and we are left with the above expression for the Taylor series.

\subsubsection{Proposition: Zeros of Holomorphic Functions are Isolated}
Let $ U \subset \C $ be a region. The zeros of every non-constant holomorphic function $ f: U \to \C $ are isolated. More formally, for every zero $ z_0 \in U $ of $ f $, there exists positive rela number $ \delta \in \R^{+} $ such that $ f(z) \neq 0 $ for all $ z $ in the open disk $ D(z_0, \delta) $ of radius $ \delta $ centered at $ z_0 $.

\subsubsection{Consequences: Cluster Points of Zeros}
Let $ U \subset \C $ be a region and $ f: U \to \C $ be a non-constant holomorphic function. In this case, all of $ f $'s zeros do not have cluster points in $ U $.

More so, if any two holomorphic functions $ f, g: U \to \C $ coincide on a subset $ E \subset U $ that has cluster points in $ U $, then $ f \equiv g $ everywhere on $ U $. We show this by applying the previous statement to the function $ f - g $.

\subsection{Isolated Singularities}

\subsubsection{Definition: Isolated Singularity}
Let $ U \subset \C $ be a region, $ z_0 \in U $ be a complex number, $ R \in \R^{+} $ be a positive real number, and $ f: U \setminus \{z_0\} \to \C $ be a complex function. In this case, $ z_0 $ is an \textit{isolated singularity} of the function $ f $ if there exists a disk $ D(z_0, R) $ centered at $ z_0 $ such that $ f $ is holomorphic on $ D \setminus \{z_0\} $, i.e. everywhere on $ D $ except at $ z_0 $ itself.

\subsubsection{Definition: Removable Singularity}
Let $ U \subset \C $ be a region and let $ z_0 \in U $ be an isolated singularity of the function $ f: U \setminus \{z_0\} \to \C $. If all coefficients $ a_n $ in the principle part of $ f $'s Laurent series about $ z_0 $ are equal to zero, then $ z_0 $ is a \textit{removable singularity} of $ f $. In this case, we can write
\begin{align*}
	f(z) = \sum_{n=0}^{\infty}a_n(z - z_0)^n
\end{align*}

Equivalently, $ z_0 $ is a removable singularity of $ f $ if there exists holomorphic function $ g : U \to \C  $ that coincides with $ f $ on $ U \setminus \{z_0\} $ defined by
\[
	g(z) = \begin{cases}
		f(z), &  z \in U \setminus \{z_0\}\\
		c_0, & z = z_0
	\end{cases}
\]
where $ c_0 $ is the $ 0 $-index coefficient of $ f $'s Laurent series.

\subsubsection{Proposition: Bounded Functions and Removable Singularities}
Let $ U \subset \C $ be a region and let $ z_0 \in U $ be an isolated singularity of the function $ f: U \setminus \{z_0\} \to \C $. If $ f $ is bounded in some neighborhood of $ z_0 $, then $ z_0 $ is a removable singularity of $ f $.


\subsubsection{Definition: Pole}
Let $ U \subset \C $ be a region and let $ z_0 \in U $ be an isolated singularity of the function $ f: U \setminus \{z_0\} \to \C $. If only finitely many coefficients $ a_n $ in the principle part of $ f $'s Laurent series about $ z_0 $ are nonzero, then $ z_0 $ is a \textit{pole} of $ f $.

\subsubsection{Proposition: Pole and Divergence}
Let $ U \subset \C $ be a region and let $ z_0 \in U $ be a pole of the function $ f: U \setminus \{z_0\} \to \C $. In this case $ \displaystyle{\lim_{z \to z_0} \abs{f(z)} = \infty} $.


\subsubsection{Definition: Essential Singularity}
Let $ U \subset \C $ be a region and let $ z_0 \in U $ be an isolated singularity of the function $ f: U \setminus \{z_0\} \to \C $. If all coefficients $ a_n $ in the principle part of $ f $'s Laurent series about $ z_0 $ are nonzero, then $ z_0 $ is a \textit{essential singularity} of $ f $.\\



\subsubsection{Casorati Weierstrass Theorem}
Let $ z_0 $ be an essential singularity of the function $ f $. In this case for all $ w \in \C $ and for all real $ \epsilon, \delta > 0 $ there exists $ z $ in $ D(z_0, \delta) \setminus \{z_0 \} $ such that $ \abs{f(z) - w} < \epsilon $.

Interpretation: A function $ f(z) $ takes on values arbitrarily close to \textit{every} complex number $ w \in \C $ in every neighborhood of an essential singularity.

\subsubsection{Infinity as an Isolated Singularity}
\begin{itemize}
	\item The point $ \infty $ is an isolated singularity of the function $ f $ if the point $ 0 $ is an isolated singularity of the function $ \tilde{f}(z) \coloneqq f\left(\frac{1}{z}\right) $.

	\item If the point $ 0 $ is a removable singularity, pole, or essential singularity of $ \tilde{f}(z) \coloneqq f\left(\frac{1}{z}\right) $, then the point $ \infty $ is correspondingly a removable singularity, pole, or essential singularity of the function $ f(z) $.
	
	\item If $ \tilde{f}(z) \coloneqq f\left(\frac{1}{z}\right) $ has the Laurent series $ \displaystyle{	\tilde{f}\left(\frac{1}{z}\right) = \sum_{-\infty}^{\infty} c_n z^{n}} $ about the point $ 0 $, then $ f(z) $ has the Laurent series
	\begin{align*}
		f(z) = \sum_{-\infty}^{\infty} c_n z^{-n}
	\end{align*}
	about the point $ \infty $.
	
	\item If the point $ 0 $ is a zero/pole of degree $ n $ of the function $ \tilde{f} $, then the point $ \infty $ is correspondingly a zero/pole of degree $ n $ of the function $ f $.
\end{itemize}


\subsubsection{Definition: Meromorphic Function}
The function $ f $ is \textit{meromorphic} on the open subset $ U \subset \C $ of the complex plane if there exists subset $ S \subset U $  such that
\begin{enumerate}
	\item $ S $ does not have cluster points in $ D $
	\item Every point in $ S $ is a pole of $ f $
	\item $ f $ is holomorphic on $ D \setminus S $
\end{enumerate}
Interpretation: A meromorphic function $ f $ is a function that is holomorphic on the subset $ U $, except for on a set $ S $ of isolated points, which must be poles of $ f $.

\textbf{Note}: Every meromorphic function on the open subset $ U $ can be expressed as the ratio of two holomorphic functions.


\subsection{Complex Powers and Logarithms}

\subsubsection{Complex Logarithm}
\textbf{Complex Logarithm}: A complex logarithm of the complex number $ z \in \C $ is any complex number $ w = \ln z $ for which $ z = e^{w} $. Because the complex exponent has periodic behavior, a complex number $ z $ in general has multiple complex logarithms. If $ z = \abs{z}e^{i(\phi + 2\pi k)} $, then
\begin{align*}
	(\ln z)_k = \ln \abs{z} + i(\phi + 2\pi k)
\end{align*}
are all complex logarithms of $ z $, and the complex logarithmic function is not well-defined.

\textbf{Complex Logarithmic Function}: We define the complex logarithmic function as $ \ln : \C \setminus (-\infty, 0] \to \C $ with the relation
\begin{align*}
	\ln z = \ln (\abs{z}e^{i\phi}) = \ln \abs{z} + i \phi
\end{align*}
for $ \phi \in (-\pi, \pi) $. The left half of the real line is removed from the domain so that $ \ln $ is holomorphic on its domain.

\subsubsection{Complex Logarithm: Integration and Differentiation}
Let $ U = \C \setminus (-\infty, 0] $ and define the point $ w_0 \in U $. In this case, for all $ w \in U $:
\begin{itemize}
	\item $ \displaystyle{\ln w - \ln w_0 = \int_{w_0}^{w} \frac{\diff z}{z} = \int_{\gamma} \frac{\diff z}{z}} $\\
	where the path $ \gamma \in C^1 $ is a continuously differentiable path in $ U $ with $ w_0 $ as its starting point and $ w $ as its ending point.
	
	\item $ \displaystyle{\dv{}{w} \ln w = \frac{1}{w}} $
\end{itemize}

\subsubsection{Proposition: Branches of the Complex Logarithm}
Let $ U \subset \C $ be a region such that $ \operatorname{Ind}_{\gamma}(z_0) = 0$ for all closed paths $ \gamma $ in $ U $ and all points $ z_0 \in U^{c} $ i.e.  all closed curves in $ U $ don't wind around points outside of $ U $. In this case, for all holomorphic functions $ f: U \to \C $ without zeros on $ U $ there exists holomorphic function $ g = \ln f $, i.e. holomorphic function $ g: D \to \C $ such that $ e^{g(z)} = f(z) $ for all $ z \in U $. More so, any two such holomorphic functions $ g $ differ by $ 2\pi i n $ where $ n \in \mathbb{Z} $. 

Interpretation: We can define different branches of the complex logarithm on arbitrary complex regions; such branches of the logarithm differ by $ 2\pi in $.

\subsubsection{Definition: Complex Power Function}
For all $ \alpha \in \C \setminus (-\infty, 0]$ and all $ z \in \C $ we define
\begin{align*}
	z^{\alpha} = e^{\alpha \ln z}
\end{align*}
Interpretation: We use the definition of the complex logarithm to define the complex power function.


\subsection{Residue}

\subsubsection{Definition: Residue}
Let $ f $ be a holomorphic function and $ z_0 $ be an isolated singularity of $ f $. The coefficient $ a_{-1} $ in the Laurent series of the holomorphic function $ f $ expanded about the isolated singularity $ z_0 $ is called the \textit{residue} of the function of $ f $ at the point $ z_0 $ and is denoted by $ \Res(f; z_0) $.

Interpretation: If the function $ f $ has an isolated singularity at $ z_0 $, then the residue $ \Res(f; z_0) $ is the coefficient $ a_{-1} $ in the Laurent series
\begin{align*}
	f(z) = \sum_{-\infty}^{\infty} a_n (z-z_0)^n
\end{align*}

\subsubsection{Lemma: Residue and Integration}
Let $ U \subset \C $ be a region, $ z_0 \in U $ be a point in $ U $ and let $ \gamma : \R \to U $ be a closed path in $ U $ for which $ \operatorname{Ind}_{\gamma}(z_0) = 1$. If the function $ f : U \to \C $ is holomorphic on $ U $, except possibly at $ z_0 $, then
\begin{align*}
	\frac{1}{2\pi i}\oint_{\gamma}f(z)\diff z = \operatorname{Ind}_{\gamma}(z_0) a_{-1} = \Res(f; z_0)
\end{align*}
Interpretation: We write $ f(z) $ as in infinite sum in terms of its Laurent series expansion and apply the integral identity
\[
	\oint_{\gamma}z^{k} \diff z = 
	\begin{cases}
		2\pi i, & k = -1\\
		0, & \text{otherwise}
	\end{cases}
\]
where $ \gamma $ is a simple closed curve enclosing the origin, for instance the unit circle $ C(0, 1) $. From this identity, it follows that all terms in $ f $'s Laurent series integrate to zero except the term with $ n = -1 $, what remains is the coefficient $ a_{-1} $, which is the residue $ \Res(f; z_0) $.


\subsubsection{Residue Theorem}
Let $ U \subset \C $ be a region, let $ S \subset U $ be a subset of $ U $ such that $ S $ does not have cluster points in $ U $ (i.e. $ S $ is a set of isolated points in $ U $), let the function $ f $ be holomorphic on $ U \setminus S $ and define the closed path $ \gamma $ in $ U \setminus S $ such that $ \operatorname{Ind}_{\gamma}(z_0) = 0$ for all $ z_0 \in U^{c} $. In this case
\begin{align*}
	\frac{1}{2\pi i} \oint_{\gamma}f(z) \diff z = \sum_{z_0 \in S} \Res(f; z_0) \operatorname{Ind}_{\gamma}(z_0)
\end{align*}
Interpretation: In practice, $ S $ is the set of $ f $'s isolated singularities. The theorem expresses $ f $'s line integral via that sum of $ f $'s residues at the isolated singularities.


\subsubsection{Integrals of Rational Functions with Sinusoidal Arguments}
Let $ R $ be a rational function of the form $ R(\cos \phi, \sin \phi) $ that is continuous on the unit circle $ z = e^{i\phi} $. In this case
\begin{align*}
	\int_{0}^{2\pi}R(\cos \phi, \sin \phi) \diff \phi = -i \oint_{\abs{z}=1} R\left [\frac{1}{2}\left (z + \frac{1}{2}\right ), \frac{1}{2i} \left(z - \frac{1}{z}\right)\right]\frac{\diff z}{z}
\end{align*}
Interpretation: We calculate a difficult-to-evaluate integral in terms of the integrand's residue.

\subsubsection{Integrals of Single-Variable Rational Functions}
Let $ R $ be a single-variable holomorphic function with a finite number of isolated singularities $ z_0 $ in the upper half of the complex plane, no singularities on the real line, and a zero of degree at least two at $ \infty $. In this case:
\begin{align*}
	&\int_{-\infty}^{\infty}R(x) \diff x = 2\pi i\sum_{\operatorname{Im} z_0 > 0} \Res(R;z_0)\\
	&\int_{-\infty}^{\infty}R(x)e^{ix} \diff x = 2\pi i\sum_{\operatorname{Im} z_0 > 0} \Res(Re^{ix};z_0)
\end{align*}
Interpretation: We calculate a difficult-to-evaluate integral in terms of the integrand's residue.


\subsubsection{Mellin Transform in Terms of Residue}
The Mellin transform of the function $ f $ is the parameter-dependent integral
\begin{align*}
	\{\mathcal{M}f \}(t) =  \int_{0}^{\infty}f(x)x^{t-1}\diff x \qquad (t > 0)
\end{align*}
Let $ f $ be holomorphic on $ \C $ except possibly at a finite number of points $ \alpha_{i} = \alpha_1, \dots, \alpha_n$ that do not lie on the line $ [0, \infty) $ and let $ a, b $ be constants such that $ a < b $ and $ \abs{f(z)z^b} $ is bounded for large $ z $ and $ \abs{f(z)z^a} $ is bounded in a neighborhood of $ 0 $. In this case the Mellin transform of $ f $ is
\begin{align*}
	\{\mathcal{M}f \}(t) = \int_{0}^{\infty}f(x)x^{t-1}\diff x = -\frac{\pi e^{-\pi i t}}{\sin \pi t} \sum_{i} \Res(f(z)z^{t-1}; \alpha_{i}) \qquad (t \in (a, b) \setminus \mathbb{Z})
\end{align*}
Interpretation: If $ f $ meets certain conditions, we can calculate $ f $'s Mellin transform in terms of its residues at the isolated singularities $ \alpha_i $, which is often easier than by definition.

\subsubsection{Residue at a First Degree Zero}
Let the point $ z_0 \in \C $ be a first degree zero of the function $ g $ and let $ f $ be holomorphic in a neighborhood of $ z_0 $. In this case
\begin{align*}
	\Res(\frac{f}{g}; z_0) = \frac{f(z_0)}{g'(z_0)}
\end{align*}
Interpretation: Under the above conditions, we can calculate the residue of the quotient $ f/g $ at the point $ z_0 $ with the above formula, which is easier than by definition with a series expansion.

\subsubsection{Residue at Poles}
Let the function $ f $ have a pole of degree $ n $ at the point $ z_0 \in \C $ and be holomorphic on a neighborhood of $ z_0 $. In this case
\begin{align*}
	\Res(f; z_0) = \lim_{z \to z_0} \frac{\big(  (z-z_0)^n f(z)\big)^{(n-1)}}{(n-1)!} \equiv \lim_{z\to z_0} \dv[(n-1)]{}{z} \left[\frac{(z-z_0)^n f(z)}{(n-1)!}\right]
\end{align*}
Interpretation: We can calculate the residue of $ f $ at its poles with the above formula instead of using the definition.


\subsection{Open Mapping Theorem and Maximum Modulus Principle}

\subsubsection{Definition: Open Map}
The map $ f:X \to \C $ is an \textit{open map} if for every open subset $ Y \subset X $, the set $ f(Y) $ is also open.

Interpretation: An open map maps all open subsets of its domain to open subsets.

\subsubsection{Meromorphic Line Integral On a Disk via Poles and Zeros}

Let $ f $ be meromorphic on the region $ U \subset \C $, let $ \overline{D} $ be a closed disk such that $ f $ has neither poles nor zeros on the border $ \partial D $. Finally, let $ \mathcal{Z} $ be the sum of the multiplicities of $ f $'s zeros on $ D $ and let $ \mathcal{P} $ be the sum of the degrees of the $ f $'s poles on $ D $. In this case
\begin{align*}
	\oint_{\partial D}\frac{f'(z)}{f(z)}\diff z = 2\pi i (\mathcal{Z} - \mathcal{P})
\end{align*}
Interpretation: The line integral of a meromorphic function $ f $ along the border of a disk is related directly to the number of $ f $'s poles and zeros \textit{inside} the disk.

\subsubsection{Lemma: Disks and Zeros}
Let $ f $ be holomorphic on an open neighborhood $ U $ of the point $ \alpha $ and let $ \beta = f(\alpha) $, meaning the function $ z \mapsto f(z) - \beta $ has a zero at $ \alpha $. Let the multiplicity of this zero be $ n $. In this case, there exist disks $ D(\alpha, \delta) \subset U $ and $ D(\beta, \epsilon) $ such that the equation $ f(z) = w $ has exactly $ n $ unique solutions in the disk $ D(\alpha, \delta) $ for all $ w \in D(\beta, \epsilon) \setminus \{\beta \} $. 

\textit{Interpretation}: The function $ f $ maps the disk $ D(\alpha, \delta) $ surjectively to the disk $ D(\beta, \epsilon) $ and exactly $ n $ unique points in the disk $ D(\alpha, \delta) $ map to the point $ w $ in the disk $ D(\beta, \epsilon) $.

\subsubsection{Consequence: Open Mapping Theorem}
Let $ U \subset  \C$ be a region and let $ f : U \to \C $ be a non-constant holomorphic function. In this case, $ f $ is an open map.

\subsubsection{Consequence: Bijectivity of Holomorphic Maps}
Let the function $ f $ be non-constant and holomorphic on a neighborhood of the point $ z_0 $ (implying $ f $ is an open map by the open mapping theorem). In this case there exists an open neighborhood $ U $ of $ z_0 $ such that:
\begin{enumerate}
	\item $ f $ maps $ U $ bijectively to the open subset $ f(U) $ and
	\item the inverse function $ f^{-1}: f(U) \to U $ is also holomorphic.
\end{enumerate}

\subsubsection{Maximum Modulus Principle}
Let $ f $ be a non-constant holomorphic function defined on the region $ U \in \C $. In this case the modulus $ \abs{f} $ does not attain a maximum value at any point $ z \in U $. More so, $ \abs{f} $ can reach a minimum value only its zeros.

Reciprocally, let $ U \subset C $ be a region and let $ g:U\to \C $ be an arbitrary function. In this case, if there exists a point $ z_0 \in U $ for which 
\begin{align*}
	\abs{g(z_0)} \geq \abs{g(z)} \ \text{for all} \ z \in U
\end{align*}
then $ g $ is a constant function.

\subsubsection{Consequence: Maximum Modulus Principle on a Compact Set}
Let $ K \subset \C $ be a compact set and let the function $ f $ be holomorphic and non-constant on a neighborhood of $ K $. In this case, the restricted function $ \abs{f} \big |_{K} $ can attain its maximum only at points $ z \in \partial K $ on the border $ \partial K $ and its minimum only either on the border $ \partial K $ or at $ f $'s zeros.

\subsubsection{Schwarz Lemma}
Let $ R, r \in \R^+ $ be positive real numbers and let $ f : D(0, R) \to D(0, r) $ be a holomorphic function such that $ f(0) = 0 $. In this case, either 
\begin{flalign*}
	&\qquad \quad \abs{f(z)} < \frac{r}{R}\abs{z} \quad \text{for all} \quad z \in D(0, R) \setminus \{0 \} && \text{and} && \abs{f'(0)} < \frac{r}{R}&
\end{flalign*}
or
\begin{flalign*}
	&\qquad \quad  f(z) = \frac{r}{R} w z \quad \text{for all} \ z \in D(0, R) \text{ and } w \in \C \ \text{such that} \ \abs{w} = 1&
\end{flalign*}

\subsubsection{Definition: Biholomorphism and Automorphism}
Let $ U, V \in \C $ be two open regions. A bijective holomorphic map $ f : U \to V $ between $ U $ and $ V $ is called a \textit{biholomorphism} from $ U $ to $ V $. A bijective holomorphic map $ f: U \to U $ mapping $ U $ to itself is called an \textit{automorphism} of $ U $.

\subsubsection{Automorphisms of the Unit Disk}
\begin{itemize}
	\item The function of the form
	\begin{align*}
		f_{\alpha}(z) = \frac{z - \alpha}{1 - \overline{\alpha}z}; \quad \alpha \in D(0, 1)
	\end{align*}
	is an automorphism of the disk D(0, 1).
	
	\item Every automorphism $ f: D(0, 1) \to D(0, 1) $ of the unit disk is of the form 
	\begin{align*}
		f(z) = w f_{\alpha}(z)
	\end{align*}
	for some $ \alpha \in D(0, 1) $ and $ w \in \C $ such that $ \abs{w} = 1 $.
\end{itemize}

\newpage

\section{Harmonic Functions}

\textbf{Definition: Harmonic Functions}\\
Harmonic functions are functions $ u: \R^n \to \R $ satisfying the equality
\begin{align*}
	\Delta u = \sum \pdv[2]{u}{x_i} = 0
\end{align*}
Interpretation: Harmonic functions are functions whose Laplacian is zero.

\subsection{Harmonic Functions in the Plane}
%For this section, let $ D(0, 1) \subset \R^2 $ be the open unit disk, denoted simply by $ D_1 $. And let $ \overline{D}_1 $ be the closed unit disk.

\subsubsection{Poisson Kernel on the Unit Disk}
The Poisson kernel on the unit disk is the function $ P_r : D(0, 1) \to \R $ given by
\begin{align*}
	P_r(\theta) = \frac{1 - r^2}{1 - 2r\cos \theta + r^2}; \quad r\in[0, 1), \theta \in \R
\end{align*}
Interpretation: The values of $ r $ and $ \theta $ for which $ P_r $ is defined correspond to points on the open unit disk.

\textbf{Sketched Derivation}: Applying Cauchy's formula to curve $ \gamma $ along the border of the unit disk in the complex plane leads to the equality that for all $ z \in \overline{D}(0,1) $:
\begin{align*}
	f(z) = \frac{1}{2\pi i} \oint_{\gamma} f(\zeta) \frac{1 - \abs{z}^2}{\abs{1-\overline{z}\zeta}^2} \frac{\diff \zeta}{\zeta}
\end{align*}
If we write $ \zeta = e^{i\theta} $ and $ z = r e^{i\phi} $ for $ r\in[0, 1), \theta \in \R $ and parameterize the line integral, the expression becomes
\begin{align*}
	f(re^{i\phi}) = \frac{1}{2\pi} \int_{0}^{2\pi} \frac{1 - r^2}{1 - 2r \cos(\theta - \phi) + r^2} f(e^{i\phi}) \diff \theta
\end{align*}
The integrand with $ \phi = 0 $ is the Poisson kernel.

\subsubsection{Poisson Formula on the Unit Disk}
For every function $ u $ that is harmonic on the open unit disc $ D(0, 1) $ and continuous on the closed unit disk $ \overline{D}(0, 1) $:
\begin{align*}
	u(re^{i\phi}) = \frac{1}{2\pi} \int_{0}^{2\pi} P_r(\theta - \phi) u\left(e^{i\phi} \right)\diff \theta
\end{align*} 
for all $ r\in[0, 1), \phi \in \R $.

Interpretation: The value of a harmonic function at a point $ re^{i\phi} $ on the open unit disk is directly related to an integral of the Poisson kernel and the function's value on the unit circle at the point $ e^{i\phi} $.

\subsubsection{Properties of the Poisson Kernel}
For all $ r\in[0, 1) $ and $ \theta \in \R $, the Poisson kernel $ P_r $ is positive, even, and continuous with period $ 2\pi $. More so
\begin{enumerate}
	\item For $ \theta \in [0, 2\pi] $,
	 \[ \lim_{r\to1}P_r(\theta) = 
	 \begin{cases}
		0, & \theta \neq 0\\
		\infty, & \theta = 0	
	\end{cases} \qquad \qquad 	 
	\]

	\item For angles $ \phi, \theta $ such that $ 0 \leq \phi \leq \theta \leq \pi $ we have $ P_r(\theta) \leq P_r(\phi) $. In other words, at a fixed radius $ r $, the value of the Poisson kernel decreases with increasing angle.
	
	\item $ \displaystyle{\frac{1}{2\pi} \int_{0}^{2\pi} P_r(\theta)\diff \theta = 1} $. This is simply a special case of the Poisson formula for $ u = 1 $ and $ \phi = 0 $.
\end{enumerate}


\subsubsection{Poisson Formula on an Arbitrary Disk}
On an arbitrary disk $ D(\alpha, R) $ centered at the point $ \alpha $ with radius $ R $, the Poisson formula states that for all $ r \in D(\alpha, R) $
\begin{align*}
	u(\alpha + re^{i\phi}) = \frac{1}{2\pi} \int_{0}^{2\pi} \frac{R^2 - r^2}{R^2 - 2 Rr \cos(\theta - \phi) + r^2} u(\alpha + re^{i\phi}) \diff \theta
\end{align*}

\subsubsection{Mean Value Property in the Plane}
For every function $ u $ that is harmonic on the open disc $ D(\alpha, R) $ and continuous on the closed disk $ \overline{D}(\alpha, R) $:
\begin{align*}
	u(\alpha) = \frac{1}{2\pi}\int_{0}^{2\pi}u(\alpha + Re^{i\theta}) \diff \theta
\end{align*}
Interpretation: This is a special case of the Poisson formula on a disk with $ r = 0 $. The property equates the value of the function $ u $ at the center of a disk to the average value function along the disk's border.


\subsubsection{Maximum Principle in the Plane}
\begin{enumerate}
	\item If $ u $ is a non-constant, harmonic function on the \textit{open} region $ U $, then $ u $ cannot attain either a maximum or a minimum anywhere on $ U $. 
	
	\item If $ u $ is a non-constant, harmonic function on the \textit{compact} region $ K $. then $ u $ can attain an a maximum or a minimum only on the border $ \partial K $.
\end{enumerate}



\subsubsection{Dirichlet Problem on the Unit Disk}
Let $ f : \partial D(0, 1) \to \R$ be a continuous function defined on the unit circle. In this case, there exists exactly one function $ u $ continuous on the closed unit disk $ \overline{D}(0, 1) $ and harmonic on the open unit disk for which
\begin{align*}
	f = u \big |_{\partial D(0, 1)}
\end{align*}

Such a function $ u $ is given in terms of the Poisson formula as
\[
	u(re^{i\phi}) = 
	\begin{cases}
		\displaystyle{\frac{1}{2\pi}\int_{0}^{2\pi}P_r(\phi - \theta) g(e^{i\phi})\diff \phi}, & r < 1\\[2.0mm]
		f(z) & r = 1
	\end{cases}	
\]
Interpretation: Given a function $ f $ defined on the unit circle, there exists exactly one harmonic function $ u $ defined on the unit disk such that $ u $ is equal to $ f $ on the unit circle. More so, $ f $ and $ u $ are closely related by the Poisson formula for a disk.
 

\subsection{Harmonic Functions in Space}

\textbf{Notation:} For this section, unless explicitly stated otherwise:
\begin{itemize}
	\item Let the region $ U \subset \R^3 $ be an open, connected, and bounded subset of $ \R^3 $ and let $ \overline{U} = U \cup \partial U $ be the closed set $ U $. 
	\item Let $ U $ have a smooth, outward-oriented surface $ \partial U \in C^1 $, meaning that we can locally parameterize the $ \partial U $ at every point on the surface with a continuously differentiable vector function $ \bm{r}: \R^2 \to \R^3 $, $ \bm{r} = \bm{r}(t, s) $, such that $ \bm{r}_{t} \cross \bm{r}_s \neq 0 $ for all values of $ (t, s) $.
	\item Let $ \bm{n}(\bm{r}) $ denote the unit normal vector to the surface $ \partial U $ at the point $ \bm{r} $.
\end{itemize}


\subsubsection{Fundamental Solution of the Laplace Equation in Space}
\begin{itemize}
	\item The Laplace equation $ \Delta u = 0 $ for harmonic functions $ u : \R^3 \to \R $ reads
	\begin{equation*}
		\Delta u = \pdv[2]{u}{x} + \pdv[2]{u}{y} + \pdv[2]{u}{z} = 0
	\end{equation*}
	The Laplace equation can be written $ \Delta u(r) = u''(r) + \frac{2}{r}u'(r) = 0 $	for functions $ u = u(r) $ whose value depends only on the distance $ r = \sqrt{x^{2} + y^{2} + z^{2}} $ from the origin. 
	
	The general solution to the equation $ u''(r) + \frac{2}{r}u'(r) = 0 $ is $ u(r) = a + \frac{b}{r}$.
	
	
	\item The \textit{fundamental solution} of the Laplace equation in space is the function $ u : \R^+ \to \R $ 
	\begin{equation*}
		u(r) = -\frac{1}{4\pi r} \qquad (r > 0)
	\end{equation*}

\end{itemize}

\subsubsection{Quick Review of Gauss's and Directional Derivatives}
We need these three concepts to understand Green's identities, which follow.
\begin{enumerate}
	\item For the continuously differentiable vector field $ \bm{F} : \overline{U} \to \R^3  $
	\begin{align*}
		 \iiint_{U} (\div{\bm{F}}) \diff V = \oiint_{\partial U} (\bm{F} \cdot \bm{n}) \diff S
	\end{align*}
	Interpretation: The volume integral of the divergence $ \div{\bm{F}} $ over the entire region $ U $ equals the surface integral of $ \bm{F} $ over the region's boundary $ \partial U $.
	
	\item The \textit{gradient} of the scalar function $ u: U \to \R $ is $ \displaystyle{\grad{u} = \left(\pdv{u}{x}, \pdv{u}{y}, \pdv{u}{z} \right)} $
	
	\item The \textit{directional derivative} of the continuously differentiable scalar function $ u: U \to \R $ in the direction of the vector $ \uvec{n} \in \R^{3} $ is $\, \displaystyle{\pdv{u}{} \equiv u_{\uvec{n}} = \grad{u} \cdot \uvec{n}} $
\end{enumerate}


\subsubsection{Green's Identities in Space}
\begin{itemize}
	\item \textit{Green's identities} for all twice-continuously differentiable scalar functions $ u, v: U \to \R $ defined on a neighborhood of $ U $ and for the point $ \bm{r}_0 \in U $  are
	\begin{itemize}
		\item[--] $ \displaystyle{\iiint_{U} \left(v \Delta u +  \grad{u} \cdot \grad{v}\right) \diff V = \oiint_{\partial U} v u_{\uvec{n}}\diff S } $\\
		
		\item[--] $ \displaystyle{ \iiint_U \left(v \Delta u - u \Delta v  \right) \diff V = \iint_{\partial U} \left(v u_{\uvec{n}} - u v_{\uvec{n}}  \right)\diff S  } $
		
		\item[--] $ \displaystyle{u(\bm{r}_0) = \frac{1}{4\pi} \iint_{\partial U}\left(\frac{u_{\uvec{n}}(\bm{r})}{\norm{\bm{r} - \bm{r}_0}} - u(\bm{r}) \pdv{}{\uvec{n}}\frac{1}{\norm{\bm{r} - \bm{r}_0}}  \right) \diff S - \frac{1}{4\pi} \iiint_U \frac{\Delta u}{\norm{\bm{r} - \bm{r}_0}} \diff V } $
	\end{itemize}
	
	\item \textit{Implication:} For any harmonic function $ u $ on a neighborhood of the closed region $ \overline{U} $
	\begin{equation*}
		\oiint_{\partial U} u_{\uvec{n}} \diff S \equiv \oiint_{\partial U} (\grad{u} \cdot \uvec{n} )\diff S  = 0
	\end{equation*}
	\textit{Interpretation}: The closed surface integral of a harmonic function $ u $'s directional derivative normal to the surface of integration is zero. Derived directly from the first identity with $ v = 1 $ and $ u : U \to \R $ an arbitrary harmonic function.
\end{itemize}

\subsubsection{Mean Value Property for Harmonic Functions in Space}
Consider the closed sphere $ \overline{K}(\bm{r}_0, R) \subset U $ of radius $ R $ centered at $ \bm{r}_{0} $ and contained completely in the region $ U \subset \R^{3} $. For all harmonic functions $ u: U \to \R $
\begin{equation*}
	u(\bm{r}_0) = \frac{1}{4\pi R^2} \iint_{\partial K} u(\bm{r}) \diff S
\end{equation*}
\textit{Interpretation}: The value of the function $ u $ at the center of the closed sphere $ K $ equals the average value of $ u $ on the sphere's surface.

\subsubsection{Maximum and Minimum Principle for Harmonic Functions in Space}
Consider the \textit{open} subset $ U \subset \R^{3} $ and the \textit{compact} subset $ \overline{K} \subset \R^3 $.
\begin{itemize}
	\item Any non-constant function $ u : U \to \R $ that is harmonic on $ U $ cannot attain either a maximum or a minimum on $ U $. 

	\item Any non-constant function $ u : \overline{K} \to \R $ that is harmonic on $ K $ and continuous on $ \overline{K} $ can attain a maximum or minimum only on the border $ \partial K $. 
\end{itemize}


\subsubsection{Dirichlet Problem in Space}


For the region $ U \subset \R^3 $ and given the function $ f : \partial U \to \R $, the Dirichlet problem is to find a function $ u $ that is continuous on the border $ \overline{U} $ and harmonic on the interior $ U $ for which $ \displaystyle{f = u \big |_{\partial U}} $; i.e, to find a harmonic function $ u $ that has the same values as the given function $ f $ on the boundary $ \partial U $.

If it exists, the solution $ u $ to the Dirichlet problem is unique.



\subsubsection{Green's Function in Space}
In three dimensions, a Green's function (formally, a Green's function of the Laplacian operator) on the region $ U \subset \R^3 $ with smooth border $ \partial U $ is a function $ G : \overline{U} \cross U \to \R $ such that for all $ \bm{r}_0 \in U $:
\begin{enumerate}
	\item The function $ \displaystyle{\bm{r} \mapsto G(\bm{r}, \bm{r}_0) + \frac{1}{4\pi \norm{\bm{r} - \bm{r}_0}}   } $ is continuous on $ \overline{U} $ and harmonic on $ U $.
	\item For all $ \bm{r} \in \partial U $, $ G(\bm{r}, \bm{r}_0) = 0 $
\end{enumerate}

\subsubsection{Poisson Kernel and Formula in Terms of Green's Function}
In three-dimensional space, the Poisson kernel and Poisson formula are defined in terms of Green's function. 
\begin{enumerate}
	\item \textbf{Poisson Kernel}: In terms of Green's function, the Poisson kernel $ P_r : \partial U \cross U \to  \R $ in space is given by
	\begin{align*}
		P_r(\bm{r}, \bm{r}_0) = \pdv{}{\uvec{n}} G(\bm{r}, \bm{r}_0)  = \big(\grad{G(\bm{r}, \bm{r}_0)} \big)\cdot \uvec{n}
	\end{align*}
	
	\item \textbf{Poisson Formula}: Let $ u : U \to \R $ be a  harmonic function. In this case, for all $ \bm{r}_0 \in U $
	\begin{align*}
		u(\bm{r}_0) = \oiint_{\partial U} \pdv{}{\uvec{n}} G(\bm{r}, \bm{r}_0) u(\bm{r}) \diff S = \oiint_{\partial U} P_r(\bm{r}, \bm{r}_0) u(\bm{r}) \diff S
	\end{align*}

\end{enumerate}

\newpage

\section{Fourier Analysis}

\subsection{Convolution}
Convolutions are used, among other things, to approximate a given non-differentiable function in terms of smooth functions.

\subsubsection{Definition: Convolution}
The \textit{convolution} of the functions $ f, g: \R \to \C $, denoted by $ f * g $, is the parameter-dependent integral
\begin{align*}
	(f*g)(x) = \int_{-\infty}^{\infty}f(x-t)g(t)\diff t
\end{align*}
assuming the integral converges absolutely.

\textbf{Note: Condition for Absolute Convergence} The integral
\begin{align*}
	\int_{-\infty}^{\infty}f(x-t)g(t)\diff t
\end{align*}
converges absolutely if $ f $ is bounded and piecewise continuous on its domain and $ g $ is piecewise continuous on its domain and has compact support. Of course, there are other conditions for absolute convergence; this is just one.

\subsubsection{Properties of Convolutions}
Convolutions are linear, commutative, and associative. In terms of symbols, let $ f, g, h: \R \to \C $ be functions. In this case:
\begin{flalign*}
	&\qquad 1.\ (\alpha f + \beta g)*h =  \alpha (f*g) + \beta (g*h) && (\text{linearity})&\\
	&\qquad 2.\ g*f = f*g  && (\text{commutativity})&\\
	&\qquad 3.\  f*(g*h) = (f*g)*h  && (\text{associativity})&
\end{flalign*}

\subsubsection{Differentiating Convolutions}
Let $ f, g:\R \to \C $ be two functions.
\begin{itemize}
	\item If $ f $ is a continuously differentiable function, and the integral $ \int_{-\infty}^{\infty} \abs{f'(x-t)g(t)}\diff t$ converges uniformly on every finite interval of $ x $ then
	\begin{align*}
		(f*g)' = f'*g
	\end{align*}
	
	\item Similarly, $ f $ is an arbitrary function, $ g $  is continuously differentiable and the integral $ \int_{-\infty}^{\infty} \abs{g'(x-t)f(t)}\diff t$ converges uniformly on every finite interval of $ x $, then
	\begin{align*}
		(f*g)' = f*g'
	\end{align*}
	
	\item If $ g $ is a smooth function (is infinitely continuously differentiable) with compact support then $ f*g $ is also smooth and
	\begin{align*}
		(f*g)^{(n)} = f * g^{(n)}; \quad n \in \mathbb{N}
	\end{align*}
\end{itemize}


\subsubsection{Definition: The Space $ L^1(\R) $}
The space $ L^1(\R) $ is the extension of the space $ C_{c}(\R) $ (the set of all continuous complex functions $ f:\R \to \C $ with compact support) with respect to the norm
\begin{align*}
	\norm{f}_{1} = \int_{\R}\abs{f(x)} \diff x
\end{align*}
In other words, we create the $ L^1(\R) $ space by adding to the $ C_c(\R) $ space all functions that are limits of functions sequences in $ C_c(\R) $ with respect to the $ \norm{\cdot}_1 $ norm. \\

\textbf{Note: Interpreting the $ L^1(\R) $ Space}\vspace{1mm}

Elements of the $ L^1(\R) $ space may be viewed as functions $ f : \R \to \C $ with a finite Lebesgue integral $ \int_{\R}\abs{f(x)} \diff x $ (i.e. $ \norm{f}_1  $ norm). In this interpretation, we view two elements $ f \in  L^1(\R) $ as equal if their values agree except possibly on a set with zero measure. 

\subsubsection{Proposition: Convolutions of Functions in $ L^1(\R) $}
Let $ f, g: \R \to \C $ be two functions.
\begin{itemize}
	\item If $ f $ is an element of $ L^1(\R) $ and $ g $ is a bounded, piecewise continuous function, then $ f*g $ is a continuous function.
	
	\item If $ f, g $ are both elements of $ L^1(\R) $:
	\begin{enumerate}
		\item The convolution $ f * g $ exists and is itself an element of $ L^1(\R) $
		\item $ \displaystyle{\norm{f*g}_1 \leq \norm{f}_1 \norm{g}_1} $
	\end{enumerate}
	

\end{itemize}

\subsubsection{Definition: The Function $ g_{(\delta)} $}
Let $ g:L^1(\R) $ be a function and define $ \delta \in \R $ such that $ \delta > 0 $. In this let $ g_{(\delta)}(x) $ denote the function
\begin{align*}
	g_{(\delta)}(x) \coloneqq \frac{1}{\delta} g\left(\frac{x}{\delta}\right) \qquad (\delta > 0)
\end{align*}


\subsubsection{Proposition: Properties of $ g_{(\delta)} $}
Let $ g:L^1(\R) $ be a function for which $ \int_{-\infty}^{\infty}g(x) \diff x = 1 $.
\begin{itemize}
	\item In this case, for all $ \delta > 0 $,
	\begin{align*}
		\int_{-\infty}^{\infty}g_{\delta}(x) \diff x = 1
	\end{align*}

	\item If $ g $ has compact support then, for small $ \delta $, $ g_{(\delta)} $ is non-zero only in a small neighborhood of the point $ 0 $. In this case, for all continuous $ f:\R \to \C $
	\begin{align*}
		(f *g_{(\delta)}) = \int_{_{-\infty}}^{\infty}f(x-t)g_{(\delta)}(t) \diff t \approx f(x) \int_{_{-\infty}}^{\infty} g_{(\delta)}(t) \diff t = f(x)
	\end{align*}
\end{itemize}

\subsubsection{Theorem: Convergence of Convolutions Involving $ g_{(\delta)} $}
Let $ g \in L^1(\R) $ be a function for which $ \int_{-\infty}^{\infty}g(x) \diff x = 1 $.
\begin{itemize}
	\item For all bounded, continuous $ f:\R \to \C $, the convolutions $ f*g_{(\delta)} $ converge to $ f $ uniformly on all finite intervals $ [a, b] \subset \R $ as $ \delta $ approaches $ 0 $.
	In equation form:
	\begin{align*}
		\lim_{\delta \to 0}  ( f*g_{(\delta)})(x) = f(x)
	\end{align*}
	
	\item For all functions $ f \in L^1(\R) $ the convolutions $ f*g_{(\delta)} $ converge to $ f $ with respect to the norm $ \norm{\cdot}_{1} $ as $ \delta $ approaches $ 0 $. 
	\begin{align*}
		\lim_{\delta \to 0} \norm{f*g_{(\delta)}) - f} = 0
	\end{align*}
\end{itemize}

\textbf{Note}: If we choose $ g $ to be a smooth function, it follows that we can uniformly approximate a continuous function $ f $ with smooth functions on every finite interval $ [a, b] \subset \R $. 

More so, if $ f $ has compact support in the interval of approximation $ [a, b] $ and $ g $ is a smooth function with a with compact support in $ [a, b] $, we are led to the following consequence:

\subsubsection{Consequence: Approximation By Smooth Functions}
Let $ [a, b] \subset \R $ be a finite interval and let $ f: \R \to \C $ be a continuous function with compact support in $ [a, b] $. In this case, for all $ \epsilon > 0 $, there exists a sequence $ (f_n) $ of smooth functions with supports in the interval $ [a-\epsilon, b+\epsilon] $ that converges uniformly to $ f $.

\subsubsection{Weierstrass Approximation Theorem}
Every continuous function  $ f:\R \to \R $ can be uniformly approximated by polynomials on the compact interval $ [a, b] \subset \R $. In other words, for all $ \epsilon > 0 $ there exists polynomial $ p : \R \to \C $ such that
\begin{align*}
	\max_{x\in[a, b]} \abs{f(x) - p(x)} < \epsilon
\end{align*}

\subsubsection{Definition: Schwartz Space $  \mathcal{S}(\R) $}
The Schwartz space $ \mathcal{S}(\R) $ of rapidly decreasing functions is the set of all smooth functions $ f:\R \to \C $ for which the functions of the form $ x \mapsto f^{(m)}(x)x^n $ are bounded for all $ m, n \in \mathbb{N} $.

\textbf{Note}: The Schwartz space is a subset of $ L^1(\R) $ since the function $ x \mapsto (1 + x^2)f(x) $ is bounded and continuous (and thus an element of $  L^1(\R) $) for all $ f \in \mathcal{S}(\R) $.

\subsubsection{Proposition: Properties of the Schwartz Space}
\begin{itemize}
	\item For every function $ f \in  \mathcal{S}(\R) $,
	\begin{itemize}
		\item all translations $ f_t(x) = f(x - t) $,
		\item all functions of the form $ x \mapsto f(ax)$ for all $ a \in \R $,
		\item all derivatives $ f^{(n)} $ and
		\item all products of the form $ fp $ where $ p:\R \to \C $ is a polynomial
	\end{itemize}
	are also elements of $ \mathcal{S}(\R) $.
	
	\item If $ f, g : \R \to \C $ are elements of $ \mathcal{S}(\R)  $, then the convolution $ f * g $ is also in $ \mathcal{S}(\R)  $.
\end{itemize}


\subsection{The Fourier Transform in $ \R $}


\subsubsection{Motivation}

The expansion of the function $ f $ into a Fourier series in terms of the complex sinusoidal function $ e^{ik\frac{2\pi}{w}x} $ where $ k \in \mathbb{Z} $ is
\begin{align*}
	f(x) = \sum_{-\infty}^{\infty} c_k e^{ik\frac{2\pi}{w}x} =  \sum_{-\infty}^{\infty}\left(\frac{1}{w}\int_{-w/2}^{w/2} f(t)  e^{-ik\frac{2\pi}{w}t} \diff t \right) e^{ik\frac{2\pi}{w}x}
\end{align*}
for $ x \in \left(- \frac{w}{2}, \frac{w}{2} \right) $.


For large $ \omega $, in the limit where $ f(x) $ rapidly approaches zero as $ \abs{x} $ approaches $ \infty $, we make the approximation
\begin{align*}
	f(x) = \int_{-w/2}^{w/2} f(t)  e^{-ik\frac{2\pi}{w}t} \diff t \approx \int_{-\infty}^{\infty} f(t)  e^{-ik\frac{2\pi}{w}t} \diff t \qquad (\text{large } w)
\end{align*}
Next, we introduce the new variables $ \Delta \xi = \frac{2\pi}{w} $ and $ \xi_k = k \frac{2\pi}{w} $ to obtain
\begin{align*}
	\frac{1}{w} \int_{-\infty}^{\infty} f(t)  e^{-ik\frac{2\pi}{w}t} \diff t  = \frac{\Delta \xi}{2\pi} \int_{-\infty}^{\infty} f(t)  e^{-i \xi_k t} \diff t 
\end{align*}
Finally, we define the function $ \displaystyle{\widehat{f}(\xi_k) \coloneqq \frac{1}{\sqrt{2\pi}} \int_{-\infty}^{\infty} f(t)  e^{-i \xi_k t} \diff t } $
and obtain
\begin{align*}
	&f(x) \approx \frac{1}{\sqrt{2\pi}} \sum_{-\infty}^{\infty} \widehat{f}(\xi_k) e^{i\xi_k x} \Delta \xi \qquad (\text{large } w) \\
	&\lim_{w \to \infty} f(x) = \frac{1}{\sqrt{2\pi}} \int_{-\infty}^{\infty} \widehat{f}(\xi) e^{i\xi x} \diff \xi 
\end{align*}

\subsubsection{Definition of the Fourier Transform}
The \textit{Fourier transform} of the function $ f \in L^{1}(\R) $, denoted by $ \widehat{f} $, is defined as
\begin{align*}
	\widehat{f}(\xi) = \frac{1}{\sqrt{2\pi}} \int_{-\infty}^{\infty} f(x)e^{-i\xi x} \diff x
\end{align*}
Note that the above integral is absolutely convergent because $ \abs{e^{-i\xi x}} = 1 $.


\subsubsection{Properties of the Fourier Transform}
Define the function $ f \in L^{1}(\R) $. In this case:
\begin{enumerate}
	\item The Fourier transform $ \widehat{f} $ is continuous and $ \abs{\widehat{f}(\xi)} \leq \norm{f}_{1} $ for all $ \xi \in \R $.
	
	\item Let $ e_{t}(x) \coloneqq e^{itx} $ for all $ t \in \R $. In this case $ \displaystyle{\widehat{fe_t}(\xi) = \widehat{f}(\xi - t)} $
	
	\item Let $ f_{[a]}(x) \coloneqq f(ax) $ for all $ a > 0 $. In this case $ \displaystyle{\widehat{f_{[a]}}(\xi) = \frac{1}{a}\widehat{f}\left(\frac{\xi}{a} \right)} $
	
	\item Let $ f_t \coloneqq f(x - t) $ for all $ t \in \R $. In this case $ \displaystyle{\widehat{f_{t}}(\xi) = e^{-it\xi} \widehat{f}(\xi)} $
	
	\item Let $ \chi(x) = x $ for all $ x \in \R $. If $ \xi f \in L^{1}(\R) $, then $ \widehat{f} $ is differentiable and 
	\begin{align*}
	\big( \widehat{f} \, \big)'(\xi) = -i \left( \widehat{\chi f}\right)(\xi)
	\end{align*}
	
	\item If $ f $ is continuously differentiable and $ f' \in L^{1}(\R) $ then $ \widehat{f}'(\xi) = i \xi \widehat{f}(\xi) $.
	
	\item For all $ g \in L^{1}(\R) $, $ \displaystyle{\widehat{f*g} = \sqrt{2\pi} \widehat{f} \widehat{g}} $.
	
	\item For all $ f \in \mathcal{S}(\R) $, $ \widehat{f} \in \mathcal{S}(\R) $.
\end{enumerate}

\subsubsection{Inverse Fourier Transform}

\textbf{Lemma (Special Case)}: Let $ g_{0}(x) \coloneqq e^{-\frac{1}{2}x^2} $ and $ (g_0)_{[a]}(x) \coloneqq e^{-\frac{1}{2}(ax)^2} $ for $ a > 0 $. In this case,
\begin{align*}
	\widehat{g_0} = g_0  \quad \text{and} \quad \widehat{(g_0)_{[a]}}(\xi) = \frac{1}{a} e^{-\frac{\xi^2}{2a^2}}
\end{align*}

\textbf{General Statement}: Let $ f \in L^{1}(\R) $ be a function for which $ \widehat{f}  \in L^{1}(\R) $. In this case
\begin{align*}
	f(x) = \frac{1}{\sqrt{2\pi}} \int_{-\infty}^{\infty} \widehat{f}(\xi) e^{ix \xi} \diff \xi
\end{align*}
for almost all $ x \in \R $. \\

\textbf{Inverse Fourier Transform}: The inverse Fourier transform of the function  $ f \in L^{1}(\R) $ function for which $ \widehat{f}  \in L^{1}(\R) $, denoted by $ \check{f} $, is defined as
\begin{align*}
	\check{f}(x) \coloneqq \frac{1}{\sqrt{2\pi}} \int_{-\infty}^{\infty} f(t) e^{i x \xi} \diff \xi = \widehat{f}(-x)
\end{align*}

\subsubsection{Inverse Fourier Transform and Schwartz Space}
The Fourier transform maps the space $ \mathcal{S}(\R) $ bijectively onto itself.

\subsubsection{Riemann-Lebesgue Lemma}
For all $ f \in L^{1}(\R) $, $ \displaystyle{\lim_{\abs{\xi} \to \infty} \widehat{f}(\xi) = 0} $.
In other words, the Fourier transform of a function vanishes the argument $ \xi $ approaches $ \infty $ in absolute value.

\subsubsection{Fourier Transform and Lipschitz Continuity}
Let the continuous function $ f \in L^{1}(\R) $ be Lipschitz continuous at the point $ x \in \R $. In this case
\begin{align*}
	f(x) = \lim_{A \to \infty} \frac{1}{\sqrt{2\pi}} \int_{-A}^{A} \widehat{f}(\xi) e^{ix\xi} \diff \xi
\end{align*}
We can define the value of Lipschitz continuous function in $ L^{1}(\R) $ in terms of the function's Fourier transform.

\subsubsection{Plancherel Theorem: Motivation and Background}
Let $ f, g \in \mathcal{S}(\R) $ be two functions in the Schwartz space. In terms of the inverse Fourier transform, we can manipulate the inner product $ \expval{f, g} $ as follows:
\begin{align*}
	\expval{f, g} &\coloneqq \int_{-\infty}^{\infty} f(x) \overline{g}(x) \diff x = \int_{-\infty}^{\infty} f(x) \overline{g(x)} \diff x = \int_{-\infty}^{\infty} f(x) \left(\frac{1}{\sqrt{2\pi}} \int_{-\infty}^{\infty} \overline{\widehat{g}(\xi)e^{ix\xi}}\diff \xi \right) \diff x\\
	&= \int_{-\infty}^{\infty} \overline{\widehat{g}(\xi)} \left( \frac{1}{\sqrt{2\pi}} \int_{-\infty}^{\infty} f(x) e^{-ix\xi} \diff x \right) \diff \xi = \int_{-\infty}^{\infty} \overline{\widehat{g}(\xi)} \widehat{f}(\xi) \diff \xi = \expval{\widehat{f}, \widehat{g}}
\end{align*}

This means that the Fourier transform, i.e. the mapping $ f \mapsto \widehat{f} $, preserves the inner product on $ \mathcal{S}(\R) $ and thus also the derived norm, meaning $ \norm{\widehat{f}}_{2} = \norm{f}_2 $ for all $ f \in \mathcal{S}(\R) $. 

Recall that we can define the space $ L^{2}(\R) $ as a completion of the set of all continuous functions with compact support. It follows from the section on convolutions that all functions in $ L^{2}(\R) $ can be uniformly approximated with smooth functions with support in a fixed interval. From these two points, it follows that every function $ f \in L^{2}(\R) $ is the limit of some sequence $ (f_n) $ of smooth functions with compact support; i.e.
\begin{align*}
	\lim_{n \to \infty} \norm{f - (f_n)}_2 = 0.
\end{align*}

Because all functions $ f_n - f_m $ are in $ \mathcal{S}(\R) $, if follows that 
\begin{align*}
	\norm{\widehat{f_n} - \widehat{f_m} }_{2} = \norm{f_n - f_m}_2 
\end{align*}
for all $ f_n, f_m $ in such a s sequence $ (f_n) $.

Because the sequence $ (f_n) $ is convergent by Cauchy's criterion, it follows that the sequence $ (\widehat{f}_n) $ is also convergent by Cauchy's criterion. 

The limit of the sequence $ (\widehat{f}_n) $ may then be defined as the Fourier transform $ \mathcal{F}(f) $ of the function $ f $.

In this way, the Fourier transform becomes a linear map of the space $ L^{2}(\R) $ onto itself, since the transform preserves the inner product. This forms the basis for the Plancherel theorem.

\subsubsection{Plancherel Theorem}
The Fourier transform in $ \mathcal{S}(\R) $ can be uniquely extended to a unitary operator on the space $ L^{2}(\R) $.


\subsection{Basic Concepts: The Fourier Transform in $ \R^n $}

\subsubsection{The Spaces $ L^{1}(\R^n) $ and $ L^{2}(\R^n) $ }
\begin{itemize}
	\item The space $ L^1(\R^n) $ is a completion of the space $ C_c(\R^n) $ of all continuous functions $ f:\R^n \to \R $ with compact support in the one-norm 
	\begin{equation*}
		\norm{f}_{1} = \int_{\R^n} \abs{f(\bm{x})} \diff V
	\end{equation*}
	where $ \bm{x} = (x_1, x_2, \dots, x_n) $ is an element of $ \R^n $ and $ \diff V = \diff x_1, \diff x_2, \dots, \diff x_n $ is a volume element of $ \R^n $.
	
	\item Analogously, the space $ L^2(\R^n) $ is a completion of the space $ C_c(\R^n) $ of all continuous functions $ f:\R^n \to \R $  with compact support in the two-norm 
	\begin{equation*}
		\norm{f}_{2} = \int_{\R^n} \abs{f(\bm{x})} \diff V
	\end{equation*}

	\item Both norms are induced by the inner product 
	\begin{align*}
		\expval{f, g} = \int_{\R^n} f(\bm{x})\overline{g(\bm{x})} \diff V
	\end{align*}
	where $ f, g: \R^n \to \R$ are integrable functions.
\end{itemize}

\subsubsection{Convolution in $ \R^n $}
A convolution of the functions $ f, g:  \R^n \to \R $ in $ \R^n $ is defined as
\begin{equation*}
	f*g = \int_{\R^n} f(\bm{t})g(\bm{x} - \bm{t}) \diff V(\bm{t})
\end{equation*}
assuming the integral is absolutely convergent.

The properties of convolutions in $ \R^n $ are analogous to those of convolutions in $ \R $. 

\subsubsection{Note}
Let $ g\in \L^{1}(\R^n) $ be a function, let $ \delta > 0 $ be a constant, and define
\begin{equation*}
	g_{(\delta)} \coloneqq \delta^{-n}g(\delta^{-1}\bm{x}) \qquad (\delta > 0)
\end{equation*}
In this case, if $ \displaystyle{\int_{\R^n} g(\bm{x}) \diff V = 1} $, then analogously $ \displaystyle{\int_{\R^n} g_{(\delta)}(\bm{x}) \diff V = 1} $

\subsubsection{Theorem: Approximation by Convolution}
Let $ g\in \L^{1}(\R^n) $ be a function such that $ \displaystyle{\int_{\R^n} g(\bm{x}) \diff V = 1} $. In this case:
\begin{enumerate}
	\item For all bounded continuous functions $ f : \R^n \to \C $ the sequence of functions $ f * g_{(\delta)} $ converges uniformly to $ f $ on all compact subsets of $ \R^n $ as $ \delta $ approaches zero.

	\item For all functions $ f \in L^{1}(\R^n) $, 
	\begin{equation*}
		\lim_{\delta \to 0} \norm{f*g_{(\delta)} - f}_{1} = 0
	\end{equation*}
	In other words, as $ \delta $ approaches zero, the function $ f*g_{(\delta)} $ becomes arbitrarily close to $ f $.
\end{enumerate}

\subsubsection{Schwartz Space in $ \R^n $}
The Schwartz space $ \mathcal{S}(\R^n) $ consists of all infinitely continuously differentiable functions $ f: \R^n \to \C $ for which all the derivatives
\begin{equation*}
	x_{1}^{k_1} \dots x_{n}^{k_n} \frac{\partial_{j_1 + \dots + j_n} f}{\partial x_{1}^{j_1} \dots \partial x_n^{j_n}} \qquad (k_1, \dots, k_n, j_1, \dots, j_n \in \mathbb{N})
\end{equation*}
are bounded.

\subsection{The Fourier Transform in $ \R^n $}

\subsubsection{Definition: The Fourier Transform in $ \R^n $}
For Fourier transform of the function $ f \in L^{1}(\R^n) $ is
\begin{equation*}
	\widehat{f}(\bm{\xi}) = \frac{1}{(\sqrt{2\pi})^n} \int_{\R^n} f(\bm{x})e^{-i \expval{\bm{x}, \bm{\xi}}} \diff V (\bm{x})
\end{equation*}
where $ \expval{\bm{x}, \bm{\xi}} $ denotes the standard inner product on $ \R^n $, namely $ \expval{\bm{x}, \bm{\xi}} = x_1 \xi_1 + \dots + x_n \xi_n $.

\subsubsection{Properties of the Fourier Transform in $ \R^n $}
The properties of the Fourier transform in $ \R^n $ are analogous to those of the Fourier transform in $ \R $. 

For the function $ f \in L^{1}(\R^n) $
\begin{enumerate}
	\item The function $ \widehat{f} $ is continuous on $ \R^n $ and $ \abs{\widehat{f}(\bm{\xi})} \leq \norm{f}_{1} $ for all $ \bm{\xi} \in \R^n$.
	
	\item For all $ \bm{t} \in \R^n $, let $ e_{\bm{t}} $ denote the function $ e_{\bm{t}}(\bm{x}) \coloneqq e^{i\expval{\bm{t}, \bm{x}}} $. In this case
	\begin{equation*}
		\widehat{f e_{\bm{t}}} (\bm{\xi}) = \widehat{f}(\bm{\xi - \bm{t}})
	\end{equation*}
	
	\item Scaling: for all $ a > 0 $, let $ f_{[a]}(\bm{x}) \coloneqq f(a\bm{x}) $. In this case
	\begin{equation*}
		\widehat{f_{[a]}} (\bm{\xi}) = \frac{1}{a^n} \widehat{f}\left(\tfrac{\bm{\xi}}{a}\right)
	\end{equation*}
	
	\item Translation: for all $ \bm{t} \in \R^n $, let $ f_{\bm{t}} \coloneqq f(\bm{x} - \bm{t})$. In this case
	\begin{equation*}
		\widehat{f_{\bm{t}}} (\bm{\xi}) = e^{-i\expval{\bm{t}, \bm{\xi}}} \widehat{f}(\bm{\xi})
	\end{equation*}
	
	\item Let $ \chi_{j}(\bm{x}) = x_j $ be the function mapping $ \bm{x} \in \R^n $ to the $ j $th component of the vector $ \bm{x} $ and let $ f : \R^n \to \R $ be a function such that $ \chi_j f $ is an element of $ L^{1}(\R^n) $. In this case,
	\begin{equation*}
		\pdv{\widehat{f}}{\xi_j} (\bm{\xi}) = - i \widehat{(\chi_j f)} (\bm{\xi})
	\end{equation*}
	
	\item If $ \pdv{f}{x_j} $ is an element of $ L^{1}(\R^n) $, then
	\begin{equation*}
		\widehat{\pdv{f}{x_j}}(\bm{\xi}) = i \xi_j \widehat{f}(\bm{\xi})
	\end{equation*}
	
	\item Convolutions: for all functions $ g \in L^{1}(\R^n) $, $ \displaystyle{\widehat{f*g}} = \left(\sqrt{2\pi}\right)^n \widehat{f}\widehat{g} $.
	
	\item For all functions $ f \in \mathcal{S}(\R^n) $, the transform $ \widehat{f} $ is also an element of $ \mathcal{S}(\R^n) $.
	
	\item The Fourier transform commutes with rotations (orthogonal transformations with determinant $ +1 $) in $ \R^n $. If $ \mathcal{R} $ denotes a rotation in $ \R^n $ and $ \mathcal{R}f $ denotes the function $ (\mathcal{R}f)(\bm{x}) = f\left(\mathcal{R}^{-1}(\bm{x}) \right) $, then for all $ \bm{\xi} \in \R^n $
	\begin{equation*}
		\widehat{(\mathcal{R}f)}(\bm{\xi}) = \widehat{f}\left (\mathcal{R}^{-1} (\bm{\xi})\right )
	\end{equation*}
\end{enumerate}

\subsubsection{Note: Products and the Gaussian Kernel}
If the function $ f: \R^n \to \R $ is a product of $ n $ single-variable functions, i.e.
\begin{equation*}
	f(\bm{x}) = f_1(x_1) \cdots f_n(x_n) \qquad (f_i: \R \to \R)
\end{equation*}
then the Fourier transform $ \widehat{f} $ can also be written as a product of $ n $ single-variable functions.

An important example of such a function is the Gaussian kernel
\begin{align*}
	\frac{1}{(\sqrt{2\pi})^n} e^{-\frac{1}{2}\norm{x}^2} = \frac{1}{\sqrt{2\pi}} e^{-\frac{1}{2}x_1^2} \cdots  \frac{1}{\sqrt{2\pi}} e^{-\frac{1}{2}x_n^2}
\end{align*}

\subsubsection{Inverse Fourier Transform}
If $ f \in L^{1}(\R^n) $ is a function for which $ \widehat{f} $ is also an element of $  L^{1}(\R^n) $, then
\begin{equation*}
	f(\bm{x}) =	\frac{1}{(\sqrt{2\pi})^n} \int_{\R^n} \widehat{f}(\bm{\xi}) e^{i\expval{\bm{x}, \bm{\xi}}} \diff V(\bm{\xi})
\end{equation*}

\subsubsection{Plancherel Theorem in $ \R^n $}
The Fourier transform can be uniquely extended to an unitary operator on $ L^2(\R^n) $ and
\begin{equation*}
	\norm{\widehat{f}\,}_{2} = \norm{f}_{2} \quad \text{for all} \quad f \in L^1(\R^n) \cap L^2(\R^n)
\end{equation*}

\subsubsection{Riemann-Lebesgue Lemma in $ \R^n $}
For all functions $ f \in L^1(\R^n) $, $ \displaystyle{\lim_{\norm{\bm{\xi}} \to \infty} \widehat{f}(\bm{\xi}) = 0} $. In other words, the Fourier transform vanishes for large values of the argument $ \bm{\xi} $.

\section{Partial Differential Equations}

\subsection{The Fourier Transform and the Heat Equation}

\subsubsection{Definition: The Heat Equation}
The heat equation is a partial differential equation describing the change of the quantity $ u(\bm{r}, t) $ in space and time of the form
\begin{equation*}
	\pdv{u}{t} = c \left(\pdv[2]{u}{x} + \pdv[2]{u}{y} + \pdv[2]{u}{z}\right) = c \Delta u
\end{equation*}
where $ c > 0 $ is a constant and $ \Delta u $ denotes the Laplacian operation.

\subsubsection{Background and Motivation}
We are interested in solutions of the heat equation for the initial condition $ u(\bm{r}, 0) = f(\bm{r}) $ where $ f $ is a given function that approaches zero as $ \norm{r} $ approaches $ \infty $. 

\subsubsection{Fourier Transform of Heat Equation}
The Fourier transform of the function $ u(\bm{r}, t) $ at a fixed time $ t $ is
\begin{equation*}
	\widehat{u}(\bm{\rho}, t) = \frac{1}{(\sqrt{2\pi})^2} \int_{\R^3} u(\bm{r}, t)e^{-i\expval{\bm{r}, \bm{\rho}}} \diff V
\end{equation*}
and the Fourier transform of the heat equation at fixed $ t $ is
\begin{equation*}
	\widehat{\left(\pdv{u}{t}\right)} = \pdv{\widehat{u}}{t} = - c \norm{\bm{\rho}}^2 \widehat{u}
\end{equation*}
This expression can be written in the form
\begin{equation*}
	\pdv{}{t} \left[e^{c\norm{\bm{\rho}^2}t } \widehat{u}\right] = 0
\end{equation*}
which shows that the derivative of the function $ e^{c\norm{\bm{\rho}^2}t } \widehat{u} $ with respect to time is zero; i.e. $ e^{c\norm{\bm{\rho}^2}t } \widehat{u} $ is constant with respect to time. We then write
\begin{equation}
	e^{c\norm{\bm{\rho}^2}t } \widehat{u}(\bm{\rho}, t) = A(\bm{\rho}) \label{ft:eq:ft_constant}
\end{equation}
where $ A $ is a function of only position $ \bm{\rho} $.

Next, applying the Fourier transform to the initial condition $ u(\bm{r}, 0) = f(\bm{r})$ gives
\begin{equation*}
	\widehat{u}(\bm{\rho}, 0) = \widehat{f}(\bm{\rho})
\end{equation*}

Evaluating Equation \ref{ft:eq:ft_constant} at $ t = 0 $ results in $ A(\bm{\rho}) = \widehat{f}(\bm{\rho}) $, leading to
\begin{equation*}
	\widehat{u}(\bm{\rho}, t) = \widehat{f}(\bm{\rho})   e^{-c\norm{\bm{\rho}^2}t }
\end{equation*}
The plan is to apply the inverse Fourier transform to this equation to map $ \widehat{u}(\bm{\rho}, t) $ back into position-time space, thus solving the heat equation.

\textbf{Lemma}: From the earlier properties of the Fourier transform, we have
\begin{equation*}
	\mathcal{F}\left(e^{-a^2 \norm{\bm{r}}^2} \right) = \mathcal{F}\left(e^{-\frac{1}{2}\norm{\sqrt{2}a\bm{r}}^2} \right) = \frac{1}{(\sqrt{2}a)^3}e^{-\frac{1}{2} \norm{\frac{1}{\sqrt{2}a}\bm{\rho}}^2} =  \tfrac{1}{(\sqrt{2}a)^3}e^{-\frac{\norm{\bm{\rho}}^2}{4a^2}}
\end{equation*}

Next we choose the constant $ a > 0 $ such that
\begin{equation*}
	\frac{1}{4a^2} = ct \implies a = \frac{1}{2\sqrt{ct}}
\end{equation*}
It follows that for fixed time $ t $,
\begin{equation*}
	\mathcal{F}\left(e^{-c\norm{\bm{\rho}}^2t} \right)(\bm{r}) = \frac{1}{(\sqrt{2ct})^3} e^{-\frac{\norm{\bm{r}}^2}{4ct}} \equiv K_{t}(\bm{r}) 
\end{equation*}
The function $ K_{t}(\bm{r}) $ is called the \textit{heat kernel}. 

We now return to the equation
\begin{equation*}
	\widehat{u}(\bm{\rho}, t) = \widehat{f}(\bm{\rho})   e^{-c\norm{\bm{\rho}^2}t }
\end{equation*}
and apply the inverse Fourier transform with our intermediate results to get
\begin{equation*}
	u(\bm{r}, t) = \frac{1}{(\sqrt{2\pi})^3} (f*K_{t})(\bm{r}) = \frac{1}{(\sqrt{4\pi ct})^3} \int_{\R^3}f(\bm{r} - \bm{s})e^{-\frac{\norm{\bm{s}}^2}{4ct}}\diff V (\bm{s})
\end{equation*}

\subsection{Vibration of Strings and the Wave Equation}

\subsubsection{Finite One-Dimensional String with Fourier Method}
\begin{itemize}
	\item The one-dimensional wave equation is
	\begin{equation*}
		u_{tt} = c^2u_{xx}
	\end{equation*}
	If the string is fixed at the endpoints, the boundary conditions are $ u(0, t) = u(l, t) = 0 $. The initial position and velocity distributions $ u(x, 0) $ and $ u_{t}(x, 0) $ are given by $ f(x) $ and $ g(x) $.
	
	The goal is to solve the wave equation $ u_{tt} = c^2u_{xx} $ for the boundary conditions $ u(0, t) = u(l, t) = 0 $ and initial conditions $ u(x, 0) = f(x, 0) $ and $ u_{t}(x, 0) = g(x, 0) $.
	
	\item Separate the solution into the product $ u(x, t) = X(x)T(t) $ where $ X $ and $ T $ are twice-differentiable non-zero functions. The wave equation becomes
	\begin{equation*}
		\frac{1}{c^{2}}\frac{T''(t)}{T(t)} = \frac{X''(x)}{X(x)}
	\end{equation*}
	Because the left and right sides of the equation are simultaneously equal and dependent on different variables, they must be constant. We write
	\begin{equation*}
  		\frac{1}{c^{2}}\frac{T''(t)}{T(t)} = \frac{X''(x)}{X(x)} \equiv - \lambda
  	\end{equation*}
  	which leads to the two equations
  	\begin{equation*}
  		X'' + \lambda X = 0 \quad \text{and} \quad T'' + c^{2}\lambda T = 0
  	\end{equation*}
  	Because $ T(t) $ is non-zero, the boundary conditions lead to $ X(0) = X(l) = 0$. 
  	
  	\item The general solution to $ X'' + \lambda X = 0 $ 
  	\begin{equation*}
  		X(x) = A \cos \omega x + B \sin \omega x \qquad (\lambda = \omega^{2})
  	\end{equation*}
  	The boundary conditions lead to $ A = 0 $ and $ n $ eigenvalues $ \omega_{n} = \frac{n\pi}{l}, n \in \mathbb{N} $ and eigenfunctions $ X_{n}(x) = B_n \sin \frac{n\pi}{l} $.
  	
  	\item The solutions to $ T'' + c^{2}\lambda T = 0 $ with $ \lambda = \omega^{2} = \left(\frac{n\pi}{l}\right)^{2} $ are
  	\begin{equation*}
  		T_{n}(t) = A_n \cos(\omega_n c t ) + B_n \sin( \omega_n c t)
  	\end{equation*}
  	
  	\item The solution to $ u(x, t) = X(x)T(t) $ is thus
  	\begin{equation*}
  		u_{n}(x, t) = \left[A_n \cos(\frac{n\pi c}{l} t ) + B_n \sin( \frac{n\pi c}{l} t)\right] \sin (\frac{\pi n}{l} x)
  	\end{equation*}
  	Because the wave equation is linear, the general solution is a linear superposition of the solutions:
  	\begin{equation*}
  		u(x, t) = \sum_{n=1}^{\infty} u_{n}(x, t) = \sum_{n=1}^{\infty}\left(A_n \cos \frac{n\pi c}{l} t  + B_n \sin \frac{n\pi c}{l} t\right)\sin\frac{\pi n}{l} x
  	\end{equation*}
  
  	\item The initial conditions $ u(x, 0) = f(x) $ and $ u_{t}(x, 0) = g(x) $ lead to
  	\begin{equation*}
  		f(x) = \sum_{n=1}^{\infty} A_n \sin\frac{\pi n}{l} x \quad \text{and} \quad g(x) = \sum_{n=1}^{\infty} \frac{n\pi c}{l} B_n  \sin\frac{\pi n}{l} x
  	\end{equation*}
  	
  	\item The coefficients $ A_{n} $ and $ B_{n} $ are found with a sine expansion of $ f(x) $ and $ g(x) $. This is possible if $ f, g \in L^{2}(0, l) $. First, $ f, g $ are expanded to the interval $ [-l, l] $ using $ f(x) = -f(x)$ on the interval $ [-a, 0) $ (analogously for $ g $), then expanded onto the entire real line with period $ 2l $. 
  	
  	The functions $ f, g $ can then be written as a Fourier sine series with the function $ \sin \frac{n \pi}{l}x $. The Fourier sine expansions produce the solutions for the coefficients:
  	\begin{equation*}
  		A_{n} = \frac{2}{l}\int_{-l}^{l}f(x) \sin \frac{n \pi}{l}x \diff x \quad \text{and} \quad B_n = \frac{l}{n\pi c} \frac{2}{l}\int_{-l}^{l}g(x) \sin \frac{n \pi}{l}x \diff x
  	\end{equation*}
\end{itemize}

\subsubsection{d'Alembert's Formula}
\begin{itemize}
	\item We again look for solutions to the wave equation $ u_{tt} = c^{2}u_{xx} $ with the initial conditions $ u(x, 0) = f(x) $ and $ u_{t}(x, 0) = 0$. 
	
	\item Assume solutions of the form
	\begin{equation*}
		u(x, t) = F(x - ct) + G(x + ct)
	\end{equation*}	
	where $ F, G $ are twice differentiable functions.
	
	The initial conditions read
	\begin{equation*}
		u(x, 0) = F(x) + G(x) = f(x) \qquad u_{t}(x, 0) = c(G'(x) - F(x)) = g(x)
	\end{equation*}
	
	\item Differentiating the first equation, solving for $ F'(x) $, and inserting this into the second equation leads to
	\begin{equation*}
		G'(x) = \frac{f'(x)}{2} + \frac{g'(x)}{2c} \quad \text{and} \quad F'(x) = \frac{f'(x)}{2} - \frac{g'(x)}{2c}
	\end{equation*}
	
	\item Integrating the expression for $ G'(x) $ with respect to $ x $ gives
	\begin{equation*}
		G(x) = \frac{f(x)}{2} + \frac{1}{2c} \int_{0}^{x} g(\chi)\diff \chi + C
	\end{equation*}
	Combining this with $ F(x) + G(x) = f(x) $ leads to
	\begin{equation*}
		F(x) = \frac{f(x)}{2} - \frac{1}{2c} \int_{0}^{x} g(\chi)\diff \chi + C
	\end{equation*}
	
	\item The solution for $ u(x, t) = F(x - ct) + G(x + ct) $ is thus
	\begin{align*}
		u(x, t) &= \frac{1}{2}\big[ f(x-ct) + f(x + ct)\big] + \frac{1}{2c}\left[\int_{0}^{x+ct}g(\chi)\diff \chi - \int_{0}^{x-ct}g(\chi)\diff \chi \right]\\
		&= \frac{1}{2}\big[ f(x-ct) + f(x + ct)\big] + \frac{1}{2c}\left[\int_{0}^{x+ct}g(\chi)\diff \chi + \int_{x-ct}^{0}g(\chi)\diff \chi \right]\\
		&= \frac{1}{2}\big[ f(x-ct) + f(x + ct)\big] + \frac{1}{2c} \int_{x-ct}^{x+ct}g(\chi)\diff \chi
	\end{align*}
	which is the \textit{d'Alembert formula} for the one-dimensional wave equation. To satisfy the wave equation, $ f $ must be twice-differentiable and $ g $ once-differentiable.
	
	\item If additionally $ f $ and $ g $ are odd periodic functions with period $ 2l $ for which $ f(l) = g(l) = 0 $, then $ u(0, t) = u(a, t) = 0 $ and the d'Alembert formula satisfies the boundary conditions $ u(0, t) = u(a, t) $. 
	
	The equality $ u(0, t) = 0 $ follows from the odd condition $ f(-x) = -f(x) $ and identity $ \int_{-a}{a}f(x)\diff x = 0 $ for odd functions
	\begin{equation*}
		u(0, t) = \frac{1}{2}\big[ f(-ct) + f(ct)\big] + \frac{1}{2c} \int_{-ct}^{+ct}g(\chi)\diff \chi = \frac{1}{2}\big[-f(ct) + f(ct) \big] + 0 = 0
	\end{equation*}
	
	The equality $ u(a, t) = 0  $ follows from the periodic condition $ f(x + a) = f(x - a) $ and the fact that the integral of an odd function over a full period is zero.
	\begin{align*}
		u(a, t) &= \frac{1}{2}\big[ f(a-ct) + f(a + ct)\big] + \frac{1}{2c} \int_{a-ct}^{a+ct}g(\chi)\diff \chi\\
		&=\frac{1}{2}\big[ -f(ct-a) + f(ct+a)\big] + \frac{1}{2c} \int_{a-ct}^{a+ct}g(\chi)\diff \chi\\
		&= 0 + 0 = 0
	\end{align*}
	
	
\end{itemize}

\section{Second-Order Homogeneous LDEs}

\subsection{Zeros of Solutions to Second-Order Homogeneous LDEs}

For the entirety of this section, let $ I \subset \R $ by an interval on the real line and let $ p, q : I \to \R $ be continuous functions on $ I $.

\subsubsection{Homogeneous 2nd Order Linear 
Differential Equation}
A homogeneous second-order linear differential equation is a differential equation of the form
\begin{equation*}
	y'' + p(x) y' + q(x) y = 0
\end{equation*}
where $ y $ is a function of $ x $.

The \textit{trivial solution} to such an equation is $ y \equiv 0 $. All other solutions are non-trivial.

\subsubsection{Zeros}
\begin{itemize}
	\item The zeros of nontrivial solutions to 2nd order homogeneous LDEs $ y'' + py' + qy = 0 $ cannot have (finite) cluster points. 
	
	\item Every zero of a nontrivial solution is a simple zero. In a equation form:
	\begin{equation*}
		y(x_0) = 0 \implies y'(x_0) \neq 0
	\end{equation*}
\end{itemize}

\subsubsection{Shared Zeros and Linear Dependence}
Let $ y_1 $ and $ y_2 $ be two solutions of the equation $ y'' + py' + qy = 0 $. If $ y_1 $ and $ y_2 $ have a shared zero, then $ y_1 $ and $ y_2 $ are linearly independent. 

Expressed in symbols, if there exists $ x_0 \in I $ such that $ y_1(x_0) = y_2(x_0) = 0$, then there exists constant $ \alpha \in \R $ such that $ y_1 = \alpha y_2 $.

\subsubsection{Zeros and Linear Independence}
Let $ y_1 $ and $ y_2 $ be linear independent solutions of $ y'' + py' + qy = 0 $, and let $ x_1, x_2 \in I $ be two zeros of $ y_1 $. In this case, the solution $ y_2 $ has exactly one zero in the open interval $ (x_1, x_2) $.


\subsubsection{Normal Form of a Homogeneous 2nd-Order LDE}
The motivation is comparing the solutions to $ y'' + py' + qy = 0 $ to the solutions of the simpler equation $ y'' + \alpha y = 0 $ where $ \alpha \in \R $ is a constant.

If $ p $ is continuously differentiable and $ p $ is continuous on $ I $, then the homogeneous second-order linear differential equation $ y'' + p(x)y' + q(x)y = 0 $  can be written in the \textit{normal form}
\begin{equation*}
	u'' + Q(x)u = 0
\end{equation*}
with the substitution $ y = uv $ where
\begin{align*}
	v = \exp(-\frac{1}{2} \int p(x) \diff x) && \text{and}
	&& Q(x) = q(x) - \frac{p(x)^2}{4} - \frac{p'(x)}{2}
\end{align*}


\subsubsection{Theorem: Sturm's Comparison Criterion}
Let $ q, r: I \to \R $ be continuous functions on $ I $ such that $ q(x) > r(x)$ for all $ x \in I $. 

In this case, between any two zeroes $ x_1, x_2 $ of the nontrivial solution $ u $ of the equation
\begin{equation*}
	u'' + r u = 0
\end{equation*}
there is at least one zero the solution to the equation
\begin{equation*}
	y'' + qy = 0
\end{equation*}
in the interval $ (x_1, x_2) $.

\subsubsection{Implication: }
If $ q(x) < 0 $ for all $ x \in I $, then any non-trivial solution $ y $ of the equation $ y'' + qy = 0 $ has at most one zero in $ I $.


\subsubsection{Example: Zeroes of the Bessel Equation}
Let $ y $ be a non-trivial solution to the Bessel equation
\begin{equation*}
	x^2 y'' + xy' + (x^2 - \nu^2)y = 0 \qquad (x > 0, \nu \geq 0)
\end{equation*}
The number of zeros depends on $ \nu $ as follows
\begin{itemize}
	\item If $ \nu \in \left [0, \frac{1}{2}\right ) $, then every interval of width $ \pi $ contains at least one zero of the solution $ y $.
	
	\item If $ \nu = \frac{1}{2} $, then the distance between subsequent zeroes of $ y $ is exactly $ \pi $.
	
	\item If $ \nu > \frac{1}{2} $, then every interval of width $ \pi $ contains at most one zero of $ y $.
\end{itemize}
In any case, $ y $ has infinitely many zeros on the positive real line $ (0, \infty) $

\subsection{Introduction to Sturm-Liouville Theory}
For the entirety of this section, let $ I = [a, b] \subset \R $ be an interval on the real line.

\subsubsection{Definition: The Sturm-Liouville Problem}
We are interested in solving problems of the form
\begin{equation*}
	P(x) y'' + Q(x)y' + R(x) y = - \lambda y
\end{equation*}
on the interval $ [a, b] $ with boundary conditions
\begin{align*}
	&\alpha_1 y(a) + \alpha_2 y'(a) = 0 && \alpha_1^2 + \alpha_2^2 \neq 0\\
	&\beta_1y(b) + \beta_2 y'(b) = 0 &&  \beta_1^2 + \beta_2^2
\end{align*}
where $ P, Q, R : [a, b] \to \R $ are real continuous functions and $ \alpha_i, \beta_i \in \R$ are real constants.

The constant parameter $ \lambda $ must be determined to fit the boundary conditions.


\subsubsection{Space of Continuous and Twice-Differential Functions on $ [a, b] $}
Let $ C[a, b] $ be the space consisting of all continuous complex functions on the interval $ [a, b] $ equipped with the inner product
\begin{equation*}
	\expval{f, g} = \int_{a}^{b} f(x) \overline{g(x)} \diff x
\end{equation*}
Meanwhile, $ C^2[a, b] $ denotes the space of all twice-differentiable complex-valued functions on the interval $ [a, b] $.

\subsubsection{The Second-Degree Linear Differential Operator $ L $}
For all continuous functions $ P, Q, R:[a, b] \to \R $, the mapping $ L $ defined by
\begin{equation*}
	L : C^2[a, b] \to C[a, b], \qquad y \mapsto Py'' + Qy' + Ry 
\end{equation*}
is linear, and is called a second-degree linear differential operator. 

In terms of $ L $, we can write the differential equation in the Sturm Liouville problem as
\begin{equation*}
	Ly = -\lambda y
\end{equation*}
which is an eigenvalue problem for the operator $ L $; we are interested in eigenvectors $ y \in C^2[a, b] $ that solve the eigenvalue problem while also satisfying the border conditions of the Sturm-Liouville problem. 

\subsubsection{Review of Self-Adjoint Operators}
An operator is self-adjoint (or symmetric for real operators) if it can be diagonalized, i.e. has a complete set of eigenvectors.

The adjoint $ L^* $ of a linear operator $ L $ is defined by the relationship
\begin{equation*}
	\expval{Lu, v} = \expval{u, L^*v}
\end{equation*}
for all $ u $ in the domain of $ L $ and all $ v $ in the domain of $ L^* $.

In the case of a differential operator, $ u, v $ are twice-differentiable functions on $ [a, b] $.

In this case, from the definition of the differential operator $ L $, we have
\begin{equation*}
	\expval{Lu, v} = \int_{a}^{b} (Pu'' + Q u' + R u) \overline{v} \diff x
\end{equation*}
Assuming $ P $ and $ Q $ are twice and once continuously differentiable, respectively, integration by parts gives:
\begin{equation*}
	\expval{Lu, v} = \dots = \big[P(u' \overline{v} - u \overline{v}') + (Q - P)u\overline{v} \big]_{a}^{b} + \int_{a}^{b} u \overline{[(Pv)'' - (Qv)' + Rv]} \diff x
\end{equation*}

\subsubsection{Defining the Adjoint of the Differential Operator}
From the above equality, we define the adjoint $ L^* $ of the differential operator $ L $ with the relationship
\begin{align*}
	L^* v &\coloneqq (Pv)'' - (Qv)' + Rv \\
	&=Pv'' + (2P' - Q)v' + (P'' - Q' + R)v
\end{align*}
where $ v \in \C^2[a, b] $ is a twice-continuously differentiable function.

With this definition, we recover the identity
\begin{equation*}
	\expval{Lu, u} = \expval{u, L^*v}
\end{equation*}
as long as
\begin{equation*}
	\left[P(u'\overline{v} - u \overline{v}') + (Q - P')u\overline{v}\right]_{a}^{b} = 0
\end{equation*}

\subsubsection{Formally Self-Adjoint Differential Operator}
In this case, the operator $ L $ is called \textit{formally self-adjoint} if $ L^* = L $. In this case
\begin{equation*}
	2P' - Q = Q \qquad \text{and} \qquad P'' - Q' + R = R
\end{equation*}
which is equivalent to the condition $ Q = P' $.  If $ Q = P' $, we the earlier condition for the existence of the adjoint becomes
\begin{equation*}
	\left[P(u'\overline{v} - u \overline{v}') \right]_{a}^{b} = 0
\end{equation*}
and we can write $ L $ in the form
\begin{equation*}
	Ly = (Py')' + Ry
\end{equation*}
When $ L $ can be written in this form, integration by parts shows that $ L $ is formally self-adjoint, i.e.
\begin{equation*}
	\expval{Lu, v} = \expval{u, Lv} + \left[P(u'\overline{v} - u \overline{v}') \right]_{a}^{b}
\end{equation*}
even when $ P $ is only a once continuously differentiable function.

\textbf{Condition:} $ L $ is formally self-adjoint on $ [a, b] $ when $ Q = P' $ and $ P $ is a real, continuously differentiable function and $ R $ is a continuous real function.

\subsubsection{Self-Adjoint and Identity}
If the differential operator $ L $ is formally self-adjoint on the interval $ [a, b] $, then
\begin{equation*}
	\expval{Lu, v} = \expval{u, Lv} + \left[P(u'\overline{v} - u \overline{v}') \right]_{a}^{b}
\end{equation*}

\subsubsection{Implication}
If the functions $ u, v \in C^2[a, b] $ satisfy the boundary conditions noted earlier, then $ \expval{Lu, v} = \expval{u, Lv} $ for all formally self-adjoint differential operators $ L $.

This is shown by showing that $ u'\overline{v} - u \overline{v}' = 0 $ at the points $ a $ and $ b $.


\subsection{More General Sturm-Liouville Problem}

\subsubsection{Sturm-Liouville Problem with a Weight}
In this case, the earlier equation becomes
\begin{equation*}
	Ly = -\lambda w y
\end{equation*}
instead of $ Ly = -\lambda y $. In this case, $ w:[a, b] \to \R $ is a positive, continuous function called the \textit{weight} and $ L $ is the earlier-defined differential operator.

As before, $ \lambda $ are the eigenvalues of the operator $ L $ and solutions $ y $ satisfying the equation and boundary conditions are the operator $ L $'s eigenfunctions.

\subsubsection{Inner Product, Norm, and Orthogonal Functions with a Weight}
The positive continuous function $ w $ defines an inner product on the space $ C[a, b] $ given by
\begin{equation*}
	\expval{f, g}_{w} = \int_{a}^{b} f(x)\overline{g(x)} w(x) \diff x
\end{equation*}
The functions $ f, g $ are called \textit{orthogonal with respect to the weight $ w $} if $ \expval{f, g}_{w} = 0 $.

The norm induced by the inner product $ \expval{\cdot, \cdot}_{w} $ is denoted by $ \norm{\cdot}_{w} $ and
\begin{equation*}
	\norm{f}_{w} = \sqrt{\expval{f, f}_{w}}
\end{equation*}

Finally we denote the completion of the space $ C[a, b] $ in the norm $ \norm{\cdot}_{w} $  by $ L_{w}^{2}(a, b) $.


\subsubsection{Proposition: Eigenvalues of Self-Adjoint Differential Operators}
The eigenvalues of the formally self-adjoint differential operator $ L $ of the form $ Ly = (Py')' + Ry $ where $ P $ has no zeroes on $ [a, b] $ with respect to the standard Sturm-Liouville boundary conditions are real. 

More so, eigenfunctions of $ L $ corresponding to different eigenvalues are mutually orthogonal with respect to the weight $ w $.

Finally, for any two of $ L $'s eigenfunctions corresponding to the same eigenvalue are linearly dependent.

Summary: Eigenvalues of formally self-adjoint differential operators are real. Eigenfunctions of different eigenvalues are orthogonal, and eigenfunctions of the same eigenvalue are linearly dependent.

\subsubsection{Motivation}
When solving
\begin{equation*}
	Ly = -\lambda w y
\end{equation*}
with respect to the usual boundary conditions and when $ L $ is formally self-adjoint, we are interested in when L has sufficiently many non-zero, mutually orthogonal (with respect to the weight $ w $) eigenfunctions to form an orthogonal basis of the Hilbert space $ L_{w}^{2}(a, b) $. 

\subsubsection{Definition: Regular Sturm-Liouville Problem}
Let $ L: C^2[a, b] \to C[a, b] $ be a self-adjoint differential operator of the form
\begin{equation*}
	Ly = (Py')' + Ry
\end{equation*}
where $ P \in C^1[a, b] $ is a real, continuously differentiable function and $ R \in C[a, b] $ is a real, continuous function. A \textit{regular Sturm-Liouville} is the problem of finding all eigenvalues $ \lambda \in \C $ of the differential operator $ L $ for which the equation
\begin{equation*}
	Ly = -\lambda w y
\end{equation*}
has a non-trivial solution $ y \in C^2[a, b] $ with respect to the boundary conditions
\begin{align*}
	&\alpha_1 y(a) + \alpha_2 y'(a) = 0 && \alpha_1^2 + \alpha_2^2 \neq 0\\
	&\beta_1y(b) + \beta_2 y'(b) = 0 &&  \beta_1^2 + \beta_2^2
\end{align*}
and finding the solution $ y $.

\subsubsection{Sturm-Liouville Theorem}
For all regular Sturm-Liouville problems there exists an orthonormal basis of the Hilbert space $ L_{w}^2(a, b) $ consisting of real eigenfunctions $ u_n, n \in \mathbb{N} $ of the operator $ L $.

For the eigenvalue $ \lambda_n $ corresponding to the eigenfunction $ u_n $, 
\begin{equation*}
	\lim_{n \to \infty} \lambda_n = \infty
\end{equation*}

For all functions $ y \in C^2[a, b] $ satisfying the boundary conditions, the series
\begin{equation*}
	\sum_{n=1}^{\infty}\expval{y, u_n}_{w}u_n
\end{equation*}
converges uniformly to $ y $ on the interval $ [a, b] $.

\subsubsection{Lemma With Green's Function}
The idea is that this would be used to prove the Sturm-Liouville theorem. 

If $ y_1 $ and $ y_2 $ are two linearly independent solutions of the differential equation
\begin{equation*}
	y'' + qy = 0
\end{equation*}
satisfying the boundary conditions $ y_1(a) = 0 $ and $ y_2(b) = 0 $ and the Green's function $ G $ defined by
\[
	G(x, t) = \frac{1}{W} 
	\begin{cases}
		y_1(t)y_2(x), & t \leq x\\
		y_1(x)y_2(t), & x \leq t\\
	\end{cases}
	= \frac{1}{W} y_1 \big(\min\{t, x\}\big) y_2 \big(\max\{t, x\} \big)
\]

then 
\begin{equation*}
	y_p = \int_{a}^{b} G(x, t) f(t) \diff t
\end{equation*}
solves the non-homogeneous equation
\begin{equation*}
	y'' + qy = f
\end{equation*}
and satisfies the boundary conditions $ y(a) = 0 $ and $ y(b) = 0 $.


\subsection{Solving Linear Differential Equations with Power Series}
For the entirety of this section, let $ p, q  $ be holomorphic functions in a neighborhood of $ 0 $, meaning we can expand them into the power series
\begin{equation*}
	p(z) = \sum_{n= 0}^{\infty} p_N z^n \qquad \text{and} \qquad \sum_{n=0}^{\infty} q_n z^n
\end{equation*}
where $ p_k, q_k \in \C $ are complex coefficients. 

The goal is to solve the equation
\begin{equation*}
	y'' + py' + qy = 0
\end{equation*}
with the aid of the power series
\begin{equation*}
	y = \sum_{n=0}^{\infty}c_nz^n
\end{equation*}
where the coefficients $ c_n \in \C $ are found by inserting the series for $ p $ and $ q $ into the differential equation and finding a recurrence relation.

A similar approach follows for functions holomorphic on a neighborhood of some point $ z_0 $ other than zero. In that case, $ p, q $ must be holomorphic on a neighborhood of $ z_0 $, and the solution is of the form
\begin{equation*}
	y = \sum_{n=0}^{\infty}c_n(z-z_0)^n
\end{equation*}
The series for $ y $ converges on every disk on which the series for $ p $ and $ q $ also converge.

\subsubsection{Theorem: Power Series Solutions}
If $ p, q $ are holomorphic functions on the disk $ D(z_0, R) $ of radius $ R $ centered at the point $ z_0 \in \C $, then for any complex constants $ c_0, c_1 \in \C $ there exists a solution $ y $ of the equation 
\begin{equation*}
	y'' + py' + qy = 0
\end{equation*}
that is holomorphic on the on the disk $ D(z_0, R) $ and satisfies the boundary conditions $ y(z_0) = c_0 $ and $ y'(z_0) = c_1 $.

\subsubsection{Legendre Equation}
The Legendre equation is a second-order differential equation of the form
\begin{equation*}
	(z^2 - 1)y'' + 2z' - \nu (\nu + 1) y = 0
\end{equation*}
where 
\begin{equation*}
	p(z) = \frac{2z}{z^2 - 1} \quad \text{and} \quad q(z) = - \frac{\nu (\nu + 1)}{z^2 - 1}
\end{equation*}
are holomorphic functions on the unit disk $ D(0, 1) $.

Plugging $ \displaystyle{y = \sum_{0}^{\infty} c_k z^k} $ into the equation leads to
\begin{align*}
	&c_{2n} = \frac{(-1)^n}{(2n)!} \nu(\nu-2)\cdots(\nu - 2n + 2)(\nu + 1)(\nu + 3)\cdots(\nu + 2n -1)c_0\\
	&2_{2n+1} = \frac{(-1)^n}{(2n+1)!}(\nu-1)(\nu-3)\cdots(\nu - 2n + 1)(\nu+2)(\nu + 4)\cdots(\nu + 2n)c_1\\
\end{align*}
with $ c_0 = 1 $ and $ c_1 = 0 $, we get the solution 
\begin{equation*}
	y_1 = \sum_{n=0}^{\infty}c_{2n}z^{2n} = 1 - \frac{\nu(\nu+1)}{2!}z^2 + \frac{\nu(\nu-2)(\nu+1)(\nu+3)}{4!}z^4 - \dots
\end{equation*}
and with $ c_0 = 0 $ and $ c_1 = 1 $, we get the linearly independent solution
\begin{equation*}
	y_2 = \sum_{n=0}^{\infty}c_{2n+1}z^{2n+1} = z - \frac{(\nu-1)(\nu+2)}{3!}z^3 + \frac{(\nu-1)(\nu-3)(\nu+2)(\nu+4)}{5!}z^5 - \dots
\end{equation*}
Both solutions converge for $ \abs{z} < 1 $.

\subsubsection{Legendre Polynomials}
The polynomials of the form
\begin{equation*}
	P_n(z) = \sum_{k=0}^{[\frac{n}{2}]}(-1)^{k}\frac{(2n-2k)!}{2^nk!(n-k)!(n-2k)!}z^{n-2k}
\end{equation*}
are called Legendre polynomials for $ n \in \mathbb{N} $. The Legendre polynomials may be generated by the Rodrigues formula
\begin{equation*}
	P_n(z) = \frac{1}{2^nn!}\dv[n]{}{z}(z^2 - 1)^n
\end{equation*}
The Legendre polynomial $ P_n $ generated by the Rodgrigues formula satisfies the Legendre equation for $ \nu = n $.

For small $ \abs{t} $
\begin{equation*}
	\frac{1}{\sqrt{1-2zt+t^2}} = \sum_{n=0}^{\infty}P_n(z)t^n
\end{equation*}
Additionally,
\begin{equation*}
	(n+1)P_{n+1}(z) = (2n+1)zP_n(z) - nP_{n-1}(z)
\end{equation*}
This identity allows us to recursively calculate all Legendre polynomials once $ P_0 = 1 $ and $ P_1 = z $ are known.

\subsubsection{Orthogonality of the Legendre Polynomials}
\begin{equation*}
	\int_{-1}^{1}P_m(x)P_n(x) \diff x = \delta_{m, n}\frac{2}{2n+1}
\end{equation*}
where
\[
	\delta_{m, n} = \begin{cases}
		1, & m = n\\
		0, & \text{otherwise}
	\end{cases}
\]
In other words, the Legendre polynomials are orthogonal when integrated over the interval $ [-1, 1] $.


\subsubsection{Convergence of Legendre Polynomials in the $ L^2(-1, 1) $ Space}
For all functions $ f \in L^2(-1, 1) $, the series
\begin{equation*}
	\sum_{n=0}^{\infty}a_nP_n \qquad a_n = \frac{2n+1}{2}\int_{-1}^{1}f(x)P_n(x) \diff x
\end{equation*}
converges uniformly to $ f $ in the $ L^2(-1, 1) $ norm. In other words,
\begin{equation*}
	\lim_{N\to \infty}\norm{\sum_{n=0}^{N}}a_n P_n - f = 0 \qquad \norm{f} = \sqrt{\int_{-1}^{1} \abs{f(x)}^2} \quad \text{for all} \quad f \in L^2(-1, 1)
\end{equation*}

\subsubsection{Zeros of General Orthogonal Polynomials}
Let $ I = (a, b) \subseteq \R $ be a real interval and let $ w : I \to \R^+ $ be a positive function such that
\begin{equation*}
	\int_{a}^{b} x^n w(x) \diff x < \infty \quad \text{for all} \quad n \in \mathbb{N}
\end{equation*}
Note that this condition is automatically fulfilled if $ I $ is finite and $ w $ is continuous on $ I $.

In this case, the Hilbert space
\begin{equation*}
	L_{w}^2(a, b) \coloneqq \{f : (a, b) \to \C; \int_{a}^{b}\abs{f(x)}^2 w(x)\diff x < \infty \}
\end{equation*}
contains all polynomials. 

The family of polynomials $ (p_n), n \in \mathbb{N} $ is called the family of orthogonal polynomials with weight $ w $ if $ \expval{p_n, p_m}_{w} = 0 $ for $ n \neq m $ where
\begin{equation*}
	\expval{f, g}_{w} = \int_{a}^{b} f(x) \overline{g}(x)w(x) \diff x
\end{equation*}

\subsubsection{Oscillation of Orthogonal Polynomials}
Let $ (p_n) $ be a sequence of orthogonal polynomials with weight $ w $ on the interval $ (a, b) $ such that $ p_n $ is of degree $ n $. In this case, $ p_n $ has exactly $ n $ zeros on the interval $ (a, b) $.

\subsubsection{Associated Legendre Polynomials}
The associated Legendre polynomials associated with the Legendre polynomial $ P_n $, denoted by $ P_{n}^{m} $, are
\begin{equation*}
	P_{n}^{m}(z) \coloneqq (1 - z^2)^{\frac{m}{2}}\dv[m]{}{z}P_n(z), \qquad m = 0, 1, \dots, n
\end{equation*}
Note that the associated Legendre polynomials satisfy the differential equation
\begin{equation*}
	\left[(1- z^2)y'\right]' + \left[n(n+1)-\frac{m^2}{1-z^2}\right]y = 0
\end{equation*}
Additionally, for $ m > 0 $
\begin{equation*}
	P_{n}^{m}(1) = P_{n}^{m}(-1) = 0
\end{equation*}
For a fixed $ m $, the associated polynomials $ P_{n}^{m}(n \geq m) $ are mutually orthogonal.

\subsubsection{Theorem: Associated Legendre Polynomials as a Basis of $ L^2(-1, 1) $}
For a fixed $ m $, the family of associated Legendre polynomials $ \big(P_{n}^{m}\big)_{n=m}^{\infty} $ for an orthogonal basis of the Hilbert space $ L^2(-1, 1)  $ and
\begin{equation*}
	\norm{P_{n}^{m}}^2 = \frac{2}{2n + 1}\frac{(n+1)!}{(n-m)!}
\end{equation*}

\subsubsection{Example: Stationary-State Temperature Distribution on a Sphere}
Let the center of the sphere be the origin, let $ a \in \R^+ $ be the radius of the sphere. We use a spherical coordinates system. Let the temperature at the point $ (r, \phi, \theta) $ at time $ t $ be $ u(r, \phi, \theta, t) $. 

Temperature satisfies the heat equation $ \pdv{u}{t} = c \Delta u $ where $ c $ is a positive constant. In spherical coordinates, the Laplace operator $ \Delta $ reads
\begin{equation*}
	\Delta u = u_{rr} + \frac{2}{r}u_r + \frac{1}{r^2\sin \theta}(u_{\theta}\sin \theta)_{\theta} + \frac{1}{r^2\sin^2\theta }u_{\phi \phi}
\end{equation*}

Let the temperature at the surface of the sphere be given by $ u(a, \theta, \phi) = f(\theta, \phi) $ where $ f $ is a given function. For the stationary state solution, $ \pdv{u}{t} = 0$, and the heat equation becomes the Dirichlet problem
\begin{equation*}
	\Delta u = 0 \ \ \text{for} \ \ r < a \qquad \text{and} \qquad u(a, \phi, \theta) = f(\phi, \theta)
\end{equation*}

Using the Fourier method of separation of variables leads to the ansatz 
\begin{equation*}
	u(r, \theta, \phi) = R(r) \Theta(\theta) \Phi(\phi)
\end{equation*}
which, when plugged in to the original differential equation and evaluating the spherical Laplacian, yields
\begin{equation*}
	r^2 \sin^2 \theta \left(\frac{R''}{R} + \frac{2}{r} \frac{R'}{R}\right) + \sin \theta \frac{(\Theta'\sin\theta)'}{\Theta} = - \frac{\Phi''}{\Phi}
\end{equation*}
The eventual solution is in terms of the spherical harmonics, which are based on the associated Legendre polynomials.

\end{document}






