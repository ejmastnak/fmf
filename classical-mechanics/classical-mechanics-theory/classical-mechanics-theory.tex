\documentclass[11pt, a4paper]{article}
\usepackage[T1]{fontenc}
\usepackage{mwe}
\usepackage[margin=3.5cm]{geometry}
\usepackage[normalem]{ulem}  % for underline with line wrapping

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{bm} % for bold vectors in math mode
\usepackage{physics} % many useful physics commands
\usepackage[separate-uncertainty=true]{siunitx} % for scientific notation and units
\usepackage{xcolor}  % to color hyperref links
\usepackage[colorlinks = true, allcolors=blue]{hyperref}


\setlength{\parindent}{0pt} % to stop indenting new paragraphs
\newcommand{\eqtext}[1]{\qquad \text{#1} \qquad}


\newcommand{\diff}{\mathop{}\!\mathrm{d}} % for differentials to not be italicized and have a little space
\newcommand{\R}{\mathbb{R}} % shorthand for the real numbers
\newcommand{\e}{\mathbf{e}} % shorthand for basis vector

\newcommand{\bdot}[1]{\dot{\bm{#1}}} % dotted bold vector 
\newcommand{\bddot}[1]{\ddot{\bm{#1}}} % ddotted bold vector 
\newcommand{\mat}[1]{\mathbf{#1}} % for matrices

\newcommand{\uvec}[1]{\bm{\hat{\mathbf{#1}}}} % unit vector
\newcommand{\uveci}{{\bm{\hat{\textnormal{\bfseries\i}}}}}
\newcommand{\uvecj}{{\bm{\hat{\textnormal{\bfseries\j}}}}}

\newcommand{\veff}{V_{\text{eff}}}  % effective potential
 

\pdfinfo{
	/Title (Classical Mechanics Theory Notes)
	/Author (Elijan Mastnak)
	/Subject (Physics)
}


\begin{document}
\title{Classical Mechanics Theory Notes}
\author{Elijan Mastnak}
\date{2019-2020 Summer Semester}
\maketitle

\begin{center}
	\textbf{About These Notes}
\end{center}

These are my theory notes from the course \textit{Klasi\v{c}na Mehanika} (Classical Mechanics), given to second-year physics students at the Faculty of Math and Physics in Ljubljana, Slovenia. The content is a medley of Professor Anton Ram\v{s}ak's lectures at the University of Ljubljana and Professor David Tong's excellent \href{http://www.damtp.cam.ac.uk/user/tong/dynamics.html}{lecture notes on Classical Dynamics}, generously made freely available on \href{http://www.damtp.cam.ac.uk/user/tong/teaching.html}{his website}.  The content in these notes is fairly standard for an undergraduate Classical Dynamics course, so I am making the notes publicly available in the hope that they might help others learning the same material.

\vspace{2mm}
\textit{Navigation}: For easier document navigation, the table of contents is ``clickable'', meaning you can jump directly to a section by clicking the colored section names in the table of contents. Unfortunately, \uline{the clickable links do not work in most online or mobile PDF viewers}; you have to download the file first.

\vspace{2mm}
\textit{On Authorship:} All credit for the content in these notes goes to Professors Anton Ram\v{s}ak and David Tong, and I make no claim whatsoever to originality or authorship. 

\vspace{2mm}
\textit{Disclaimer:} Mistakes---both trivial typos and legitimate errors---are likely. Keep in mind that these are the notes of an undergraduate student in the process of learning the material himself---take what you read with a grain of salt. If you find mistakes and feel like telling me, by \href{https://github.com/ejmastnak/fmf}{Github} pull request, \href{mailto:ejmastnak@gmail.com}{email} or some other means, I'll be happy to hear from you, even for the most trivial of errors.

\tableofcontents

\newpage

\section{Curvilinear Coordinates and Newtonian Dynamics}

\subsection{Curvilinear Coordinate Systems}

In general, we are interested in:
\begin{enumerate}
	\item Coordinates and coordinate curves
	\item Expression for position $ \bm{r} $ in terms of coordinates
	\item Expressions for basis vectors
	\item Magnitudes of each basis vector $ \abs{\e_i} = \sqrt{\abs{\e_i \cdot \e_i}} $ as well as dot products in mixed basis vector terms. We are basically checking if the basis vectors are orthonormal.
\end{enumerate}

\subsubsection{Cartesian Coordinates}
\begin{itemize}	
	\item Coordinates: $ (x, y, z) $
	\item Basis vectors: $ \uvec i, \uvec j, \uvec k $
	\item Position: $ \bm{r} = x \uvec i + y \uvec j + z \uvec{k} $
	\item Definitions of basis vectors:
	\begin{align*}
		& \uvec i = \pdv{\bm{r}}{x} && \uvec j = \pdv{\bm{r}}{y} && \uvec k = \pdv{\bm{r}}{z}
	\end{align*}
	
	In Cartesian coordinates, the basis vectors have the same magnitude and direction at all points in space. For this reason, we call $ \uvec i, \uvec j, \uvec k $ a \textit{global basis}.
	
	\item The global Cartesian basis $  \uvec i, \uvec j, \uvec k $ is orthonormal. This means that all the basis vectors have magnitude one while the dot products of mixed basic are zero.
	\begin{align*}
		&\abs{\uvec i} = \sqrt{\uvec i \cdot \uvec i} = 1 && 	\abs{\uvec j} = \sqrt{\uvec j \cdot \uvec j} = 1 && 	\abs{\uvec k} = \sqrt{\uvec k \cdot \uvec k} = 1\\
		&\uvec{i} \cdot \uvec{j} = \uvec{j} \cdot \uvec{i} = 0 && \uvec{i} \cdot \uvec{k} = \uvec{k} \cdot \uvec{i} = 0 && \uvec{j} \cdot \uvec{k} = \uvec{j} \cdot \uvec{k}= 0
	\end{align*}
	
	
	
\end{itemize}

\subsubsection{General Curvilinear Coordinates in Three Dimensions}
For a general three-dimensional coordinate system:
\begin{enumerate}	
	\item Coordinates: $ (x_{\alpha}, x_{\beta}, x_{\gamma}) $
	\item Basis vectors: $ \e_{\alpha} ,  \e_{\beta},  \e_{\gamma} $
	
	\item Definitions of basis vectors:
	\begin{align*}
		& \e_{\alpha} = \pdv{\bm{r}}{x_{\alpha}} && \e_{\beta} = \pdv{\bm{r}}{x_{\beta}} && \e_{\gamma} = \pdv{\bm{r}}{x_{\gamma}}
	\end{align*}
	
	\textbf{Important}: In general, the basis vectors $ \e_{\alpha} ,  \e_{\beta},  \e_{\gamma} $ vary in magnitude and direction at different points in space. Because $ \e_{\alpha} ,  \e_{\beta},  \e_{\gamma} $ are different at different points in space, we cannot define position $ \bm{r} $ in terms of $ \e_{\alpha} ,  \e_{\beta},  \e_{\gamma} $. This wouldn't be well defined. Instead, we express position in terms of the global basis $ \uvec i, \uvec j, \uvec k $ and write the Cartesian coordinates $ x, y, z $ as functions of the curvilinear coordinates $ x_{\alpha}, x_{\beta}, x_{\gamma} $. 

	\item Position: $ \bm{r} = x(x_{\alpha}, x_{\beta}, x_{\gamma}) \uvec i + y(x_{\alpha}, x_{\beta}, x_{\gamma}) \uvec j + z(x_{\alpha}, x_{\beta}, x_{\gamma}) \uvec{k} $
	
	Were are interested in how the Cartesian coordinates $ (x, y, z) $ are expressed in terms of the curvilinear coordinates $ (x_{\alpha}, x_{\beta}, x_{\gamma}) $. That is, we want expressions for $ x, y, $ and $ z $ as functions of $ (x_{\alpha}, x_{\beta}, x_{\gamma}) $.
	\item Differential of position and velocity:
	\begin{align*}
		&\diff \bm{r} = \e_{\alpha} \diff x_{\alpha} + \e_{\beta} \diff x_{\beta} +  \e_{\gamma} \diff x_{\gamma}\\
		&\bm{v} = \dv{\bm{r}}{t} =  \e_{\alpha} \dv{x_{\alpha}}{t} + \e_{\beta} \dv{x_{\beta}}{t} +  \e_{\gamma}  \dv{x_{\gamma}}{t} \\
		&\ \ = \e_{\alpha} \dot{x}_{\alpha} + \e_{\beta}\dot{x}_{\beta}  +  \e_{\gamma} \dot{x}_{\gamma} 
	\end{align*}
	
	Locally, the general basis vectors $ \e_{\alpha} ,  \e_{\beta},  \e_{\gamma} $ are constant in a small neighborhood of every point in space. Because of this local constant behavior on a small scale, we can write the differential of position in terms of general basis vectors.
	
\end{enumerate}

\subsubsection{Polar Coordinates}
Polar coordinates are used in two-dimensional space in situations with circular symmetry.
\begin{enumerate}
	\item Coordinates: ($ r, \phi $) 
	\begin{enumerate}
		\item $ r $ is the distance from a point in space to the origin
		\item $ \phi $ is the angle between the basis vector $ \uvec{i} $ and a ray connected a point to the origin.
		\item The coordinate curves for $ r $ are concentric circles centered at the origin, while the coordinate curves for $ \phi $ are rays originating at the origin radiating out into space.
	\end{enumerate}
	\item Position: 
	\begin{align*}
		& \bm{r}(r, \phi) = r \cos \phi \uvec{i} + r \sin \phi \uvec{j} && \text{where} &&x(r, \phi) = r \cos \phi \quad y(r, \phi) = r \sin \phi
	\end{align*}
	The Jacobian determinant for polar coordinates is $ \det \mathbf{J} = r $.
	\item Basis vectors:
	\begin{align*}
		\e_{r} = \cos \phi \uvec{i} + \sin \phi \uvec{j} && \e_{\phi} = - r \sin \phi \uvec{i} + r \cos \phi \uvec{j}
	\end{align*}
	\item The polar basis is orthogonal but not fully normal. We have: 
	\begin{align*}
	 \abs{\e_r}^2 = 1 \qquad  \abs{\e_\phi}^2 = r^2 \qquad  \e_r \cdot \bm \e_\phi = 0
	\end{align*}
	
	\item In polar coordinates, kinetic energy $ T $, acceleration $ \ddot{\bm{r}} $, and Newton's second law are:
	\begin{align*}
		&T = \frac{1}{2}m \left(\dot{r}^2 + r^2  \dot{\phi}^2\right) && \sum \bm{F} = m \ddot{\bm{r}} = m\e_{r}(\ddot{r} + \dot{\phi}^2 r) + m \e_{\phi} \left (\ddot{\phi} + 2\frac{\dot{\phi} \dot{r}}{r} \right )
	\end{align*}
\end{enumerate}

\subsubsection{Spherical Coordinates}
\begin{enumerate}
	\item Coordinates: ($ r, \phi, \theta $) where $ r $ is the distance from a point in space to the origin, $ \phi $ is the angle between $ \uvec{i} $ and the projection of the point onto the $ \uvec{i} \uvec{j} $ plane, and $ \theta $ is the angle between the point and $ \uvec{k} $.
	
	
	The coordinate curves for $ r $ are concentric spheres centered at the origin, while the coordinate curves for $ \phi $ and $ \theta $ are rays radiating from the origin into space.
	\item Position: 
	\begin{align*}
		& \bm{r}(r, \phi) = r \cos \phi \sin \theta \uvec{i} + r \sin \phi \sin \theta \uvec{j} + r \cos \theta \uvec{k}\\
	 	&x(r, \phi, \theta) = r \cos \phi \sin \theta \quad y(r, \phi, \theta) = r \sin \phi \sin \theta \quad z(r, \phi, \theta) = r \cos \theta
	\end{align*}
	The Jacobian determinant for spherical coordinates is $ \det \mathbf{J} = r^2 \sin \theta $.
	\item Basis vectors:
	\begin{align*}
		&\e_{r} = \cos \phi \sin \theta \uvec{i} + \sin \phi \sin \theta \uvec{j} + \cos \theta \uvec{k}\\
		& \e_{\phi} = - r \sin \phi \sin \theta \uvec{i} + r \cos \phi \sin \theta \uvec{j} + 0 \uvec{k}\\
		& \e_{\theta} = - r \cos \phi \cos \theta \uvec{i} + r \sin \phi \sin \theta \uvec{j} - r \sin \theta \uvec{k}
	\end{align*}
	
	\item The spherical basis is orthogonal but not fully normal. We have: 
	\begin{align*}
	 \abs{\e_r}^2 = 1 \qquad  \abs{\e_\phi}^2 = r^2 \sin \theta \qquad \abs{\e_\theta}^2 = r^2
	\end{align*}
	
	\item In spherical coordinates, kinetic energy $ T $ is
	\begin{align*}
		&T = \frac{1}{2}m \left (\abs{\dot{r} \e_r + \dot{\phi} \e_\phi + \dot{\theta} \e_\theta} \right )^2 = \frac{1}{2}m \left(\dot{r}^2 + \dot{\phi}^2 r^2 \sin^2 \theta + \dot{\theta}^2r^2 \right)
	\end{align*}
\end{enumerate}

\subsection{Dynamics of a Single Particle}
A particle is an object of insignificant size, relative to the context of the problem. 

\subsubsection{Reference Frames}
\begin{itemize}
	\item An inertial frame is unaccelerated. 
	
	Equivalently, an inertial frame is defined as a frame in which a free particle with constant mass travels in straight line $ \bm{r} = \bm{r}_0 + \bm{v}t $.
	
	\item In Euclidean space, there are 10 linearly independent transformations that preserve inertial frames. These are three rotations, three translations, three boosts and one time translation, and together they form the Galilean group.
\end{itemize}


\subsubsection{Momentum and Force}

\begin{itemize}
	\item A particle's \textit{linear momentum} $ \bm{p} $ is defined as $ \bm{p} = m \bm{v} $.
	
	\item Linear momentum and force are independent of the choice of origin.
	
	\item The general form of Newton's second law reads $ \bm{F}(\bm{r}, \dot{\bm{r}}) = \dv{\bm{p}}{t} $. For a particle with constant mass, $ \bm{F} = m \ddot{\bm{r}} $

	\item If the net force $ \bm{F} $ on a particle is zero, then the particle's linear momentum $ \bm{p} $ is conserved. $ \bm{F} = 0 \implies \bm{p} = \text{constant} $.

	\item Newton's third law states $ \bm{F}_{12} = - \bm{F}_{21} $
\end{itemize}
Newton's laws only hold in inertial frames. 

\subsubsection{Angular Momentum and Torque}
\begin{itemize}
	\item A particle's \textit{angular momentum} $ \bm{L} $ with respect to the origin is defined as $ \bm{L} = \bm{r} \cross \bm{p} = m (\bm{r} \cross \bm{v}) $
	
	\item The rotational analog of Newton's second law relates the torque $ \bm{\tau} $ on the particle relative to the origin to angular momentum $ \bm{L} $ with respect to the origin via $ \bm{\tau} = \dv{\bm{L}}{t} $. 
	
	Torque is related to force by $ \bm{\tau} = \bm{r} \cross \bm{F} $, obtained via
	\begin{align*}
		\bm{\tau} = \dv{\bm{L}}{t} = \dv{}{t}[\bm{r} \cross \bm{p}] = \dot{\bm{r}} \cross \bm{p} + \bm{r} \cross \dot{\bm{p}} = \bm{0} + \bm{r} \cross \bm{F} =  \bm{r} \cross \bm{F}
	\end{align*}
	since $ \dot{\bm{r}} \cross \bm{p} = m (\bm{v} \cross \bm{v}) = m \cdot (\bm{0}) = \bm{0} $.
	
	\item If the net torque $ \bm{\tau} $ on a particle is zero, then the particle's angular momentum $ \bm{L} $ is conserved. $ \bm{\tau} = 0 \implies \bm{L} = \text{constant} $.
	
	\item Both angular momentum and torque are measured with respect to a chosen reference point and thus depend on the choice of origin.
	

\end{itemize}

\subsubsection{Work, Energy and Conservative Forces}
\begin{itemize}
	\item The work $ W $ done by a force $ F $ on a particle along the curve $ \gamma $ is defined by the line integral $ W = \int_{\gamma} \bm{F} \cdot \diff \bm{r} $.
	
	\item The \textit{kinetic energy} of a particle of mass $ m $ moving with velocity $ \bm{v} $ is defined as $ T = \frac{1}{2}m \abs{\bm{v}}^2 = \frac{1}{2}m v^2$.
	
	
	\item The change in a particle's kinetic energy under the influence of a force $ \bm{F} $ equals the work done by the force.
	
	If the particle travels from position $ \bm{r}_1 $ at time $ t_1 $	to position $ \bm{r}_2 $ at time $ t_2 $, the change in the particle's kinetic energy is
	\begin{equation*}
		T(t_2) - T(t_1) = \int_{t_1}^{t_2} \dv{T}{t} \diff t = \int_{t_1}^{t_2} \bm{F} \cdot \dot{\bm{r}} \diff t = \int_{\bm{r}_1}^{\bm{r}_2} \bm{F} \cdot \diff \bm{r} = W
	\end{equation*}
	
	\item \textit{Conservative forces} are a special type of force that depend only on $ \bm{r} $ and not $ \dot{\bm{r}} $ and have the property that the work done by the force on a particle moving between two points is independent of the path taken.
	
	Conservative forces can be written as the gradient of a potential energy $ V $. In this case, $ \bm{F} = - \grad{V} $. The work done by a conservative force on a particle along a curve $ \gamma $ equals the change in potential energy between the endpoints.
	\begin{align*}
		W = \int_{\gamma} \bm{F} \cdot \diff \bm{r} = - (V_2 - V_1) \qquad \text{and} \qquad \oint_{\kappa} \bm{F} \cdot \diff \bm{r} = 0
	\end{align*}
	where $ \kappa $ is a closed curve.
	
	\item Conservative forces arising from potentials include the gravitational and electrostatic forces. For particles under the influence of conservative forces, we have the energy conservation law
	\begin{equation*}
		T_1 + V_1 = T_2 + V_2 \equiv E
	\end{equation*}
	stating that the particle's total energy $ E $ is conserved. The law arises from
	\begin{equation*}
		W = T_2 - T_1 = - \int_{\bm{r}_1}^{\bm{r}_2} V(r) \cdot \diff \bm{r} = -V_2 + V_1
	\end{equation*}
\end{itemize}

\subsection{Dynamics of Systems of Particles} \label{subsec:newton_many_particles}

This section considers a system of $ N $ particles with masses $ m_1, m_2, \dots, m_N$ and position vectors $ \bm{r}_1, \bm{r}_2, \dots, \bm{r}_{N} $.

\subsubsection{Center of Mass}

\begin{itemize}
	\item The total mass of the system is $ M =  m_1 + m_2 + \dots + m_N$
	
	\item The system's center of mass $ \bm{r}^* $ is
	\begin{align*}	
		\bm{r}^* = \frac{m_1 \bm{r}_1 + m_2 \bm{r}_2 + \dots + m_N \bm{r}_N }{m_1 + m_2 + \dots + m_N} = \frac{\sum_{i = 1}^{N} m_i \bm{r}_i}{\sum_{i = 1}^{N} m_i} =  \frac{1}{M} \sum_{i = 1}^{N} m_i \bm{r}_i
	\end{align*}
	
	\item The velocity of the center of mass is $ \bm{v}^* = \dv{\bm{r}^*}{t} $, and the acceleration of the center of mass is $ \bm{a}^* = \dv{\bm{v}^*}{t} = \dv[2]{\bm{r}^*}{t}$
	
\end{itemize}

\subsubsection{Momentum and Forces}
\begin{itemize}
	\item The momentum $ \bm{p}^* $ of the system's center of mass is
	\begin{align*}
		\bm{p}^* = \sum_{i = 1}^{N} \bm{p}_i = M \dv{\bm{r}^*}{t} = M \bm{v}^*
	\end{align*}
	
	\item The net external force $ \bm{F}_{ext} $ acting on the system is related to the center of mass's momentum via $ \displaystyle{\bm{F}_{ext} = \dv{\bm{p}^*}{t}} $. 
	
	If the system's mass is constant, $ \displaystyle{\bm{F}_{ext} = \dv{\bm{p}^*}{t} = M \bm{a}^*} $
	
	\item Central internal forces are forces that can be written in the form
	\begin{align*}
		\bm{F}_{ij} = F_{ij}\frac{\bm{r}_{i} - \bm{r}_{j}}{\abs{\bm{r}_{i} - \bm{r}_{j}}} \quad i \neq j
	\end{align*}

\end{itemize}

\subsubsection{Angular Momentum and Torque}
\begin{itemize}
	\item The angular momentum $ \bm{L}^* $ of the system's center of mass relative to the origin is
	\begin{align*}
		\bm{L}^* = \sum_{i=1}^{N} \bm{L}_{i} = M (\bm{r}^* \cross \bm{v}^*) + \sum_{i=1}^{N} m_i( \bm{r}_{i}' \cross \bm{v}_{i}')
	\end{align*}
	where $ \bm{r}'_{i} $ is the position of the $ i $th particle relative to the center of mass $ \bm{r^*} $, defined implicitly by the relationship $ \bm{r}_{i} = \bm{r}^* + \bm{r}_{i}' $.
	
	\item The angular momentum $ \bm{L}^* $ of the center of mass is related to the net torque $ \bm{\tau} $ acting on the system via
	\begin{align*}
		\bm{\tau}_{ext} + \bm{\tau}_{int} = \dv{\bm{L}^*}{t}
	\end{align*}
	
	If all internal forces are central, the net internal torque vanishes and we have
	\begin{align*}
		\bm{\tau}_{ext} = \dv{\bm{L}^*}{t}
	\end{align*}
\end{itemize}

\subsubsection{Work and Energy}
\begin{itemize}
	\item The total kinetic energy of a system of $ N $ particles is 
	\begin{equation*}
		T = \frac{1}{2}\sum_{i}^{N}m_{i}\bddot{r}_{i}^{2}
	\end{equation*}
	We can decompose the position vector $ \bm{r}_{i} $ into
	\begin{equation*}
		\bm{r}_{i} = \bm{R} + \tilde{\bm{r}}_{i}
	\end{equation*}
	where $ \bm{R} $ is the position of the system's center of mass and $ \tilde{\bm{r}}_{i} $ is the distance from the $ i $th particle to the center of mass.
	
	\item With the decomposition $ \bm{r}_{i} = \bm{R} + \tilde{\bm{r}}_{i} $, the total kinetic energy becomes
	\begin{equation*}
		T = \frac{1}{2}M \bdot{R}^{2} + \frac{1}{2}\sum_{i}^{N}m_{i}\dot{\tilde{\bm{r}}}_{i}^{2}
	\end{equation*}
	This form tells us that the total kinetic interpretation splits up into the kinetic energy of the center of mass and the \textit{internal kinetic energy} describing how the system's particles move around the center of mass.
	
	\item Following the same story line as for a single particle, the change in kinetic energy between two times is
	\begin{equation*}
		T(t_{2}) - T(t_{1}) = \sum_{i}^{N} \int \bm{F}^{\text{ext}}_{i} \cdot \diff \bm{r}_{i} + \sum_{i\neq j} \int \bm{F}_{ij} \cdot \diff \bm{r}_{i} 
	\end{equation*}
	As before, we need conservative forces to recover energy conservation. For systems of particles, we need both
	\begin{itemize}
	\item Conservative external forces $ \bm{F}^{\text{ext}}_{i} = - \grad_{i}V_{i}(\bm{r}_{1}, \ldots, \bm{r}_{N}) $ and...
	\item Conservative internal forces $ \bm{F}_{ij} = - \grad_{i}V_{ij}(\bm{r}_{1}, \ldots, \bm{r}_{N}) $
	\end{itemize}
	where $ \grad_{i} \equiv \pdv{}{\bm{r}_{i}} $. 
	
	\item To recover Newton's third law $ \bm{F}_{ij} = - \bm{F}_{ji} $, along with the condition that $ \bm{F}_{ij} $ is parallel to the relative position $ \bm{\bm{r}_{i} - \bm{r}_{j}} $, we must consider central internal potentials satisfying 
	\begin{equation*}
		 V_{ij} = V_{ji} \eqtext{and} V_{ij} = V_{ij}(\abs{\bm{r}_{i} - \bm{r}_{j}})
	\end{equation*}
	More so, must consider a restriction on the external forces of the form
	\begin{equation*}
		V_{i} = V_{i}(\bm{r}_{i})
	\end{equation*}
	so the force on the $ i $th particle is independent of the positions of the other particles.
	
	With these conditions, we can define the \textit{total potential energy}
	\begin{equation*}
		V = \sum_{i}^{N}V_{i} + \sum_{i < j}V_{ij}
	\end{equation*}
	and show that the system's \textit{total energy} $ H = T + V $ is conserved. \textbf{TODO}
\end{itemize}

\subsubsection{Virial Theorem}
\begin{itemize}
	\item We consider a stable system of $ N $ particles and define the quantity 
	\begin{equation*}
		G = \sum_{i}^{N} \bm{p}_{i} \cdot \bm{r}_{i}
	\end{equation*}
	Using the product rule, the rate of change of $ G $ with respect to time is
	\begin{equation*}
		\dv{G}{t} = \sum_{i} \bdot{p}_{i} \cdot \bm{r}_{i} + \sum_{i} \bm{p} \cdot \bdot{r}_{i} = \sum_{i} \bm{F}_{i} \cdot \bm{r}_{i} + 2 T
	\end{equation*}
	where $ T = \frac{1}{2} \sum_{i} m \bdot{r}^{2} $ is the system's total kinetic energy.
	
	\item Here's the key step: as long as the system is stable, it will stay in a bounded region of phase space, so $ G $ can only take on a bounded set of values. Because the value of $ G $ is bounded, the average value of its rate of change $ \dv{G}{t} $ over an infinite time period is zero.
	
	If we can further assume the system makes periodic trajectory in phase space, we can reach the same conclusion more elegantly. Suppose the system starts at some point in its phase space where $ G = G_{0} $. Because of the imposed periodicity, after some amount of time the system will eventually return to its starting point in phase space and $ G $ will return to its initial value $ G_{0} $. The average of $ \dv{G}{t} $ over this time period vanishes. 
	
	In either case, we have the result $ \expval{\dv{G}{t}} = 0 $ over a suitably long time period.
	
	\item Taking the time average of the equation for $ \dv{G}{t} $ and applying $ \expval{\dv{G}{t}} = 0 $ gives
	\begin{equation*}
		\expval{\dv{G}{t}} = \expval{\sum_{i} \bm{F}_{i} \cdot \bm{r}_{i}} + 2 \expval{T} = 0 \implies 2 \expval{T}  = -\expval{\sum_{i} \bm{F}_{i} \cdot \bm{r}_{i}}
	\end{equation*}
	This is the \textit{virial theorem} for a stable system of $ N $ particles. What exactly does it mean? In fact, it is a way of relating the system's average kinetic and potential energies. The potential energy is hidden in the $ \bm{F}_{i} $: if we can assume the forces are conservative, we can relate force to potential with $ \bm{F}(\bm{r}) = - \grad{V}(\bm{r}) $.
	
	\item The virial theorem gives a beautiful result for interactions governed by a central potential $ V = V(r) $ of the form $ V(r) = k r^{n}$; the result is
	\begin{equation*}
		2 \expval{T} = n \expval{V}
	\end{equation*} 
	To derive this, we start with an expression for the force. Although the discussion is a bit premature (see the central forces chapter), because the force is central we can write
	\begin{equation*}
		\bm{F} = -\grad{V}(r) = -\grad(kr^{n}) = - k n r^{n-1} \uvec{r}
	\end{equation*}
	where $ \uvec{r} = \frac{\bm{r}}{r} $. In component form, the force on the $ i $th particle is $ \bm{F}_{i} = - k n r_{i}^{n-1} \uvec{r}_{i} $.
	\begin{equation*}
		\bm{F}_{i} = - k n r_{i}^{n-1} \uvec{r}_{i} = -k n r_{i}^{n-2}\bm{r}_{i} \eqtext{where}  \uvec{r}_{i} = \frac{\bm{r}_{i}}{r_{i}}
	\end{equation*}
	Evaluating the dot product $ \bm{F}_{i} \cdot \bm{r}_{i} $ in the sum gives
	\begin{equation*}
		\bm{F}_{i} \cdot \bm{r}_{i} = \left(-k n r_{i}^{n-2}\bm{r}_{i}\right) \cdot \bm{r}_{i} = - k n r_{i}^{n} = -n V(r_{i})
	\end{equation*}
	All we have to do is sum over the $ i = 1, \ldots, N $ particles to get
	\begin{equation*}
		-\expval{\sum_{i} \bm{F}_{i} \cdot \bm{r}_{i}} = - \expval{\sum_{i} (-n V(r_{i}))} = + n V(r) \implies 2 \expval{T} = n \expval{V}
	\end{equation*}
		
\end{itemize}






\subsection{Newton's Laws in Rotating Systems}
This section will generalize Newton's second law $ \bm{F} = \dot{\bm{p}} $, which is valid only in inertial frames, to a more general expression that holds in both inertial and non-inertial frames. If you think about it, this an important goal, since nearly every frame of reference you will work with is to some extend non-inertial (the Earth, for instance rotates around both its own axes and the sun).
\begin{itemize}
	\item In this section we will be dealing with
	\begin{itemize}
		\item An inertial coordinate system $ S $ with coordinate axes $ (x, y, z) $
		\item An rotating coordinate system $ S' $ with coordinate axes $ (x', y', z') $
		\item A vector quantity in space (typically the position vector $ \bm{r} $), which we will describe in terms of both the inertial or non-inertial coordinates.
	\end{itemize} 
	In this first section, the origins of $ S $ and $ S' $ will coincide. $ S $ is at rest and $ S' $ rotates with respect to $ S $ about an axis through the mutual origin with angular velocity $ \bm{\omega} $.
	
	To begin, we'll assume the $ z $ and $ z' $ axes coincide and denote the angle between the $ x $ and $ x' $ axes as $ \theta $. 
	
	\item We first consider the motion of particles. Consider a particle that is sitting stationary in the rotating frame $ S' $. This could be, for example, a child sitting on a carousel. From the perspective of the fixed frame $ S $, the particle will appear to move with the velocity
	\begin{equation*}
		\bdot{r} = \bm{\omega} \cross \bm{r}
	\end{equation*}
	Because we choose the $ z $ and $ z' $ axes to coincide we have $ \bm{\omega} = \omega \uvec{z} = \dot{\theta} \uvec{z} $ where $ \omega = \dot{\theta}$ is the angular speed and the direction of $ \bm{\omega} $ is the axis of rotation, defined in the right-hand sense.
	
	\item The key step is extending this description of rotation to the axes of $ S' $ themselves. Let $ \e_{1}', \e_{2}' $ and $ \e_{3}' $ be the unit vectors pointing along the $ x', y' $ and $ z' $ axes of $ S' $. Just like a particle in $ S' $ appeared in $ S $ to move with velocity $ \bdot{r} = \bm{\omega} \cross \bm{r} $, the unit vectors rotate with velocity
	\begin{equation*}
		\dot{\e}_{i}' = \bm{\omega}\cross \e_{i}'
	\end{equation*}
	from the perspective of the inertial frame $ S $. The rotation of the unit vectors encoded in the above equation will allow us to understand motion in rotating frames.
	
\end{itemize}

\subsubsection{Velocity and Acceleration in a Rotating Frame}
\begin{itemize}
	\item Consider a particle moving around in space; we will then analyze its motion in both the $ S $ and $ S' $ frames. When I was first learning, it helped me to remember we are analyzing the \textit{same} particle in both frames, we are just encoding its dynamics in two different coordinate systems. Or, more formally (in linear algebra terms), we are writing the same vector quantity in different bases.
	
	\item Let $ \e_{1}, \e_{2} $ and $ \e_{3} $ be the unit vectors pointing along the $ x, y $ and $ z $ axes of $ S $. In this basis the position of the particle in $ S $ is 
	\begin{equation*}
		\bm{r} = \sum_{i=1}^{3}r_{i}\e_{i} \equiv r_{i}\e_{i}
	\end{equation*}
	where the second equality adopts the shorthand summation convention. Alternatively, the position measured in $ S' $ is
	\begin{equation*}
		\bm{r} = r_{i}'\e_{i}'
	\end{equation*}
	Note that the position vector $ \bm{r} $ is the same in both frames since the origins coincide, but the coordinates $ r_{i} $ and $ r_{i}' $ will in general differ, since they're measured with respect to different axes.
	
	\item Equipped with the position vector $ \bm{r} $, we can now compute the velocity. The product rule for derivatives is essential here. Measured in frame $ S $, the velocity is
	\begin{equation*}
		\bdot{r} = \dot{r}_{i}\e_{i} + r_{i}\dot{\e}_{i} =  \dot{r}_{i}\e_{i}
	\end{equation*}
	We have the simple expression $ \bdot{r} = \dot{r}_{i}\e_{i} $ because the axes $ \e_{i} $ do not change with time (i.e. $ \dot{e}_{i} = 0 $) since $ S $ is inertial. This won't hold in $ S' $, where the velocity is
	\begin{align*}
		\bdot{r} &= \dot{r}_{i}'\e_{i}' + r_{i}'\dot{\e}_{i}' =\dot{r}_{i}'\e_{i}' + r_{i}'(\bm{\omega} \cross \e_{i}') = \dot{r}_{i}'\e_{i}' + \bm{\omega} \cross (r_{i}' \e_{i}')\\
		&= \dot{r}_{i}'\e_{i}' + \bm{\omega} \cross \bm{r}
	\end{align*}
	where we have used the handy expression $ \dot{\e}_{i}' = \bm{\omega}\cross \e_{i}' $.
	
	\item We now introduce a new notation to highlight the physics and hopefully clarify what is going on in the transitions between frames. We write the velocity of the particle seen by an observer in $ S $ as
	\begin{equation*}
		\left(\dv{\bm{r}}{t}\right)_{S} = \dot{r}_{i}\e_{i}
	\end{equation*}
	Similarly, we write the velocity as seen by an observer rotating with the frame $ S' $ as
	\begin{equation*}
		\left(\dv{\bm{r}}{t}\right)_{S'} = \dot{r}_{i}'\e_{i}'
	\end{equation*}
	
	\item Equipped with this notation and the equation $ 	\bdot{r} = \dot{r}_{i}'\e_{i}' + \bm{\omega} \cross \bm{r} $, we see that observers in the two frames measure two different velocities related by 
	\begin{equation*}
		\left(\dv{\bm{r}}{t}\right)_{S} = \left(\dv{\bm{r}}{t}\right)_{S'} + \bm{\omega} \cross \bm{r}
	\end{equation*}
	We now see the discrepancy is just the relative velocity $ \bm{v}_{\text{rel}} = \bm{\omega} \cross \bm{r} $ between the two frames.
	
	\item On to the particle's acceleration; we just have to continue our time differentiation of $ \bm{r} $. In $ S $ the acceleration is simply
	\begin{equation*}
		\bddot{r} = \ddot{r}_{i} \e_{i}
	\end{equation*}
	where we are again helped by $ \dot{\e}_{i} = 0$. In the frame $ S' $ the expression is more complicated. From the expression $ \bdot{r} = \dot{r}_{i}'\e_{i}' + \bm{\omega} \cross \bm{r} $ with $ \dot{\e}_{i}' = \bm{\omega} \cross \e_{i}' $ and $ \bm{r} = r_{i}' \e_{i}' $, time differentiation and a few steps of algebra lead to
	\begin{equation*}
		\bddot{r} = \ddot{r}_{i}'\e_{i}' + 2 \dot{r}_{i}' \bm{\omega} \cross \e_{i}' + r_{i}'\bdot{\omega} \cross \e_{i}' + r_{i}'\bm{\omega} \cross (\bm{\omega} \cross \e_{i}')
	\end{equation*}
		
	\item We adopt a analogous notation for acceleration as we did for velocities: the acceleration of the particle seen by an observer in $ S $ is
	\begin{equation*}
		\left(\dv[2]{\bm{r}}{t}\right)_{S} = \ddot{r}_{i}\e_{i}
	\end{equation*}
	and the acceleration as seen by an observer rotating with the frame $ S' $ is
	\begin{equation*}
		\left(\dv[2]{\bm{r}}{t}\right)_{S'} = \ddot{r}_{i}'\e_{i}'
	\end{equation*}
	If we equate the expressions for $ \bddot{r} $ in the inertial and rotating bases and adopt the new notation, leaving the quantities $ \bm{r} $ and $ \bm{\omega} $ in vector form (i.e. not expanding them in either the $ \e_{i} $ or $ \e_{i}' $ bases) we get the vector equation
	\begin{equation*}
		\left(\dv[2]{\bm{r}}{t}\right)_{S} = \left(\dv[2]{\bm{r}}{t}\right)_{S'} + 2 \bm{\omega} \cross  \left(\dv{\bm{r}}{t}\right)_{S'} + \bdot{\omega} \cross \bm{r} + \bm{\omega} \cross (\bm{\omega} \cross \bm{r})
	\end{equation*}
	This result is important: it lets us generalize Newton's second law to rotating frames.
\end{itemize}

\subsubsection{Newton's Second Law in Rotating Frames}
\begin{itemize}
	\item The messy mathematics is behind us. Let's take a look at how an observer rotating with the frame $ S' $ would see Newton's second law of motion applied to a particle moving space. In the inertial frame we have good old Newton's second law $ m \bddot{r} = \bm{F} $, or in our new notation
	\begin{equation*}
		m \left(\dv[2]{\bm{r}}{t}\right)_{S} = \bm{F}
	\end{equation*}
	where $ \bm{F} $ is the net force acting on the particle. Combining this with our last result, multiplying through by $ m $ and rearranging produces
	\begin{equation*}
		m\left(\dv[2]{\bm{r}}{t}\right)_{S}' = \bm{F} - 2m\bm{\omega} \cross  \left(\dv{\bm{r}}{t}\right)_{S'} - m\bdot{\omega} \cross \bm{r} - m\bm{\omega} \cross (\bm{\omega} \cross \bm{r})
	\end{equation*}
	This is Newton's second in rotating frames of reference. To explain the particle's motion, an observer rotating with $ S' $ must introduce the existence of three further terms on the right side of the equation besides the traditional net force $ \bm{F} $. The three extra terms are called \textit{fictitious forces} and are a legitimate physical consequence of the frame $ S' $'s rotation. Put simply, they arise because $ S' $ is not inertial. We will go over each in the next section.
	
	Note that from the perspective of an observer rotating with $ S' $ a free particle (for which $ \bm{F} = 0 $) does not travel with uniform motion $ m\left(\dv[2]{\bm{r}}{t}\right)_{S}' = 0 $ because of the three fictitious forces.
	

	
%	Remember: the particle is not an intrinsic property of either the rotating or inertial frame. The particle exists and space and can be analyzed just as well using the coordinates of either frame. It does not make sense to say a particle ``in'' the frame $ S' $, but it is fine to say a particle as \textit{observed} in the frame $ S' $.

\end{itemize}

\subsubsection{Fictitious Forces}
We will now analyze each term in the generalized second law
\begin{equation*}
	m\left(\dv[2]{\bm{r}}{t}\right)_{S}' = \bm{F} - 2m\bm{\omega} \cross  \left(\dv{\bm{r}}{t}\right)_{S'} - m\bdot{\omega} \cross \bm{r} - m\bm{\omega} \cross (\bm{\omega} \cross \bm{r})
\end{equation*}
\begin{enumerate}
	\item The term $ -2m \bm{\omega} \cross \left(\dv{\bm{r}}{t}\right)_{S'} $ is called the \textit{Coriolis force}.
	\begin{itemize}
		\item It depends on the velocity $ \left(\dv{\bm{r}}{t}\right)_{S'} $ of the particle as measured by an observer rotating with $ S' $. Because the force is velocity dependent it is felt only by moving particles. Note also that the force is independent of position.
		
		\item The Coriolis force has an interesting effect: it makes moving particles turn in circles. In fact, you probably (sort of) already knew this: the Coriolis force is mathematically identical to the familiar Lorentz force felt by a charged particle moving in a magnetic field. Just compare the equations:
		\begin{equation*}
			\bm{F}_{\text{cor}} \sim m \bm{v} \cross \bm{\omega} \eqtext{and} \bm{F}_{\text{mag}} \sim q \bm{v} \cross \bm{B}
		\end{equation*}
		We know the Lorentz force makes moving charged particles turn in circles and can expect the Coriolis force to do the same. More formally, the circles result because the force is always perpendicular to velocity by virtue of the cross product $ \bm{v} \cross \bm{\omega} $.
		
		\item The magnitude of the Coriolis force is
		\begin{equation*}
			\abs{\bm{F}_{\text{cor}}} = 2 m \omega v \sin \theta
		\end{equation*}
		where $ \theta $ is the angle between the particle's velocity $ \bm{v} $ and the axis of rotation $ \bm{\omega} $. 
		
	\end{itemize}
	
	
	\item The term $ -m \bm{\omega} \cross (\bm{\omega} \cross \bm{r}) $ is called the \textit{centrifugal force}. 
	\begin{itemize}
		\item With the vector identity $ \bm{a} \cross (\bm{b} \cross \bm{c}) = (\bm{a} \cdot \bm{c})\bm{b} - (\bm{a} \cdot \bm{b})\bm{c} $ it can be written
		\begin{align*}
			\bm{F}_{\text{cent}} &= -m \bm{\omega} \cross (\bm{\omega} \cross \bm{r})\\
			&=- m(\bm{\omega} \cdot \bm{r}) \bm{\omega} + m \omega^{2} \bm{r}
		\end{align*}
		The centrifugal force on a particle points from the particle perpendicularly away from the axis of rotation. 
			
		\item The magnitude of the centrifugal force is
		\begin{equation*}
			\abs{\bm{F}_{\text{cent}}} = m \omega^{2} \operatorname{proj}_{\bm{\omega}}(\bm{r})
		\end{equation*}
		where $ \operatorname{proj}_{\bm{\omega}}(\bm{r}) $ is the orthogonal projection of the position vector onto the axis of rotation $ \bm{\omega} $.
		
		\item There's an interesting interpretation of the centrifugal force. First, note that the force does not depend on the particle's velocity, only on its position $ \bm{r} $. This suggest we can view the centrifugal force as a conservative force, with an associated potential, the form
		\begin{equation*}
			\bm{F}_{\text{cent}} = - \grad V(\bm{r}) \eqtext{where} V(\bm{r}) = -\frac{m}{2}\abs{\bm{\omega} \cross \bm{r}}^{2}
		\end{equation*}
		In the rotating frame $ V $ has the interpretation of a potential energy depending on the particle's position associated with the frame's rotation. The potential is negative. We know particles tend to minimize their energy, so we expect particles in a centrifugal potential to fly out from the axis of rotation; increasing $ \abs{r} $ will minimize the potential energy. This agrees with our earlier conclusion that that centrifugal force acts outward from the axis of rotation.
			
	\end{itemize}
	
	
	\item The term $ - m \bdot{\omega} \cross \bm{r} $ is called the \textit{Euler force}. It arises only when $ S' $ rotates with variable angular velocity $ \bm{\omega} $ (i.e. $ \bdot{\omega} \neq 0 $). Because most everyday examples of non-inertial frames rotate with (nearly) constant angular velocity, the Euler force is usually negligible.
	
\end{enumerate}


\subsubsection{Rotation With Moving Origins}
Staying with our frames $ S $ and $ S' $, we now consider the general case when the origins of $ S $ and $ S' $ are separated by the vector $ \bm{R} $, and the origins move relative to each other in space. 

$ S $ still rotates with angular velocity $ \bm{\omega} $ about an axis through its center.

A real-world example would be an (almost) inertial system $ S $ at the center of the sun and a non-inertial system $ S' $ on the Earth; the $ S' $ Earth system both orbits around the sun (relative motion of origins) and rotates about an axis through its center. 

We have
\begin{align*}
	&\bm{r} = \bm{r}_{O} + \bm{r}'\\
	&\bm{v}_{L} = \bm{v}_{M} + \bm{v}_{O} + \bm{\omega} \cross \bm{r}'\\
	&\bm{a}_{L} = \bm{a}_{M} + \bm{a}_{O} + \dot{\bm{\omega}}\cross \bm{r}' +  2 \bm{\omega} \cross \bm{v}_{M} + \bm{\omega} \cross (\bm{\omega} \cross \bm{r}')\\
	&m\bm{a}_{M} = \bm{F} - m \bm{a}_{O} - m\dot{\bm{\omega}}\cross \bm{r}' -  2m \bm{\omega} \cross \bm{v}_{M} - m\bm{\omega} \cross (\bm{\omega} \cross \bm{r}')
\end{align*}
where $ \bm{v}_{O} $ and $ \bm{a}_{O} $ are the relative velocity and accelerations of the origins. They are measured in the inertial frame $ L $.

\textbf{Or, using different symbols:}

The dynamics of rotating coordinate system $ M $ whose origin is separated from the origin of a lab system $ L $ by the vector $ R $, including fictitious forces, are governed by the equations
\begin{align*}
	&\bm{r} = \bm{R} + \bm{r}'\\
	&\bm{v}_{L} = \bm{v}_{M} + \dot{\bm{R}}_{L} + \bm{\omega} \cross \bm{r}'\\
	&\bm{a}_{L} = \bm{a}_{M} + \ddot{\bm{R}}_{L} + \dot{\bm{\omega}}\cross \bm{r}' +  2 \bm{\omega} \cross \bm{v}_{M} + \bm{\omega} \cross (\bm{\omega} \cross \bm{r}')\\
	&m\bm{a}_{M} = \bm{F} - m \ddot{\bm{R}}_{L} - m\dot{\bm{\omega}}\cross \bm{r}' -  2m \bm{\omega} \cross \bm{v}_{M} - m\bm{\omega} \cross (\bm{\omega} \cross \bm{r}')
\end{align*}

\iffalse
\subsubsection{Some Example Problems}

\subsubsection{Convention for Rotating Earth Problems}
\begin{itemize}
	\item Inertial system $ S: \{\uvec{i}, \uvec{j}, \uvec{k} \} $ at the center of the earth with the $ \uvec{k} $ axis pointing toward the north pole and $ \uvec{i} \cross \uvec{j} = \uvec{k} $. The Earth's angular velocity $ \bm{\omega} $ points in the same direction as $ \uvec{k} $.
	
	\item Non-inertial system $ S' : \{\e_1, \e_2, \e_3 \} $ on the Earth's surface in the northern hemisphere at colatitude $ \theta $ measured from the polar ($ \uvec{k} $) axis. 
	
	\item The basis of the non-inertial system, from the perspective an observer on the Earth's surface:
	\begin{itemize}
		\item $ \e_3 $: up (normal to and out of the earth's surface)

		\item $ \e_2 $: east
		
		\item $ \e_1 $: south
	\end{itemize} 
	
\end{itemize}
This convention produces
\begin{align*}
	 &\bm{\omega} = -\omega \sin \theta \e_1 + \omega \cos \theta \e_3\\
	 & \bm{\omega} \cross \bm{v}_{M} = -w \cos \theta \dot{y}' \e_1 + w(\cos \theta \dot{x}' + \sin \theta \dot{z}') \e_2 - w\sin \theta \dot{y}' \e_3
\end{align*}


\subsubsection{Problem Solving Outline} To solve for a body's motion in a non-inertial system:
\begin{enumerate}
	\item Decide on an inertial and rotating system and identify their origins and vector bases.
	
	\item Identify all forces acting on the body and write Newton's second law for rotating systems for the body in vector form, including fictitious forces.
	
	\item Write out Newton's second law in terms of the rotating basis vectors and evaluate any vector products.
	
	\item Write out the equations of motion for $ \bm{a}' = (\ddot{x}', \ddot{y}', \ddot{z}') $ in component form. Solve the equations of motion using techniques in differential equations.
\end{enumerate}

\subsubsection{Free Motion on a Rotating Disk}
A particle is fixed to a disk rotating with constant angular velocity $ \bm{\omega} $. At $ t = 0 $, the particle is released and henceforth experiences no external forces. Solve for the motion of the particle in a coordinate system rotating with the disk with the general conditions $ \bm{r}'(0) = (x_0, y_0, 0)$ and $ \bm{v}'(0) = (\dot{x}_0, \dot{y}_0, 0)$.

\vspace{3mm}
\textbf{Solution}: 
\begin{enumerate}
	\item Let $ S $ be an fixed inertial system with the origin at the disk's center with basis vectors $ \{\uvec{i}, \uvec{j}, \uvec{k} \} $.
	
	Let $ S' $ be a system rotating with the disk, also with origin at the disk's center, with basis vectors $ \{\e_1, \e_2, \e_3 = \uvec{k} \} $. 
	
	In the rotating system, the relevant vector quantities are
	\begin{equation*}
		\bm{\omega} = \omega \e_3 \qquad \bm{r}' = x' \e_1 + y' \e_2 \qquad \bm{v}' = \dot{x}' \e_1 + \dot{y}' \e_2 \qquad \bm{a}' = \ddot{x}' \e_1 + \ddot{y}' \e_2
	\end{equation*}
	
	\item In the rotating system, the particle experiences the Coriolis and centrifugal forces, while the net external force $ \bm{F} = 0$. Write Newton's law for rotating coordinate systems:
	\begin{equation*}
		m \bm{a}' = - 2 m \bm{\omega} \cross \bm{v}' - m \bm{\omega} \cross (\bm{\omega} \cross \bm{r}')
	\end{equation*}
	Evaluate the cross products to get
	\begin{equation*}
		\bm{\omega} \cross \bm{v}' = - \omega \dot{y}' \e_1 + \omega \dot{x}' \e_2 \qquad \bm{\omega} \cross (\bm{\omega} \cross \bm{r}') = -\omega^2 x' \e_1 - \omega^2 y' \e_2
	\end{equation*}
	Plug the cross products into Newton's law and separate the components $ \e_1 $ and $ \e_2 $ to get the coupled equations of motion
	\begin{equation*}
		\ddot x = 2 \omega \dot y + \omega^2 x \qquad \qquad \ddot y = - 2 \omega \dot x + \omega^2 y
	\end{equation*}
	I have dropped the prime notation to avoid clutter, e.g. $ x' \to x $.
	
	\item Decouple the equations using the complex number system: multiply $ \ddot{y} $ by the imaginary unit $ i $ add the equations for $ \ddot{x} $ and $ \ddot{y} $ and introduce the complex variable $ u \coloneqq x + iy $.
	\begin{equation*}
		\ddot{u} = -2 \omega i \dot{u} + \omega^2 u \implies \ddot{u} + 2 \omega i \dot{u} - \omega^2 u = 0
	\end{equation*}
	Solve the equation with the ansatz $ u = e^{i\lambda t} $ to get the characteristic equation 
	\begin{equation*}
		\lambda^2 + 2 \omega \lambda + \omega^2 = (\lambda + \omega)^2 = 0 \implies \lambda = - \omega
	\end{equation*}
	and thus the general solution
	\begin{equation*}
		u(t) = A e^{-i\omega t} + Bte^{-i\omega t} = (A + Bt)e^{-i\omega t}
	\end{equation*}
	
	\item Convert the solution to real form by writing 
	\begin{equation*}
		A = x_0 + v_{x_0}t \qquad B = y_0 + v_{y_0}t \implies u(t) = (x_0 + v_{x_0}t + i(y_0 + v_{y_0}t))e^{-i\omega t}
	\end{equation*}
	and using $ u = x + iy $ and Euler's formula $ e^{-i \omega t} = \cos \omega t - i\sin \omega t $. 
	\begin{align*}
		&x = \Re u = (x_0 + v_{x_0}t)\cos \omega t + (y_0 + v_{y_0}t) \sin \omega t\\
		&y = \Im u = - (x_0 + v_{x_0}t) \sin \omega t + (y_0 + v_{y_0}t) \cos \omega t
	\end{align*}
	or, in matrix form, reintroducing prime notation
	\[
		\begin{bmatrix}
			x'\\
			y'
		\end{bmatrix}
		= 
		\begin{bmatrix}
			\cos \omega t & \sin \omega t\\
			-\sin \omega t & \cos \omega t
		\end{bmatrix}
		\begin{bmatrix}
			x_0 + v_{x_0}t\\
			y_0 + v_{y_0}t
		\end{bmatrix}
		= \mathbf{R}_{\omega t}
		 \begin{bmatrix}
			x_0 + v_{x_0}t\\
			y_0 + v_{y_0}t
		\end{bmatrix}
	\]
	where $ \mathbf{R} $ is a rotation matrix by the angle $ \omega t $.

	
\end{enumerate}

\subsubsection{Free Fall on the Rotating Earth}
Find the eastward deflection of a free-falling body near the the Earth's surface with the initial conditions $ \bm{r}'(0) = (0, 0, h) $ and $ \dot{\bm{r}}'(0) = (0, 0, 0) $.

\begin{itemize}
	\item Place the origin of the rotating system at the Earth's surface and the origin of the inertial system at the Earth's center.
	
	\item Neglect all fictitious forces except the Coriolis force; evaluate the cross product $ \bm{\omega} \cross \bm{v}' $. Write Newton's law and separate components into $ \ddot{x}, \ddot{y}, \ddot{z} $. 
	\begin{align*}
		&\ddot x = 2 \omega \dot y \cos \theta\\
		&\ddot y = - 2\omega (\dot x \cos \theta + \dot z \sin \theta)\\
		&\ddot z = - g + 2 \omega \dot y \sin \theta
	\end{align*}
	\textbf{Note}: The prime notation is dropped from here forward.
	
	\item Integrate the expressions for $ \ddot{x} $, $ \ddot{y} $, and $ \ddot{z} $ once each, \textit{including constants of integration}, to get expressions for $ \dot{x} $, $\dot{y}$, $ \dot{z} $. Apply the initial conditions to solve for the constants of integration and get:
	\begin{align*}
		&\dot{x} = 2 \omega y \cos \theta \\
		&\dot{y} = -2 \omega (x \cos \theta + (z - h) \sin \theta )\\
		&\dot{z} = -gt + 2 \omega y\sin \theta 
	\end{align*}
	
	\item Plug the expressions for $ \ddot{x} $ and $ \ddot{z} $ into the equation for $ \ddot{y} $, neglect the $ \omega^2 $ terms, and solve the resulting differential equation for $ y(t) $ to get
	\begin{equation*}
		y(t) = \frac{\omega g t^3}{3}  \sin \theta
	\end{equation*}
\end{itemize}

\textbf{Approximate Perturbation Calculation}
\begin{itemize}
	\item Assume $ \dot{z} \approx -gt $ and integrate $ \dot{z} $. With the chosen initial conditions, this produces gives $ z \approx -\dfrac{gt^2}{2} + h $.
	
	\item Neglect the $ x $ term in the expression for $ \dot{y} $ (assume $ w x \approx 0 $) and plug the expression for $ z $ into the expression for $ \dot{y} $. Solve for $ y $ and apply the initial condition $ \dot{y}(0) = 0 $ to obtain the approximate eastern deflection
	\begin{align*}
		y(t) \approx \frac{wgt^3}{3}\sin \theta
	\end{align*}
\end{itemize}

\subsubsection{Foucault Pendulum}
\begin{itemize}
	\item Place the origin of the rotating system at the pendulum's axis/rotation point and the origin of the inertial system at the Earth's center.
	
	\item Neglect all fictitious forces except the Coriolis force; evaluate the cross product $ \bm{\omega} \cross \bm{v}' $.
	
	\item Identify the net force is $ \bm{T} + m\bm{g} $; with the approximation $ l \gg x, y, z $, write the tension as
	\begin{align*}
		\bm{T} = T\frac{-x\e_1' - y\e_2' - (z-l)\e_3'}{\sqrt{x^2 + y^2 + (l-z)^2}} \approx T\left (-\frac{x}{l}\e_1' - \frac{y}{l}\e_2' - \frac{(z-l)}{l}\e_3'\right )
	\end{align*}
	
	\item Write Newton's law and separate components into $ \ddot{x}, \ddot{y}, \ddot{z} $. Use the $ \ddot{z} $ equation with the approximations $ \ddot{z} \approx 0 $ and $ z/l \approx 0 $ to solve for the magnitude of tension $ T $.
	\begin{align*}	
		T = mg - 2m\omega \sin \theta \dot{y}'
	\end{align*}
	
	\item Plug the expression for tension into $ \ddot{x} $ and $ \ddot{y} $, use the approximation $ \dot{z} \approx 0 $, and get the follow equations for $ x $ and $ y $:
	\begin{align*}
		&\ddot{x} = -\frac{g}{l} x + \frac{2 \omega \sin \theta }{l}x \dot y + 2 \omega \cos \theta \dot y\\
		&\ddot{y} = -\frac{g}{l} y + \frac{2 \omega \sin \theta }{l}y \dot y - 2 \omega \cos \theta \dot x
	\end{align*}
	
	\item To solve the system, neglect the second-order terms $ x \dot{y} $ and $ y \dot{y}$, multiply $ \ddot y $ by $ i $, add the equations for $ \ddot{x} $ and $ \ddot{y} $, and solve the equation in the complex numbers using $ u = x + iy $. With the abbreviations $ \frac{g}{l} = k^2$ and $ \alpha = \omega \cos \theta $, the resulting equation is
	\begin{align*}
		\ddot u + 2 \alpha i \dot u + k^2 u = 0
	\end{align*}
	
%	\item Use the initial conditions $ x_0 = 0, \dot x_0 = 0, y_0 = L, \dot y_0 = 0 $ to recover the solutions for $ x $ and $ y $.

\end{itemize}

\fi

\newpage 
\section{Lagrangian Mechanics}

\subsection{Lagrange's Equations and the Principle of the Least Action} \label{ssec:lag:lag_and_least_action}

\subsubsection{Coordinates and Degrees of Freedom}
Lagrangian mechanics uses slightly different coordinates than the Newtonian position vector $ \bm{r} $, so let's start by sorting our coordinates out. Suppose we are dealing with a system of $ N $ particles under the influence of a conservative net force.
\begin{itemize}
	\item We need $ 3N $ coordinates to uniquely describe a system of $ N $ particles in 3 dimensions. $ N $ is for the number of particles in the system and $ 3 $ because each particle can move in three dimensions.
	
	In Newtonian mechanics we usually package these coordinates into position vectors $ \bm{r}_1, \bm{r}_{2}, \dots, \bm{r}_{N} $ where $ \bm{r}_{i} = (x_i, y_i, z_i)  $ are the coordinates of the $ i $th mass point and $ i = 1, \ldots, N $.
	
	\item Some terminology: a three dimensional system of $ N $ particles has $ 3N $ \textit{degrees of freedom}; each of the $ N $ particles contributes three. Degrees of freedom tell us how many quantities we must know to uniquely specify the configuration (position) of our system in space. For example, we need three coordinates to uniquely describe the position of a point particle in 3 dimensions, so a single particle has $ 3 $ degrees of freedom.
	
	Our system's $ 3N $ degrees of freedom parameterize a $ 3N $ dimensional space called the \textit{configuration space}. Each $ 3N $-dimensional point in the phase space represents a configuration of the system (i.e. the position of all $ N $ particles). The time evolution of our system corresponds to a $ 3N $-dimensional curve in configuration space.
	
	\item Our new coordinates: We will replace the $ N $ Newton-style position vectors $ \bm{r}_{i} $ with $ 3N $ coordinates $ x^{A} $ where $ A = 1, \ldots, 3N $. Note that the $ A $ is not a power but an ``up'' index; you'll see more of this notation in tensor calculus. For our purposes in this course  the placement of the indexes is not critical; you can read $ x^{A} $ as $ x_{A} $.
	
	\item On to Newton's laws with our new coordinates $ x^{A} $. For our conservative system we have $ \bm{F} = - \grad V $. In Newtonian mechanics the equation of motion for the $ i $th particle would be $ \bdot{p}_{i} = - \pdv{V}{\bm{r}_{i}}$. With our new coordinates, Newton's equations of motion read
	\begin{equation*}
		\dot{p}_{A} = - \pdv{V}{x^{A}}, \qquad A = 1, \ldots, 3N
	\end{equation*}
	where $ p_{A} = m_{A}\dot{x}^{A} $.
	
\end{itemize}

\subsubsection{Lagrangian and Principle of Least Action}
We continue with our system of $ 3N $ particles under the influence of a conservative force. We start by defining the Lagrangian function, the cornerstone of Lagrangian mechanics.
\begin{itemize}
	\item Our system's \textit{Lagrangian} function, or simply \textit{Lagrangian}, is a function of the positions $ x^{A} $ and velocities $ \dot{x}^{A} $ given by
	\begin{equation*}
		L(x^{A}, \dot{x}^{A}) = T(\dot{x}^{A}) - V(x^{A})
	\end{equation*}
	where $ T = \frac{1}{2}\sum_{A}m_{A}(\dot{x}^{A})^{2}$ is the system's total kinetic energy and $ V(x^{A}) $ is the system's total potential energy. 
	
	\item Recall the time evolution of our system corresponds to a $ 3N $ dimensional path in configuration space. An \textit{action} is a property of a path $ x(t) $ in configuration space, and is defined as
	\begin{equation*}
		S[x(t)] = \int_{t_i}^{t_f} L(x(t), \dot{x}(t)) \diff t
	\end{equation*}
	where $ L(x, \dot x) = T(\dot{x}) - V(x) $ is the Lagrangian. 
	

	
	\item For the principle of least action, we consider all smooth paths in the configuration space between the fixed endpoints $ x_{i}$ and $ x_{f} $ where $ x(t_i) = x_i $ and $ x(t_f) = x_{f} $.
	
	The \textit{principle of least action states}: 
	\begin{quote}
		The path taken by a system between two points in its configuration space is an extremum of the action $ S $.
	\end{quote}
	The extremum could be a maximum, minimum, or saddle point.
	
	In fact, all the fundamental laws of physics can be written in terms of an action principle, but that's another story.
	

\end{itemize}

\subsubsection{Proof of Least Action Principle}
\begin{itemize}
	\item Consider a smooth paths through configuration space between the fixed endpoints $ x^{A}_{i}$ and $ x^{A}_{f} $ where $ x^{A}(t_i) = x^{A}_i $ and $ x^{A}(t_f) = x^{A}_{f} $. We'll write the path $ x^{A}(t) $. Then consider varying the path just slightly. Instead of $ x^{A}(t) $ we have
	\begin{equation*}
		x^{A} \to x^{A}(t) + \delta x^{A}(t)
	\end{equation*}
	where $ \delta x^{A} $ is small compared to $ x^{A} $. 
	
	\item Although the interior of the path can vary as $ x^{A} \to x^{A}(t) + \delta x^{A}(t) $, we'll insist on keeping our endpoints fixed, so $ x^{A}(t_i) = x^{A}_i $ and $ x^{A}(t_f) = x^{A}_{f} $. In other words, the variation vanishes at the endpoints $ x^{A}_{i} $ and $ x^{A}_{f} $ and
	\begin{equation*}
		\delta x^{A}(t_{i}) = \delta x^{A}(t_{f}) = 0 \implies x^{A}(t_{i}) = x^{A}_{i} \quad \text{and} \quad x^{A}(t_{f}) = x^{A}_{f}
	\end{equation*}
	If the talk of variation of paths in configuration space seems abstract, think in everyday terms of walking between the same two points $ x_{i} $ and $ x_{f} $, but taking a slightly different path between them. 
	
	\item The change in action $ \delta S $ corresponding to our slight change in path $ \delta x^{A}(t) $ is
	\begin{align*}
		\delta S &= \delta \left[\int_{t_{i}}^{t_{f}}L(x^{A}, \dot{x}^{A}) \diff t \right] = \int_{t_{i}}^{t_{f}} \delta L(x^{A}, \dot{x}^{A}) \diff t\\
		& = \int_{t_{i}}^{t_{f}} \left(\pdv{L}{x^{A}} \delta x^{A} + \pdv{L}{\dot{x}^{A}} \delta \dot{x}^{A} \right) \diff t\\
		&= \int_{t_{i}}^{t_{f}}\pdv{L}{x^{A}} \delta x^{A} \diff t + \int_{t_{i}}^{t_{f}}\pdv{L}{\dot{x}^{A}} \delta \dot{x}^{A} \diff t
	\end{align*}
	
	\item We integrate the second integral by parts with 
	\begin{equation*}
		\diff v = \delta \dot{x}^{A} \diff t \implies v = \delta x^{A} \eqtext{and} u = \pdv{L}{\dot{x}^{A}}  \implies \diff u = \dv{}{t}\pdv{L}{\dot{x}^{A}}
	\end{equation*}
	Applying $ \int u \diff v = uv - \int v \diff u $ and joining the two integrals into one integrand, the variation in action reads 
	\begin{equation*}
		\delta S = \int_{t_{i}}^{t_{f}}\left[\pdv{L}{x^{A}} - \dv{}{t}\pdv{L}{\dot{x}^{A}} \right] \delta x^{A} \diff t + \left[\pdv{L}{\dot{x}^{A}} \delta x\right]_{t_{i}}^{t^{f}}
	\end{equation*}
	Since we have fixed the endpoints $ \delta x^{A}(t_{i}) = \delta x^{A}(t_{f}) = 0 $ the last term (the $ uv $ term from integration by parts) vanishes. We're left with
	\begin{equation*}
		\delta S = \int_{t_{i}}^{t_{f}}\left[\pdv{L}{x^{A}} - \dv{}{t}\pdv{L}{\dot{x}^{A}} \right] \delta x^{A} \diff t
	\end{equation*}
	
	\item Back to the principle of least action: the requirement that action $ S $ is an extremum holds only if $ \delta S = 0 $ for all small variations in the path $ \delta x^{A}(t) $. Since $ \delta x^{A} \neq 0 $, the requirement $ \delta S = 0 $ for all paths holds if the other term in the integrand is zero, namely
	\begin{equation*}
		\pdv{L}{x^{A}} - \dv{}{t}\pdv{L}{\dot{x}^{A}} = 0 \qquad \text{for all } A = 1, \ldots, 3N
	\end{equation*}
	These equations are called \textit{Lagrange's equations}, and we'll see they replace Newton's equations in Lagrangian mechanics. 
	
	\item To finish the proof of the least action principle, we just need to show that Lagrange's equations are equivalent to Newton's. From the definition of the Lagrangian $ L(x^{A}, \dot{x}^{A}) = T(\dot{x}^{A}) - V(x^{A}) $, we have
	\begin{equation*}
		\pdv{L}{x^{A}} = - \pdv{V}{x^{A}} \eqtext{and} \pdv{L}{\dot{x}^{A}} = \pdv{T}{\dot{x}^{A}} =  \pdv{}{\dot{x}^{A}}\left[\frac{1}{2}m \left (\dot{x}^{A}\right )^{2}\right] = p_{A}
	\end{equation*}
	Putting the pieces together, we see the Lagrange and Newton equations are equivalent 
	\begin{equation*}
		\dv{}{t}\pdv{L}{\dot{x}^{A}} = \pdv{L}{x^{A}}  \iff \dot{p}_{A} = - \pdv{V}{x^{A}} \iff \bdot{p}_{i} = \bm{F}_{i}
	\end{equation*}
	Since Newton's equations are known to hold, so must Lagrange's, meaning $ \pdv{L}{x^{A}} - \dv{}{t}\pdv{L}{\dot{x}^{A}} = 0 $, which means $ \delta S = 0 $ for all variations $ \delta x^{A}(t) $. This concludes the proof of the least action principle.
	
\end{itemize}


\subsubsection{Lagrange Equations In Changing Coordinate Systems}
Lagrangian mechanics have two strong advantages over Newtonian mechanics: Lagrange's equations hold in any coordinate system (Newton's second law holds only in inertial systems) and the Lagrangian formalism greatly simplifies systems with constraints.  We'll start by examining Lagrange's equations in changing coordinate systems and deal with constraints in the next section.
\begin{itemize}
	\item \textbf{Notation:} First, a note on a wonderfully efficient notation we'll use for the rest of the course, called the \textit{Einstein summation convention}. When an index appears twice in a single term without further specification, it implies summation of that term over all values of the index. Here's a simple example using the index $ i = 1, 2, 3 $:
	\begin{equation*}
		a_{i}b^{i} \equiv \sum_{i = 1}^{3} a_{i}b_{i} = a_{1}b_{1} + a_{2}b_{2} + a_{3}b_{3}
	\end{equation*}
	Recognize this? It's the dot product of the vectors $ \bm{a} \cdot \bm{b} $.
	
	Here's a concrete example of how we'll use the convention in this course. Consider some quantity $ q $ (they'll turn out to be coordinates) that is a function of the coordinates $ x_{A}, A = 1, \ldots, 3N $ and time, so $ q = q(x_{1}, \ldots, x_{3N}, t) $. Using the chain rule, summation convention and dot notation for time derivatives, the time derivative of $ q $ is then
	\begin{equation*}
		\dot{q} = \pdv{q}{x^{A}} \dot{x}^{A} + \pdv{q}{t} \eqtext{or, equivalently} \dv{q}{t} = \sum_{A = 1}^{3N} \pdv{q}{x_A} \dv{\dot{x}^{A}}{t} + \pdv{q}{t}
	\end{equation*}
	Once you get a feel for it, the left hand side is a lot cleaner.
	
	\item With summation convention behind us, we turn our focus to Lagrange's equations in changing coordinate systems. Staying with our system of $ N $ particles with coordinates $ x_{A} $, let's introduce a new coordinate system
	\begin{equation*}
		q_{a} = q_{a}(x_{1}, \ldots, x_{3N}, t)
	\end{equation*}
	where $ a = 1, \ldots, 3N $ and the $ t $ dependence allows for a coordinate system that changes with time. As already written earlier, $ q_{a} $ change with time as
	\begin{equation*}
		\dot{q} = \pdv{q}{x^{A}} \dot{x}^{A} + \pdv{q}{t}
	\end{equation*}
	
	\item For the $ q_{a} $ to be a well-defined coordinate system we should be able to invert the relationship to recover the original $ x^{A} $ as $ x^{A} = x^{A}(q_{1}, \ldots, q_{3N}, t) $. Formally, this as possible as long as the $ 3N \cross 3N $ matrix $ \pdv{x^{A}}{q_{a}} $ is non-singular, i.e.
	\begin{equation*}
		\det \pdv{x^{A}}{q_{a}} \neq 0
	\end{equation*}
	but this condition is more a mathematical technicality than something we have to deal with in real systems. 
	
	\item Assuming we can invert $ q_{a}(x^{A}, t) $ to recover $ x^{A} = x^{A}(q_{a}, t) $, we have the time derivative
	\begin{equation*}
		\dot{x}^{A} = \pdv{x^{A}}{q_{a}} \dot{q}_{a} + \pdv{x^{A}}{t}
	\end{equation*}
	Armed with expressions for $ x^{A} $ and $ \dot{x}^{A} $ in terms of the new coordinates $ q_{a} $, we can write the Lagrangian $ L(x^{A}, \dot{x}^{A}) $ in terms of $ q_{a} $:
	\begin{equation*}
		L(x^{A}, \dot{x}^{A}) = L\left(x^{A}(q_{a}, t), \dot{x}^{A}(q_{a}, \dot{q}_{a}, t) \right )
	\end{equation*}
	We now have a bit of derivative work to do: we need to calculate $ \pdv{L}{\dot{q}_{a}}  $ and $ \dv{}{t} \left (\pdv{L}{\dot{q}_{a}}\right)  $. The chain rule tells us
	\begin{equation*}
		\pdv{L}{q_{a}} = \pdv{L}{x^{A}}\pdv{x^{A}}{q_{a}} + \pdv{L}{\dot{x}^{A}}\left(\pdv{x^{A}}{q_{a}}{q_{b}}\dot{q}_{b}+ \pdv{x^{A}}{q_{a}}{t} \right)
	\end{equation*}
	and 
	\begin{equation*}
		\pdv{L}{\dot{q}_{a}} = \pdv{L}{\dot{x}^{A}} \pdv{\dot{x}^{A}}{\dot{q}_{a}}
	\end{equation*}
	To simplify $ \pdv{L}{\dot{q}_{a}} $ we'll need the intermediate result $ \pdv{\dot{x}^{A}}{\dot{q}_{a}} = \pdv{x^{A}}{q_{a}} $, which we find by taking the partial derivative of $ \dot{x}^{A} $ with respect to $ \dot{q}_{a} $: 
	\begin{equation*}
		\pdv{\dot{x}^{A}}{\dot{q}_{a}} = \pdv{}{\dot{q}_{a}}\left[\pdv{x^{A}}{q_{a}} \dot{q}_{a}\right] + \pdv{}{\dot{q}_{a}} \left[\pdv{x^{A}}{t}\right] = 0 + \pdv{x^{A}}{q_{a}} \pdv{\dot{q}_{a}}{\dot{q}_{a}} + 0 \implies \pdv{\dot{x}^{A}}{\dot{q}_{a}} = \pdv{x^{A}}{q_{a}} 
	\end{equation*}
	With this result we have
	\begin{equation*}
		\pdv{L}{\dot{q}_{a}} = \pdv{L}{\dot{x}^{A}} \pdv{\dot{x}^{A}}{\dot{q}_{a}} = \pdv{L}{\dot{x}^{A}} \pdv{x^{A}}{q_{a}} 
	\end{equation*}
	The time derivative of $ \pdv{L}{\dot{q}_{a}} = \pdv{L}{\dot{x}^{A}} \pdv{x^{A}}{q_{a}}  $, using the product and chain rules, is
	\begin{align*}
		\dv{}{t} \left (\pdv{L}{\dot{q}_{a}}\right) &= \dv{}{t}\left[\pdv{L}{\dot{x}^{A}}\right]\pdv{x^{A}}{q_{a}}  +  \dv{}{t}\left[\pdv{x^{A}}{q_{a}} \right] \pdv{L}{\dot{x}^{A}}\\
		&= \dv{}{t}\left[\pdv{L}{\dot{x}^{A}}\right]\pdv{x^{A}}{q_{a}}  +  \pdv{L}{\dot{x}^{A}} \left(\pdv{x^{A}}{q_{a}}{q_{b}}\dot{q}_{b} + \pdv{x^{A}}{q_{a}}{t}\right)
	\end{align*}
	
	\item We now combine the equations for $ \pdv{L}{\dot{q}_{a}}  $ and $ \dv{}{t} \left (\pdv{L}{\dot{q}_{a}}\right)  $. The term $  \pdv{L}{\dot{x}^{A}}\left(\pdv{x^{A}}{q_{a}}{q_{b}}\dot{q}_{b}+ \pdv{x^{A}}{q_{a}}{t} \right) $ conveniently cancels. Grouping the remaining $ \pdv{x^{A}}{q_{a}} $ terms gives
	\begin{equation*}
		\dv{}{t}  \left (\pdv{L}{\dot{q}_{a}}\right)  - \pdv{L}{\dot{q}_{a}} =\left[ \dv{}{t}\left(\pdv{L}{\dot{x}^{A}}\right) - \pdv{L}{x^{A}}\right]\pdv{x^{A}}{q_{a}}
	\end{equation*}
	This is an excellent result: it tells us that if Lagrange's equations hold in the $ x^{A} $ coordinate system they also hold in the $ q_{a} $ system. In other words, Lagrange's equations are preserved across any coordinate transformation of the form $ q_{a} = q_{a}(x_{1}, \ldots, x_{3N}, t) $.
	
	How to see this result? If Lagrange's equations hold in the $ x^{A} $ coordinates then by definition of the Lagrange equation $ \dv{}{t}\left(\pdv{L}{\dot{x}^{A}}\right) - \pdv{L}{x^{A}} = 0 $. But if $ \dv{}{t}\left(\pdv{L}{\dot{x}^{A}}\right) - \pdv{L}{x^{A}} = 0 $ then our result tells us that $ \dv{}{t}  \left (\pdv{L}{\dot{q}_{a}}\right) - \pdv{L}{\dot{q}_{a}} = 0 $, which means Lagrange's equations also hold in the $ q_{a} $ coordinates. The converse (i.e. the LE holding for $ q_{a} $ implying the LE hold for $ x_{A} $) holds as long as $ \det \pdv{x^{A}}{q_{a}} \neq 0$. 
	
\end{itemize}


\subsection{Constraints and Generalized Coordinates}
We continue with our system of $ N $ particles and coordinates $ x_{A}, A = 1, \ldots, 3N $. So far we have tacitly assumed the particles in our system can roam anywhere in $ \mathbb{R}^{3} $. But what if there are constraints restricted where the particles can move? In Newton mechanics we handle constraints with ``constraint forces'', like the normal force of a surface preventing an object from falling through the floor. Lagrangian mechanics greatly simplify the treatment of constraints. But first, some background.

\subsubsection{Holonomic Constraints} \label{sssec:lag:hol_const}
Formally, constraints are conditions that reduce a system's degrees of freedom. In Lagrangian mechanics constraints are often desirable since they make a system's motion simpler.
\begin{itemize}
	\item A \textit{holonomic constraint} is a relationship between the coordinates $ x^{A} $ that can be written in the form
	\begin{equation*}
		f_{\alpha}(x_{A}, t ) = 0 \qquad \alpha = 1, \ldots, 3N - n
	\end{equation*}
	where $ t $ allows for the constraint to depend on time. A system as a whole is called a \textit{holonomic system} if all of its constraints are holonomic.

	
	\item Holonomic constraints can solved in terms of $ n $ \textit{generalized coordinates} $ q_{1}, \ldots, q_{n} $ to which we will assign the index $ i $ and label $ q_{i} $. Once we solve a system's constraints in terms of the generalized coordinates $ q_{i} $ we can transform from the original coordinates $ x^{A} $ to the generalized coordinates $ q_{i} $:
	\begin{equation*}
		x_{A} = x_{A} (q_{1}, \ldots, q_{n})
	\end{equation*}
	A system with $ 3N - n $ constraints and thus $ n $ generalized coordinates has $ n $ degrees of freedom, since we need $ n $ generalized coordinates to uniquely describe the system.
	
	\item Since all the indexes and variables can be confusing, here's a quick review. Feel free to skip. To have a simple a system as possible, we want as many constraints as possible. A completely free system has zero constraints and a completely fixed system that can't move at all has $ 3N $ constraints. In our notation the system has $ 3N - n $ constraints, so $ n $ should be small to maximize the number of constraints. If $ n $ is small, we only need a small number of generalized coordinates to uniquely describe our system. This is good, we want to be able to describe the system with as few coordinates as possible.
	
	\item Here's how Lagrangian mechanics handles constraints. For each of the $ 3N -n  $ constraints $ f_{\alpha} $ we introduce $ 3N - n $ new variables $ \lambda_{\alpha} $, called \textit{Lagrange multipliers}.
	
	In terms of the Lagrange multipliers we define a new Lagrangian
	\begin{equation*}
		L' = L(x^{A}, \dot{x}^{A}) - \lambda_{\alpha}f_{\alpha}(x^{A}, t)
	\end{equation*}
	We can treat the Lagrange multipliers $ \lambda_{\alpha} $ as new coordinates. Using our new Lagrangian $ L' $ the Lagrange-Euler equations for $ \lambda_{\alpha} $ are then
	\begin{equation*}
		\pdv{L'}{\lambda_{\alpha}} - \dv{}{t}\left(\pdv{L'}{\dot{\lambda}_{\alpha}} \right) = 0 \implies f_{\alpha}(x^{A}, t) = 0 
	\end{equation*}
	This simply recovers the constraints $ f_{\alpha}(x^{A}, t) = 0  $. 
	
	Tthe Lagrangian equations for $ x^{A} $ are more interesting. We have
	\begin{equation*}
		\pdv{L'}{x^{A}} - \dv{}{t}\left(\pdv{L'}{\dot{x}^{A}} \right) = 0 \implies \pdv{L}{x^{A}} + \lambda_{\alpha} \pdv{f_{\alpha}}{x^{A}} -  \dv{}{t}\left(\pdv{L}{\dot{x}^{A}} \right) = 0
	\end{equation*}
	This result will tell us how the Lagrangian formalism handles constraints.
	\begin{equation*}
		 \dv{}{t}\left(\pdv{L}{\dot{x}^{A}} \right) - \pdv{L}{x^{A}} = \lambda_{\alpha} \pdv{f_{\alpha}}{x^{A}}
	\end{equation*}
	Notice the left hand side is the familiar Lagrange equation of motion for the unconstrained system. The right hand side is the manifestation of the constraint forces in our system. In principle, these equations could be solved just like in the Newtonian formalism. But there's a much easier way to go about it using the generalized coordinates $ q_{i} $.
	
\end{itemize}

	

\subsubsection{Holonomic Constraints and Generalized Coordinates}
%Often, we only want to solve for a system's motion and aren't interested in the specific nature of the constraint forces. 
\begin{itemize}
	\item The Lagrangian formalism makes it possible to solve for the motion of a constrained system in terms of the $ n $ generalized coordinates $ q_{i} $ instead of $ 3N $ coordinates $ x^{A} $. 
	
	This is really useful. Why? Because $ n $ is usually small and $ 3N $ is usually large.\footnote{At least in introductory classical dynamics courses :)} It's easier to solve a few equations instead of many equations. 
	
	\item Derive the system's equations of motion directly in the generalized coordinates means we must be able to write the Lagrangian in terms of the $ q_{i} $ in the form:
	\begin{equation*}
		L(q_i, \dot{q}_i, t) = L\left (x^{A}(q_i, t), \dot{x}^{A}(q_i, \dot{q}_i, t)\right )
	\end{equation*}
	following is a quick proof.
	
	\item We'll work with the modified Lagrangian 
	\begin{equation*}
		L' = L(x^{A}, \dot{x}^{A}) - \lambda_{\alpha}f_{\alpha}(x^{A}, t) 
	\end{equation*}
	and change from the $ x^{A} $ coordinates to the generalized coordinates and Lagrange multipliers:
	\begin{equation*}
		x^{A} \to 
		\begin{cases}
			q_{i}, & i = 1, \ldots, n\\
			\lambda_{\alpha}, & \alpha = 1, \ldots, 3N
		\end{cases}
	\end{equation*}
	Notice we start with $ 3N $ coordinates $ x^{A} $ and end with $ n + 3N - n = 3N $ coordinates, so our accounting is okay.
	
	\item Using our new Lagrangian $ L' = L'(q_{i}, \dot{q}_{i}, \lambda_{\alpha}, t) $ we can find the Lagrange equations for $ q_{i} $ (just like in the previous section \ref{sssec:lag:hol_const} with $ L'(x^{A}, \dot{x}^{A}, \lambda_{\alpha}), t $). They are
	\begin{equation*}
		\pdv{L'}{q_{i}} - \dv{}{t}\left(\pdv{L'}{\dot{q}_{i}} \right) = 0 \implies \dv{}{t} \left(\pdv{L}{\dot{q}_i} \right)- \pdv{L}{q_i} = \lambda_{\alpha} \pdv{f_{\alpha}}{q_i}
	\end{equation*}
	But because the constraints $ f_{\alpha} $ are by definition independent of the generalized coordinates $ q_{i} $, we have $ \lambda_{\alpha} \pdv{f_{\alpha}}{q_i} = 0 $ leaving
	\begin{equation*}
		 \dv{}{t} \left(\pdv{L}{\dot{q}_i} \right)- \pdv{L}{q_i} = 0
	\end{equation*}
	This is a great result. It tells us that if we're interested only in the dynamics of the generalized coordinates $ q_{i} $ we can work directly with the Lagrangian $ L(q_{i}, \dot{q}_{i}, t) $ and ignore the Lagrange multipliers, This basically means we only have to solve $ n $ equations instead of $ 3N $. If our system is highly constrained, $ 3N - n $ is a big difference!
	
\end{itemize}

\subsubsection{A Summary of Constraints and Coordinates in Lagrangian Mechanics}
Keeping with a system of $ N $ particles in three dimensions.
\begin{itemize}
	\item In Lagrangian mechanics we begin with $ 3N $ coordinates $ x^{A} $; $ 3N $ is the default number of coordinates needed to describe $ N$ particles in 3 dimensions. 
	
	Usually the system has some constraints. These simplify the motion and allow us to describe the dynamics with fewer coordinates, called generalized coordinates.
	
	For each additional constraint, we need one fewer coordinate to describe our system. If we have $ 3N - n $ constraints, we then need only $ 3N - (3N - n) = n $ generalized coordinates. Basically, the generalized coordinates are the simplified coordinates left over after applying all the constraints.
	
	\item Because it's fewer variable to work with, we describe a system in terms of the $ n $ generalized coordinates $ q_i $ with $ i = 1, \ldots, n $. These coordinates form an $ n $-dimensional space called the configuration space. 
	
	The system's time evolution corresponds to a $ n $-dimensional curve in configuration space. The time evolution is governed by the Lagrangian 
	\begin{equation*}
		L = L(q_i, \dot{q}_i, t) = T(\dot{q}_i) - V(q_i)
	\end{equation*}
	such that the coordinates $ q_{i} $ oby the Lagrange equations
	\begin{equation*}
		\dv{}{t}\left(\pdv{L}{\dot{q}_i}\right) - \pdv{L}{q_i} = 0
	\end{equation*}
	where a system of $ n $ second order (generally) non-linear differential equations. The goal of Lagrangian mechanics is then solving the Lagrange equations for the dynamics of the generalized coordinates $ q_{i} $.
	
	\item Finally, for the sake of completeness, a few words on something we won't have to deal with in this course. But it's good to know such things exist.
	
	Constraints that cannot be written in the form $ f(x_{A}, t) = 0 $ are called \textit{non-holonomic} constraints. Two common examples are: constraints with inequalities and velocity-dependent constraints that cannot be integrated into the form $ f(x^{A}, t) = 0 $, e.g;
	\[
	\begin{array}{l  l}
		\text{Constraint with an inequality:} & \quad f(x_{A}, t) \leq C, \quad (C \in \R)\\
		\text{Velocity dependent constraint:} & \quad g(x^A, \dot{x}^A, t) = 0
	\end{array}
	\]
	And a some vocabulary: If a constraint has an explicit time dependence, it is called \textit{rheonomic}. If a constraint is not explicitly time-dependent, it is called \textit{scleronomic}

\end{itemize}

\subsection{Lagrange's Equations and D'Alembert's Principle}
D'Alembert's principle is another way to derive Lagrange's equations using the concept of virtual displacements and virtual work. By the way, even though we started with the principle of least action, derivation by D'Alembert's principle is the conventional way to introduce Lagrange's equations. I think this version is more work, so I put the principle of least action derivation first.

\subsubsection{Virtual Displacements and D'Alembert's Principle}
\begin{itemize}
	\item First, we split the forces acting on our system into active forces and constraint forces. 
	\begin{equation*}
		\bm{F}_{i} = \bm{F}_{i}^{a} + \bm{F}_{i}^{c}
	\end{equation*}
	Active forces are the forces that directly affect the dynamics of the generalized coordinates. The constraints, well, constrain the possible paths our system can take. They're the forces associated with the Lagrange multipliers, which we've shown we can ignore if we're interested only in the dynamics of the generalized coordinates. In general, constraint forces are perpendicular to a system's motion (think normal force, tension forces, etc...), so they can't do work on the system. 
	
	We'll come back to the separation of forces $ \bm{F}_{i} = \bm{F}_{i}^{a} + \bm{F}_{i}^{c} $ shortly.
		
	\item Constraint forces that are perpendicular to the system's motion for all displacements, including virtual displacements, are called \textit{ideal constraints}. These are the common constraints like normal force and tension. For this section and this course, we'll consider only ideal constraints. For a system with ideal constraints, in which the constraint forces are always perpendicular to motion, the work done by constraint forces is zero.
	
	\item We'll return to our vector notation, using $ N $ position vectors $ \bm{r}_{i}, i = 1, \ldots, N $ instead of the $ 3N $ Lagrange-style coordinates $ x^{A} $. 
	
	A definition: a \textit{virtual displacement} of a system is a change in the configuration of the system as the result of any arbitrary infinitesimal change of the coordinates \textit{at a given instant in time} consistent with the forces and constraints imposed on the system at that instant in time. 
	
	The displacement is called virtual to distinguish it from an actual displacement in a time \textit{interval} $ \diff t $, during which the the forces and constraints might change.
	
	Think of a virtual displacement as a sort of freeze-frame, capturing the system's possible displacement at a single moment in time for given the forces and constraints acting at that instant.
	
	To distinguish them from displacements $ \diff \bm{r} $ than occur in a finite time interval $ \diff t $, we denote virtual displacements by $ \delta \bm{r} $.
	
	Virtual work is the work of a force in the direction of a virtual displacement, $ \delta W = \bm{F} \cdot \delta \bm{r}
	 $.
	
	
	\item First, we'll consider a static equilibrium situation, then move to dynamics. For a system in equilibrium, the net force on each particle vanishes, so $ \bm{F}_{i} = 0 $. If $ \bm{F}_{i} = 0  $ then naturally any work done by the net force also vanishes. We then have
	\begin{equation*}
		\bm{F}_{i}^{(\text{eq})} \cdot \delta \bm{r}_{i} = 0
	\end{equation*}
	where the notation stresses that the net force $ \bm{F}_{i}^{(\text{eq})} $ is such that the system is in equilibrium. Using the general decomposition of the net force into $ \bm{F}_{i}^{(\text{eq})} = \bm{F}_{i}^{(a)} + \bm{F}_{i}^{(c)} $, this becomes
	\begin{equation*}
		 \left (\bm{F}_{i}^{(a)} + \bm{F}_{i}^{(c)}\right ) \cdot \delta \bm{r}_{i} = 0
	\end{equation*}
	Restricting ourselves to a system with ideal constraint, $ \bm{F}_{i}^{(c)} $ will always be perpendicular to $ \delta \bm{r}_{i} $, so the virtual work done by the constraint forces vanishes. We then have
	\begin{equation*}
		\bm{F}_{i}^{(a)} \cdot \delta \bm{r}_{i} = 0
	\end{equation*}
	for any system in equilibrium. This result is called the \textit{principle of virtual work}. It gives an condition for equilibrium for any system with ideal constraints: the total virtual work done by the active forces must vanish. 
	
	Note, however, that this condition does \textit{not} require that the virtual work on each particle is zero, just that the sum of the individual work (i.e. the total work) adds up to zero. This means that the \textit{individual} $ \bm{F}_{i}^{(a)} $ need not equal zero for a system in equilibrium. 
	
%	Formally, this occurs because the $ \delta \bm{r}_{i} $ are not linearly independent.
	
	
	\item On to dynamics---we'll use little trick here. We take Newton's equation of motion $ \bm{F}_{i} = \bdot{p}_{i} $, which applies to an accelerating particle, then rearrange it to get
	\begin{equation*}
		\bm{F}_{i}^{(\text{eq})} \equiv \bm{F}_{i} - \bdot{p}_{i} = 0
	\end{equation*}
	which we interpret, \`{a} la Goldstein, as follows: the accelerating system would be in equilibrium if acted on by a net force $ \bm{F}_{i}^{(\text{eq})} $ equal to the accelerating force $ \bm{F}_{i} $ minus a ``reversed effective force'' $ \bdot{p}_{i} $. We can then plug $\bm{F}_{i}^{(\text{eq})} = \left(\bm{F}_{i} - \bdot{p}_{i}\right) $ into the equilibrium equation $ \bm{F}_{i}^{(\text{eq})} \cdot \delta \bm{r}_{i} = 0 $ to get
	\begin{equation*}
		\left(\bm{F}_{i} - \bdot{p}_{i}\right) \cdot \delta \bm{r}_{i} = 0
	\end{equation*}
	Decomposing the net force into the active and constraint force $ \bm{F}_{i} = \bm{F}_{i}^{(a)} + \bm{F}_{i}^{(c)} $ and then recalling that the virtual work $ \bm{F}_{i}^{(c)}\cdot \delta   \bm{r}_{i} $ is zero for ideal constraints, we get 
	\begin{align*}
		0 &= \left[ \left(\bm{F}_{i}^{(a)} + \bm{F}_{i}^{(c)}\right) - \bdot{p}_{i}\right] \cdot \delta \bm{r}_{i} = \left( \bm{F}_{i}^{(a)} - \bdot{p}_{i}\right) \cdot \delta \bm{r}_{i} + \bm{F}_{i}^{(c)}\cdot \delta \bm{r}_{i} \\
		&= \left( \bm{F}_{i}^{(a)} - \bdot{p}_{i}\right) \cdot \delta \bm{r}_{i} + 0
	\end{align*}
	The result
	\begin{equation*}
		\left( \bm{F}_{i}^{(a)} - \bdot{p}_{i}\right) \cdot \delta \bm{r}_{i}= 0
	\end{equation*}
	is called \textit{D'Alembert's principle}. The result is important in that it applies to dynamics as well as statics, and only contains the active forces. I stress again that the quantity $ \bm{F}^{(a)} - \bdot{p} $ is \textit{not} generally zero for each particle individually, just that all the $ \bm{F}_{i}^{(a)} - \bdot{p}_{i} $ for the particles together sum to zero.
	
\end{itemize}

\subsubsection{Deriving the Lagrange Equations: Take Two, Part 1}
\begin{itemize}
	\item D'Alembert's principle (which I'm now writing with the index $ j $---explained shortly)
	\begin{equation*}
		\left( \bm{F}_{j}^{(a)} - \bdot{p}_{j}\right) \cdot \delta \bm{r}_{j}= 0
	\end{equation*}
	is an important result, but it can't quite get us to Lagrange's equations. The problem is that in the presence of constraints, the coordinates $ \bm{r}_{j} $ are in general dependent on each other.
	
	For our equations of motion to be well defined, we'll need to introduce a set of \textit{independent} coordinates. In fact, we have just what we need for the job: the generalized coordinates $ q_{i} $. The goal will be to transform D'Alembert's principle from $ \bm{r}_{j} $ to $ q_{i} $.
	
	That's also why I changed indices: we had previously used $ i $ for the generalized coordinates $ q_{i} $, and I wanted to stay consistent. We can't use $ i $ for both the vector coordinates $ \bm{r} $ and generalized coordinates $ q $ since there are different number of each, so we'll use $ j $ for the $ \bm{r}_{j} $. It's just notational struggles---nothing of physical significance.
	
	\item We start with the transformation, introduced in Subsection \ref{sssec:lag:hol_const},
	\begin{equation*}
		\bm{r}_{j} = \bm{r}_{j}(q_{1}, \ldots, q_{n}, t)
	\end{equation*}
	The total derivative of $ \bm{r}_{j} $ is then
	\begin{equation*}
		\diff \bm{r}_{j} = \pdv{\bm{r}_{j}}{q_{i}}\diff q_{i} + \pdv{\bm{r}_{j}}{t}\diff t
	\end{equation*}
	For virtual displacements, which by definition occur for $ \diff t= 0 $, we have
	\begin{equation*}
		\delta \bm{r}_{j} = \pdv{\bm{r}_{j}}{q_{i}}\delta q_{i}
	\end{equation*}
	While the total virtual work $ \bm{F}_{j} \cdot \delta \bm{r}_{j}$ becomes
	\begin{equation*}
		\bm{F}_{j} \cdot \delta \bm{r}_{j} = \bm{F}_{j} \cdot \left(\pdv{\bm{r}_{j}}{q_{i}}\delta q_{i}\right) \equiv Q_{i} \delta q_{i}
	\end{equation*}
	where we defined a \textit{generalized force} with components
	\begin{equation*}
		Q_{i} = \bm{F}_{j} \pdv{\bm{r}_{j}}{q_{i}}
	\end{equation*}
	The transformation $ \bm{F}_{j} \cdot \delta \bm{r}_{j} = Q_{i} \delta q_{i} $ takes care of the first term $ \bm{F}_{j}^{(a)} \cdot \delta \bm{r}_{j} $ in D'Alembert's principle, where we could safely equate $ \bm{F}_{j} \cdot \delta \bm{r}_{j} $ to $ \bm{F}_{j}^{(a)} \cdot \delta \bm{r}_{j}$ because D'Alembert's principle requires a priori that the constraint forces do no work, so the $ \bm{F}^{(c)} $ terms don't contribute to the virtual work $ Q_{i}\delta q_{i} $.
	
	\item The transformation from $ \bm{r}_{j} $ to $ q_{i} $ in the second term $ \bdot{p}_{j} \cdot \delta \bm{r}_{j} $ requires a bit more effort. Writing $ \bdot{p} = m \bddot{r} $ and substituting the expression for $ \delta r_{j}(q_{i}) $, we get
	\begin{equation*}
		\bdot{p}_{j} \cdot \delta \bm{r}_{j} = m_{j}  \bddot{r}_{j} \cdot \left(\pdv{\bm{r}_{j}}{q_{i}} \delta q_{i}\right)
	\end{equation*}
	Next, we'll use a little trick. By reverse engineering the product rule, we can write
	\begin{equation*}
		m_{j}\bddot{\bm{r}}_{j} \pdv{r_{j}}{q_{i}} = \dv{}{t}\left[m_{j}\bdot{r}_{j}  \pdv{\bm{r}_{j}}{q_{i}} \right] - \bdot{r}_{j} \dv{}{t}\left[m_{j}\pdv{\bm{r}_{j}}{q_{i}} \right]
	\end{equation*}
	Getting an expression for $ \bdot{r}_{j} $ isn't too hard: a time differentiation of $ \bm{r}_{j} = \bm{r}_{j}(q_{1}, \ldots, q_{n})$ with the chain rule gives
	\begin{equation*}
		\bdot{r}_{j} = \dv{\bm{r}_{j}}{t} = \pdv{\bm{r}_{j}}{q_{i}} \dot{q}_{i} + \pdv{\bm{r}_{j}}{t}
	\end{equation*}
	
	\item The next step is basically the foundation of the Lagrangian formalism (i.e. it's important): we define the $ \dot{q}_{i} $ as a \textit{new variable, independent of the} $ q_{i} $. Even though they both involve the coordinates $ q $, the Lagrangian formalism treats the $ q_{i} $ and $ \dot{q}_{i} $ as if they were just as different as the hypothetical variables $ x $ and $ y $. 
	
	If we can view the $ \dot{q}_{i} $ as new, independent coordinates, we can take the partial derivative of  $ \bdot{r}_{j} = \pdv{\bm{r}_{j}}{q_{i}} \dot{q}_{i} + \pdv{\bm{r}_{j}}{t} $ with respect to $ \dot{q}_{i} $ with the product rule to get
	\begin{align*}
		\pdv{\bdot{r}_{j}}{\dot{q}_{i}} &= \pdv{}{\dot{q}_{i}} \left[\pdv{\bm{r}_{j}}{q_{i}}\right] \dot{q}_{i} + \pdv{\bm{r}_{j}}{q_{i}} \pdv{\dot{q}_{i}}{\dot{q}_{i}} + \pdv{}{\dot{q}_{i}} \left[ \pdv{\bm{r}_{j}}{t}\right] \\
		&= 0 +  \pdv{\bm{r}_{j}}{q_{i}} + 0 \implies \pdv{\bdot{r}_{j}}{\dot{q}_{i}} = \pdv{\bm{r}_{j}}{q_{i}}
	\end{align*}
	The result $ \pdv{\bdot{r}_{j}}{\dot{q}_{i}} = \pdv{\bm{r}_{j}}{q_{i}} $ looks like we just trivially ``canceled the dots'' but we could only do that because we defined the $ \dot{q}_{i} $  as independent coordinates.
	
	\item Back to where we left off with
	\begin{equation*}
		m_{j}\bddot{\bm{r}}_{j} \pdv{\bm{r}_{j}}{q_{i}} = \dv{}{t}\left[m_{j}\bdot{r}_{j}  \pdv{\bm{r}_{j}}{q_{i}} \right] - \bdot{r}_{j} \dv{}{t}\left[m_{j}\pdv{\bm{r}_{j}}{q_{i}} \right] \equiv \mathrm{I} - \mathrm{II}
	\end{equation*}
	where we'll tackle the expression term by term. Starting with I, we'll use the result $ \pdv{\bdot{r}_{j}}{\dot{q}_{i}} = \pdv{\bm{r}_{j}}{q_{i}} $ and a reverse engineered chain rule to get
	\begin{equation*}
		I \equiv \dv{}{t}\left[m_{j} \bdot{r}_{j}  \pdv{\bm{r}_{j}}{q_{i}} \right] =  \dv{}{t}\left[m_{j} \bdot{r}_{j}  \pdv{\bdot{r}_{j}}{\dot{q}_{i}} \right] = \dv{}{t} \left[\pdv{}{\dot{q}_{i}}  \left(\frac{m_{j} \bdot{r}_{j}^{2}}{2}\right)\right] = \dv{}{t} \left(\pdv{T}{\dot{q}_{i}}\right)
	\end{equation*}
	Look who showed up: it's the system's total kinetic energy $ T =\frac{ m_{j} \bdot{r}_{j}^{2}}{2} $.
	
	\item On to the second term $ \mathrm{II} \equiv m_{j} \bdot{r}_{j} \dv{}{t}\left[\pdv{\bm{r}_{j}}{q_{i}} \right] $. First, we'll calculate the derivative $ \dv{}{t} \pdv{\bm{r}_{j}}{q_{i}} $, using the chain rule and remembering $ \bm{r}_{j} = \bm{r}_{j}(q_{1}, \ldots, q_{n}, t) $:
	\begin{equation*}
		\dv{}{t} \pdv{\bm{r}_{j}}{q_{i}} = \pdv{\bm{r}_{j}}{q_{i}}{q_{k}} \dot{q}_{k} + \pdv{\bm{r}_{j}}{q_{i}}{t} = \pdv{}{q_{i}} \left[\pdv{\bm{r}_{j}}{q_{k}} \dot{q}_{k} + \pdv{\bm{r}_{j}}{t}\right] = \pdv{}{q_{i}}\left[\dv{\bm{r}_{j}}{t}\right] = \pdv{\bdot{r}_{j}}{q_{i}}
	\end{equation*}
	where we can factor out the derivative $ \pdv{}{q_{i}} $ in the second equality because $ \pdv{\dot{q}_{k}}{q_{i}} = 0$ (remember, the $ q_{i} $ and $ \dot{q}_{i} $ are different variables).
	
	With the result $ 	\dv{}{t} \pdv{\bm{r}_{j}}{q_{i}} = \pdv{\bdot{r}_{j}}{q_{i}} $ the term II, after a reverse engineered chain rule, becomes
	\begin{equation*}
		\mathrm{II} = m_{j} \bdot{r}_{j} \dv{}{t}\left[\pdv{\bm{r}_{j}}{q_{i}} \right]  = m_{j} \bdot{r}_{j} \pdv{\bdot{r}_{j}}{q_{i}} = \pdv{}{q_{i}} \left[\frac{m_{j} \bdot{r}_{j}^{2}}{2} \right] = \pdv{T}{q_{i}}
	\end{equation*}
	
	\item The hard work is done: we've eliminated the $ \bm{r}_{j} $ from both terms I and II in favor of $ q_{i} $. Putting the pieces together, D'Alembert's principle in terms of $ q_{i} $ reads
	\begin{equation*}
		\left[\dv{}{t} \left(\pdv{T}{\dot{q}_{i}}\right) - \pdv{T}{q_{i}} - Q_{j}\right]\delta q_{i} = 0
	\end{equation*}
	Here's a summary of how we put the pieces back together, starting with $ \left(\bm{F}_{j}^{(a)} - \bdot{p}_{j}\right)\cdot \delta \bm{r}_{j} = 0 $
	\begin{align*}
		0 &=\bm{F}_{j}^{(a)}\cdot \bm{r}_{j} - \bdot{p}_{j}\cdot \delta \bm{r}_{j} =  Q_{i}\delta q_{i} - m_{j}  \bddot{r}_{j} \cdot \pdv{\bm{r}_{j}}{q_{i}} \delta q_{i} = \left[Q_{i} - (\mathrm{I} - \mathrm{II})\right] \delta q_{i}\\
		&= \left[Q_{i} - \dv{}{t}\left(\pdv{T}{\dot{q}_{i}}\right) +  \pdv{T}{q_{i}} \right] \delta q_{i} \implies \left[\dv{}{t} \left(\pdv{T}{\dot{q}_{i}}\right) - \pdv{T}{q_{i}} - Q_{i}\right]\delta q_{i} = 0
	\end{align*}
	Now, here's why we transformed to generalized coordinates in the first place. Because the $ q_{i} $ \textit{independent} of each other, the virtual displacements in separate coordinates $ \delta q_{i} $ and $ \delta q_{j} $ for $ i \neq $ are also independent. Because of the independence of the $ q_{i} $, the equality in D'Alembert's principle holds for \textit{all} $ i = 1, \ldots, n $ only if
	\begin{equation*}
		\left[\dv{}{t} \left(\pdv{T}{\dot{q}_{i}}\right) - \pdv{T}{q_{i}} - Q_{i}\right] = 0 \eqtext{or} \dv{}{t} \left(\pdv{T}{\dot{q}_{i}}\right) - \pdv{T}{q_{i}} = Q_{i}
	\end{equation*}
	This is starting to look like the Lagrange's equations we saw in Section \ref{ssec:lag:lag_and_least_action}.

\end{itemize}

\subsubsection{Deriving the Lagrange Equations: Take Two, Part Two}
\begin{itemize}
	\item The equations of motion 
	\begin{equation*}
		\dv{}{t} \left(\pdv{T}{\dot{q}_{i}}\right) - \pdv{T}{q_{i}} - Q_{j} = 0
	\end{equation*}
	we just derived are in fact more general than the Lagrange equations $ \pdv{L}{q_{i}} = \dv{}{t}\left(\pdv{L}{\dot{q}_{i}}\right) $ we saw in Section \ref{ssec:lag:lag_and_least_action}. To get to the more familiar form, we'll assume the forces acting on our system are conservative and thus can be derived from a scalar potential via 
	\begin{equation*}
		\bm{F} = - \grad{V}(\bm{r}_{1}, \ldots, \bm{r}_{N}) \eqtext{or, by components} \bm{F}_{j} = - \pdv{V}{\bm{r}_{j}}
	\end{equation*}
	In this case, the generalized forces $ Q_{i} = \bm{F}_{j} \cdot \pdv{\bm{r}_{j}}{q_{i}} $ can be conveniently written
	\begin{equation*}
		Q_{i} = - \pdv{V}{\bm{r}_{j}} \cdot \pdv{\bm{r}_{j}}{q_{i}} = - \pdv{V}{q_{i}}
	\end{equation*}
	Plugging $ Q_{i} $ into the equations of motion then gives
	\begin{equation*}
		\dv{}{t} \left(\pdv{T}{\dot{q}_{i}}\right) - \pdv{T}{q_{i}} - \left(- \pdv{V}{q_{i}} \right) = \dv{}{t} \left(\pdv{T}{\dot{q}_{i}}\right) - \pdv{(T - V)}{q_{i}} = 0
	\end{equation*}
	
	\item One more assumption: we restrict our system to velocity independent potentials (which still covers most of the common interactions in nature, e.g. gravitational, electrostatic, etc...). A velocity-independent potential means $ V \neq V(\dot{q}_{i})$. The immediate implication $ \pdv{V}{\dot{q}_{i}} = 0 $ lets us do a little trick, namely rewriting
	\begin{equation*}
		\pdv{T}{\dot{q}_{j}} = \pdv{(T - V)}{\dot{q}_{j}}
	\end{equation*}
	The equations of motion then read
	\begin{equation*}
		\dv{}{t} \left(\pdv{T}{\dot{q}_{i}}\right) - \pdv{(T - V)}{q_{i}} = \dv{}{t} \left[\pdv{(T - V)}{\dot{q}_{i}}\right] - \pdv{(T - V)}{q_{i}} = 0
	\end{equation*}
	Or, in terms of the Lagrangian $ L \equiv T - V $, the familiar Lagrange equations
	\begin{equation*}
		\dv{}{t} \left(\pdv{L}{\dot{q}_{i}}\right) - \pdv{L}{q_{i}} = 0
	\end{equation*}
	
\end{itemize}

\iffalse

\textbf{Don't Worry!} 
\begin{itemize}
	\item In practice, the number of particles and constraints in common problems is small and manageable. The number of particles in the system might number 1 to 5 while the number of constraints might be 1 to 3. 
	
	\item Likewise, the constraints on the system are usually intuitive and easy to visualize, (for example the length of a rope stuff) even though the definitions of constraints look formal and abstract.
\end{itemize}

\subsubsection{Generalized Coordinates}

Analyzing a system's dynamics can be made easier or more difficult to analyze depending on the coordinates we choose to describe the system. For example, we generally use spherical coordinates when working with a spherically symmetric system because it is easiest! Spherical coordinates are best adapted to that particular system's geometry.

Analogously, a system can be made much easier to analyze if we choose a set of coordinates adapted to the system's constraints.

Informally, generalized coordinates are just the set of coordinates that do the best job simplifying a system's dynamics for that system's constraints.

\textbf{Effect of Constraints on Coordinates}

A constraint is a condition linking two coordinates in a system together. Each constraint on system:
\begin{enumerate}
	\item Decreases the number of degrees of freedom by one.
	\item Changes the affected coordinates (which were initially independent) into dependent coordinates.Let's take a closer look at constraints:
\end{enumerate}

A system of $ n $ particles with $ s $ constraints acting on it thus has $ 3n - s $ degrees of freedom. More so, because of the constraints, the coordinates are in general dependent.

\textbf{Generalized Coordinates Formally} \textit{Only for holonomic constraints!!!?}

Because the original coordinates $ \bm{r}_1, \bm{r}_{2}, \dots, \bm{r}_{n}  $ are now dependent on each other because of the constraints linking the coordinates together, we can theoretically use the $ s $ constraints to write the original coordinates in terms of new coordinates, which we call $ q_1, \dots, q_{3n-s} $. 
\begin{align*}
	\bm{r}_1 &= \bm{r}_1(q_1, q_2, \dots, q_{3n-s}, t)\\
	\bm{r}_2 &= \bm{r}_1(q_1, q_2, \dots, q_{3n-s}, t)\\
	&\ \, \vdots\\
	\bm{r}_n &= \bm{r}_1(q_1, q_2, \dots, q_{3n-s}, t)
\end{align*}

The remaining $ 3n-s $ coordinates $ q_1, q_2, \dots, q_{3n-s} $ that remain are independent and are the general coordinates.

In practice, the transformation to the generalized coordinates is obvious and we don't go through a complicated process like this.

\textbf{Simply Put:} The general coordinates are just the coordinates that after taking constraints into account decrease the system's degrees of freedom as much as possible.


\subsubsection{Dynamical Quantities In Terms of Generalized Coordinates}
\textbf{First off, don't worry}. All of these expressions are presented in their general cases, which looks theoretical, abstract and not particularly intuitive. In practice, dealing with these quantities is much easier than these equations make it look.

Let's say we have a system of $ n $ particles with $ s $ holonomic constraints. We start with $ 3n $ degrees of freedom and apply the constraints to get $ 3n - s $ degrees of freedom, and denote $ \nu \equiv 3n -s $ for shorthand. The constraints induce the coordinate transformation equations
\begin{align*}
	\bm{r}_1 &= \bm{r}_1(q_1, q_2, \dots, q_{\nu}, t)\\
	\bm{r}_2 &= \bm{r}_1(q_1, q_2, \dots, q_{\nu}, t)\\
	&\ \, \vdots\\
	\bm{r}_n &= \bm{r}_1(q_1, q_2, \dots, q_{\nu}, t)
\end{align*}
to $ \nu = 3n - s $ independent generalized coordinates.

\begin{enumerate}
	\item Generalized velocity:
	
	\item Generalized force:
	
	\item Virtual displacement
	
	\item Virtual work
\end{enumerate}
\fi




\subsection{Noether's Theorem and Symmetries of the Lagrangian}
\subsubsection{Constants of Motion and Some Examples} \label{sssec:consts_motion}
\begin{itemize}
	\item First, a definition: for a system with the generalized coordinates $ q_i $, a function $ F(q_i, \dot q_i, t) $(i.e. a function of the generalized coordinates their time derivatives, and (possibly) time) is called a \textit{constant of motion} or a \textit{conserved quantity} if
	\begin{equation*}
		\dv{F}{t} = \pdv{F}{q_i}\dot{q}_i + \pdv{F}{\dot{q}_i}\ddot{q}_i + \pdv{F}{t} = 0
	\end{equation*}
	wherever $ q_{i}(t) $ satisfy the Lagrange equations. In other words, its total time derivative must be zero for all allowed configurations of $ q_{i}(t) $. 
	
	This definition tells us that any conserved quantity $ F $ is constant along a path followed by the system through its configuration space.
	
	\item \textbf{First Example:} If $ L $ doesn't depend explicitly on time (i.e. $ \pdv{L}{t} = 0 $), the quantity 
	\begin{equation*}
		H = \dot{q}_{i}\pdv{L}{\dot{q}_{i}} - L
	\end{equation*}
	is conserved. $ H $ is called the system's \textit{Hamiltonian}.  We'll hear all about it in Section \ref{sec:hamilton}. The Hamiltonian is associated with the system's total energy, and in fact when $ \pdv{L}{t} = 0  $ we have $ H = T + V $, which you can straightforwardly prove by recognizing $ \dot{q}_{i}\pdv{L}{\dot{q}_{i}} = 2T $ is twice the system's kinetic energy and substituting $ L = T- V $. 
	
	To show the Hamiltonian is conserved when $ L = L(q_i, \dot{q}_i) $  and  $\pdv{L}{t} = 0 $ we calculate
	\begin{equation*}
		\dv{H}{t} = \dv{}{t}\left[\dot{q}_i \pdv{L}{\dot{q}_i} - L(q_i, \dot{q}_i) \right] = \ddot{q}_{i} \pdv{L}{\dot{q}_i}  + \dot{q}_i\dv{}{t}\left( \pdv{L}{\dot{q}_i}\right) - \pdv{L}{q_{i}}\dot{q}_{i} - \pdv{L}{\dot{q}_{i}}\ddot{q}_{i}
	\end{equation*}
	Because $ \dv{}{t}\left( \pdv{L}{\dot{q}_i}\right) = \pdv{L}{q_i} $ wherever $ q_{i} $ satisfy the Lagrange equations we have
	\begin{equation*}
		\dv{H}{t} = \ddot{q}_{i} \pdv{L}{\dot{q}_i} - \pdv{L}{\dot{q}_{i}}\ddot{q}_{i} + \dot{q}_i\left(\pdv{L}{q_{i}}\right) - \pdv{L}{q_{i}}\dot{q}_{i} = 0
	\end{equation*}	
	
	\textbf{Second Example:} If $ \pdv{L}{q_i} = 0 $ for some $ q_i $, then the quantity
	\begin{equation*}
		p_i \equiv \pdv{L}{\dot{q}_i}
	\end{equation*}
	is a constant of motion. The proof is a straightforward application of the Lagrange equations $ \dv{}{t} \pdv{L}{\dot{q}_i} = \pdv{L}{q_i} $ and the condition $ \pdv{L}{q_i} = 0 $:
	\begin{equation*}
		\dv{p_i}{t} \equiv \dv{}{t} \left(\pdv{L}{\dot{q}_i}\right) = \pdv{L}{q_i} = 0 
	\end{equation*}
	The quantity $ p_{i} $ is called the \textit{generalized momentum} corresponding to the generalized coordinate $ q_{i} $. In fact, we can re-write the Lagrange equations in the form
	\begin{equation*}
		\dot{p}_{i} = \pdv{L}{q_{i}}
	\end{equation*}
	The generalized momenta of Cartesian coordinates (e.g. $ x, y, z $) agree with the Newtonian momentum $ \bm{p} = m \bdot{r} $ but that is not the case for other types of generalized coordinates (e.g. angles or polar coordinates). 
	
	Generalized momenta play an important role in Hamiltonian dynamics, discussed in Section \ref{sec:hamilton}.
	 
\end{itemize}

\subsubsection{Symmetries of the Lagrangian} \label{subsubsec:symmetries}
We'll need to define the concept of a symmetry before stating Noether's theorem.
\begin{itemize}
	\item Consider a one-parameter family of maps of the form
	\begin{equation*}
		q_i(t) \to Q_i(s, t) \eqtext{such that} Q_i(0, t) = q_i(t)
	\end{equation*}
	parameterized by $ s \in \R $.	Such a map is called a \textit{continuous symmetry of the Lagrangian} $ L = L(q_i, \dot{q}_i, t) $ if 
	\begin{equation*}
		\pdv{}{s} L\left (Q_i(s, t), \dot{Q}_i(s, t), t\right ) = 0 \qquad \text{for all } s \in \R
	\end{equation*}
	
	\item That probably sounds abstract. Basically, we want to show that the Lagrangian for the coordinates $ q_{i} $ and $ Q_{i} $ is the same, i.e. $ L(q_i, \dot{q}_i, t) = L(Q_i, \dot{Q}_i, t) $. 
	
	As an example we'll discuss symmetry of translation: the Lagrangian is the same under a translation of spatial coordinates. We write the map as 
	\begin{equation*}
		\bm{r}_{i} \to \bm{r}_{i} + s \uvec{n}
	\end{equation*}
	for some unit vector $ \uvec{n} $ and scalar parameter $ s $; it is just a translation of the origin by $ s \uvec{n} $. In the language of $ q_{i} $ and $ Q_{i} $, we have
	\begin{align*}
		&q_{i} \leftrightarrow \bm{r}_{i} \eqtext{and} Q_{i} \leftrightarrow \bm{r}_{i} + s\uvec{n}\\
		&\dot{q}_{i} \leftrightarrow \bdot{r}_{i} \eqtext{and} \dot{Q}_{i} \leftrightarrow \bdot{r}_{i}
	\end{align*}
	If the Lagrangian $ L(q_{i}, \dot{q}_{i}, t) $ is
	\begin{equation*}
		L(q_{i}, \dot{q}_{i}, t) = \frac{1}{2}\sum_{i}m_{i} \bdot{r}_{i}^{2} - V(\abs{\bm{r}_{i} - \bm{r}_{j}})
	\end{equation*}
	then the Lagrangian $ L\big (Q_i(s, t), \dot{Q}_i(s, t), t\big ) \leftrightarrow L(\bm{r}_{i} + s\uvec{n}, \bdot{r}_{i}, t) $ would be
	\begin{align*}
	L\big (Q_i(s, t), \dot{Q}_i(s, t), t\big ) &=\frac{1}{2}\sum_{i}m_{i} \bdot{r}_{i}^{2} - V\big(\abs{(\bm{r}_{i} + s\uvec{n}) - (\bm{r}_{j} + s\uvec{n})}\big ) \\
	&=\frac{1}{2}\sum_{i}m_{i} \bdot{r}_{i}^{2} - V(\abs{\bm{r}_{i} - \bm{r}_{j}})
	\end{align*}
	It follows immediately that 
	\begin{equation*}
	\pdv{}{s}L\big (Q_i(s, t), \dot{Q}_i(s, t), t\big ) = 0 \eqtext{and}  L\big (Q_i(s, t), \dot{Q}_i(s, t), t\big ) = L(q_{i}, \dot{q}_{i}, t)
	\end{equation*}
	The first equation is the formal definition that our space translation map $ \bm{r}_{i} \to \bm{r}_{i} + s \uvec{n} $ is a symmetry of the Lagrangian, while the second equation gives a more intuitive reason why: the translated and untranslated Lagrangians are the same!
\end{itemize}

\subsubsection{Statement of Noether's Theorem}	
\begin{itemize}
	\item  Here it is:
	\begin{quote}
		For every continuous symmetry of the Lagrangian, there exists a corresponding constant of motion $ \displaystyle{\pdv{L}{\dot{q}_i} \pdv{Q_i}{s} \bigg |_{s=0}} $
	\end{quote}
	\begin{itemize}
		\item \textbf{Proof:} Applying the chain rule to $ L\left (Q_i(s, t), \dot{Q}_i(s, t), t\right ) $ gives
		\begin{equation*}
			\pdv{L}{s} = \pdv{L}{Q_{i}} \pdv{Q_{i}}{s} + \pdv{L}{\dot{Q}_{i}} \pdv{\dot{Q}_{i}}{s}
		\end{equation*}
		By definition of a continuous symmetry $ \pdv{L}{s} = 0 $ for all $ s $. Choosing $ s = 0 $ and applying $ \eval{Q_{i}}_{s=0} = q_{i} $ to $ \pdv{L}{s} $ we have:
		\begin{equation*}
			0 \equiv \eval{\pdv{L}{s}}_{s=0} = \eval{\pdv{L}{q_{i}} \pdv{Q_{i}}{s}}_{s=0} + \eval{\pdv{L}{\dot{q}_{i}} \pdv{\dot{Q}_{i}}{s}}_{s=0}
		\end{equation*}
		
		\item Next, we'll need the intermediate result $ \eval{\pdv{\dot{Q}_{i}}{s}}_{s=0} = \eval{\dv{}{t}\pdv{Q_{i}}{s}}_{s=0} $. The result might already be intuitive; feel free to skip to the next bullet point. The key is the simplifications arising from $ s =0 $. Differentiating $ Q_{i} = Q_{i}(s, t) $ gives
		\begin{equation*}
			\dot{Q}\big|_{s=0} = \eval{\dv{Q_{i}}{t}}_{s=0} = \eval{\pdv{Q_{i}}{s}\dot{s}}_{s=0} + \eval{\pdv{Q_{i}}{t}}_{s=0} = 0 + \eval{\pdv{Q_{i}}{t}}_{s=0}
		\end{equation*}
		Differentiating $ \dot{Q}_{i} $ with respect to $ s $ then gives the desired result
		\begin{equation*}
			\eval{\pdv{\dot{Q}_{i}}{s}}_{s=0} = \eval{\pdv{Q_{i}}{s}{t}}_{s=0} = \eval{\pdv{}{t}\pdv{Q_{i}}{s}}_{s=0} = \eval{\dv{}{t}\pdv{Q_{i}}{s}}_{s=0}
		\end{equation*}
		where we could replace $ \pdv{}{t} \to \dv{}{t}$ in the last equality for the special case $ s = 0 $.
			
		\item Back to the main proof, where we left off with 
		\begin{equation*}
			0 \equiv \eval{\pdv{L}{s}}_{s=0} = \eval{\pdv{L}{q_{i}} \pdv{Q_{i}}{s}}_{s=0} + \eval{\pdv{L}{\dot{q}_{i}} \pdv{\dot{Q}_{i}}{s}}_{s=0}
		\end{equation*}		
		Substituting $ \pdv{L}{q_{i}} = \dv{}{t}\pdv{L}{\dot{q}_{i}}$ (the Lagrange equations), using $ \eval{\pdv{\dot{Q}_{i}}{s}}_{s=0} = \eval{\dv{}{t}\pdv{Q_{i}}{s}}_{s=0} $ and recognizing a reverse product rule gives
		\begin{equation*}
			0 \equiv \eval{\dv{}{t}\left(\pdv{L}{\dot{q}_{i}}\right) \pdv{Q_{i}}{s}}_{s=0} + \eval{\pdv{L}{\dot{q}_{i}}  \dv{}{t}\left(\pdv{Q_{i}}{s}\right)}_{s=0} =\dv{}{t} \left[\pdv{L}{\dot{q}_{i}}\pdv{Q_{i}}{s} \right]_{s=0}
		\end{equation*}
		The result $ \dv{}{t} \left[\pdv{L}{\dot{q}_{i}}\pdv{Q_{i}}{s} \right]_{s=0} = 0 $ proves that $ \pdv{L}{\dot{q}_{i}}\pdv{Q_{i}}{s} $ evaluated at $ s=0 $ is indeed a constant of motion.
	\end{itemize}

\end{itemize}

\subsubsection{Examples with Noether's Theorem}

\textbf{Linear Momentum and the Homogeneity of Space}

\smallskip 
Note that we'll briefly return to vector notation: it's easier for these examples.
\begin{itemize}
	\item  Consider an closed system of $ N $ particles with masses $ m_1, \ldots, m_N$ and position vectors $ \bm{r}_1, \ldots, \bm{r}_{N} $. The system's Lagrangian is
	\begin{equation*}
		L = \frac{1}{2}\sum_{i}m_{i} \bdot{r}_{i}^{2} - V(\abs{\bm{r}_{i} - \bm{r}_{j}})
	\end{equation*}
	
	\item We mentioned in Subsection \ref{subsubsec:symmetries} that the symmetry of space translation is written
	\begin{equation*}
		\bm{r}_{i} \to \bm{r}_{i} + s \uvec{n}
	\end{equation*}
	which basically means shifting origin from $ \bm{0} $ to $ s \uvec{n} $. We showed in Subsection \ref{subsubsec:symmetries} that $ \bm{r}_{i} \to \bm{r}_{i} + s \uvec{n} $ is a valid continuous symmetry of the Lagrangian $ L $ since
	\begin{equation*}
		\pdv{}{s}	L(\bm{r}_{i} + s \uvec{n}, \bdot{r}_{i}, t)  = 0 \eqtext{and} L(\bm{r}_{i}, \bdot{r}_{i}, t) = L(\bm{r}_{i} + s \uvec{n}, \bdot{r}_{i}, t)
	\end{equation*}	
	This is a formal way of saying that space is homogeneous and a translation of the system by sn does nothing to the equations of motion. 
	
	\item Applying Noether's theorem to the symmetry $ \bm{r}_{i} \to \bm{r}_{i} + s \uvec{n} $ tells us that
	\begin{equation*}
		\eval{\pdv{L}{\dot{q}_{i}} \pdv{Q_{i}}{s}}_{s=0} = \sum_{i}^{N} \pdv{L}{\bdot{r}_{i}} \cdot \uvec{n} =  \sum_{i}^{N} \bm{p}_{i} \cdot \uvec{n} 
	\end{equation*}
	is a constant of motion. The quantity $ \sum_{i} \bm{p}_{i} \cdot \uvec{n}  $ is the system's total linear momentum in the direction of the vector $ \uvec{n} $. But since the choice of $ \uvec{n} $ is arbitrary, $ \sum_{i} \bm{p}_{i} \cdot \uvec{n} $ for all $ \uvec{n} $, meaning the system's total linear momentum $ \sum_{i} \bm{p}_{i}$ is conserved. 
	
	This is a profound result. Noether's theorem has shown us that homogeneity of space and the translational symmetry of the Lagrangian are responsible for conservation of linear momentum.
	
	\item Here is an intuitive and wonderfully informal explanation \`{a} la Tong: By homogeneity of space, one point in space is just as good as any other. Because one point is much the same as the next, why would a system of particles speed up (i.e. change it's linear momentum) to get ``there'' when ``here'' is just as good? This manifests itself as conservation of linear momentum.
		
\end{itemize}

\textbf{Angular Momentum and the Isotropy of Space}
Isotropy of space is a fancy way of saying that space has the same properties in all directions. This manifests itself as invariance of space under rotations. But we'll have to be a bit more formal.
\begin{itemize}

	\item Sticking with the closed system of $ N $ particles, if we rotate our system about some axis $ \uvec{n} $, isotropy of space implies that all particles $ \bm{r}_{i} \to \bm{r}_{i}' $ are rotated by the same amount. We can write the rotational mapping as an infinitesimal rotation
	\begin{equation*}
		\bm{r}_{i} \to \bm{r}_{i} + \delta \theta \uvec{n} \cross \bm{r}_{i}
	\end{equation*}
	parameterized by the infinitesimal angle $ \delta \theta $. 
	
	\textit{Aside:} We're working with infinitesimal rotations, which can be written in the form $ \bm{r} \to \bm{r} + \delta \bm{r} = \bm{r} +  \delta \theta \uvec{n} \cross \bm{r} $ (instead of using a $ 3 \cross 3 $ rotation matrix). This makes the math easier. The justification is that we can reconstruct a finite rotation as a series of many infinitesimal rotations.
	
	\item If the Lagrangian is invariant under the rotational mapping, the conserved quantity is
	\begin{align*}
		&\eval{\pdv{L}{\dot{q}_{i}} \pdv{}{\delta \theta}[\bm{r}_{i} + \delta \theta \uvec{n} \cross \bm{r}_{i}]}_{\delta \theta=0} = \sum_{i}^{N} \pdv{L}{\bdot{r}_{i}} \cdot (\uvec{n} \cross \bm{r}_{i}) =  \sum_{i}^{N} \bm{p}_{i} \cdot (\uvec{n} \cross \bm{r}_{i})\\
		&{}\qquad=  \sum_{i}^{N} \uvec{n} \cdot ( \bm{r}_{i} \cross \bm{p}_{i}) =  \uvec{n} \cdot \sum_{i}^{N}  \bm{L}_{i} = \uvec{n} \cdot \bm{L}
	\end{align*}
	which we recognize as the total linear momentum in the direction of $ \uvec{n} $. The conclusion is the same as with linear momentum $ \bm{p} $: since $ \uvec{n} \cdot \bm{L} $ is conserved and $ \uvec{n} $ is arbitrary, the system's total linear momentum $ \bm{L} $ is conserved.
	
\end{itemize}

\textbf{Energy and the Homogeneity of Time}
\begin{itemize}
	\item Homogeneity of time is a statement that the laws of physics don't change with time; they hold just as well today as they did yesterday. We write the corresponding symmetry as 
	\begin{equation*}
		t \to t + s
	\end{equation*}
	which is just a shifting of time by the parameter $ s $. 
	
	\item If $ L $ is invariant under a time translation it cannot have explicit dependence on time, meaning
	\begin{equation*}
		L = L(q_{i}, \dot{q}_{i}) \eqtext{and} \pdv{L}{t} = 0
	\end{equation*}
	But we have already shown in Subsection \ref{sssec:consts_motion} that $ \pdv{L}{t} = 0 $ implies the Hamiltonian 
	\begin{equation*}
		H = \pdv{L}{\dot{q}_{i}}\dot{q}_{i} - L
	\end{equation*}
	is conserved. We also showed that $ H = T + V$ is the system's total energy, so homogeneity of time leads us to conservation of energy. 
	
	\item In fact, we have kind of cheated here. A derivation of energy conservation directly from Noether's theorem requires a more general statement of the theorem than given in this text. The better version is stated in terms of perturbations of the generalized coordinates and time. It's actually not too bad. I might add it later.
	
\end{itemize}


\subsection{Small Oscillations and Stability}
Let's say our system of $ N $ particles is resting in a state of equilibrium. Then we displace it ever so slightly. What happens? The answer lies in the study of small oscillations, which deals with small-displacement oscillations of a system of $ N $ particles about the equilibrium position. Happily, the dynamics is described by a simple and familiar system: the harmonic oscillator. 
	
In fact, the motion of an $ N $ particle system near equilibrium can be modeled by a set of $ N $ \textit{uncoupled} (i.e. independent) simple harmonic oscillators, each vibrating at a different frequency. More to come.
\subsubsection{One Dimensional Example}
\begin{itemize}

	\item Let's start small, with a single particle and one degree of freedom $ q $. In both Newtonian and Lagrangian mechanics, the motion is governed by a second-order differential equation with the general form
	\begin{equation*}
		\ddot{q} = f(q)
	\end{equation*}
	for some (generally) non-linear function $ f(q) $.
	
	\item At an equilibrium point $ q = q_{0} $ the particle's acceleration $ \ddot{q} $ is zero, so the equation of motion must satisfy $ f(q_{0}) = 0$ at $ q_{0} $. 
	
	If we start at rest at equilibrium with the initial conditions 
	\begin{equation*}
		q = q_{0} \eqtext{and} \dot{q} = 0
	\end{equation*}
	the system will remain in equilibrium for all time (formally, solving the equation of motion gives $ q(t) = q_{0} $).
	
	\item But what happens if we start ever so slightly away from $ q_{0} $? Allowing for time-dependence, we write
	\begin{equation*}
		q(t) = q_0 + \eta(t)
	\end{equation*}
	where $ \eta(t) $ are small displacements about equilibrium $ q_{0} $. 
	
	A first-order Taylor eqpansion of $ \ddot{q} = f(q(t)) $ gives 
	\begin{equation*}
		 \ddot{q}(t) = f( q_0 + \eta(t)) \approx f(q_{0}) + f'(q_0) \eta(t) = f'(q_{0})\eta(t)
	\end{equation*}
	where we've used the equilibrium requirement $  f(q_{0}) = 0 $. Since $ \ddot{q} = \ddot{\eta} $, we have:
	\begin{equation*}
		\ddot{\eta} (t) = f'(q_{0})\eta(t)
	\end{equation*}
	
	\item There are two possible outcomes for what happens neqt, depending on the sign of $ f'(q_{0}) $.
	\begin{enumerate}
		\item If $ f'(q_0) < 0$, the acceleration $ \ddot{\eta} $ points towards $ q_0 $, so $ q_0 $ is a position of stable equilibrium. The solution is sinusoidal oscillation about $ q_0 $:
		\begin{equation*}
			 \eta(t) = \eta_0 \cos (\omega (t - t_0) ) \qquad \text{where} \quad \omega^2 = - f'(q_0)
		\end{equation*}
		The system undergoes stable harmonic oscillations about $ q_{0} $ at frequency $ \omega $.
		
		\item If $ f'(q_0) > 0$, the acceleration $ \ddot{\eta} $ points away from $ q_0 $, so $ q_0 $ is a position of unstable equilibrium. The solution is exponential:
		\begin{equation*}
			\eta(t) = A e^{\lambda t} +  B e^{- \lambda t}  \qquad \text{where} \quad  \lambda = f'(q_0)
		\end{equation*}
		for general initial conditions (besides the very special case $ A = 0 $) $ \eta $ grows rapidly and the first-order Taylor approximation breaks down. The system is said to be \textit{linearly unstable} at $ q_{0} $.
	\end{enumerate}

\end{itemize}

\subsubsection{$ N $ Degrees of Freedom}
\begin{itemize}
	\item We now generalize to a system with $ N $ degrees of freedom.  Our beginning steps are analogous to the one-dimensional case; the equations of motion are
	\begin{equation*}
		\ddot{q}_i = f_i(q_1, \dots q_N), \qquad i = 1, \dots, n
	\end{equation*}
	where we've defined the vector of coordinates $ \bm{q} = (q_{1}, \ldots, q_{N}) $. An equilibrium position $ \bm{q}^{0} =  (q_1^{0}, \dots q_N^{0})$ satisfies
	\begin{equation*}
		\ddot{q}_{i} = 0 \eqtext{and} f_{i}(\bm{q}^{0}) \equiv f_i(q_1^{0}, \ldots, q_n^{0}) = 0 \qquad \quad \text{for all } i = 1, \dots, n
	\end{equation*}
	
	\item Small displacements from the equilibrium point are written
	\begin{equation*}
		q_i(t) = q_i^{0} + \eta_i(t)
	\end{equation*}
	and a first-order Taylor expansion of $ \ddot{\eta}_{i} = \ddot{q}_i $ gives
	\begin{align*}
		\ddot{\eta}_i (t) &= f_i\left (q_1^{0} + \eta_1(t), \ldots, q_N^{0} + \eta_N(t)\right ) \\
		&\approx f_{i}\left (q_1^{0}, \ldots, q_N^{0}\right ) + \sum_{j=1}^{N}\pdv{}{q_j} \left[f_{i}\left (q_1^{0}, \ldots, q_N^{0}\right )\right] \eta_{j} \\
		&= \sum_{j=1}^{N}\pdv{}{q_j} \left[f_{i}\left (q_1^{0}, \ldots, q_N^{0}\right )\right] \eta_{j} \qquad  \left(\text{since } f_{i}\left (q_1^{0}, \ldots, q_N^{0}\right )  \equiv 0\right)
	\end{align*}
	where the one-dimensional $ f'(x_{0})\eta $ is replaced with the total derivative $ \pdv{f_{i}}{q_{j}}\eta_{j} $ because $ f_{i} = f_{i}(q_{1}, \ldots, q_{N})$ is now a multi-variable function.
	
	\item Since were using multivariable calculus we'll switch to matrix form, which makes notation much cleaner. We introduce a vector of displacement $ \bm{\eta} \in \R^{N}$ and the $ (N \cross N) $ matrix $\mat{F}$ given by
	\begin{equation*}
		\bm{\eta} =
		\begin{bmatrix}
			 \eta_1\\
			 \vdots\\
			 \eta_n
		\end{bmatrix}
		\eqtext{and}
		\mathbf{F} =
		\begin{bmatrix}
			\pdv{f_1}{q_1} & \cdots & \pdv{f_1}{q_N}\\
			\vdots & \ddots & \vdots\\
			\pdv{f_N}{q_1} & \cdots & \pdv{f_N}{q_N}\\
		\end{bmatrix}_{q_i = q_{i}^{0}}
	\end{equation*}
	where $ \mat{F} $ is the matrix of partial derivatives \textit{evaluated at equilibrium} $ q_{i} = q_{i}^{0} $. The system's equation of motion near equilibrium then reads
	\begin{equation*}
		\ddot{\bm{\eta}} = \mathbf{F} \bm{\eta}
	\end{equation*}

	\item We have reduced the dynamics of the system to an eigenvalue problem. To finish our solution we must $ \mathbf{F} $'s eigenvectors and eigenvalues. 
	
	But first, a necessary bit of linear algebra theory:
	\begin{itemize}
		\item 	We cannot assume a priori that $ \mat{F} $ has a complete set of orthogonal eigenvectors with real eigenvalues. It will turn out, however, that any matrix $ \mat{F} $ derived from a physical Lagrangian system has all real eigenvalues. We'll prove this in a few paragraphs; for now we'll assume $ \mat{F} $ has real eigenvalues.
		
		\item In general, any matrix, including e.g. $ \mathbf{F} $, has different right and left eigenvectors $ \bm{\mu}_{a} $ and $ \bm{\zeta}_{a} $ satisfying
		\begin{equation*}
			\mathbf{F} \bm{\mu}_{a} = \lambda_a^2 \bm{\mu}_{a}  \qquad  \bm{\zeta}_{a}^{T} \mathbf{F} = \lambda_{a}^{2} \bm{\zeta}_{a}^{T}
		\end{equation*}
		where $ a = 1, \dots, N $ and \textit{there is no implied sum over $ a $}. The left and right eigenvectors are orthonormal and satisfy $ \bm{\mu}_{a} \cdot \bm{\zeta}_{b} = \delta_{ab} $. 
		
		Note that even though the eigenvectors differ, the eigenvalues $ \lambda_{a}^{2} $ are the same for $ a = 1, \ldots, N $.
		
		\item Although the eigenvalues $ \lambda_{a}^{2} $ are real for any physical system of interest, they are not always positive, allowing for the possibility of complex square roots $ \sqrt{\lambda_{a}^{2}} = \pm \lambda_{a} \in \mathbb{C} $. That's okay; we'll see complex $  \lambda_{a}  $ correspond to oscillation.

	\end{itemize}

	\item Back to small oscillations, which we've reduced to the eigenvalue problem $ \ddot{\bm{\eta}} = \mathbf{F} \bm{\eta} $. The most general solution to this equation is
	\begin{equation*}
		\bm{\eta}(t) = \sum_{a}^{N} \bm{\mu}_{a} \left(A_a e^{\lambda_a t} + B_a e^{ -\lambda_a t} \right)
	\end{equation*}
	where $ \bm{\mu}_{a} $ are $ \mat{F} $'s (left) eigenvectors, $ \lambda_{a} $  are $ \mat{F} $'s eigenvalues, and $ A_a $ and $ B_a $ are integration constants determined by the initial conditions. 
	
	We have two possible behaviors for each $ a $, depending on the sign on the eigenvalue $ \lambda_{a}^{2} $
	\begin{enumerate}
		\item If $ \lambda_a^2 < 0 $ then $ \pm \lambda_a \in \mathbb{C} $ is complex-valued and we write 
		\begin{equation*}
			\lambda_a = i \omega_a
		\end{equation*}
		for some real number $ \omega_a \in \R $. This represents oscillation with the eigenfrequency $ \omega_a $ about the equilibrium point $ q_{a}^{N} $. The system is stable if displaced in the corresponding direction $ \bm{\eta} = \bm{\mu}_a $.
		
		\item If $ \lambda_a^2 > 0 $ then $ \pm \lambda_a \in \R $ is real-valued (corresponding to an exponential solution $ \eta_{a}(t) = A_{a} e^{\lambda_{a} t} +  B_{a} e^{- \lambda_{a} t} $)  and the system has a linear instability if displaced in the corresponding direction $ \bm{\eta} = \bm{\mu}_a $.
	\end{enumerate}
	
	\item The eigenvectors $ \bm{\mu}_{a} $ are called \textit{normal modes} and the associated value $ \omega_{a} $ is called the \textit{eigenfrequency} or \textit{normal frequency}. The equilibrium point $ \bm{q}^{0} = (q_{1}^{0}, \ldots, q_{N}^{0}) $ is stable only if $ \lambda_{a}^{2} < 0 $ for all $ i = 1, \dots, n $, in which case the system oscillates about the equilibrium point as a linear superposition of the normal modes, each at the corresponding eigenfrequency.
	
	In real form, the solution can be written
	\begin{equation*}
		\bm{\eta}(t) = \sum_{a; \lambda_{a}^{2} > 0} \bm{\mu}_{a} \left[A_a e^{\lambda_a t} + B_a e^{ -\lambda_a t}\right] + \sum_{a; \lambda_{a}^{2} < 0}  A_a \bm{\mu}_{a} \cos (\omega_a (t - t_a))
	\end{equation*}
	where $ A_a, B_a $ and $ t_{a} $ are $ 2n $ integration constants determined by the initial conditions; the $ t_{a} $ replace the $ B_{a} $ for the oscillatory modes with $ \lambda_{a}^{2} < 0 $.
\end{itemize}
\textbf{Proof: F's Eigenvectors are Real}
\smallskip 

We want to show $ \mat{F} $'s eigenvalues are real as long as $ \mat{F} $ is derived from a physical Lagrangian system (i.e. something we'd actually see in nature).
\begin{itemize}
	\item Consider a general Lagrangian of the form
	\begin{equation*}
		L = \frac{1}{2}\sum_{i, j} \mathrm{T}_{ij}(\bm{q}) \dot{q}_i \dot{q}_j - V(\bm{q})
	\end{equation*}
	where $ \mat{T}: \R^{N} \to \R^{N \cross N} $ is matrix encoding the coefficients of the kinetic energy and $ \bm{q} \in \R^{N} $ is a vector of coordinates. We'll assume $ \mat{T} $ is invertible and positive definite for all $ \bm{q} $. Finally, we'll need the potential energy matrix $ \mat{V}: \R^{N} \to \R^{N \cross N} $
	\begin{equation*}
		\mat{V}(\bm{q}) =
		\begin{bmatrix}
			\pdv{V}{q_1}{q_{1}} & \cdots & \pdv{V}{q_{1}}{q_N}\\
			\vdots & \ddots & \vdots\\
			\pdv{V}{q_1}{q_{N}} & \cdots & \pdv{V}{q_N}{q_{N}}\\
		\end{bmatrix}
	\end{equation*}
	Both $ \mat{T} $ and $ \mat{V} $ come out real-valued and symmetric by construction.
	
	\item Expanding about the equilibrium point $ \bm{q}^{0} $ to linear order in displacement $ \bm{\eta} $ gives
	\begin{equation*}
		\mat{T}(\bm{q}^{0}) \bddot{\eta} = -\mat{V}(\bm{q}^{0}) \bm{\eta} \eqtext{or} \mathrm{T}_{ij}(\bm{q}^{0}) \ddot{\eta}_{j} = - \mathrm{V}_{ij}(\bm{q}^{0}) \eta_{j} \quad \text{for } i = 1, \ldots, N
	\end{equation*}
	This might look frightening at first, but it is really just a set of equations of motion for the displacements $ \bddot{\eta}(t) $.
	
	\item We'll always be working with $ \mat{T} $ and $ \mat{V} $ evaluated at equilibrium $ \bm{q}^{0} $, so let's define the shorthand
	\begin{equation*}
		\mat{T}^{0} = \mat{T}(\bm{q}^{0}) \eqtext{and} \mat{V}^{0} = \mat{V}(\bm{q}^{0})
	\end{equation*}
	Rearranging our result to get $ \bddot{\eta} = - \left(\mat{T}^{0}\right)^{-1}\mat{V}^{0} \bm{\eta} $ and comparing to the equation of motion $ \bddot{\eta} = \mat{F} \bm{\eta} $, we see
	\begin{equation*}
		\mat{F} = - \left (\mat{T}^{0}\right )^{-1} \mat{V}^{0}
	\end{equation*}
	
	\item While $ \mat{T}^{0} $ and $ \mat{V}^{0} $ are both symmetric, they are not necessarily simultaneously diagonalizable (this occurs only if $ \mat{T}^{0} $ is a scalar multiple of the identity matrix $ \mat{I} $), which means that $ \mat{F} $ is not symmetric in general, as mentioned in the earlier interlude on linear algebra theory.
	
	However, we can show $ \bm{F} $ has real eigenvalues. Since $ \mat{F} = - \left (\mat{T}^{0}\right )^{-1} \mat{V}^{0} $ we have
	\begin{equation*}
		\mat{F}\bm{u} = \lambda^{2} \bm{\mu} \implies \mat{V}^{0}\bm{\mu} = - \lambda^{2} \mat{T}^{0} \bm{\mu}
	\end{equation*}
	Multiplying the equation by complex conjugate $ \bar{\bm{\mu}} $ gives
	\begin{equation*}
		\bar{\bm{\mu}} \mat{V}^{0}\bm{\mu} = - \lambda^{2} \bar{\bm{\mu}} \mat{T}^{0} \bm{\mu}
	\end{equation*}
	Since $ \mat{V}^{0}  $ and $ \mat{T}^{0} $ are both symmetric, the quantities $ \bar{\bm{\mu}} \mat{V}^{0}\bm{\mu} $ and $ \bar{\bm{\mu}} \mat{T}^{0} \bm{\mu} $ are both real, which suggests $ \lambda^{2} $ must be real too.
	
	In principle if both matrix quantities were zero the trivial equality $ 0 = 0 $ would hold even for $ \lambda^{2} \in \mathbb{C} $. But this can't happen, since we've assumed $ \mat{T} $ is positive definite we know $\bar{\bm{\mu}} \mat{T}^{0} \bm{\mu} > 0 $. It follows that $ \mat{F} $'s eigenvalues $ \lambda^{2} $ are indeed real.
\end{itemize}

\subsubsection{Direct Lagrangian Mechanics Approach}
\begin{itemize}
	\item We consider a system of $ N $ degrees of freedom with the coordinates $ \bm{q} = (q_{1}, \ldots, q_{N}) $ whose Lagrangian can be written
	\begin{equation*}
		L = T - V = \frac{1}{2} \sum_{i,j}\mathrm{T}_{ij}(\bm{q})\dot{q}_{i}\dot{q}_{j} - V
	\end{equation*}
	where $ \mat{T} $ is an $ (N \cross N) $ matrix encoding the coefficients of the kinetic energy. By construction $ \mat{T} $ turns out to be symmetric, so $ \mathrm{T}_{ij} = \mathrm{T}_{ji} $. We'll assume $ \pdv{L}{t} = 0$, so the total energy is conserved and can be written
	\begin{equation*}
		H = \pdv{L}{\dot{q}_{i}} \dot{q}_{i} - L = T + V
	\end{equation*}
	
	\item We assume there exists a stationary solution of Lagrange's equations at the equilibrium position 
	\begin{equation*}
		\bm{q}(t) = \bm{q}^{0} \eqtext{or, by components} q_{i}(t) = q_{i}^{0} \quad \text{for } i = 1, \ldots, N
	\end{equation*}
	At such a point the system is stationary so $ \dot{q}_{i} = 0 $ for all $ i $ and the kinetic energy term vanishes from the Lagrangian. We have
	\begin{equation*}
		L \big |_{\bm{q}^{0}} = - V \big |_{\bm{q}^{0}} \eqtext{and} \eval{\pdv{L}{q_{i}}}_{\bm{q}^{0}} =  - \eval{\pdv{V}{q_{i}}}_{\bm{q}^{0}} = 0
	\end{equation*}

	\item Stationary states $ \bm{q}^{0} $ can be absolutely stable, unstable, or metastable. 
	\begin{itemize}
		\item \textit{Absolutely stable states} satisfy
			\begin{equation*}
				V(\bm{q}^{0}) < \bm{V}(\bm{q}) \quad \text{for all } \bm{q} \neq \bm{q}^{0}
			\end{equation*}
			In other words, absolutely stable states are positions of absolute minimum of the potential energy $ V $. 
			
		\item \textit{Metastable states} must satisfy the same condition, but only in a neighborhood of $ \bm{q}^{0} $
		\begin{equation*}
			V(\bm{q}^{0}) < \bm{V}(\bm{q}) \quad \text{for } \bm{q} \text{ near } \bm{q}^{0}
		\end{equation*}
		In other words, metastable states are local minima of the potential energy $ V $. 
		
		\item \textit{Unstable states} satisfy $ V(\bm{q}^{0}) > \bm{V}(\bm{q}) $. Such states are maxima of the potential energy, and the force $ \bm{F} = - \grad V $ pushes particles away from the equilibrium position. Such states are not of interest in the study of small oscillations.
	\end{itemize}
	
	
	\item We'll deal with metastable and absolutely stable states. We denote small displacements from equilibrium by $ \bm{\eta}(t) $ and write
	\begin{equation*}
		\bm{q}(t) = \bm{q}^{0} + \bm{\eta}(t) \eqtext{or, by components} q_{i}(t) = q_{i}^{0}(t) + \eta_{i}(t)
	\end{equation*}
	We then assume $ V(\bm{q}) $ is an analytic function of the coordinates $ \bm{q} $, which is just a guarantee we can expand it into a Taylor series about equilibrium $ \bm{q}^{0} $. To second order in $ \bm{q} $ we have
	\begin{align*}
		V(\bm{q}) &\approx V(\bm{q}^{0}) + \eval{\pdv{V}{q_{i}}}_{\bm{q}^{0}} \eta_{i} + \frac{1}{2}\eval{\pdv{V}{q_{i}}{q_{j}}}_{\bm{q}^{0}}\eta_{i}\eta_{j}\\
		&=V(\bm{q}^{0}) + \frac{1}{2}\eval{\pdv{V}{q_{i}}{q_{j}}}_{\bm{q}^{0}}\eta_{i}\eta_{j}
	\end{align*}
	where the linear term vanishes by the equilibrium condition $\eval{\pdv{V}{q_{i}}}_{\bm{q}^{0}} = 0 $. The meta-stable equilibrium condition $ V(\bm{q}) > V(\bm{q}^{0}) $ then implies
	\begin{equation*}
		\frac{1}{2}\eval{\pdv{V}{q_{i}}{q_{j}}}_{\bm{q}^{0}}\eta_{i}\eta_{j} > 0 \iff \frac{1}{2} \mathrm{V}_{ij}\eta_{i}\eta_{j} > 0
	\end{equation*}
	where the second expression is written in terms of the matrix $ \mat{V} $ of potential energy second derivatives
	\begin{equation*}
		\mat{V} =
		\begin{bmatrix}
			\pdv{V}{q_1}{q_{1}} & \cdots & \pdv{V}{q_{1}}{q_N}\\
			\vdots & \ddots & \vdots\\
			\pdv{V}{q_1}{q_{N}} & \cdots & \pdv{V}{q_N}{q_{N}}\\
		\end{bmatrix}_{\bm{q} = \bm{q}^{0}}
	\end{equation*}
	By construction $ \mat{V} $ comes out to be symmetric and positive-definite, which will be important later on.
	
	\item We can then write the system's Lagrangian near equilibrium in the matrix notation
	\begin{equation*}
		L = \frac{1}{2} \mathrm{T}_{ij}\dot{\eta}_{i}\dot{\eta}_{j} - \frac{1}{2}\mathrm{V}_{ij}\eta_{i}\eta_{j} + V^{0}
	\end{equation*}
	where $ \mat{T} = \mat{T}\big |_{\bm{q}^{0}} $. Lagrange's equations for the displacements $ \eta_{i} $ are then written
	\begin{equation*}
		\mathrm{T}_{ij} \ddot{\eta}_{j} + \mathrm{V}_{ij} \eta_{j} = 0 \eqtext{or} \mat{T} \bddot{\eta} = \mat{V} \bm{\eta}
	\end{equation*}
	
	\item The basic solution of the equations of motion $ \mathrm{T}_{ij} \ddot{\eta}_{j} + \mathrm{V}_{ij} \eta_{j} = 0 $ are so called \textit{characteristic oscillations}, which are harmonic oscillations of the all the displacement components $ \eta_{i}(t) $ with the same frequency $ \omega $, represented by the ansatz
	\begin{equation*}
		\eta_{j}(t) = \alpha a_{j} e^{-i\omega t}
	\end{equation*}
	where $ \alpha $ describes the amplitude of the oscillations and the unit vector $ \bm{a} = (a_{1}, \ldots, a_{N}) $ encodes the direction of each displacement component $ \eta_{i} $. 
	
	To get a relationship between $ \omega^{2} $ and $ \bm{a} $, we calculate $ \ddot{\eta}_{j} = -\omega^{2}\alpha a_{j}e^{-\omega t}  $, plug this in to the equation of motion, cancel like terms and rearrange to get
	\begin{equation*}
		\mathrm{V}_{ij} a_{j} = \omega^{2}\mathrm{T}_{ij}a_{j} \eqtext{or} \mat{V} \bm{a} = \omega^{2} \mat{T} \bm{a} 
	\end{equation*}

	\item The result $ \mat{V} \bm{a} = \omega^{2} \mat{T} \bm{a}  $ is important: we have reduced the dynamics of small oscillations to a generalized eigenvalue problem involving the matrices $ \mat{T} $ and $ \mat{V} $. Because the matrices are symmetric, the eigenvalues $ \omega^{2} $ are all real and because $ \mat{T} $ is positive definite, we know the eigenvalues will be positive $ \omega^{2} > 0 $.
	

	Note, however, that this is in general \textit{not} a simple eigenvalue problem of the form $ \mat{A} \bm{x} = \omega^{2} \bm{x} $; there are two matrices involved!
	
	
\end{itemize}

\subsubsection{The Simplified Eigenvalue Problem}
\begin{itemize}
	\item Let's start on more familiar territory with the simple eigenvalue problem of the general form $  \mat{A} \bm{x} = \omega^{2} \bm{x}  $. This occurs if $ \mat{T} = T \mat{I} $, i.e. if $ \mat{T} $ is diagonal with identical scalar elements $ T $. In this case, the problem reduces to the familiar eigenvalue problem $ \mat{V} \bm{a} = \omega^{2} T \bm{a} $.
	
	\item Because $ \bm{V} $ is symmetric (and the $ \mat{a} $ are normalized by construction) the eigenvectors are orthogonal:
	\begin{equation*}
		\bm{a}_{i}^{T} \cdot \bm{a}_{j} = \delta_{ij}
	\end{equation*}
	We write the eigenvectors $ \bm{a}_{i} $ in the $ N \cross N $ matrix $ \mat{A} $ 
	\begin{equation*}
		\mat{A} = [\bm{a}_{1}, \ldots, \bm{a}_{N}] =
		\begin{bmatrix}
			a_{11} & \cdots & a_{1N}\\
			\vdots & \ddots & \vdots\\
			a_{N1} & \cdots & a_{NN}
		\end{bmatrix}
	\end{equation*}
	Because the $ \bm{a}_{i} $ are orthonormal (i.e. $ \bm{a}_{i} \cdot \bm{a}_{j} = \delta_{ij} $) we have
	\begin{equation*}
		\mat{A}^{T} \mat{A} = \mat{I} \implies \mat{A} = \mat{A}^{-1}
	\end{equation*}
	
	\item Some new notation coming fast: for $ \mat{V} $'s eigenvalues we'll write $ \omega^{2} \equiv \lambda $, so the eigenvalue problem reads 
	\begin{equation*}
		\mat{V} \bm{a} = \lambda \mat{T} \bm{a} = \lambda T \mat{I}
		\eqtext{or} (\mat{V} - \lambda T \mat{I}) \bm{a} = 0
	\end{equation*}
	(We're still assuming $ \mat{T} = T \mat{I} $). $ \mat{A} $'s eigenvalues are $ \lambda_{i}T $ for $ i = 1, \ldots, N $, which we'll write $ \tilde{\lambda}_{i} \equiv \lambda_{i}T $ for shorthand, so our problem now reads $ (\mat{V} - \tilde{\lambda}\mat{I}) \bm{a} = 0 $. 	Since we require $ \bm{a} \neq \bm{0} $, the equation is satisfied if $ \abs{\mat{V} - \lambda T \mat{I}} = 0 $.
	
	\item In terms of left and right eigenvectors, the eigenvalue problem is 
	\begin{equation*}
		(\mat{V} - \tilde{\lambda}_{i}\mat{I}) \bm{a}_{i} = 0 \eqtext{and} \bm{a}_{j}^{T}(\mat{V} - \tilde{\lambda}_{j}\mat{I}) = 0
	\end{equation*}
	We then combine these two equations into the matrix equation
	\begin{equation*}
		\mat{A}^{T} \mat{V} \mat{A} - \mat{A}^{T} \mat{A} \mat{\Lambda} = 0
	\end{equation*}
	where $ \mat{\Lambda} $ is a diagonal matrix whose diagonal elements are the eigenvalues $ \tilde{\lambda}_{i} $. Because the eigenvectors $ \bm{a}_{i} $ are orthonormal and $ \mat{A}^{T} \mat{A} = \mat{I} $, the matrix $ \mat{\Lambda} $ is also unitary.

	From the matrix equation $ \mat{A}^{T} \mat{V} \mat{A} = \mat{A}^{T} \mat{A} \mat{\Lambda}  $, we can interpret the eigenvector matrix $ \mat{A} $ as a transformation matrix that transforms $ \mat{V} $ into the diagonal form $ \mat{\Lambda} $, i.e.
	\begin{equation*}
		\mat{A}^{T} \mat{V} \mat{A} = \mat{A}^{-1} \mat{V} \mat{A} = \mat{A}^{-1} \mat{A} \mat{\Lambda}  = \mat{\Lambda}
	\end{equation*}
	where we've used $ \mat{V} \mat{A} = \mat{A} \mat{\Lambda}  $ and the orthogonality property $ \mat{A}^{T} = \mat{A}^{-1} $.
	
\end{itemize}

\subsubsection{Generalized Eigenvalue Problem}
\begin{itemize}
	\item On to the generalized eigenvalue problem with $ \mat{T} \neq T \mat{I} $
	\begin{equation*}
		\mat{V}\bm{a} = \omega^{2} \mat{T} \bm{a} = \lambda \mat{T} \bm{a}
	\end{equation*}
	where we'll continue with the notation $ \lambda \equiv \omega^{2} $ for the eigenvalues. Both $ \mat{V} $ and $ \mat{T} $ are real and symmetric, so the eigenvalues $ \lambda $ and eigenvectors $ \bm{a} $ are real. 
	
	\item As before, we write $ (\mat{V} - \lambda \mat{T}) \bm{a} = 0$ and require $ \abs{\mat{V} - \lambda \mat{T}} = 0 $, which disregards the trivial solution $ \bm{a} = 0$. 
	
	In terms of left and right eigenvectors, the eigenvalue problem reads
	\begin{equation*}
		\mat{V}\bm{a}_{i} = \lambda_{i} \mat{T} \bm{a}_{i} \eqtext{and} \mat{a}_{j}^{T}  \mat{V} = \lambda_{j} \mat{a}_{j}^{T} \mat{T} 
	\end{equation*}
	Next, we'll prove the eigenvectors satisfy a generalized orthogonality. Multiplying the first equation from the left by $ \bm{a}_{j}^{T} $ and the second equation from the right by $ \bm{a}_{i} $ gives
	\begin{equation*}
		\mat{a}_{j}^{T} \mat{V}\bm{a}_{i} = \lambda_{i} \mat{a}_{j}^{T}  \mat{T} \bm{a}_{i} \eqtext{and} \mat{a}_{j}^{T}  \mat{V}\bm{a}_{i} = \lambda_{j} \mat{a}_{j}^{T} \mat{T} \bm{a}_{i}
	\end{equation*}
	Subtracting the equations leads to $ (\lambda_{i} - \lambda_{j}) \mat{a}_{j}^{T} \mat{T} \bm{a}_{i} = 0 $, which implies 
	\begin{equation*}
		\mat{a}_{j}^{T} \mat{T} \bm{a}_{i} = 0  \qquad \text{for} \quad \lambda_{i} \neq \lambda_{j}
	\end{equation*}
	Even for degenerate eigenvalues $ \lambda_{i} = \lambda_{j}, i \neq j $, we can choose the eigenvectors so they satisfy the orthogonality relation.  More so, because $ \mat{T} $ is positive definite, its diagonal elements must be positive and nonzero. This allows us to chose the eigenvectors to satisfy the generalized normalization condition
	\begin{equation*}
		\bm{a}_{i}^{T} \mat{T} \bm{a}_{i} = 1
	\end{equation*}
	
	\item Together, the generalized orthogonality ($ \mat{a}_{j}^{T} \mat{T} \bm{a}_{i} = 0 $) and normalization ($ \bm{a}_{i}^{T} \mat{T} \bm{a}_{i} = 1 $) conditions mean that the eigenvector matrix $ \mat{A} $ transforms the kinetic energy matrix $ \mat{T} $ into the identity matrix
	\begin{equation*}
		\mat{A}^{T} \mat{T} \mat{A} = \mat{I}
	\end{equation*}
	Like for the simpler case, we can now write the eigenvalue problem as a matrix equation 
	\begin{equation*}
		\mat{V} \mat{A} = \mat{T} \mat{A} \mat{\Lambda}
	\end{equation*}
	where $ \mat{\Lambda} $ is a diagonal matrix whose elements are the eigenvalues $ \lambda_{i} $. 
	
	As before, we can view $ \mat{A} $ as a transformation matrix that transforms $ \mat{V} $ into the diagonal form $ \mat{\Lambda} $. Using $ \mat{V} \mat{A} = \mat{T} \mat{A} \mat{\Lambda} $ and $ \mat{A}^{T} \mat{T} \mat{A} = \mat{I} $ we have
	\begin{equation*}
		\mat{A}^{T} \mat{V} \mat{A} = \mat{A}^{T} \mat{T} \mat{A}\mat{\Lambda} = \mat{\Lambda}
	\end{equation*}
	In the general case, however, $ \mat{A} $ has the additional property of transforming $ \mat{T} $ into the identity matrix $ \mat{I} $.
	
\end{itemize}

\subsubsection{Normal Coordinates}
\begin{itemize}
	\item A few sections ago we derived the equations of motion governing small oscillations
	\begin{equation*}
		\mathrm{T}_{ij} \ddot{\eta}_{j} + \mathrm{V}_{ij} \eta_{j} = 0
	\end{equation*}
	and said the basic solutions were the characteristic oscillations
	\begin{equation*}
		\eta_{j}(t) = \alpha a_{j} e^{-i\omega t}
	\end{equation*}
	The general solution is a linear superposition of the characteristic oscillations. 
	
	\item The general solution is best written in terms of \textit{normal coordinates}, which replace the small displacements $ \eta_{i} $ of the original coordinates $ q_{i} $ with the amplitudes $ \alpha_{j} $ of the characteristic oscillations $ \bm{a}_{j} $. We write the transformation to the normal coordinates as
	\begin{equation*}
		\eta_{i}(t) = \alpha_{j}(t) a_{j_{i}} =  a_{j_{i}} \alpha_{j}(t)
	\end{equation*}
	where $ a_{j_{i}} $ is the $ i $-th component of the $ j $-th eigenvector $ \bm{a}_{j} $. Note also that $ a_{j_{i}} $ corresponds to the element $ \mathrm{A}_{ij} $ of the eigenvector matrix $ \mat{A} = [\bm{a}_{1}, \ldots, \bm{a}_{N}] $.
	
	We can thus write the transformation to normal coordinates in the matrix form
	\begin{equation*}
		\bm{\eta}(t) = \mat{A} \bm{\alpha}(t) \eqtext{or} \bm{\eta}^{T}(t) = \bm{\alpha}^{T}(t) \mat{A}^{T} 
	\end{equation*}
	
	\item The normal coordinates allow us to concisely write the system's Lagrangian
	\begin{equation*}
		L = \frac{1}{2} \left( \mathrm{T}_{ij}\dot{\eta}_{i}\dot{\eta}_{j} - \mathrm{V}_{ij}\eta_{i}\eta_{j} \right) + V^{0} =  \frac{1}{2}\left(\bdot{\eta}^{T} \mat{T} \bdot{\eta} - \bm{\eta}^{T} \mat{V} \bm{\eta}\right) + V^{0}
	\end{equation*}
	in terms of the eigenvalues $ \omega_{j}^{2} $. First, let's redefine the potential so $ V^{0} = 0$. Then, using $ \bm{\eta} = \mat{A} \bm{\alpha}  $ and the identities $ \mat{A}^{T} \mat{T} \mat{A} = \mat{I} $ and $  \mat{A}^{T} \mat{V} \mat{A} = \mat{\Lambda} = \operatorname{diag}(\omega_{j}^{2}) $ we have
	\begin{align*}
		L &= \frac{1}{2}\left(\bdot{\eta}^{T} \mat{T} \bdot{\eta} - \bm{\eta}^{T} \mat{V} \bm{\eta}\right) = \frac{1}{2} \left( \bdot{\alpha}^{T} \mat{A}^{T} \mat{T} \mat{A} \bdot{\alpha} - \bm{\alpha}^{T} \mat{A}^{T} \mat{V} \mat{A} \bm{\alpha} \right)\\
		&=\frac{1}{2}\left(\bdot{\alpha}^{T} \mat{I} \bdot{\alpha} - \bm{\alpha}^{T} \mat{\Lambda} \bm{\alpha}\right) =\frac{1}{2}\left(\bdot{\alpha}^{T} \bdot{\alpha} - \bm{\alpha}^{T} \mat{\Lambda} \bm{\alpha}\right)\\
		&=\frac{1}{2}\sum_{j}\left(\dot{\alpha}_{j}^{2} - \omega_{j}^{2} \alpha_{j}^{2} \right)
	\end{align*}
	
	\item The time dependence of each normal coordinate $ \alpha_{j} $ is the harmonic oscillation
	\begin{equation*}
		\alpha_{j}(t) = \alpha_{j_{0}} \cos(\omega_{j}t - \delta)
	\end{equation*}
	where the amplitude $ \alpha_{j_{0}} $ and phase $ \delta $ are integration constants determined by the initial conditions.
	
	The Lagrangian is thus a sum of $ j = 1, \ldots, N$ uncoupled harmonic oscillators $ \alpha_{j}(t) $, each vibrating at the frequency $ \omega_{j} $, where the amplitude of oscillation is the $ j $-th normal coordinate $ \alpha_{j} $. 
	

\end{itemize}

\subsection{A Concluding Example: A Particle in an Electromagnetic Field} \label{ssec:lag:em_lag}
\begin{itemize}
	\item This example is important because of the velocity-dependent nature of the electromagnetic interaction (i.e. the Lorentz force). So far, we've worked almost exclusively with velocity-independent forces in our discussion of Lagrangian mechanics. Now we'll see how the Lagrangian formalism handles a velocity-dependent force.
	
	\item We'll return to vector coordinates for this discussion. The electric field $ \bm{E} $ and magnetic field $ \bm{B} $ can be written in terms of a scalar potential $ \phi(\bm{r}, t) $ and a vector potential $ \bm{A}(\bm{r}, t) $, respectively
	\begin{equation*}
		 \bm{E} = -\grad{\phi} - \pdv{\bm{A}}{t} \eqtext{and} \bm{B} = \cross \bm{A} 
	\end{equation*} 
	The Lagrangian for a particle of charge $ e $ in an electromagnetic field is (currently without derivation)
	\begin{equation*}
		L = \frac{1}{2}m \bdot{r}^{2} - e(\phi - \bdot{r}\cdot \bm{A})
	\end{equation*}
	Note the Lagrangian splits into the usual kinetic energy term $ \frac{1}{2}m \bdot{r}^{2} $ and an additional term due to the EM interaction. The momentum $ \bm{p} $ conjugate to the coordinate $ \bm{r} $ is
	\begin{equation*}
		\bm{p} = \pdv{L}{\bdot{r}} = m \bdot{r} + e\bm{A}
	\end{equation*}
	Note that the momentum is not simply the Newtonian $ m \bdot{r} $, but is modified in the present of an EM field.
	
	\item With Lagrangian in hand, we can calculate Lagrange's equations
	\begin{equation*}
		\dv{}{t}\left(\pdv{L}{\bdot{r}}\right) - \pdv{L}{\bm{r}} = \dv{}{t}(m \bdot{r} + e\bm{A}) + e \grad{\phi} - e  \grad (\bdot{r}\cdot \bm{A})
	\end{equation*}
	In terms of components and the indices $ a, b \in \{1, 2, 3\} $ of the Cartesian components the equation of motion reads
	\begin{equation*}
		m\ddot{r}^{a} = -e\left(\pdv{\phi}{r^{a}} + \pdv{A_{a}}{t} \right) + e \left(\pdv{A_{b}}{r^{a}} - \pdv{A_{a}}{r^{b}} \right)\dot{r}^{b}
	\end{equation*}
	
	\item In terms of indices and components, the definitions of the $ \bm{E} $ and $ \bm{B} $ fields are
	\begin{equation*}
		E_{a} = -\pdv{\phi}{r^{a}} - \pdv{A_{a}}{t} \eqtext{and}  B_{a} = \epsilon_{cab}\pdv{A_{b}}{r^{a}} \iff \epsilon_{abc}B_{c} = \pdv{A_{b}}{r^{a}} - \pdv{A_{a}}{r^{b}}
	\end{equation*}
	But these expressions agree exactly with the terms in parentheses in the equation of motion! Substitution, the equation of motion becomes
	\begin{equation*}
		m\ddot{r}^{a} = e E_{a} + \epsilon_{abc} e \dot{r}^{b} B_{c} \eqtext{or} m \bddot{r} = e (\bm{E} + \bdot{r} \cross \bm{B})
	\end{equation*}
	which is the Lorentz force law!
	
\end{itemize}


\newpage
\section{Dynamics of Central Force Motion}
The section analyzes the motion of particles in a central force potential in three spatial dimensions. We will start with Newtonian mechanics and use some Lagrangian mechanics later on.

\subsection{The Central Force Problem}

\subsubsection{Two Body Problem}
The two body problem is the name given to solving the dynamics of two mutually interacting particles. It turns out we can reduce the two body problem into an equivalent one-body problem by using conserved quantities. Here's how it works:
\begin{itemize}
	\item First, let's define the actors involved. We consider two bodies of mass $ m_{1} $ and $ m_{2} $ whose position is given by the position vectors $ \bm{r}_{1} $ and $ \bm{r}_{2} $. We denote the total mass by $ M = m_{1} + m_{2} $ and define the relative separation as
	\begin{equation*}
		\bm{r} = \bm{r}_{1} - \bm{r}_{2}
	\end{equation*}
	Finally, we define the center of mass $ \bm{R} $ with the equation
	\begin{equation*}
		M\bm{R} = m_{1}\bm{r}_{1} + m_{2} \bm{r}_{2}
	\end{equation*}
	
	\item We begin simplifying the problem by writing
	\begin{equation*}
		\bm{r}_{1} = \bm{R} + \frac{m_{2}}{M}\bm{r} \eqtext{and} \bm{r}_{2} = \bm{R} - \frac{m_{1}}{M}\bm{r}
	\end{equation*}
	Under the assumption that the two bodies are isolated, there is no external force on the system, which means the center of mass travels with constant velocity, i.e. $ \bddot{R} = 0 $.
	
	\item Meanwhile, the relative motion of the two particles is governed by
	\begin{equation*}
		\bddot{r} = \bddot{r}_{1} - \bddot{r}_{2} = \frac{\bm{F}_{12}}{m_{1}} -  \frac{\bm{F}_{21}}{m_{2}} = \frac{m_{1} + m_{2}}{m_{1}m_{2}}
	\end{equation*}
	where $ \bm{F}_{12} $ and $ \bm{F}_{21} $ are the forces exerted by the second body on the first body and vice versa, respectively. The last equality uses Newton's third law, which tells us $ \bm{F}_{12} = - \bm{F}_{21} $. 
	
	\item It is customary (and efficient) to write the equation of motion for $ \bddot{r} $ in the condensed form
	\begin{equation*}
		\mu \bddot{r} = \bm{F}_{12}
	\end{equation*}
	where we have defined the \textit{reduced mass}
	\begin{equation*}
		\mu = \frac{m_{1}m_{2}}{m_{1} + m_{2}}
	\end{equation*}
	Keep in mind that when one of the particles is much more massive than the other, the reduced mass nearly equals the mass of the lighter particle (e.g. $ m_{2} \gg m_{1} \implies \mu \approx m_{1} $). Such situation come up often in practice (e.g. a satellite orbit an planet or an electron orbiting a hydrogen atom).
	
	\item The equation $ \mu = \frac{m_{1}m_{2}}{m_{1} + m_{2}} $ is a great result: we have encoded the dynamics of our two body system in a single vector $ \bm{r} $, effectively turning our two body problem into a one body problem (we could do this because the velocity of the center of mass is conserved).
	
	To proceed further, we have to make some assumptions about the nature of the interaction $ \bm{F}_{12} $. If $ \bm{F}_{12} $ is a \textit{central force}, meaning it depends only on the magnitude $ r = \abs{r} $ of the relative separation, we can make a great deal more progress in analyzing the two body problem. We will dedicate the rest of this section to analyzing central forces.
	

\end{itemize}

\subsubsection{Basics of the Central Force Problem}

\begin{itemize}
	\item We start with a single particle in a central force potential (a potential that depends only on the distance $ r = \abs{\bm{r}} $ from the origin.) The equation of motion for our one-particle system is
	\begin{equation*}
		m \ddot{\bm{r}} = - \grad V(r)
	\end{equation*}
	where $ V = V(r) $ is a central potential. Both the gravitational and electrostatic interactions have central potentials, so the results of this section have wide applicability in classical physics.
	
	\item The central problem is solved using angular momentum
	\begin{equation*}
		\bm{L} = \bm{r} \cross \bm{p} = m \bm{r} \cross \bdot{r}
	\end{equation*}
	Angular momentum is conserved in a central potential. The proof is straightforward; we just have to show $ \dv{\bm{L}}{t} = 0 $
	\begin{equation*}
		\dv{\bm{L}}{t} = m \bdot{r} \cross \bdot{r} + m \bm{r} \cross \bddot{r} = 0 - \bm{r} \cross \grad{V}(r) = 0
	\end{equation*}
	where the last equality holds because $ \bm{r} $ and $ \grad{V}(r) $ are parallel for a central potential.
	
	\item The conservation of angular momentum has far-reaching consequences for the central force problem. For one, it means all motion takes place in a plane. How to show this? We know $ \bm{L} $ is conserved, so its direction and magnitude are fixed and unchanging. By definition $ \bm{L} = \bm{r} \cross \bm{p}$ we know $ \bm{L} $ and position $ \bm{r} $ are perpendicular, so 
	\begin{equation*}
		\bm{L} \cdot \bm{r} = 0
	\end{equation*}
	and the position of the particle is always perpendicular to $ \bm{L} $. But because $ \bm{L} $ is \textit{fixed} and $ \bm{r} $ is always perpendicular to $ \bm{L} $, $ \bm{r} $ must lie in a \textit{plane} perpendicular to $ \bm{L} $.	By the same argument, starting with $ \bm{L} = m \bm{r} \cross \bdot{r} $, we have $ \bm{L} \cdot \bdot{r} $, so the particle's velocity also lies in the same plane perpendicular to $ \bm{L} $.
	
	For central forces, three dimensional dynamics is reduced to dynamics in a plane because of the conservation of $ \bm{L} $.
	
\end{itemize}

\subsubsection{Polar Coordinates and the Central Force Problem}
\begin{itemize}
	\item Because motion under central forces lies in a plane, the dynamics is best analyzed with polar coordinates. This section explains how we will set up our polar coordinate system.
	
	\item The system's conserved angular momentum $ \bm{L} $ provides a natural reference point, so we rotate our coordinate system so the angular momentum points in the positive $ z $ direction. The motion, which we have shows lies in the plane perpendicular to $ \bm{L} $, the occurs in our $ (x, y) $ plane. We define the usual polar coordinates
	\begin{equation*}
		x = r \cos \theta \eqtext{and} y = r \sin \theta 
	\end{equation*}
	
	\item  The next step is to express a particle's velocity and acceleration in polar coordinates. To do this, we introduce the two unit vectors $ \uvec{\theta} $
	
	$ \uvec{r} $ and $ \uvec{\theta} $; 
		
	they point in direction of increasing $ r $ and $ \theta $, respectively.
				
	\item This is best seen in a figure. In words, you can visualize $ \uvec{r} $ pointing from the particle's position away from the origin, parallel to the position vector $ \bm{r} $. $ \uvec{\theta} $ is perpendicular to $ \uvec{r} $ and points from the particle's position in the direction of increasing $ \theta $ in a counterclockwise sense. 
	
	In Cartesian form, the unit vectors can be written in terms of $ \theta $ as
	\begin{equation*}
		\uvec{r} = 
		\begin{bmatrix}
			\cos \theta\\
			\sin \theta
		\end{bmatrix} \eqtext{and}
		\uvec{\theta} = 
		\begin{bmatrix}
 			- \sin \theta\\
 			\cos \theta
 		\end{bmatrix} 
	\end{equation*}
	
	\item Notice that the basis $ \{\uvec{r}, \uvec{\theta} \} $ depends on the particle's coordinate $ \theta $. The change with respect to $ \theta $ is
	\begin{equation*}
		\dv{\uvec{r}}{\theta} = 
		\begin{bmatrix}
 			- \sin \theta\\
 			\cos \theta
 		\end{bmatrix} = \uvec{\theta} \eqtext{and}
 		\dv{\uvec{\theta}}{\theta} = - 
 		\begin{bmatrix}
			\cos \theta\\
			\sin \theta
		\end{bmatrix} = - \uvec{r}
	\end{equation*}
	
	\item The derivatives tell us that if the particle moves in such a way that $ \theta $ changes with time then the basis vectors $ \{\uvec{r}, \uvec{\theta} \} $ also change with time. What does this mean for $ \bm{r} $, $ \bdot{r} $ and $ \bddot{r} $? By construction of $ \uvec{r} $, the position vector is simply
	\begin{equation*}
		\bm{r} = r \uvec{r}
	\end{equation*}
	The velocity is found with the product rule for derivatives
	\begin{equation*}
		\bdot{r} = \dot{r}\uvec{r} + r \dv{\uvec{r}}{t}
	\end{equation*}
	This turns into a more useful expression with the chain rule $ \dv{\uvec{r}}{t} = \dv{\uvec{r}}{\theta} \dv{\theta}{t} $ and identity $ \dv{\uvec{r}}{\theta}  = \uvec{\theta} $. We get
	\begin{equation*}
		\bdot{r} = \dot{r}\uvec{r} + r\dot{\theta} \uvec{\theta} 
	\end{equation*}
	The second term $ r\dot{\theta} \uvec{\theta} $ comes from the rotation $ \dot{\theta} $ of the basis vectors and is a consequence of a non-inertial frame of reference. Notice that for a stationary system $ \dot{\theta} = 0 $ recovers the familiar expression $ \bdot{r} = \dot{r}\uvec{r} $.
	
	\item Next, acceleration. A time differentiation of $ \bdot{r} $ gives
	\begin{equation*}
		\bddot{r} = \ddot{r}\uvec{r} + \dot{r}\dv{\uvec{r}}{t}
		+ \dot{r}\dot{\theta} \uvec{\theta} + r\ddot{\theta} \uvec{\theta} + r\dot{\theta} \dv{\uvec{\theta} }{t}
	\end{equation*}
	Again, the chain rule and basic vector derivatives come in handy. Using the identities $ \dv{\uvec{r}}{t} = \dv{\uvec{r}}{\theta} \dv{\theta}{t} = \dot{\theta} \uvec{\theta}$ and $ \dv{\uvec{\theta}}{t} = \dv{\uvec{\theta}}{\theta} \dv{\theta}{t} = - \dot{\theta} \uvec{r}$ we get
	\begin{equation*}
		\bddot{r} = (\ddot{r} - r\dot{\theta}^{2}) \uvec{r} + (r \ddot{\theta} + 2 \dot{r} \dot{\theta}) \uvec{\theta}
	\end{equation*}
	
	\item As a quick example, consider uniform circular motion in the plane at radius $ r $ and constant angular speed $ \dot{\theta} = \omega $. In this case (because $ \dot{r} = 0 $) velocity is
	\begin{equation*}
		\bddot{r} = r \omega \uvec{\theta} \qquad v = \abs{\bddot{r}} = r \omega
	\end{equation*}
	At uniform angular speed $ (\dot{\omega} = \ddot{\theta} = 0) $ the acceleration is 
	\begin{equation*}
		\bddot{r} = -r \omega^{2} \uvec{r} \qquad a = \abs{\bddot{r}} = r \omega^{2}
	\end{equation*}
	which is just the familiar centripetal acceleration $ a = \frac{v^{2}}{r} $.

\end{itemize}

\subsubsection{More On Central Forces}
\begin{itemize}
	\item Recall the equation of motion $ m \bddot{r} = - \grad{V}(r) $. Because $ V = V(r)$ depends only on distance $ r $ from the origin, the gradient is
	\begin{equation*}
		\grad{V} = \dv{V}{r} \uvec{r}
	\end{equation*}
	In terms of the acceleration $ \bddot{r} = (\ddot{r} - r\dot{\theta}^{2}) \uvec{r} + (r \ddot{\theta} + 2 \dot{r} \dot{\theta}) \uvec{\theta} $, the central force equation of motion becomes
	\begin{equation*}
		m(\ddot{r} - r\dot{\theta}^{2}) \uvec{r} + m(r \ddot{\theta} + 2 \dot{r} \dot{\theta}) \uvec{\theta} = - \dv{V}{r} \uvec{r}
	\end{equation*}
	
	\item Notice the acceleration is resolved into a radial component $ (\ddot{r} - r\dot{\theta}^{2}) \uvec{r} $ and tangential  component $ (r \ddot{\theta} + 2 \dot{r} \dot{\theta}) \uvec{\theta} $. 
	
	Because there is no $ \uvec{\theta} $ term on the right hand side of the equation (or, if you will, a $ 0 \cdot \uvec{\theta} $ term), we have $ (r \ddot{\theta} + 2 \dot{r} \dot{\theta}) = 0 $. The $ \uvec{\theta} $ component being zero should make sense, since central forces act only along the radial direction.
	
	There is something cool just below the surface here. We just need to re-write $ r \ddot{\theta} + 2 \dot{r} \dot{\theta} $ as a time derivative.
	\begin{equation*}
		0 \equiv (r \ddot{\theta} + 2 \dot{r} \dot{\theta}) = \frac{1}{r} \dv{}{t} (r^{2} \dot{\theta}) \implies \dv{}{t} (r^{2} \dot{\theta}) = 0
	\end{equation*}
	In other words, the quantity $ r^{2} \dot{\theta} $ is conserved in central force motion.
	
	\item But what does the conserved quantity $ r^{2} \dot{\theta} $ actually represent? In fact, we've met it already: it is angular momentum in disguise. More specifically, it corresponds to the \textit{magnitude} of angular momentum. 
	
	To reveal this, we first rewrite $ \bm{L} $ in terms of the basis vectors $ \{\uvec{r}, \uvec{\theta} \}$:
	\begin{equation*}
		\bm{L} = m \bm{r} \cross \bdot{r} = m (r\uvec{r}) \cross (\dot{r} \uvec{r} + r \dot{\theta} \uvec{\theta})
	\end{equation*}	
	Because $ \uvec{r} \cross \uvec{r} = 0 $ and $ \big |\uvec{r} \cross \uvec{\theta}\big | = 1 $, we get the expressions
	\begin{equation*}
		\bm{L} = m r^{2} \dot{\theta} \left (\uvec{r} \cross \uvec{\theta}\right ) \implies \abs{L} = mr^{2} \dot{\theta}
	\end{equation*}	
	we see that $ r^{2}\dot{\theta} $ represents magnitude of angular momentum per unit mass. We will denote this quantity $ l $:
	\begin{equation*}
		l = r^{2} \dot{\theta}
	\end{equation*}
	
	\item Returning to the radial component of the equation of motion (corresponding to the $ \uvec{r} $ terms) we have
	\begin{equation*}
		m(\ddot{r} - r \dot{\theta}^{2}) = - \dv{V}{r}
	\end{equation*}
	Because $ l = r^{2} \dot{\theta} $ is conserved, we can write $ \dot{\theta}^{2} = \frac{l^{2}}{r^{4}} $ and get
	\begin{equation*}
		m \ddot{r} = - \dv{V}{r} + \frac{ml^{2}}{r^{3}}
	\end{equation*}
	But this is excellent! We have reduced the central force problem, originally in three dimensions, to a one-dimensional problem of radial motion. This is possible because the angular momentum vector is conserved: earlier, conservation of direction reduced our problem to planar motion, and now conservation of magnitude further reduced the problem to one dimension. 

\end{itemize}

\subsubsection{Effective Potential}
\begin{itemize}
	\item In the central force problem it is conventional (and convenient) to define an \textit{effective potential} constructed to simplify the equation of motion. This is:
	\begin{equation*}
		\veff = V(r) + \frac{ml^{2}}{2r^{2}} \quad \implies \quad m \ddot{r} = - \dv{\veff}{r} 
	\end{equation*}
	The term $ \frac{ml^{2}}{2r^{2}} $ is called the angular momentum or centrifugal barrier. It prevents a particle from getting to close to the origin, and arises because of orbital motion. We'll get a better feel for it in the next few paragraphs.
	
	\item In three dimensions, the system's total energy (the sum of the kinetic and potential energies) is
	\begin{align*}
		E &= \frac{1}{2}m \bdot{r}^{2} + V(r) = \frac{1}{2}m \left (\dot{r}\uvec{r} + r \dot{\theta} \uvec{\theta}\right )^{2} + V(r)\\
		&= \frac{1}{2}m\dot{r}^{2} + \frac{1}{2}mr^{2} \dot{\theta}^{2} + V(r)
	\end{align*}
	where the second equality hold because $ \uvec{r} $ and $ \uvec{\theta} $ are orthonormal. Using the conservation of $ l $ which implies $ \dot{\theta}^{2} = \frac{l^{2}}{r^{4}} $ gives
	\begin{equation*}
		E = \frac{1}{2}m\dot{r}^{2} + \frac{ml^{2}}{2r^{2}} + V(r) = \frac{1}{2}m\dot{r}^{2} + \veff(r)
	\end{equation*}
	This result is important: we have derived the same effective potential as the one-dimensional problem, but began the analysis in three dimensions. This basically says the effective one dimensional system governed by $ \quad m \ddot{r} = - \dv{\veff}{r}  $ coincides with the	three dimensional system. 
	
	We also see the extra term in the effective potential is a contribution from the angular kinetic energy.
	
\end{itemize}

\subsubsection{Orbits with $ V(r) = -\frac{k}{r} $ Classified by energy} 

We now turn to a concrete example: we will study the classic $ \frac{1}{r} $ potential $ V(r) = -\frac{k}{r} $. In this case the effective potential is
\begin{equation*}
	\veff = -\frac{k}{r} + \frac{ml^{2}}{2r^{2}}
\end{equation*}
The minimum of the effective potential is:
\begin{equation*}
	r_{\text{min}} = \frac{ml^{2}}{k} \eqtext{and} V_{\text{min}} = V(r_{\text{min}}) = -\frac{k^{2}}{2ml^{2}}
\end{equation*}

We can use these results to classify the possible forms of motion in a $ \frac{1}{r} $ potential based on the system's energy $ E $ (it helps to graph the effective potential as a function or $ r $). There are three options
\begin{enumerate}
	\item If $ E = V_{\text{min}} $ the particle rests at the minimum of the potential well $ \veff $ and stays at the distance $ r_{\text{min}} $ from the origin. Although the particle has fixed radial position, it still moves with angular speed $ \dot{\theta} = \frac{l}{r_{\text{min}}^{2}} $: the particle moves in a circular orbit about the origin.
	
	\item If $ E \in (V_{\text{min}}, 0) $, the particle is trapped in a potential well and oscillates back and forth between the points of maximum energy. Since the particle also has angular speed $ \dot{\theta} = \frac{l}{r_{\text{min}}^{2}} $, the particle moves in a closed orbit in which radial distance $ r $ varies with time. For $ V = - \frac{k}{r} $, this turns out to be an ellipse.
	
	\item If $ E > 0 $, the particle has enough energy to overcome the potential well so the corresponding is unbounded. The particle approaches the origin from infinity, reaches a point of closest approach, and returns back out to infinity. For $ V = - \frac{k}{r} $, the exact trajectory turns out to be a hyperbola.
\end{enumerate}

\subsubsection{Existence and Stability of Circular Orbits}
We now consider a general central potential $ V = V(r) $ and ask when can circular orbits exist, and when are they stable? 
\begin{itemize}

	\item Circular orbits exists when there is a solution of the equation $ m\ddot{r} = - \dv{\veff}{r} $ with $ \dot{r} = 0 $ (constant radius) and fixed $ l \neq 0 $ (non-zero angular speed) for all time. The condition $ \dot{r} = 0 $ obviously implies $ \ddot{r} = 0 $, so the equation of motion reads
	\begin{equation*}
		0 \equiv m \ddot{r} = - \dv{\veff}{r} \implies \dv{\veff}{r} = 0
	\end{equation*}
	In other words, circular orbits correspond to critical points of the effective potential $ \veff $.
	
	\item The orbit is stable if small perturbations return the particle to the critical point, which means the critical point must be a minimum of $ \veff $ (i.e. $ \veff'' > 0 $) for a stable orbit.
	
	\item Let $ r_{\star} $ denote the critical point. In terms of the original potential $ V(r) $, the circular orbit condition $ \veff(r_{\star}) = 0 $ reads
	\begin{equation*}
		V'(r_{\star}) = \frac{ml^{2}}{r_{\star}^{3}}
	\end{equation*}
	(recall $ \veff = V(r) + \frac{ml^{2}}{2r^{2}} $). Meanwhile stability condition $ V''(r_{\star}) > 0 $ reads
	\begin{equation*}
		V''(r_{\star}) + \frac{3ml^{2}}{r_{\star}^{4}} > 0
	\end{equation*}
	Finally, in terms of the central force $ F(r) = - V'(r) $, the stability condition is
	\begin{equation*}
		F'(r_{\star}) + \frac{3}{r_{\star}} F(r_{\star}) < 0
	\end{equation*}
\end{itemize}

\subsection{The Orbit Equation}
In this section we study the trajectories of particles under central forces, which we call \textit{orbits}.
\begin{itemize}
	\item It is straightforward to find how radial position $ r(t) $ changes with time. Conservation of energy comes to the rescue. Since $ E $ is a constant of motion, we can write
	\begin{equation*}
		E = \frac{1}{2}m \dot{r}^{2} + \veff(r)
	\end{equation*}
	and then invert the expression to give
	\begin{equation*}
		\dv{r}{t} = \sqrt{\frac{2}{m}(E - \veff(r))}
	\end{equation*}
	This could then be integrated, numerically if nothing else, to find an expression for $ r(t) $. 
	
	When classifying orbits, it turns out to be more useful to find radial position as a function of the polar angle $ \theta $; we then get a sense of the orbit by finding the shape of $ r(\theta) $.
	
	\item We start our quest for $ r(\theta) $ with two tricks. The first is to temporarily replace $ r $ with the new coordinate
	\begin{equation*}
		u = \frac{1}{r}
	\end{equation*}
	Why? It just works: the math becomes much easier. I don't know of a good physical explanation. The second trick is our good friend the chain rule used with $ \dot{\theta} = \frac{l}{r^{2}} $. 
	
	\item We start with an expression for radial velocity $ \dot{r} $
	\begin{equation*}
		\dv{r}{t} = \dv{r}{\theta} \dv{\theta}{t} =  \dv{r}{\theta}  \frac{l}{r^{2}} = - l \dv{u}{\theta}
	\end{equation*}
	where we have used $ \diff u = -\frac{\diff r}{r^{2}} $. Meanwhile, radial acceleration is
	\begin{equation*}
		\dv[2]{r}{t} = - l \dv{}{t}\left[\dv{u}{\theta}\right] = - l \dv[2]{u}{\theta} \dot{\theta} = -\frac{l^{2}}{r^{2}} \dv[2]{u}{\theta} = -l^{2}u^{2}\dv[2]{u}{\theta} 
	\end{equation*}
	where the $ \dot{\theta} $ term comes from the chain rule and $ u = u(\theta) $.
	
	\item Recall the original radial orbit equation
	\begin{equation*}
		m \ddot{r} = - \dv{V}{r} + \frac{ml^{2}}{r^{3}} 
	\end{equation*}
	In terms of $ u $, using our expression for $ \ddot{r} $, the equation reads
	\begin{equation*}
		\dv[2]{u}{\theta} + u = \frac{1}{ml^{2}u^{2}} \eval{\dv{V}{r}}_{r = \frac{1}{u}}
	\end{equation*}
	This is \textit{orbit equation}, which we want to solve for $ u(\theta) $, which would then give us $ r(\theta) $. We could also extract the time dependence of $ r $ with $ l = r^{2} \dot{\theta}$.

\end{itemize}

\subsubsection{The Kepler Problem}
\begin{itemize}
	\item The \textit{Kepler problem} is just the name given to understanding planetary orbits about a star under the influence of gravity. The correct potential for this scenario is
	\begin{equation*}
		V_{\text{grav}}(r) = -\frac{GmM}{r}
	\end{equation*}
	where $ m $ and $ M $ are the mass of the planet and sun, respectively, while $ G $ is the universal gravitational constant. However, we will be a bit more general and  work with the potential
	\begin{equation*}
		V(r) = - \frac{km}{r}
	\end{equation*}
	with the tacit understanding that $ k = GM $. Why? By using the general form, the results we derive will apply equally well to the electrostatic potential; we just have replace $ k = \frac{-qQ}{4\pi \epsilon_{0}m} $.
	
	\item For the potential $ V = -\frac{km}{r} $, the orbit equation is simply
	\begin{equation*}
		\dv[2]{u}{\theta} + u = \frac{k}{l^{2}}
	\end{equation*}
	This is the equation for a harmonic oscillator with its center displaced by $ \frac{k}{l^{2}} $. We typically write the solution to this equation in the form $ u = A \cos \theta + B \sin \theta + \frac{k}{l^{2}}$, but for the orbit problem, it is much more useful to write
	\begin{equation*}
		u(\theta) = A \cos(\theta - \theta_{0}) + \frac{k}{l^{2}}
	\end{equation*}
	where the $ A $ and $ \theta_{0} $ are integration constants.
	
	\item We're almost there. At the orbit's point of closest approach, $ r $ is smallest and $ u $ is largest. From the our solution $ u(\theta) = A \cos(\theta - \theta_{0}) + \frac{k}{l^{2}} $, we see that $ u $ is largest when the cosine term equals one, meaning the point of closest approach occurs when $ \theta - \theta_{0} = 0$. 
	
	This result provides a natural choice for our polar coordinate system: we orient our axes so the point of closest approach occurs at $ \theta = 0 $. To satisfy $ \theta - \theta_{0} = 0$ we then have the simple result $ \theta_{0} = 0$. We then have the solution
	\begin{equation*}
		u(\theta) = A \cos \theta + \frac{k}{l^{2}} \eqtext{or} r(\theta) = \frac{1}{A \cos \theta + \frac{k}{l^{2}}}
	\end{equation*}
	
	\item By convention, we re-write the solution for $ r(\theta) $ in the form
	\begin{equation*}
		r(\theta) = \frac{r_{0}}{\epsilon \cos \theta + 1}
	\end{equation*}
	where $ r_{0} = \frac{l^{2}}{k} $ and $ \epsilon = \frac{Al^{2}}{k} $ (we simply multiplied $ r(\theta) $ above and below by $ \frac{l^{2}}{k} $).
	
	Note that $ r_{0} $ is not an integration constant; it is uniquely determined by the fixed angular momentum $ l $. The \textit{eccentricity} $\epsilon$ is effectively the new integration constant.

\end{itemize}

\subsubsection{Analyzing the Solutions}
Note that the solutions for $ r(\theta) $ given by
\begin{equation*}
	r(\theta) = \frac{r_{0}}{\epsilon \cos \theta + 1}
\end{equation*}
are \textit{conic sections} (e.g. ellipses, hyperbola, etc...). We can classify the orbits $ r(\theta) $ by the eccentricity $ \epsilon $. There are a few choices:
\begin{enumerate}
	\item For $ \epsilon < 1 $, the radial position is bounded in the interval 
	\begin{equation*}
		\frac{r_{0}}{r} \in [1 - \epsilon, 1 + \epsilon]
	\end{equation*}
	since $ \cos \theta $ falls between $ -1 $ and $ 1 $. This type of orbit is an ellipse. To double check, we can convert to Cartesian coordinates with the substitutions $ x = r \cos \theta $, $ y = \sin \theta $  and $ r^{2} = x^{2} + y^{2} $. We have
	\begin{equation*}
		r = \frac{r_{0}}{\epsilon \cos \theta + 1} \implies r^{2} = (r_{0} - \epsilon r \cos \theta)^{2} \implies x^{2} + y^{2} = (r_{0} - \epsilon x)^{2}
	\end{equation*}
	A few more steps of algebra lead to the Cartesian equation of an ellipse
	\begin{equation*}
		\frac{(x - x_{0})^{2}}{a^{2}} + \frac{y^{2}}{b^{2}} = 1
	\end{equation*}
	where 
	\begin{equation*}
		x_{0} = - \frac{\epsilon r_{0}}{1 - \epsilon^{2}} \qquad a^{2} = \frac{r_{0}^{2}}{(1 - \epsilon^{2})^{2}} \qquad b^{2} = \frac{r_{0}^{2}}{1 - \epsilon^{2}}
	\end{equation*}
	The two axes of the ellipse have lengths $ a $ and $ b $ with $ a > b $. The center of gravitational attraction (e.g. the sun) sits at the origin $ r = 0 $; the origin and ellipse's center are separated by
	\begin{equation*}
		\abs{x_{0}} = \frac{\epsilon r_{0}}{1 - \epsilon^{2}} = \epsilon a
	\end{equation*}
	The origin of gravitational attraction is a \textit{focus} of the ellipse; the other focus lies on the major axis an equal distance from the ellipse's center. Note that when $ \epsilon = 0 $, the focus and center coincide and the two axes have equal lengths $ a = b $: this a circular orbit.
	
	\item Orbits with $ \epsilon > 1 $ are hyperbolae. Repeating analogous algebraic steps to the elliptical orbit leads to the Cartesian coordinate equation
	\begin{equation*}
		\frac{1}{a^{2}} (x + x_{0})^{2} - \frac{y^{2}}{b^{2}} = 1
	\end{equation*}
	with $ a, b $ and $ x_{0} $ defined as before. 
	
	The hyperbola's asymptotes make angles $ \cos \theta = -  \frac{1}{\epsilon} $ with the $ x $ axis. This should make sense; from the polar orbit equation $ r(\theta) $ we see that $ r \to \infty $ when the denominator $ \epsilon \cos \theta + 1 $ equals zero; this occurs for $ \cos \theta = -  \frac{1}{\epsilon} $.
	
	\item The special case $ \epsilon = 1 $ is particularly simple: it is a hyperbolic orbit. The Cartesian coordinate equation is
	\begin{equation*}
		y^{2} = r_{0}^{2} - 2r_{0}x
	\end{equation*} 
\end{enumerate}

\subsubsection{Energy of the Orbit Revisited}
\begin{itemize}
	\item The solution of the orbit equation $ r(\theta)  = \frac{r_{0}}{\epsilon \cos \theta + 1}$ gives us an interesting new look at the orbit energy. Recall that
	\begin{equation*}
		E = \frac{1}{2}m\dot{r}^{2} + \veff(r) = \frac{1}{2}m\dot{r}^{2} - \frac{km}{r} + \frac{ml^{2}}{2r^{2}}
	\end{equation*}
	re-writing $ \dot{r} $ with the chain rule and substituting $ \dot{\theta} = \frac{l}{r^{2}} $ gives
	\begin{align*}
		E &= \frac{1}{2}m \left(\dv{r}{\theta}\right)^{2} \dot{\theta}^{2} - \frac{km}{r} + \frac{ml^{2}}{2r^{2}} \\
		& = \frac{1}{2}m \left(\dv{r}{\theta}\right)^{2} \frac{l^{2}}{r^{4}} - \frac{km}{r} + \frac{ml^{2}}{2r^{2}}
	\end{align*}
	
	\item We can differentiate our solution $ r(\theta) = \frac{r_{0}}{\epsilon \cos \theta + 1} $ to get
	\begin{equation*}
		\dv{r}{\theta} = \frac{r_{0}\epsilon \sin \theta}{(1 + \epsilon \cos \theta)^{2}}
	\end{equation*}
	Plugging this in to the energy expression and a few steps of rather satisfying algebra (using $ \cos^{2} \theta + \sin^{2} \theta = 1 $ and $ r_{0} = \frac{l^{2}}{k} $) leads to the simple result
	\begin{equation*}
		E = \frac{mk^{2}}{2l^{2}} (\epsilon^{2} - 1)
	\end{equation*}
	Notice that all $ \theta $ and $ r $ dependence has vanished from the expression for $ E $. This makes sense: energy is a constant of motion.
	
	\item With our nice result $ E = \frac{mk^{2}}{2l^{2}} (\epsilon^{2} - 1) $ we now return the three cases of orbit classified by eccentricity to see that:
	\begin{enumerate}
		\item Orbits with $ \epsilon < 1 $ have energy $ E < 0 $. Negative energy means a bounded orbit, in agreement with our earlier conclusion that orbits $ \epsilon < 1 $ are ellipses.
		
		\item Orbits with $ \epsilon > 1 $ have positive energy $ E > 0 $; these are unbounded orbits, in agreement with our earlier result that $ \epsilon > 1 $ leads to hyperbolic orbits.
		
		\item Finally, $ \epsilon = 0 $ leads to $ E = - \frac{mk^{2}}{2l^{2}} $. We have seen this before: it is the minimum of the effective potential, and we know from earlier that orbits with minimum $ \veff $ are circular, in agreement with our geometric interpretation that ellipses with $ \epsilon = 0 $ are circles.
		
	\end{enumerate}
\end{itemize}

\subsubsection{Kepler's Laws of Planetary Motion}
Kepler's three laws are obeyed by all planets in the solar system and were first published by Kepler in 1605.
\begin{itemize}
	\item Kepler's first law states:
	\begin{quote}
		Each planet moves in an ellipse, with the Sun at one focus.
	\end{quote}
	Without knowing, we have dedicated a good part of the past few sections to Kepler's first law when discussing the elliptical solution to the orbit equation (when $ \epsilon < 1 $). 
	
	\item Kepler's second law is:
	\begin{quote}
		The line between the a planet and the Sun sweeps out equal areas in equal times at any point in the orbit.
	\end{quote}
	The second law follows directly from conservation of angular momentum. From the equation of area in polar coordinates ($ A = \frac{1}{2}\int r(\theta)^{2}\diff \theta $), we that in the time $ \delta t $ an orbiting planet sweeps out the area
	\begin{equation*}
		\delta A = \frac{1}{2}r^{2} \delta \theta
	\end{equation*}
	Differentiating both sides with respect to time leads to
	\begin{equation*}
		\dv{A}{t} = \frac{1}{2} r^{2} \dot{\theta} = \frac{l}{2}
	\end{equation*}
	But we know that $ l $ is constant by conservation of angular momentum, so $ \dv{A}{t} $ is also constant throughout the orbit. Because conservation of $ l $ holds for all central force motion, Kepler's second law would hold for any central potential $ V = V(r) $, not just the gravitational potential $ V = -\frac{GMm}{r} $.
	
	\item Kepler's third law states:
	\begin{quote}
		The period of orbit is proportional the $ \frac{3}{2} $ power of the radius, i.e. $ T \sim r^{\frac{3}{2}} $.
	\end{quote}
	We turn to the inverse square law of gravitation 
	\begin{equation*}
		F = \frac{GMm}{r^{2}}
	\end{equation*}
	There is a neat proof of the third law that follows simply from dimensional analysis. Kepler's third law is essentially a relation ship between a length and time describing the orbit (e.g. an average radius $ R $ and the period $ T $). We recognize that the only parameter in the problem is $ GM $, so the radius and period in Kepler's law must be related by $ GM $. 
	
	Because $ GM $ has dimensions $ \text{length}^{3} \cdot \text{time}^{-2} $, or
	\begin{equation*}
		[GM] = L^{3} T^{-2}
	\end{equation*}
	By dimensional analysis, Kepler's law relating $ R, T $ and $ GM $ must then be of the form
	\begin{equation*}
		GM \sim \frac{R^{3}}{T^{2}} \quad \implies \quad T^{2} \sim \frac{R^{3}}{GM} \eqtext{or} T \sim R^{\frac{3}{2}}
	\end{equation*}
	
	\item For an elliptical orbit we can be more precise. Using the area of an ellipse $ A = \pi a b $ and our earlier relationships between $ a, b $ and $ r_{0} $ we have
	\begin{equation*}
		A = \pi a b = \pi a^{2} \sqrt{1 - \epsilon^{2}} = \frac{\pi r_{0}^{2}}{(1 - \epsilon^{2})^{3/2}}
	\end{equation*}
	Next, we use Kepler's second law: since area is swept out at a constant rate $ \dv{A}{t} = \frac{l}{2} $, we have $ \frac{A}{T} = \frac{l}{2} $ or
	\begin{equation*}
		T = \frac{2A}{L} = \frac{2\pi r_{0}^{2}}{l(1 - \epsilon^{2})^{3/2}} = \frac{2\pi}{\sqrt{GM}} \left(\frac{r_{0}}{1-\epsilon^{2}}\right)^{3/2}
	\end{equation*}
	We see that $ T $ is indeed proportional to a radius quantity squared. But what exactly does the quantity $  \frac{r_{0}}{1-\epsilon^{2}}$ represent? It turns out to have a very nice interpretation. From the orbit equation $ r(\theta) $ we see that the points of minimum and maximum approach occur at
	\begin{equation*}
		r_{\text{min}} = \frac{r_{0}}{(1 + \epsilon)} \eqtext{and} r_{\text{max}} = \frac{r_{0}}{(1 - \epsilon)}
	\end{equation*}
	respectively. The average of these quantities is none other than
	\begin{equation*}
		R = \frac{1}{2}(r_{\text{min}} + r_{\text{max}}) = \frac{r_{0}}{(1-\epsilon^{2})}
	\end{equation*}
	$ R $ is the average radius of the orbit. In this interpretation, we have
	\begin{equation*}
		T = \frac{2\pi}{\sqrt{GM}} R^{3/2}
	\end{equation*}
	and Kepler's third law emerges crystal clear.
	
	
\end{itemize}

\subsubsection{The Two-Body Central Force Problem with Lagrangian Mechanics}
A new approach to the same problem: solving for the motion of two bodies under the influence of a central force two-body problem. We'll see the Lagrangian approach gives the same result as the Newtonian one, as it must.
\begin{itemize}
	\item As usual, we have our two bodies with position vectors and masses $ \bm{r}_{1}, m_{1} $  and $ \bm{r}_{2}, m_{2}$, respectively. The center of mass $ \bm{R} $ is and reduced mass $ \mu $ are
	\begin{equation*}
		(m_{1} + m_{2}) \bm{R} = m_{1}\bm{r}_{1} + m_{2}\bm{r}_{2} \eqtext{and} \mu = \frac{m_{1}m_{2}}{m_{1} + m_{2}}
	\end{equation*}
	while the relative position vector $ \bm{r} $ and its magnitude $ r $ are
	\begin{equation*}
		\bm{r} = \bm{r}_{1} - \bm{r}_{2}  \eqtext{and} r = \abs{\bm{r}}
	\end{equation*}
	The system's Lagrangian is
	\begin{equation*}
		L = T - V = \frac{1}{2}\left(m_{1}\bdot{r}_{1}^{2} + m_{2}\bdot{r}_{2}^{2}\right) - V(r)
	\end{equation*}

	\item We start by writing the Lagrangian in terms of the center of mass $ \R $ and relative position $ \bm{r} $:
	\begin{equation*}
		L = \frac{1}{2}(m_{1} + m_{2}) \bdot{R}^{2} + \frac{1}{2}\mu \bdot{r}^{2} - V(r)
	\end{equation*}
	Note that the Lagrangian decomposes into a piece describing the center of mass $ \bm{R} $  and a piece describing the relative separation $ \bm{r} $. 
	
	Since there are no external forces acting on the system the motion of the center of mass is uniform, i.e. $ \bdot{R} $. This means the $ \frac{1}{2}(m_{1} + m_{2}) \bdot{R}^{2} $ term is also constant and thus won't affect the system's dynamics. 
	
	\item We know from the Newtonian approach that the angular momentum $ \bm{L} $ is conserved; it follows trivially from $ \bdot{L} = \bm{r} \cross \bm{F} = 0 $ for central forces. Here's an elegant Lagrange-style approach to the same result: our system's Lagrangian is invariant under infinitesimal rotations, so Noether's theorem tells us the system's angular momentum must be conserved. The angular momentum is 
	\begin{equation*}
		\bm{L} = \bm{r} \cross \bm{p} 
	\end{equation*}
	where $ \bm{p} = \dv{}{t}\left(\pdv{L}{\bdot{r}}\right) $ is the momentum conjugate to $ \bm{r} $; because we're using Cartesian coordinates, $ \bm{p} $ coincides with the Newtonian momentum $ m \bdot{r} $.
	
	\item Since $ \bm{L} = \bm{r} \cross \bm{p}  $ is perpendicular to $ \bm{r} $ by definition, the system's orbit must lie in a plane perpendicular to $ \bm{L} $. Planar motion is best suited to the polar coordinates $ (r, \phi) $, in terms of which the Lagrangian is
	\begin{equation*}
		L = \frac{1}{2} \mu \left(\dot{r}^{2} + r^{2} \dot{\phi}^{2}\right) - V(r)
	\end{equation*}
	We immediately see $ L $ is independent of $ \phi $, which means (see Section \ref{sssec:consts_motion}) that the quantity 
	\begin{equation*}
		\pdv{L}{\dot{\phi}} = \mu r^{2} \dot{\phi} \equiv J
	\end{equation*}
	is conserved. $ J $ is the magnitude of angular momentum $ \abs{\bm{L}} $; I'm denoting it by $ J $ and not $ L $ to avoid confusion with the Lagrangian.
	
	\item We get the system's equations of motion from the Lagrange equations for the coordinate $ r $:
	\begin{equation*}
		\dv{}{t}\left(\pdv{L}{\dot{r}}\right) - \pdv{L}{r} = \mu \ddot{r} - \mu r \dot{\phi}^{2} + \pdv{V}{r} = 0
	\end{equation*}
	We can then eliminate $ \dot{\phi} $ by writing it in terms of the conserved quantity $ J $
	\begin{equation*}
		\dot{\phi}^{2} = \frac{J^{2}}{\mu^{2} r^{4}} \implies \mu \ddot{r} = \frac{J^{2}}{2 \mu r^{3}} - V(r) \equiv - \pdv{}{r} \veff(r)
	\end{equation*}
	where $ \veff $ is the effective potential
	\begin{equation*}
		\veff(r) = V(r) + \frac{J^{2}}{\mu r^{2}}
	\end{equation*}
	
	\item Next, since the Lagrangian is not an explicit function of time (i.e. $ \pdv{L}{t} = 0 $), the system's energy is conserved (see \ref{sssec:consts_motion}) so
	\begin{equation*}
		E = \frac{1}{2}\mu \dot{r}^{2} + \veff(r)
	\end{equation*}
	is a constant of motion. In principle, this is enough to solve the dynamics as long as $ \veff $ is known. We can rearrange the above equation, separate variables, and integrate to get
	\begin{equation*}
		\int \diff t = \sqrt{\frac{\mu}{2}} \int \frac{\diff r}{\sqrt{E - \veff(r)}}
	\end{equation*}
	from which we could solve for $ r(t) $, numerically if nothing else. 
	
	At this point we've reduced the problem to a one-dimensional problem with a single degree of freedom $ r $, just like in the Newtonian approach, summed up in our main result
	\begin{equation*}
				E = \frac{1}{2}\mu \dot{r}^{2} + \veff(r)
	\end{equation*}
	The procedure from here on is analogous to what we've already solved, so I won't repeat.
	
\end{itemize}


\subsection{Laplace-Runge-Lenz Vector}

\subsubsection{Derivation}
\begin{itemize}
	\item Let's return to the two body central force problem, denoting the positions of the two bodies by $ \bm{r}_{1} $ and $ \bm{r}_{2} $ and defining the relative position vector $ \bm{r} $ as
	\begin{equation*}
		\bm{r} = \bm{r}_{1} - \bm{r}_{2}
	\end{equation*}
	Because the force is assumed to be central, Newton's second law can be written
	\begin{equation*}
		m \bddot{r} = F(r) \uvec{r}
	\end{equation*}
	where $ \uvec{r} $ is the unit vector in the direction of the relative position vector and $ m $ is the reduced mass. For the gravitational force $ F(r) = \frac{-k}{r^{2}} $ we have
	\begin{equation*}
		m \bddot{r} = \frac{-k}{r^{2}} \uvec{r}
	\end{equation*}
	
	\item Next, we take right-side cross product of both sides of Newton's law with the angular momentum  $ \bm{L} = m \bm{r} \cross \bdot{r} $. The result is
	\begin{equation*}
		\bddot{r}\cross \bm{L} = k \dot{\uvec{r}}
	\end{equation*}
	To start we first compute the time derivative $ \dot{\uvec{r}} $; this seems odd, but it turns out super useful in the next step. The result is
	\begin{equation*}
		\dot{\uvec{r}} = \frac{\bdot{r}(\bm{r}\cdot \bm{r}) - (\bm{r}\cdot \bdot{r})\cdot \bm{r}}{r^{3}} = \frac{r^{2}\bdot{r} - (\bm{r}\cdot \bdot{r}) \bm{r}}{r^{3}}
	\end{equation*}
	We then return to cross product of Newton's law to get
	\begin{equation*}
		m \bddot{r}\cross \bm{L} = \frac{-k}{r^{2}} \uvec{r} \cross \bm{L} \implies m \bddot{r}\cross \bm{L} = - \frac{km}{r^{3}} \bm{r} \cross (\bm{r} \cross \bdot{r})
	\end{equation*}
	We cancel masses, use the identity $ \bm{a} \cross (\bm{b} \cross \bm{c}) = (\bm{a} \cdot \bm{c})\bm{b} - (\bm{a} \cdot \bm{b})\bm{c} $, and conveniently recognize the expression for $ \dot{\uvec{r}} $:
	\begin{equation*}
		\bddot{r}\cross \bm{L} = - \frac{k}{r^{3}}((\bm{r}\cdot \bdot{r})\bm{r} - r^{2}\bdot{r}) = +k\frac{(r^{2}\bdot{r} - (\bm{r}\cdot \bdot{r})\bm{r})}{r^{3}} = k \dot{\uvec{r}}
	\end{equation*}
	
	\item Because $ \bdot{L} = 0 $ (i.e. $ \bm{L} $ is conserved in any central force problem), we can write the left hand side in the form $ \bddot{r}\cross \bm{L} = \dv{}{t}[\bdot{r}\cross \bm{L}] $ which then gives us
	\begin{equation*}
		\dv{}{t}[\bdot{r}\cross \bm{L}] = k \dot{\uvec{r}}
	\end{equation*}
	Since $ k $ is a constant, we can integrate the equation with respect to time to get
	\begin{equation*}
		\bdot{r} \cross \bm{L} = k \uvec{r} + \bm{x}
	\end{equation*}
	where $ \bm{x} \neq \bm{x}(t) $ is a time-independent vector resulting from the integration over time. (You could think of $ \bm{x} $ as a vector integration constant).
	
	\item Finally, we divide the equation by $ k $ and rearrange to get
	\begin{equation*}
		\bm{A} \equiv \frac{\bm{x}}{k} =  \frac{\bdot{r} \cross \bm{L}}{k} - \uvec{r} 
	\end{equation*}
	where we have defined the Laplace-Runge-Lenz vector as $ \bm{A} \equiv \frac{\bm{x}}{k} $. Because both $ \bm{x} $ and $ k $ are time independent so is $ \bm{A} $, i.e. the LRL vector is conserved for the $ F \sim \frac{1}{r^{2}} $ central force problem.
	
\end{itemize}

\subsubsection{The LRL Vector and the Orbit Equation}
The LRL vector gives us a neat way of deriving the orbit equation for the Kepler problem of planetary motion.
\begin{itemize}
	\item Starting with the definition of the LRL vector, we take the dot product of both sides with $ \bm{r} $. With the help of the vector identity $ (\bm{a} \cross \bm{b}) \cdot \bm{c} = (\bm{c} \cross \bm{a}) \cdot \bm{b}$ we get
	\begin{equation*}
		\bm{A}\cdot\bm{r} =  \frac{\bdot{r} \cross \bm{L}}{k}\cdot\bm{r} - \uvec{r} \cdot\bm{r} = \frac{(\bm{r} \cross \bdot{r})\cdot\bm{L}}{k} - r = \frac{\bm{L}\cdot\bm{L}}{mk} - r = \frac{L^{2}}{km} - r
	\end{equation*}
	
	\item If we write $ \bm{A} \cdot \bm{r} = A r \cos \theta $ where $ \theta $ is the angle between $ \bm{A} $ and $ \bm{r} $, and solve for $ r $ we get
	\begin{equation*}
		r = \frac{L^{2}}{km}\frac{1}{1 + A \cos \theta}
	\end{equation*}
	This should look familiar: it is our solution to the orbit equation for the Kepler problem with the perihelion set to $ \theta = 0 $. We had previously written the solution as
	\begin{equation*}
		r(\theta) = \frac{r_{0}}{1 + \epsilon \cos \theta} \eqtext{where} r_{0} = \frac{l^{2}}{\tilde{k}}, \ l = \frac{L}{m}, \, \tilde{k} = Gm
	\end{equation*}
	
	\item If you look closely, the $ k $'s don't seem to match. Not to fear, it's just because we weren't using the reduced mass in our original solution of the orbit equation. Here's a detailed explanation; feel free to skip. I have explicitly denoted the old constant from our first encounter with the orbit equation as $ \tilde{k} = Gm $. This time around (recall we wrote $ F = -\frac{k}{r^{2}} $) we have been using $ k = GMm $ where $ M $ is the mass of the large body and $ m $ the mass of the smaller, orbiting body. We're left in a notational muddle, since we have also used $ m $ for the reduced mass $ \frac{mM}{m + M} $. But in the typical Kepler problem with $ M \gg m $ the reduced mass is nearly equal to the mass of the smaller body. We then have $ k = m \tilde{k} $, and we see both orbit equations agree.
	
	\item Comparing the two orbit equations reveals an awesome result: comparing the coefficient of the $ \cos \theta $ term tells us
	\begin{equation*}
		A = \epsilon
	\end{equation*}
	In other words, the eccentricity of the orbit is the magnitude of the LRL vector.
\end{itemize}

\subsection{Scattering}
\textbf{TODO}



\newpage
\section{The Motion of Rigid Bodies}

\begin{itemize}
	\item Rigid bodies are objects (discrete or continuous distributions of mass points) where the distance between the points is fixed, i.e. $ \abs{\bm{r}_{i} - \bm{r}_{j} } $ is constant for all $ i, j $. Rigid bodies have zero internal degrees of freedom because their constituent points are fixed.
	
	\item In general, a rigid body with a free center of mass has six degrees of freedom: three from rotation and three from translation. A rigid body with a \textit{fixed} center of mass looses it translational freedom, so it has only three rotational degrees of freedom.

	The general motion of a free rigid body can be separated into a translation of the center of mass and rotation about a point, often chosen to be the center of mass.
	
\end{itemize} 

\subsection{Rigid Body Kinematics}

\subsubsection{On Frames and Degrees of Freedom}
\begin{itemize}
	\item In general the analysis involves a fixed (inertial) lab frame $ \{\tilde{\e}_{a} \} $ and a body-fixed frame $ \{\e_{a} \} = \{\e_{a} \}(t)$ that moves with the body. Both frames have orthonormal axes: $ \tilde{\e}_{a} \cdot \tilde{\e}_{b} = \delta_{ab} $ and $ \e_{a}(t) \cdot \e_{b}(t) = \delta_{ab} $.
	
	\item For all times $ t $, there exists a \textit{unique} rotation matrix $ \mathbf{R}(t) $ for which $ \e_{a}(t) = \mat{R}_{ab}(t) \tilde{\e}_{b} $. In other words, it is always possible to rotate the lab frame in such away that the directions of its axes $ \{\tilde{\e}_{a} \} $ coincide with the body-fixed frame $ \{\e_{a}\} $, and the corresponding rotation matrix $ \mat{R} $ is unique.
	
	\item As the rigid body rotates, we can thus describe its orientation with the $ 3 \cross 3 $ time-dependent rotation matrix $ \mathbf{R}(t) $. As for any rotation matrix $ \mat{R} $ is orthogonal, $ \mathbf{R}^{T} \mathbf{R} = \mathbf{I} $ and $ \det \R  = 1$. In general, a $ 3 \cross 3 $ matrix has 9 degrees of freedom, but the orthogonality condition $ \mathbf{R}^{T} \mathbf{R} = \mathbf{I} $ imposes 6 constraints, leading to the aforementioned 3 degrees of rotational freedom. We thus need three coordinates to parameterize a rigid body's rotation.

\end{itemize}


\subsubsection{Angular Velocity}
I hope you're comfortable with indexes and Einstein summation convention. There's a healthy dose of it coming fast.
\begin{itemize}
	\item Any point in the body $ \bm{r}(t) $ can be expanded in either the body frame or space frame:
	\begin{equation*}
		\bm{r}(t) = r_{a} \e_{a}(t) = \tilde{r}_{a}(t) \tilde{\e}_{a}
	\end{equation*}
	where $ \tilde{r}_{b}(t) = r_{a}\operatorname{R}_{ab}(t)$. In the body-fixed frame, the distances $ r_{a} $ are constant and in the lab frame, the basis vectors $ \tilde{\e}_{a} $ are constant. 
	
	\item Taking the time derivative of $ \bm{r}(t) $ produces
	\begin{align*}
		\dot{\bm{r}}(t) &=  \tilde{\e}_{a} \dv{\tilde{r}_{a}}{t} \quad \qquad \text{(lab frame)}\\
		&= r_{a} \dv{\e_{a}}{t} \quad \qquad \text{(body-fixed frame)} \\
		&=  r_{a}  \dv{\operatorname{R}_{ab}}{t} \tilde{\e}_{b} \quad \ \left(\text{using }  \tilde{r}_{b} = r_{a}\operatorname{R}_{ab}\right)
	\end{align*}

	\item Meanwhile, using the transformation $ \e_{b} = \operatorname{R}_{ab}\tilde{e}_{a} $ and the fact that the lab basis vectors $ \tilde{\e}_{a} $ are constant, we can calculate the derivative of the body-fixed basis vectors $ \{\e_{a}(t) \} $ to be
	\begin{equation*}
		\dv{\e_{a}}{t} = \dv{}{t}[\operatorname{R}_{ab} \tilde{\e}_{b}] = \dv{\operatorname{R}_{ab}}{t} \tilde{\e}_{b} 
	\end{equation*}
	Next, using the transformation $ \tilde{\e}_{b} = \operatorname{R}^{-1}_{bc}\e_{c} $,  and $ \mat{R} $'s orthogonality $ \operatorname{R}_{ij}^{-1}= \operatorname{R}_{ji} $ we finish the calculation with
	\begin{equation*}
		\dv{\e_{a}}{t} = \cdots =  \dv{\operatorname{R}_{ab}}{t} (\operatorname{R}^{-1}_{bc} \e_{c}) = \dv{\operatorname{R}_{ab}}{t} (\operatorname{R}_{cb} \e_{c}) \equiv \operatorname{\Omega}_{ac} \e_{c}
	\end{equation*}
	where we've defined $ \operatorname{\Omega}_{ac}\equiv \dv{\operatorname{R}_{ab}}{t} \operatorname{R}_{cb}$, the elements of a $ 3 \cross 3 $ matrix $ \mat{\Omega} $.
	
	The matrix $ \mathbf{\Omega} $ defined above is antisymmetric, i.e. $ \operatorname{\Omega}_{ac} = - \operatorname{\Omega}_{ca} $. To show this, we differentiate the identity $ \operatorname{R}_{ab}\operatorname{R}_{cb} = \delta_{a c} $ and recognize the definition of $ \operatorname{\Omega}_{ac} $
	\begin{equation*}
		\operatorname{R}_{ab}\operatorname{R}_{cb} = \delta_{a c} \implies \dv{\operatorname{R}_{ab}}{t}\operatorname{R}_{cb} + \operatorname{R}_{ab}\dv{\operatorname{R}_{cb}}{t} = 0 \implies \operatorname{\Omega}_{ac} + \operatorname{\Omega}_{ca} = 0
	\end{equation*}
	
	Because $ \mat{\Omega} $ is antisymmetric (its diagonal terms are necessarily zero and its off-diagonal terms are related by $ \Omega_{ab} = - \Omega_{ba} $) it has only 3 independent components. To be concrete, $ \mat{\Omega} $ looks something like this:
	\begin{equation*}
		\mat{\Omega} = 
		\begin{bmatrix}
			0 & \operatorname{\Omega}_{12} & \operatorname{\Omega}_{13}\\
			\operatorname{\Omega}_{21} & 0 & \operatorname{\Omega}_{23}\\
			\operatorname{\Omega}_{31} & \operatorname{\Omega}_{32} & 0
		\end{bmatrix}
		= 
		\begin{bmatrix}
			0 & \operatorname{\Omega}_{12} & - \operatorname{\Omega}_{31}\\-
			\operatorname{\Omega}_{12} & 0 & \operatorname{\Omega}_{23}\\
			\operatorname{\Omega}_{31} & -\operatorname{\Omega}_{23} & 0
		\end{bmatrix}
	\end{equation*}
	Since $ \mat{\Omega} $ has only 3 independent components, we can define an equivalent three-component, one-index object (i.e. a vector) $ \bm{\omega} $ with the Levi-Civita symbol with the formula
	\begin{equation*}
		 \omega_{a} = \frac{1}{2} \epsilon_{abc} \operatorname{\Omega}_{bc} \qquad a, b, c = 1, 2, 3
	\end{equation*}
	By components, we get $ \omega_{1} = \operatorname{\Omega}_{23}$ , $ \omega_{2} = \operatorname{\Omega}_{31} $ and $ \omega_{3} = \operatorname{\Omega}_{12} $ (try it yourself!).
	
	The $ \omega_{a} $ form the components of a vector in the body-fixed frame $ \{\e_{a} \} $: $ \bm{\omega} = \omega_{a} \e_{a} $.  In terms of $ \bm{\omega} $, the time derivative of the body frame is
	\begin{equation*}
		\dot{\e}_{a}(t) = \operatorname{\Omega}_{ac} \e_{c} = - \epsilon_{abc} \omega_{b} \e_{c} = \bm{\omega} \cross \bm{e}_{a}
	\end{equation*}
	where $ \e_{a} \cross \e_{b} = \epsilon_{abc} \e_{c} $. After all that work, we finally have an expression for $ \dot{\e}(t) $. But it was worth it: along the way we have defined something very important, which we haven't yet discussed: the vector $ \bm{\omega} $ is the body's \textit{instantaneous angular velocity}. I'll stress again that its components $\omega_{a}$ are measured with respect to the body-fixed frame $ \{\e_{a} \} $. Angular velocity comes up everywhere in rigid body mechanics, we'll se much more of it in the next sections.
	
	\item Informal interpretation: the angular velocity encodes the speed and direction of the body's rotation. To see this, consider a point $ \bm{r} $ in the body, and rotate the point by the infinitesimal angle $ \diff \phi $ about the fixed axis $ \uvec{n} $, where the angle between $ \bm{r} $ and $ \uvec{n} $ is $ \theta $.
	
	The vector $ \bm{r} $ changes in magnitude by $ \abs{\diff \bm{r}} = \abs{\bm{r}} \sin \theta \diff \phi $. Because the body is rigid, $ \diff \bm{r} \perp \bm{r}$, so $ \diff \bm{r} = \diff \bm{\phi} \cross \bm{r} $, where $ \diff \bm{\phi} = \diff \phi \uvec{n} $. ``Dividing'' $ \diff \bm{r} = \diff \bm{\phi} \cross \bm{r} $ by $ \diff t $ produces
	\begin{equation*}
		\dv{\bm{r}}{t} = \dv{\bm{\phi}}{t} \cross \bm{r} = \bm{\omega} \cross \bm{r}
	\end{equation*}
	Thus, $ \bm{\omega} $ is the body's instantaneous angular velocity about the rotation axis $ \uvec{n} $. In general, both $ \uvec{n} $ and $ \bm{\omega} $ change over time.

	\item As an aside, much of rigid body dynamics involves determining the angular velocity vector $ \bm{\omega}(t) $ of various rigid bodies as they spin and turn in space. Let's say we find $ \bm{\omega} $ How do we get back to our starting point, the rotation matrix $ \mat{R}(t) $, which describes the rotating body's orientation in space?
	
	First, we expand the angular velocity in the body-fixed frame to get
	\begin{equation*}
		\bm{\omega} = \omega_{a} \e_{a}
	\end{equation*}
	We then turn the vector into the $ 3 \cross 3 $ antisymmetric matrix $ \mat{\Omega} $ via
	\begin{equation*}
		\operatorname{\Omega}ab = \epsilon_{abc}\omega_{c}
	\end{equation*}
	Finally, we recover the rotation matrix $ \mat{R} $ by solving the differential equation
	\begin{equation*}
		\mat{\Omega} = \dv{\mat{R}}{t} \mat{R}^{-1}
	\end{equation*}
	which comes from the definition of $ \mat{\Omega} $ via $ \operatorname{\Omega}_{ac} = \dv{\operatorname{R}_{ab}}{t} \operatorname{R}_{cb} = \dv{\operatorname{R}_{ab}}{t} \operatorname{R}_{bc}^{-1} $. Note that this is a \textit{matrix} differential equation. It is solved with a mathematical tool called path-ordered exponentials, which is beyond the scope of this course.
	
\end{itemize}


\subsubsection{Inertia Tensor}
\begin{itemize}
	\item The inertia tensor arises naturally from computing the kinetic energy of a fixed rotating body:
	\begin{align*}
		T &= \frac{1}{2}\sum_{i} m_{i} \bdot{r}_{i} \cdot \bdot{r}_{i} = \frac{1}{2}\sum_{i} m_{i} (\bm{\omega} \cross \bm{r}_{i}) \cdot (\bm{\omega} \cross \bm{r}_{i})\\
		&= \frac{1}{2}\sum_{i} m_{i}\left[ (\bm{\omega} \cdot \bm{\omega}) (\bm{r}_{i} \cdot \bm{r}_{i} ) - (\bm{\omega} \cdot \bm{r}_{i})^2\right]
	\end{align*}
	where the last equality uses Lagrange's vector identity $ (\bm{a}\cross \bm{b})^{2} = \bm{a}^{2}\bm{b}^{2} - (\bm{a}\cdot \bm{b})^{2}$. The equality can be written 
	\begin{equation*}
		T = \frac{1}{2} \omega_{a} \operatorname{I}_{ab} \omega_{b} = \frac{1}{2} \bm{\omega} \cdot \mat{I} \bm{\omega}
	\end{equation*}
	where $ \mathbf{I} $ is the \textit{inertia tensor}. Its components, \textit{measured in the body-fixed frame}, are
	\begin{equation*}
		\operatorname{I}_{ab} = \sum_{i}m_{i} \left((\bm{r}_{i} \cdot \bm{r}_{i})\delta_{a b} - r_{i_{a}} r_{i_{b}} \right)
	\end{equation*}
	The inertia tensor is always measured with respect to a particular point in space, which determines the origin for the position vectors $ \bm{r}_{i} $. In general, the inertia tensor is different when measured with respect to different points in space. 
	
	Two important notes: By construction $ \operatorname{I}_{ab} = \operatorname{I}_{ba} $, so $ \mat{I} $ is symmetric. Second, since $ \mat{I} $ is measured in the body-fixed frame, its components are independent of time.
	
	
	For a continuous mass distribution with density $ \rho = \rho(\bm{r}) $, the inertia tensor is
	\[
		\mathbf{I} = \int \diff^{3}\bm{r} \rho(\bm{r}) 
		\begin{bmatrix}
			y^2 + z^2 & - xy & - xz\\
			-xy & x^2 + z^2 & -yz\\
			-xz & -yz & x^2 + y^2
		\end{bmatrix}
	\]
	In principle, $ \mathbf{I} $ can be calculated with respect to any point in space.
	
	\item Because $ \mathbf{I} $ is real and symmetric, it can be diagonalized, i.e. there exists an orthogonal matrix $ \mathbf{Q} $ such that $ \mathbf{I}' = \mathbf{Q} \mathbf{I} \mathbf{Q}^{T} $ is diagonal.
	
	Equivalently, we can rotate the orientation of the body-fixed frame $ \{\e_{a} \} $ to coincide with $ \mathbf{I} $'s eigenvectors, which are given by $\{ \mathbf{Q}\e_{a} \} $. In the frame $ \{\mat{Q}\e_{a} \} $ the inertia tensor $ \mathbf{I} $ is diagonal.
	
	The frame in which $ \mathbf{I} $ is diagonal is called the \textit{frame of principle axes}. In this basis corresponding to the principle axes frame, $ \mathbf{I} $ takes the form
	\[
		\mathbf{I} = 
		\begin{bmatrix}
			I_{1} & 0 & 0\\
			0 & I_{2} & 0\\
			0 & 0 & I_{3}
		\end{bmatrix}
	\]
	$ \mathbf{I} $'s eigenvalues $ I_{1, 2, 3} $ are called the \textit{principle moments of inertia}. By the way, the principle moments of inertia are always real and positive.

\end{itemize}

\subsubsection{Parallel Axis Theorem}
The parallel axis theorem is a handy tool for calculating inertia tensors. If we know a body's inertia tensor \textit{about its center of mass}, the parallel axis theorem makes it relatively easy calculate the inertia tensor about any other point. Here's a mathematical formulation:

\begin{quote}
	If $ \mathbf{I}^{\text{(cm)}} $ is a rigid body's inertia tensor measured with respect to the body's center of mass $ \bm{r}^{(\text{cm})} $, then the inertia tensor $ \mathbf{I}' $ measured about some other point $ \bm{r}' $ displaced from $ \bm{r}^{\text{(cm)}} $ by the vector $ \bm{c} $ is given by
\end{quote}
\begin{equation*}
	\operatorname{I}'_{ab} = \operatorname{I}^{\text{(cm)}}_{ab} + M ((\bm{c}\cdot \bm{c} ) \delta_{ab} - c_{a} c_{b} )
\end{equation*}
where $ M $ is the body's mass.
\smallskip

\textbf{Proof}: Starting from the definition of $ I'_{ab} $ and multiplying out:
\begin{align*}
	I'_{ab} &= \sum_{i} m_{i} \big [((\bm{r}_i - \bm{c}) \cdot (\bm{r}_i - \bm{c}) )\delta_{a b} - (r_i - c)_{a}(r_i - c)_{b}  \big]\\
	I'_{ab} &= \sum_{i} m_{i} \big[ (\bm{r}_{i}\cdot \bm{r}_{i}) \delta_{a b} - r_{i_{a}}r_{i_{b}} + \{-2\bm{r}_i \cdot \bm{c}\delta_{a b} + r_{i_{a}}c_{b} + r_{i_{b}}c_{a} \} + ((\bm{c}\cdot \bm{c}) \delta_{ab} - c_{a}c_{b}) \big]\\
	&= I^{\text{(cm)}}_{ab} + 0 + \sum_{i}m_{i}  (\bm{c}^{2} \delta_{ab} - c_{a} c_{b} ) = I_{ab}^{\text{(cm)}} +  M(\bm{c}^{2} \delta_{ab} - c_{a} c_{b} )
\end{align*}
The terms in the curly brackets $ \{\cdots \} $ in the middle line are linear in $ \bm{r}_{i} $, so they vanish by definition of center of mass $ \sum_{i}m_i \bm{r}_i = 0 $. The additional term $ M(\bm{c}^{2}\delta_{ab} - c_{a}c_{b}) $ has an interesting physical interpretation: it is the inertia tensor (still measured with respect to $ \bm{r}' $) we'd find if the body's entire mass were concentrated into a point at the center of mass.

\subsubsection{Angular Momentum}
\begin{itemize}
	\item Angular momentum, like angular velocity and the inertia tensor, is calculated with respect to a given point. In terms of the inertia tensor, using the vector triple product, we have:
	\begin{align*}
		\bm{L} &= \sum_{i} m_{i} \bm{r}_{i} \cross \bdot{r}_{i} = \sum_{i} m_{i} \bm{r}_{i} \cross (\bm{\omega} \cross \bm{r}_{i}) \\
		&= \sum_{i} m_i (r_{i}^2 \bm{\omega} - (\bm{r}_{i} \cdot  \bm{\omega})\bm{r}_{i} )\\
		& = \mathbf{I} \bm{\omega}
	\end{align*}
	There is an important concept hiding in the result $ \bm{L} = \mat{I} \bm{\omega} $: in general angular velocity $ \bm{\omega} $ and angular momentum $ \bm{L} $ point in different directions. 
	
	There are probably more elegant ways of showing this, but this way worked for me. By components, $  \bm{L} = \mat{I} \bm{\omega} $ reads
	\begin{equation*}
		\begin{bmatrix}
			L_{1}\\
			L_{2}\\
			L_{3}
		\end{bmatrix}
		= 
		\begin{bmatrix}
			I_{11} \omega_{1} + I_{12}\omega_{2} + I_{13}\omega_{3}\\
			I_{21} \omega_{1} + I_{22}\omega_{2} + I_{23}\omega_{3}\\
			I_{31} \omega_{1} + I_{32}\omega_{2} + I_{33}\omega_{3}
		\end{bmatrix} 
		\implies L_{a} = I_{ab} \omega_{b}
	\end{equation*}
	In other words, each component $ L_{a} $ is a linear combination of \textit{all} of $ \bm{\omega} $'s components, which means that in general $ \bm{L} $ and $ \bm{\omega} $  different directions.  This fact leads to many of the peculiar properties of spinning objects.$ \bm{L} $ and $ \bm{\omega} $ coincide only for rotation about a principle axis of inertia.
	

	
\end{itemize}



\subsubsection{Rigid Body Motion as Translation and Rotation}
Everything we've said so far applies to a body rotating about a fixed point. The fixed point of rotation has not moved through space.

\begin{itemize}
	\item The general motion of a free rigid body can always be written as a translation through space plus a rotation about a point in space. In theory, the point of rotation could be anywhere inside or outside the body. But the rotation point is traditionally chosen to be the center of mass, because this simplifies the analysis.
	
	\item We write the position $ \bm{r}_{i} $ of a point in the body with
	\begin{equation*}
		\bm{r}_{i}(t) = \bm{R}(t) + \Delta \bm{r}_{i}(t)
	\end{equation*}
	where $ \bm{R}(t) $ is the center of mass and $ \Delta \bm{r}_{i}(t) $ is the position of the point relative to the center of mass.	With the decomposition $ \bm{r}_{i} = \bm{R} + \Delta \bm{r}_{i} $, the kinetic energy of a rotating free body decomposes into a translation of the center of mass plus rotation about the center of mass.
	\begin{align*}
		T &= \frac{1}{2} \sum_{i} m_i (\dot{\bm{r}}_{i} \cdot \dot{\bm{r}}_{i}) = \frac{1}{2} \sum_{i} m_i \left [(\dot{\bm{R}} + \Delta \dot{\bm{r}}_{i}) \cdot (\dot{\bm{R}} + \Delta \dot{\bm{r}}_{i}) \right ]\\
		&= \frac{1}{2} \sum_{i} m_i \left(\dot{\bm{R}}^2 + 2\big \{ \dot{\bm{R}} \cdot (\bm{\omega} \cross \Delta \bm{r}_{i}) \big \} + (\bm{\omega} \cross \Delta \bm{r}_{i} )^2 \right)\\
		& = \frac{1}{2} \sum_{i} m_i \dot{\bm{R}}^{2} + \frac{1}{2} \omega_{a} \operatorname{I}_{ab} \omega_{b}
	\end{align*}
	The term in curly brackets $ \{\cdots \} $ is linear in $ \Delta  \bm{r}_{i} $ vanishes by definition of center of mass $ \sum_{i}m_i \bm{r}_i = 0 $. 
	

\end{itemize}


\subsubsection{Euler Equations}
\begin{itemize}
	\item Recall rigid body motion for a free body decomposes into a translation of the center of mass and a rotation about the center of mass. For now, we'll ignore the translation and focus only on rotation about the center of mass.
	
	The angular momentum of any free body must be conserved, so $ \dot{\bm{L}} = \bm{0} $, which allows us to define the body's equation of motion. Using the body-fixed expansion of angular momentum $ \bm{L} = L_{a} \e_{a}  $ the equations of motion are
	\begin{align*}
		\bm{0} &\equiv \dv{\bm{L}}{t} = \dv{{L}_{a}}{t}\e_{a} + L_{a} \dv{{\e}_{a}}{t}  \\
		&= \dv{{L}_{a}}{t} \e_{a} + L_{a}\bm{\omega} \cross \e_{a}
	\end{align*}
	
	\item In principle, the body-fixed frame could be any frame rotating with the body. But the equations of motion simplify considerably if we choose the body-fixed frame to align with the system of principle axes in which $ \mathbf{I} $ is diagonal. 
	
	The $ \{e_{a}\} $ aligned with the principle axes $ \mat{I} = \operatorname{diag}{I_{1}, I_{2}, I_{3}} $ the angular momentum 
	If we align the body-fixed frame with the principle axes, we get the simple expression $ L_{a} = \operatorname{I}_{a} \omega_{a} $ with no summation implied over $ a $, e.g. $ L_{1} = I_{1}\omega_{1} $.
	
	 The equations of motion become
	\begin{align*}
		&I_{1}{\dot  {\omega }}_{{1}} + (I_{3}-I_{2}) \omega_{2} \omega_{3} = 0\\
		&I_{2}{\dot  {\omega}}_{{2}} + (I_{1}-I_{3}) \omega_{3} \omega_{1} = 0\\
		&I_{3}{\dot  {\omega }}_{{3}} + (I_{2}-I_{1}) \omega _{1} \omega_{2} = 0
	\end{align*}
	The equations are called the \textit{Euler equations}. They are the equations of motion for free rigid body rotating about its center of mass; you use them to calculate the body's angular velocity $ \bm{w} $ in the body-fixed frame. Since they really on $ \mat{I} $ being diagonal, they apply \textit{only} if the the body-fixed frame aligns with the system of principle of axes measured about the point of rotation. If the principle axes and body-fixed frame aren't aligned, you have to use the more general equation
	\begin{equation*}
		\bm{0} = \dv{{L}_{a}}{t} \e_{a} + L_{a}\bm{\omega} \cross \e_{a}
	\end{equation*}
	Here's a quick derivation of the Euler equations using column vectors. Note that $ \dv{L_{a}}{t} = \dv{}{t}[I_{a}\omega_{a}] = I_{a}\dot{\omega}_{a} $ because the $ I_{a} $ are constant in the body frame.
	\begin{align*}
		\bm{0} & = \dv{{L}_{a}}{t} \e_{a} + L_{a}\bm{\omega} \cross \e_{a} = I_{a}\dot{\omega}_{a} \e_{a} + I_{a}\omega_{a} \bm{\omega}\cross \bm{e}_{a}\\
		&=\begin{bmatrix}
			I_{1}\dot{\omega}_{1}\\
			I_{2}\dot{\omega}_{2}\\
			I_{3}\dot{\omega}_{3}
		\end{bmatrix} + I_{1}\omega_{1} 
		\begin{bmatrix}
			0\\
			\omega_{3}\\
			-\omega_{2}
		\end{bmatrix} + I_{2}\omega_{2} 
		\begin{bmatrix}
			-\omega_{3}\\
			0\\
			\omega_{1}
		\end{bmatrix} + I_{3}\omega_{3} 
		\begin{bmatrix}
			\omega_{2}\\
			-\omega_{1}\\
			0
		\end{bmatrix}\\
		&=
		\begin{bmatrix}
			I_{1}{\dot  {\omega }}_{{1}} + (I_{3}-I_{2}) \omega_{2} \omega_{3}\\
			I_{2}{\dot  {\omega}}_{{2}} + (I_{1}-I_{3}) \omega_{3} \omega_{1}\\
			I_{3}{\dot  {\omega }}_{{3}} + (I_{2}-I_{1}) \omega _{1} \omega_{2}
		\end{bmatrix}
		=
		\begin{bmatrix}
			0\\
			0\\
			0
		\end{bmatrix}
	\end{align*}

	
	\item We can also generalize Euler's equations to apply to a body acted on by an external torque $ \bm{M}$. Instead of starting with $ \bdot{L} = \bm{0} $ we start from $ \bdot{L} = \bm{M} $, expanding the vectors in the body-fixed frame and following an analogous derivation. The Euler equations with an external torque are
	\begin{align*}
		&I_{1}{\dot{\omega}}_{{1}} + (I_{3}-I_{2}) \omega_{2}\omega_{3} = M_1\\
		&I_{2}{\dot{\omega}}_{{2}} + (I_{1}-I_{3}) \omega_{3}\omega_{1} = M_2\\
		&I_{3}{\dot{\omega}}_{{3}} + (I_{2}-I_{1}) \omega_{1}\omega_{2} = M_3
	\end{align*}
	where $ M_{1}, M_{2} $ and $ M_{3} $ are the components of the torque in the body-fixed frame.
	
	\item I stress again that the Euler equations hold \textit{only} if the body-fixed frame aligns with the principle axes. The most general equation of motion for rigid body rotation is the vector equation
	\begin{equation*}
		\bm{M} = \dot{\bm{L}} = \dv{[\mathbf{I} \bm{\omega}]}{t}  = \mathbf{I} \dot{\bm{\omega}} + \bm{\omega} \cross (\mathbf{I} \bm{\omega})
	\end{equation*}
	where $ \mathbf{I} $ is the body's inertia tensor about the point of rotation, $ \bm{M} $ is the externally applied torque and $ \bm{\omega} $ is the body's angular velocity. Of course, all three quantities $ \mat{I}, \bm{\omega} $ and $ \bm{M} $ must be measured with respect to the same reference point. In the body-fixed system of principle axes, this equation simplifies to the Euler equations.

\end{itemize}

\iffalse
\vspace{2mm}
\textbf{Some Concepts to Know}
\begin{itemize}
	\item $ M_i = \dot{\bm{L}} \cdot \e_i \qquad \dot \e_i = \bm{\omega} \cross \e_i  $

	\item Rotation about a non-principle axis means that angular momentum changes with time.
	
	\item $ \bm{L}, \bm{\omega}, \e_{3} $ are coplanar for a symmetric free top.
	
	\item Dude. The angular velocity $ \bm{\omega} $ defines the instantaneous axis of rotation. Like, $ \bm{\omega} $ \textit{is} the axis of rotation. 
\end{itemize}
\fi


\subsection{Motion of the Free Top}
A free top is fancy name for a freely rotating rigid body with no external torques acting on it. 
\subsubsection{Symmetric Free Top}
\begin{itemize}
	\item A \textit{symmetric top} is a rotating rigid body with two equal principle moments are equal to each other e.g. $ I_{1} = I_{2}$, while the third moment $ I_{3} $ is different from $ I_{1} $ and $ I_{2} $. The $ \e_{3} $ axis is the top's axis of symmetry, and is sometimes called the \textit{figure axis}.
	
	For a free symmetric top with $ I_{1} = I_{2} $, the Euler equations become
	\begin{align*}
		&I_{1}\dot {\omega }_{1}  = \omega_{2}\omega_{3} (I_{1}-I_{3})\\
		&I_{1}\dot  {\omega }_{2}  = - \omega_{3}\omega_{1} (I_{1}-I_{3})\\
		&I_{3}\dot{\omega}_{3} = 0
	\end{align*}
	$ \omega_{3} $ is the component (measured in the body-fixed system of principle axis) of the angular velocity  about the axis of symmetry $ \e_{3} $ and, from the third Euler equation $ I_{3} \dot{\omega}_{3} = 0$, is constant for a free symmetric top.
	
	The components $ \omega_{1} $ and $ \omega_{2} $ are given by the coupled first-order differential equations
	\begin{equation*}
		\dot \omega_{1} = \Omega\omega_{2} \eqtext{and} \dot \omega_{2} = - \Omega \omega_{1} \qquad \text{where} \ \Omega = \frac{(I_{1} - I_{3})}{I_{1}} \omega_{3}
	\end{equation*}
	The equations are solved by 
	\begin{equation*}
		\omega_{1} = \omega_{0}\sin \Omega t \eqtext{and} \omega_{2} = \omega_{0}\cos \Omega t
	\end{equation*}
	This solution has a nice physical interpretation: in the body-fixed frame, the free top's angular velocity vector $ \bm{\omega} $ precesses about the figure axis $ \e_{3} $ with angular frequency $ \Omega $. The direction of $ \bm{\omega} $'s rotation depends on the sign of $ \Omega $ and thus on whether $ I_1 > I_{3} $ or $ I_{3} > I_{1} $. The precession of $ \bm{\omega} $ about the figure axis $ \e_{3} $ in the body-fixed frame is sometimes called \textit{wobble}.
	
	\item What would we see in the lab frame? We know the angular momentum $ \bm{L} $ is constant since the top is free. More so, $ \omega_{3} $ is constant, so $ L_{3} = I_{3} \omega_{3} $ is also constant. Since both $ \bm{L} $ and $ L_{3} $ are constant, the angle between the figure axis $ \e_{3} $ and angular momentum $ \bm{L} $ is constant. The figure axis $ \e_{3} $ thus precesses about the fixed angular momentum $ \bm{L} $, while the body rotates so that $ \bm{\omega} $ remains between $ \e_{3} $ and $ \bm{L} $. \href{https://www.youtube.com/watch?v=s9wiRjUKctU} {Click here for a nice animation}.
	
\end{itemize}

\subsubsection{Stability and Perturbations of The Asymmetric Top}
\begin{itemize}
	\item An asymmetric topic basically means a rigid body without any symmetries. This means none of the principal moments of inertia are equal, i.e. $ I_{1} \neq I_{2} \neq I_{3} \neq I_{1} $. The rotational motion of an asymmetric top is much more complicated than a free top's. 
	
	\item We will analyze only a simple case: when the a free asymmetric top rotating about a principle axis of inertia, e.g. $ \e_{1} $ so $ \bm{\omega} $ and $ \e_{1} $ have the same direction. In this case, in the body-fixed system of principle axes
	\begin{equation*}
		w_{1} = \Omega \eqtext{and} \omega_{2} = \omega_{3}
	\end{equation*}
	This solves Euler's equations. 
	
	\item We then ask what happens if the top's angular velocity is displaced slightly from the principle axis $ \e_{1} $, considering small perturbations about the angular velocity of the form
	\begin{equation*}
		\omega_{1} = \Omega + \eta_{1} \qquad \omega_{2} = \eta_{2} \qquad \omega_{3} = \eta_{3}
	\end{equation*}
	where the $ \eta_{a} = \eta_{a}(t) $ and $ \eta_{a} \ll \Omega $. We then substitute the $ \omega_{a} $ into the Euler equations. Since the $ \eta_{a} $ are small, we ignore terms of order $ \eta_{2} $ and higher, e.g. $ \eta_{2}\eta_{3} \approx 0 $ in the first equation. The result is
	\begin{align*}
		&I_{1}\dot{\eta}_{1} = 0\\
		&I_{2}\dot{\eta}_{2} = \Omega \eta_{3}(I_{1} - I_{3})\\
		&I_{3}\dot{\eta}_{3} = \Omega \eta_{2}(I_{2} - I_{1})
	\end{align*}
	Differentiating the second equation and solving for $ \dot{\eta}_{3} $, then substituting $ \dot{\eta}_{3} $ into the third equation gives
	\begin{equation*}
		I_{2} \ddot{\eta}_{2} = \frac{\Omega^{2}}{I_{3}} (I_{1} - I_{2})(I_{3} - I_{1}) \eta_{2} \equiv A \eta_{2}
	\end{equation*}
	Which has the familiar form $ \ddot{x} = k x $. The stability of the perturbation depends on the sign of $ A $:
	\begin{itemize}
		\item If $ A < 0 $ the disturbance will oscillate around the position of constant motion.
		\item If $ A > 0 $ the disturbance will grow exponentially, and the system is unstable.
	\end{itemize}
	From the definition $ A \equiv \frac{\Omega^{2}}{I_{3}} (I_{1} - I_{2})(I_{3} - I_{1})  $, the system is unstable ($ A > 0 $) if 
	\begin{equation*}
		I_{2} < I_{1} < I_{3} \eqtext{or} I_{3} < I_{1} < I_{2}
	\end{equation*}
	while all other possibilities are stable. Physically, this means a body will rotate stably about the principle axis with the largest or the smallest moment of inertia, but not about the intermediate axis.
	
	
	
\end{itemize}


\subsection{Euler Angles}


\begin{itemize}

	\item Informally, Euler angles are just coordinates well-suited to describing the dynamics of a rigid body. 
	
	More exactly, the Euler angles are a way of parametrizing the rotation $ \mat{R} $ from the inertial lab frame $ \{\tilde{\e}_{a} \} $ to the body-fixed frame $ \{\e_{a}\} $, which is discussed at the beginning of the chapter. The angles describe how the body-fixed system of principal axes of a rigid body is oriented relative to an inertial lab frame. 
	
	The Euler angles rest on theoretical framework of  \textit{Euler's theorem}, which tells us:
	\begin{quote}
		An arbitrary rotation in three dimensions cam be expressed as the product of 3 successive rotations about 3 (in general) different axes.
	\end{quote}

	
	\item Calling on Euler's theorem, we can get from the inertial lab system $ \{ \tilde{\e}_{a} \} $ to the body-fixed system $ \{\e_{a}\} $ in three steps, using the rotations $ \operatorname{R}_{3}(\phi), \operatorname{R}_{1}(\theta) $ and $ \operatorname{R}_{3}(\psi) $
	\begin{equation*}
		\{\tilde{\e}_{a} \} \stackrel{\operatorname{R}_{3}(\phi)}{\to} \{\e_{a}' \} \stackrel{\operatorname{R}_{1}(\theta)}{\to} 
		\{\e_{a}'' \} \stackrel{\operatorname{R}_{3}(\psi)}{\to} \{\e_{a} \}
	\end{equation*}
	where $ \operatorname{R}_{a}(\phi) $ means a rotation about the $ a $th basis vector by the angle $ \phi $, e.g. $ \operatorname{R}_{3}(\phi) $ means a rotation about $ \tilde{\e}_{3} $ by the angle $ \phi $. The angles of rotation $ \phi, \theta $ and $ \psi $ are called the \textit{Euler angles}. The three steps in explained in more detail below:
	\begin{enumerate}
		\item Rotate about $ \tilde{\e}_{3} $ by the angle $ \phi $. $ \phi $ is called the precession angle. We have
		\[
			\e_{a}' = \operatorname{R}_{3}(\phi)_{ab} \tilde{\e}_{b} \qquad \mathbf{R}_{3} (\phi) = 
			\begin{bmatrix}
				\cos \phi & \sin \phi & 0\\
				- \sin \phi & \cos \phi & 0\\
				0 & 0 & 1
			\end{bmatrix}
		\]
		
		\item Rotate about $ \e'_{1} $ by the angle $ \theta $. $ \theta $ is called the nutation angle.
		\[
			\e_{a}'' = \operatorname{R}_{1}(\theta)_{ab} \e'_{b} \qquad \mathbf{R}_{1} (\theta) = 
			\begin{bmatrix}
				1 & 0 & 0\\
				0 & \cos \theta & \sin \theta\\
				0 & - \sin \theta & \cos \theta\\
			\end{bmatrix}
		\]

		\item Rotate about $ \e''_{3} $ by angle $ \psi $ to reach the body-fixed frame $ \{\e_{a} \} $. $ \psi $ corresponds to rotation of the body about its figure axis.
		\[
			\e_{a} = \operatorname{R}_{3}(\psi)_{ab} \e''_{b} \qquad \mathbf{R}_{3} (\psi) = 
			\begin{bmatrix}
				\cos \psi & \sin \psi & 0\\
				- \sin \psi & \cos \psi & 0\\
				0 & 0 & 1
			\end{bmatrix}
		\]
	\end{enumerate}
	
	\item The angles $ \phi, \theta, \psi $ are the Euler angles. The complete rotation matrix transforming from the lab frame to the body-fixed frame is
	\begin{equation*}
		\mathbf{R}(\phi, \theta, \psi) = \mathbf{R}_{3}(\psi) \mathbf{R}_{1} (\theta) \mathbf{R}_{3}(\phi) \eqtext{and} \e_{a} = \operatorname{R}_{ab}(\phi, \theta, \psi) \tilde{\e}_{b}
	\end{equation*}
	In full, the matrix reads
	\[
		\hspace{-15mm}\mathbf{R}(\phi, \theta, \psi) =
		\begin{bmatrix}
			\cos \psi \cos \phi - \cos \theta \sin \phi \sin \psi & \sin \phi \cos \psi + \cos \theta \sin \psi \cos \phi & \sin \theta \sin \psi\\
			- \cos \phi \sin \psi - \cos \theta \cos \psi \sin \phi & - \sin \psi \sin \phi + \cos \theta \cos \psi \cos \phi & \sin \theta \cos \psi \\
			\sin \theta \sin \phi & - \sin \theta \cos \phi & \cos \theta
		\end{bmatrix}
	\]
	
	\item To expand a vector $ \bm{r} $ in the body frame: $ \bm{r} = r_{a} \e_{a} $. 
	
	To expand $ \bm{r} $ in the lab frame: $ \bm{r} = \tilde{r}_{a} \tilde{\e}_{a}$ where $ \tilde{r}_{b} = r_{a}\operatorname{R}(\phi, \theta, \psi)_{ab} $
\end{itemize}

\subsubsection{Angular Velocity and Kinetic Energy}
The goal is to write $ \bm{\omega} $ in the body fixed system in the form $ \bm{\omega} = w_1 \e_1 + w_2 \e_2 + w_3 \e_3 $ where $ \omega_{x,y,z} = \omega_{x,y,z}(\phi, \theta, \psi) $ are written in terms of the Euler angles.
\begin{itemize}
	\item By the construction of the Euler angles, the angular velocity can be written
	\begin{equation*}
		\bm{\omega} = \dot{\phi} \tilde{\e}_{3} + \dot{\theta} \e'_{1} + \dot{\psi} \e_{3}
	\end{equation*}
	where the basis vectors are the axes of rotation in each step of the Euler angles: $ \tilde{\e}_{3} $ is the lab-frame $ z $ axis, $ \e_{1}' $ is the intermediate $ x' $ axis after the first rotation, and $ \e_{3} $ is the object's figure axis.
	
	\item In terms of the body-fixed frame $ \{\e_{a} \} $, the basis vectors $ \tilde{\e}_{3}, \e_{1}' $ and $ \e_{3} $  read
	\begin{align*}
		&\tilde{\e}_{3} = \sin \theta \sin \psi \e_{1} + \sin \theta \cos \psi \e_{2} + \cos \theta \e_{3}\\
		&\e_{1}' = \cos \psi \e_{1} - \sin \psi \e_{2}\\
		&\e_{3} = \e_{3}
	\end{align*}
	\vspace{-10mm} % the dots take up too much vertical space!
	\item Plugging the basis vectors into $ \bm{\omega} = \dot{\phi} \tilde{\e}_{3} + \dot{\theta} \e'_{1} + \dot{\psi} \e_{3} $ and grouping like terms produces
	\begin{equation*}
		\bm{\omega} = (\dot \phi \sin \theta \sin \psi + \dot{\theta} \cos \psi) \e_{1} + (\dot{\phi} \sin \theta \cos \psi - \dot{\theta} \sin \psi) \e_{2} + (\dot{\phi } \cos \theta + \dot{\psi} ) \e_{3}
	\end{equation*}
	the desired expression for angular velocity in the body-fixed system.	

\end{itemize}

\textbf{Kinetic Energy}: In terms of Euler angles \textit{in a body-fixed system in which the inertia tensor is diagonal}, the body's kinetic energy reads
\begin{equation*}
	T = \frac{1}{2}\left(I_{x} \omega_{x}^2 + I_{y} \omega_{y}^{2} + I_{z} \omega_{z}^{2}\right)
\end{equation*}
where $ \omega_{x}, \omega_{y}, \omega_{z} $ are given in terms of the Euler angles as above. If additionally the top is symmetric so that $ \mathbf{I} = (I_1, I_1, I_3) $, the kinetic energy simplifies to
\begin{equation*}
	T = \frac{I_1}{2} \left (\dot{\phi}^2 \sin^2 \theta + \dot{\theta}^2\right ) + \frac{I_3}{2} \left (\dot{\phi} \cos \theta + \dot{\psi} \right )^2
\end{equation*}

\subsubsection{Free Symmetric Top In Terms of Euler Angles}
Earlier we analyzed the free symmetric top in the body-fixed frame $ \{\e_{a} \} $. This is take two, using the Euler angles and working in the \textit{lab} frame $ \{\tilde{e}_{a} \} $.
\begin{itemize}
	\item We choose the angular momentum $ \mathbf{L} $ to align with the $ \tilde{\e}_{3} $ axis. The top is free, so $ \bm{L} $ is conserved, as is the body-fixed frame component $ L_{3} = I_{3} \omega_{3} $; since both quantities are conserved, the angle between them is also conserved. 
	
	This angle is precisely the second Euler angle, i.e. the nutation angle $ \theta $, so $ \dot{\theta} = 0 $.
	
	\textit{A free symmetric top does not perform nutation when $ \bm{L} $ coincides with $ \tilde{e}_{3} $}.
	
	\item The next step is to use the Euler-angle expression for angular velocity to solve for $ \dot{\psi} $; the result is $ \dot{\psi} = \Omega \equiv \frac{(I_{1} - I_{3})}{I_{1}} \omega_{3}$, meaning the object rotates about its figure axis with angular frequency $ \Omega $.
	
	\item Finally, using $  \dot{\psi} = \Omega $ in the expression $ \omega_{3} = \dot{\phi} \cos \theta + \dot{\psi}  $, we solve for the precession frequency $ \dot{\psi} $. The result is
	\begin{equation*}
		\dot{\psi} = \frac{\omega_3 - \Omega}{\cos \theta} = \frac{I_{3} \omega_3}{I_1 \cos \theta} 
	\end{equation*}
\end{itemize}

\subsection{Heavy Symmetric Top}
A heavy top is a top acted on by gravity. Symmetric means that two of the principle moments of inertia are equal, so in the body-fixed system of principle axes we have $ \mathbf{I} = (I_1, I_1, I_3) $. This analysis assumes the top is fixed at some point (e.g. on the ground) a distance $ l $ from the center of mass.

\subsubsection{Lagrangian and Conserved Quantities}
\begin{itemize}
	\item The kinetic energy is $ T = \frac{1}{2}I_1(\omega_1 + \omega_2)^2 + \frac{1}{2}I_3 \omega_3^2 $ and the potential energy is $ V = mgl \cos \theta $. In terms of the Euler angles, the heavy symmetric top's Lagrangian is
	\begin{align*}
		L &= \frac{1}{2}I_1\left (\omega_1^{2} + \omega_2^{2}\right ) + \frac{1}{2}I_3 \omega_3^2  -  mgl \cos \theta\\
		&= \frac{1}{2} I_1\left (\dot{\phi}^2 \sin^2 \theta + \dot{\theta}^2\right ) + \frac{1}{2}I_3 \left (\dot{\phi} \cos \theta + \dot{\psi} \right )^2 -  mgl \cos \theta
	\end{align*}
	
	\item Both $ \phi $ and $ \psi $ are cyclic coordinates and lead to the conserved quantities
	\begin{align*}
		&p_{\phi} = I_1 \sin^{2}\theta \dot{\phi} + I_3 \cos \theta (\dot{\psi} + \dot{\phi} \cos \theta)\\
		&p_{\psi} = I_{3}\left(\dot{\psi} + \cos \theta \dot{\phi} \right) = I_3 \omega_3
	\end{align*}
	$ p_{\psi} $ is the top's angular momentum about the figure axis $ \e_{3} $. Like for the free symmetric top, the angular velocity component $ \omega_3 $  about the figure axis is constant. This makes sense; there is no external torque acting on the top about its figure axis. 
\end{itemize}

\textbf{Energy}
\begin{itemize}
	\item The top's total energy $ E = T + V $ is also conserved, as for any isolated mechanical system. For future use, we define the constants
	\begin{equation*}
		a = \frac{I_3}{I_1}\omega_3 \qquad b = \frac{p_{\phi}}{I_1}
	\end{equation*}
	In terms of $ a $ and $ b $, the derivatives $ \dot{\phi} $ and $ \dot{\psi} $ are
	\begin{equation*}
		\dot \phi = \frac{b-a\cos\theta}{\sin^2 \theta} \qquad \dot \psi = \frac{I_1a}{I_3} - \frac{(b- a\cos\theta)\cos \theta}{\sin^2 \theta}
	\end{equation*}
	If $ \theta = \theta(t) $ were known, we could theoretically integrate these two expressions to solve for $ \phi(t) $ and $ \psi(t) $. So the next step is to find $ \theta(t) $.
\end{itemize}

\textbf{Reduced Energy}
\begin{itemize}
	\item  We define a reduced energy $ E' $ via $ E = E' + \frac{1}{2}I_3 \omega_3^2 $. Since $ E, I_3 $ and $ \omega_3 $ are constant, $ E' $ is also constant.
	\begin{equation*}
		E' = \frac{1}{2}I_1 \dot{\theta}^2 + \veff(\theta), \qquad \veff(\theta) = \frac{I_1(b-a\cos \theta)^2}{2\sin^2 \theta} + mgl\cos \theta
	\end{equation*}
	We then introduce a new coordinate $ u = \cos \theta $, where $ u \in [-1, 1] $ because $ \theta \in [0, \pi] $, and two more constants
	\begin{equation*}
		\alpha = \frac{2 E'}{I_1} \eqtext{and} \beta = \frac{2mgl}{I_1}
	\end{equation*}
	
	\item The equations of motion for $ u = \cos \theta, \phi, \psi $ can now be written
	\begin{align*}
		& \dot{u}^2  = (1-u^{2})(\alpha - \beta u) - (b - a u)^2 \equiv f(u)\\
		&\dot{\phi} = \frac{b-au}{1-u^2}\\
		&\dot{\psi} = \frac{I_1a}{I_3} - \frac{u(b-au)}{1-u^2}
	\end{align*}
	In theory, the equation for $ \dot{u}^{2} $ could be solved analytically in terms of elliptic integrals, and then the time dependence of $ \theta $ could be implicitly extracted using $ u = \cos \theta $. With $ \theta $ in hand, we could then solve for $ \phi $ and $ \psi $.
	
	\item But there's a better, more physical, approach: using the function $ f(u) $ as a tool to analyze the nutation angle $ \theta $. Notice that $ \dot{u}^{2} = f(u) $ behaves as a cubic polynomial in $ u $. A quick look at the limits $ u \to \pm \infty $ shows 
	\begin{equation*}
		f(u) \to 
		\begin{cases}
			+ \infty \text{ as } u \to \infty\\
			- \infty \text{ as } u \to -\infty
		\end{cases}
	\end{equation*}
	Also important is the behavior at $ \pm 1 $:
	\begin{equation*}
		f(\pm 1) = - (b \mp a)^{2} \leq 0
	\end{equation*}
	Although $ f(u) $ is mathematically defined on the entire real line, the region of \textit{physical} interest is, happily, much smaller. Values of $ u $ are constrained to positive values of $ f(u) = \dot{u}^2 $ (corresponding to real values of $ \dot{u} $) in the region $ u \in [-1, 1] $ (because $ \abs{u} = \abs{\cos \theta} \leq 1$). 
	
	We'll study three special cases of motion in the next three subsections.
	
\iffalse	
	There are three main cases of physical motion depending on the sign of $ \dot{\phi} $ at $ f(u) $'s roots $ u_{1} $ and $ u_{2} $.
	\begin{enumerate}
		\item $ \dot{\phi}(u_1) > 0 $ and $ \dot{\phi}(u_2) > 0 $ 
		\item $ \dot{\phi}(u_1) > 0 $ and $ \dot{\phi}(u_2) < 0 $ 
		\item $ \dot{\phi}(u_1) > 0 $ and $ \dot{\phi}(u_2) = 0 $ 
	\end{enumerate}
\fi
\end{itemize}

\subsubsection{Letting the Top Go}
\begin{itemize}
	\item In this case, sometime called the ``released top'', we spin the top about its axis of symmetry and let it go at some angle $ \theta \neq 0 $ with $ \dot{\theta} = 0 $. The initial conditions are
	\begin{align*}
		&\dot{\theta}(0) = 0 \implies \dot{u}_{t=0}^{2} = 0 \implies f(u_{t=0}) = 0 \\
		&\dot{\phi}(0) = 0 \implies b - au_{t=0} = 0 \implies u_{t=0} = \frac{b}{a}
	\end{align*}
	
	\item Recall the quantity $ p_{\phi} = I_{1} \dot{\phi} \sin^{2} \theta + I_{3} \omega_{3} \cos \theta $ is a constant of motion. Evaluating $ p_{\phi} $ at $ t = 0 $ when $ \dot{\phi} = 0 $ and $ \theta = \theta_{0} $ gives the relationship
	\begin{equation*}
		p_{\phi} = I_{1} \dot{\phi} \sin^{2} \theta + I_{3} \omega_{3} \cos \theta = I_{3} \omega_{3} \cos \theta_{0}
	\end{equation*}
	This is enough to determine the qualitative motion of the top. When released, it starts to fall under the influence of gravity, so $ \theta $ increases. As the top falls and $ \theta $ increases (and thus $ I_{3}\omega_{3} \cos \theta $ decreases) the term $ I_{1}\dot{\phi}\sin^{2}\theta $ must increase to keep $ p_{\phi} $ constant, resulting as an increase in $ \dot \phi $. 
	
	More so, to keep the signs of $ \dot{\phi} $ and $ \omega_{3} $ balanced, the direction of precession must in the same as the direction of spin about the figure axis.
	
	
\end{itemize}

\subsubsection{Uniform Precession Without Nutation}
\begin{itemize}
	\item This means the tops spins uniformly without bobbing up and down. Mathematically, this means $ \dot{\phi} $ is constant (uniform precession) and $ \dot{\phi} = 0 $ (no nutation). 
	
	Recall the relationship $ \dot{\theta}^{2} = f(u) $. To satisfy $ \dot{\theta} = 0 $ for all time, we need $ f(u) $ to have only a single root $ u_{0} $ and no other values of $ f(u) $ in the physical range $ u \in [-1, 1] $ and $ u \geq 0 $ which constrains the top's physical motion to a single point of constant $ \dot{\theta} = 0 $. The root must satisfy
	\begin{align*}
		f(u_{0}) = (1 - u_{0}^{2})(\alpha - \beta u_{0}) - (b- au_{0})^{2} = 0\\
		f'(u_{0}) = -2u_{0}(\alpha - \beta u_{0}) - \beta(1 - u_{0}^{2}) + 2a(b - au_{0}) = 0
	\end{align*}
	Combining the equations gives the condition $ \frac{1}{2} \beta = a \dot{\phi} - \dot{\phi}^{2}u_{0} $, and substituting in the definitions $ I_{1}a = I_{3} \omega_{3} $ and $ \beta = \frac{2Mgl}{I_{1}} $ gives
	\begin{equation*}
		Mgl = \dot{\phi} (I_{3} \omega_{3} - I_{1}\dot{\phi}\cos \theta_{0}) 
	\end{equation*}
	
	\item Here is the physical interpretation: for a fixed value of $ \omega_{3} $ (the top's spin about its figure axis) and $ \theta_{0} $ (the angle from the vertical at which its released) there is an exact value of $ \dot{\phi} $ (a ``push'' in the direction of precession) for which the top will spin without nutation, i.e. satisfying $ Mgl = \dot{\phi} (I_{3} \omega_{3} - I_{1}\dot{\phi}\cos \theta_{0})  $.
	
	\item Because the condition $ Mgl = \dot{\phi} (I_{3} \omega_{3} - I_{1}\dot{\phi}\cos \theta_{0})  $ is quadratic in $ \dot{\phi} $, there are in principle two values of $ \dot{\phi} $ for which the top could precess without nutation.
	
	If you rearrange and calculate the discriminant, you'll see equation has real solutions for $ \dot{\phi} $ if
	\begin{equation*}
		\omega_{3} > \frac{2}{I_{3}}\sqrt{Mgl I_{1}\cos \theta_{0}}
	\end{equation*}
	In other words $ \omega_{3} $ must be large enough (the top must be spinning fast enough about its figure axis) to be able to precess without nutation at all. What happens when the top isn't spinning fast enough? It falls over!
	
\end{itemize}


\subsubsection{The Sleeping Top}

\begin{itemize}
	\item In this case, we start the top spinning in an upright position with $ \theta = \dot{\theta} = 0 $. When the top spins completely upright with $ \theta = 0 $, it is called a \textit{sleeping top}. But does the top stay there?
	
	Turning to the definitions $ \dot{u}^{2} = f(u) $ and $ u = \cos \theta $, the sleeping top conditions $ \theta = \dot{\theta} = 0 $ are met if $ u = 1 $ (for $ \theta = 0 $) and $ f(1) = 0 $ (for $ \dot{\theta} = 0 $).
	
	In these conditions $ a = b $ and $ \alpha = \beta $. Here's a quick confirmation; feel free to skip.
	\begin{align*}
		&a \big|_{\theta = 0} = \frac{I_{3}\omega_{3}\big|_{\theta = 0}}{I_{1}} = \frac{I_{3}(\dot{\psi} + \dot{\phi})}{I_{1}} = \frac{p_{\phi}\big|_{\theta = 0}}{I_{1}} = b \big|_{\theta = 0} \\
		&\alpha\big|_{\theta = 0} = \frac{2E' \big|_{\theta=0}}{I_{1}} = \frac{2(0 + Mgl)}{I_{1}} = \beta
	\end{align*}
	
	\item With $ a = b $ and $ \alpha = \beta $ the function $ f(u) $ simplifies to
	\begin{equation*}
		f(u) = (1-u)^{2}\left[\alpha(1-u)-a^{2}\right]
	\end{equation*}
	so $ f(u) $ has a double zero at $ u = + 1 $, while a second zero occurs at $ u_{2} = \frac{a^{2}}{\alpha - 1} $. There are two possibilities:
	\begin{itemize}
		\item If $ u_{2} > 1 $ (i.e. outside the region of physical motion) and $ \omega_{3}^{2} > \frac{4I_{1}Mgl}{I_{3}^{2}} $ the motion is stable: the only allowed physically allowed value of $ u $ corresponds to $ \theta = 0 $, since all other values of $ f(u) $ are either negative or occur outside of $ [-1, 1] $.
		
		For slight perturbations from the initial conditions, the nutation will stably oscillate with small displacements about $ \theta = 0 $. 
		
		\item If $ u_{2} < 1 $ (inside the region of physical motion) and $ \omega_{3}^{2} < \frac{4I_{1}Mgl}{I_{3}^{2}} $, their is a region of allowed physical motion to the left of the zero $ u = 1 $. The motion is unstable: if the top is displaced slightly from $ \theta = 0 $, it will fall off into the region of decreasing $ u $ and thus increasing $ \theta $.
		
	\end{itemize}
	Notice that the top is stable for fast spins $ \omega_{3} $ about the figure axis and unstable for slow spins. In practice, a sleeping top stays upright until $ \omega_{3} $ is slowed by friction to
	\begin{equation*}
		\omega_{3} = \frac{4I_{1}Mgl}{I_{3}^{2}} 
	\end{equation*}
	at which point the top starts to fall and precess.
	
	
\end{itemize}


\iffalse

\newpage
\section{Central Forces and the Two-Body Problem}

\subsection{Basic Principles, Concepts and Vocabulary}


\subsubsection{Copy and Paste Dump from Vaje}

\textbf{Lagrangian}
\begin{itemize}
	\item In general terms, the Lagrangian for a two-body system with potential $ V = V(r, \dot{r}) $ is
	\begin{align*}
		L(r, \dot r) = \frac{m_1 \dot{r}_1^2}{2} + \frac{m_2 \dot{r}_2^2}{2} - V(r, \dot{r})
	\end{align*}
	
	\item \textbf{TODO} How? In terms of relative position, the Lagrangian becomes
	\begin{align*}
		L(r, \dot r) = \frac{\mu \dot{r}^2}{2} + \frac{(m_1 + m_2)}{2}\dot{R}^{2}  - V(r, \dot{r})
	\end{align*}
	Note that $ R $ is a cyclic coordinate. This implies that $ p_R \equiv \pdv{L}{\dot R} = \dot{R}(m_1 + m_2)$ is constant.  This means that the center of mass is unaccelerated and we need only the $ \dot{r}^2 $ and $ U $ contributions of the Lagrangian.
	
	\item Apply the fact that $ \bm{F} $ is central, meaning we can write
	\begin{align*}
		\bm{F} = F \frac{\uvec{r}}{r} = - \grad{V(r, \dot{r})} = - \pdv{V}{r} \e_r
	\end{align*}
	In spherical coordinates, the Lagrangian becomes 
	\begin{align*}
		L = \frac{\mu}{2} \left(\dot{r}^2 + r^2 \dot{\theta}^2 + r^2 \sin^2 \theta \dot{\phi}^2 \right) - V(r)
	\end{align*}
	
	\item A central force implies the two bodies move in a plane. We can show this for example, via
	\begin{align*}
		&\bm{\tau} = \bm{r} \cross \bm{F} = \bm{r} \cross F \left(\frac{\uvec{r}}{r}\right) = \frac{F}{r} (\bm{r} \cross \uvec{r}) = 0\\
		&\dot{\bm{L}} = 0 \quad \implies \quad \bm{L} = \text{constant}
	\end{align*}
	If $ \bm{L} $ is constant, $ \bm{r} \cross \bm{p} $ must also be constant, implying $ \bm{r} $ and $ \bm{p} $ always lie in the same plane, meaning the motion is planar.
	
	\item Planar motion implies that with a proper choice of coordinate system (with $ \uvec{i} $ and $ \uvec{j} $ lying in the plane of motion), the polar angle is constant $ \theta = \frac{\pi}{2}$, implying $ \dot \theta = 0 $ and $ \sin \theta = 1 $. The Lagrangian further simplifies to 
	\begin{align*}
		L = \frac{\mu}{2} \left(\dot{r}^2 + r^2 \dot{\phi}^2 \right) - V(r)
	\end{align*}
	
	\item We note now that $ \phi $ is a cyclic coordinate and write
	\begin{align*}
		p_{\phi} \equiv \pdv{L}{\dot \phi} = \mu r^2 \dot \phi = \text{constant}
	\end{align*}
	In terms of $ p_{\phi} $, the Lagrangian for the two-body problem in a central field is
	\begin{align*}
		L(r, \dot{r}) = \frac{\mu \dot{r}^2}{2} + \frac{p_{\phi}^2}{2 \mu r^2} - V(r)
	\end{align*}
	This is a one-dimensional problem.
\end{itemize}

\textbf{Conserved Quantities}
\begin{itemize}
	\item Magnitude of angular momentum $ \abs{\bm{L}} = L_0 = p_{\phi} = \mu r^2 \dot{\phi} $
	
	\item Total energy $ H = \frac{\mu \dot{r}^2}{2} + \frac{p_{\phi}^2}{2 \mu r^2} + V(r) $
\end{itemize}

The quantity $ V_{ef}(r) \coloneqq \frac{p_{\phi}^2}{2 \mu r^2} + V(r)$ is called the effective potential. It is useful for determining orbits.

\subsubsection{The Actors and Parameters}
\begin{itemize}
	\item Two point bodies with masses $ m_1 $ and $ m_2 $. The bodies' positions from the origin are denoted by the position vectors $ \bm{r}_1 $ and $ \bm{r}_2 $, respectively.
	
	\item We introduce a few standard concept that are particular to the two-body problem that simplify things. These are:
	\begin{itemize}
		\item The \textit{relative position} of the bodies is $ \bm{r} = \bm{r}_2 - \bm{r}_1 $. We tend to work with the relative position rather than with the absolute position directly.
		
		\item A \textit{center of mass} with the position vector $ \displaystyle{\bm{R} = \frac{m_1 \bm{r}_1 + m_2 \bm{r}_2}{m_1 + m_2}} $ 
		
		\item A \textit{reduced mass} $ \displaystyle{\frac{1}{\mu} = \frac{1}{m_1} + \frac{1}{m_2} \quad \implies \quad \mu = \frac{m_1 m_2}{m_1 + m_2}} $.
		
		Note: if $ m_1 \gg m_2 $ then $ \mu \approx m_2 $ and $ \bm{R} \approx \bm{r}_1 $.
	\end{itemize}
	
	\item A \textit{central potential} $ V = V(r) $ that is dependent only on the relative separation of the two bodies.
	
	A resulting \textit{central force} $ \displaystyle{\bm{F} (\bm{r}) =  -\grad{V} = - \dv{V}{r} \frac{\bm{r}}{r}}$ that acts only along the direction of the relative position vector $ \bm{r} $.
	
	\textbf{Note:} Some texts define a central potential as $ V = V(r, \dot{r}) $, i.e. the potential is dependent on both the relative separation \textit{and} the relative velocity. I consider only $ V = V(r) $ because such potentials are frequently encountered in physics. 

\end{itemize}

Solving for the dynamics of two such bodies under the influence of the central force and potential described above is called the \textit{two-body problem}.

\subsubsection{Coordinate System and Planar Motion}

\begin{itemize}
	
	\item The motion of the two bodies occurs in a plane (in two dimensions). This plane is very often a conic section such as an ellipse or hyperbola.
	
	\item Conventional coordinate system: By convention, we let the vectors $ \e_x $ and $ \e_y $ span the plane of motion and the vector $ \e_z = \e_x \cross \e_y $ be normal to the plane.
	
	With this convention, the angular momentum vector has the same direction as $ \e_z $, namely $ \bm{L} = L \e_z $.
	
\end{itemize}

\subsubsection{Lagrangian in the Two-Body Problem}

The Lagrangian $ L $ (not to be confused with the magnitude of angular momentum---this should be clear from context) can be written in the simplified form
\begin{align*}
	L = \frac{\mu}{2} \abs{\dot{\bm{r}}}^2 - V(r)
\end{align*}
where $ r $ is the relative separation of the two bodies.

In polar coordinates, the Lagrangian is
\begin{align*}
	L = \frac{\mu}{2} \left( \dot{r}^2 + r^2 \dot{\phi}^2 \right) - V(r)
\end{align*}
where $ \phi $ is the polar angle of the relative position vector $ \bm{r} $.

\subsubsection{Conserved Quantities}
\begin{itemize}
	\item The  momentum of the center of mass $ \bm{P} = (m_1 + m_2) \dot{\bm{R}}  $ is constant. 
	
	This is because the center of mass $ \bm{R} $ is a cyclic coordinate in the Lagrangian, implying the center-of-mass momentum $ \bm{P} $ is constant. 
	
	We write
	\begin{align*}
		\dot{\bm{P}}(t) = \bm{0} \implies \bm{P}(t) = \bm{P}_0
	\end{align*}

	\item The angular momentum of the reduced mass $ \bm{L} = \mu \bm{r} \cross \bm{v} $ is constant. 
	

	That's because the torque $ \tau = \bm{r} \cross \bm{F} $ is zero with respect to the origin, so the angular momentum of the reduced mass $ \bm{L} $ is constant. 

	We write
	\begin{align*}
		\dot{\bm{L}}(t) = \bm{0} \implies \bm{L}(t) = \bm{L}_0
	\end{align*}


	Alternatively, the fact that $ \phi $ is a cyclic coordinate in the polar Lagrangian means that $ \bm{L} $ is constant. This lets us introduce the generalized momentum $ p_{\phi} $
	\begin{align*}
		p_{\phi} = \dv{L}{\dot{\phi}} = \mu \dot{\phi} r^2 = L_0
	\end{align*}
	Note that $ p_{\phi} $ corresponds directly to the conserved magnitude of angular momentum $ L_0 $.


	\item The total energy $ E = T + V $ of an isolated two-body system is conserved. 
	\begin{align*}
		\diff (T + V) = \diff E = 0 \implies E(t) = E_0 \equiv H
	\end{align*}
	
	 \textbf{TODO: Energy} Via integration the Euler-Lagrange Equations
	
\end{itemize}


\subsubsection{Kepler's Second Law}

Kepler's second law states that the rate at which area is swept out in a Kepler orbit (basically a central potential problem, so our ideas apply) is constant. The conservation of angular momentum offers a straightforward derivation. 

We apply the chain rule, write the area differential as $ \diff A = \frac{1}{2} r^2 \diff \phi $, and plug in the constant of motion $ L_0 \equiv p_{\phi} = \mu r^2 \dot{\phi} $ to get
\begin{align*}
	\dv{A}{t} = \dv{A}{\phi} \dv{\phi}{t} = \frac{1}{2} \frac{r^2 \diff \phi}{\diff \phi} \dot{\phi} = \frac{1}{2} r^2 \left(\frac{L_0}{\mu r^2}\right) = \frac{L_0}{2\mu} 
\end{align*}
\fi

\section{Hamiltonian Mechanics} \label{sec:hamilton}

\subsection{Hamilton's Equations}

\begin{itemize}
	\item The foundation of the Lagrangian formalism is the Lagrangian function $ L(q_{i}, \dot{q}_{i}, t) $ where $ q_{i},  i = 1, \dots, n $ are the $ n $ generalized coordinates describing our system. The equations of motion are
	\begin{equation*}
		\dv{}{t}\left(\pdv{L}{\dot{q}_{i}}\right) - \pdv{L}{q_{i}} = 0
	\end{equation*}
	In the Lagrangian formalism the equations of motion are $ n $ second order differential equations; for $ n $ second order equations we need $ 2n $ initial conditions to define our system; typically there are $ q_{i}(0) $ and $ \dot{q}_{i}(0) $. 
	
	\item The Hamiltonian formalism also uses $ n $ generalized coordinates $ q_{i} $. However, instead of the derivatives $ \dot{q}_{i} $, Hamiltonian mechanics uses the \textit{generalized momenta} 
	\begin{equation*}
		p_{i} \equiv \pdv{L}{\dot{q}_{i}}
	\end{equation*}
	Because they are derived from the Lagrangian, the generalized momenta are also functions of $ q_{i}, \dot{q}_{i} $ and $ t $; we have $ p_{i} = p_{i}(q_{j}, \dot{q}_{j}, t) $. 
	
	\item In terms of the generalized momenta $ p_{i} = \pdv{L}{\dot{q}_{i}} $ the Lagrangian equations of motion read
	\begin{equation*}
		\dv{}{t}(p_{i}) - \pdv{L}{q_{i}} = 0 \implies \dot{p}_{i} = \pdv{L}{q_{i}}
	\end{equation*}
	Notice we have eliminated the derivatives $ \dot{q}_{i} $ in favor of the momenta $ p_{i} $.
	
	\item A conceptual approach to what's going on: recall the set $ \{q_{i}\} $ defines a point in our system's $ n $-dimensional configuration space $ C $, and the time evolution of our system is represented by an $ n $-dimensional path in $ C $.
	
	However, the \textit{state} of the system is defined by both $ \{q_{i}\} $ and $ \{p_{i}\} $ in the sense that knowing both the coordinates and momenta allows us to determine the system's state at all future times. The pair $ \{q_{i}, p_{i} \} $ represents a point in our system's $ 2n $-dimensional \textit{phase space}. Knowing a single point in phase space  uniquely determines the system's evolution in time; since a point \textit{uniquely} defines the system's future, paths in phase space never cross.
\end{itemize}

\subsubsection{Mathematical Detour: The Legendre Transform}
\begin{itemize}
	\item We want to find a function defined on a system's phase space that will determine the unique evolution of $ q_{i} $ and $ p_{i} $. Such a function must naturally be a function of $ q_{i} $ and $ p_{i} $, but must contain the same information as the Lagrangian $ L(q_{i}, \dot{q}_{i}, t) $ (which we know also determines the system's time evolution). We create our desired function with a mathematical technique called the \textit{Legendre transform}. The Legendre transform goes something as follows:
	
	\item First, consider an arbitrary function $ f(x, y) $, so the total derivative is
	\begin{equation*}
		\diff f = \pdv{f}{x} \diff x + \pdv{f}{y} \diff y
	\end{equation*}
	Next we define a new function $ g(x, y, u) = ux - f(x, y)$ of three variables $ x, y $ and $ u $. The total derivative $ \diff g $ is
	\begin{equation*}
		\diff g = \diff [ux] - \diff f = u \diff x + x \diff u - \pdv{f}{x} \diff x - \pdv{f}{y} \diff y
	\end{equation*}
	
	\item The total derivative simplifies considerably for a special choice of $ u $. It is $ u(x, y) = \pdv{f}{x}$. In this case the terms $ u \diff x  $ and $ \pdv{f}{x} \diff x $ vanish. We have
	\begin{equation*}
		\diff g = x \diff u - \pdv{f}{y}\diff y
	\end{equation*}
	Notice that all instances of $ \diff x $ are gone; only $ \diff u $ and $ \diff y $ remain. In other words, $ g $ is naturally thought of as a function of only $ u $ and $ y $, i.e. $ g = g(u, y) $.
	
	\item To get an explicit expression for $ g(u, y) $, we first solve for $ x $ by inverting $ u(x, y) = \pdv{f}{x} $ to get $ x = x(u, y) $, then insert this into the definition $ g = ux - f $ to get
	\begin{equation*}
		g(u, y) = u x(u, y) - f(x(u, y), y)
	\end{equation*}
	This last result is the Legendre transform. It takes us from the function $ f(x, y) $ to the function $ g(u, y) $, eliminating the dependence on $ x $ with $ u(x, y) = \pdv{f}{x} $. 
	
	\item Importantly, the Legendre transform $ g $ preserves all information about the original $ f $. Concretely, we can recover $ f(x, y) $ from $ g(u, y) $ and $ u(x, y) = \pdv{f}{x} $ with
	\begin{equation*}
		\eval{\pdv{g}{u}}_{y} = x(u, y) \eqtext{and} 	\eval{\pdv{g}{y}}_{u} = - \pdv{f}{y}
	\end{equation*}
	which means the inverse Legendre transform
	\begin{equation*}
		f(x, y) = \left(\pdv{g}{u}\right) u - g(u, y)
	\end{equation*}
	recovers the original function $ f $.
\end{itemize}

\subsubsection{Hamilton's Equations of Motion}
\begin{itemize}
	\item The Lagrangian $ L(q_{i}, \dot{q}_{i}, t) $ was a function of the system's coordinates, their time derivatives, and possible time. In Hamiltonian mechanics, the Lagrangian is replaced by the \textit{Hamiltonian}, which is a Legendre transform of $ L $ to eliminate $ \dot{q}_{i} $ defined as
	\begin{equation*}
		H(q_{i}, p_{i}, t) = \sum_{i=1}^{n} p_{i}\dot{q}_{i} - L(q_{i}, \dot{q}_{i}, t) 
	\end{equation*}
	
	\item Where do we see the elimination of $ q_{i} $? Returning to the Einstein summation notation we have
	\begin{equation*}
		\diff H = p_{i} \diff \dot{q}_{i} + \dot{q}_{i} \diff p_{i} - \left(\pdv{L}{q_{i}}\diff q_{i} + \pdv{L}{\dot{q}_{i}}\diff \dot{q}_{i} + \pdv{L}{t}\diff t\right)
	\end{equation*}
	From the construction $ p_{i} = \pdv{L}{\dot{q}_{i}} $, the terms $ p_{i} \diff \dot{q}_{i} $ and $ - \pdv{L}{\dot{q}_{i}}\diff \dot{q}_{i} $ cancel. We have
	\begin{equation*}
		\diff H = \dot{q}_{i} \diff p_{i} - \pdv{L}{q_{i}}\diff q_{i} - \pdv{L}{t}\diff t
	\end{equation*}
	and indeed we see $ H = H(q_{i}, p_{i}, t) $. More so, we can compare our expression for $ \diff H $ to the general total differential $ \diff H = \pdv{H}{q_{i}} \diff q_{i} + \pdv{H}{p_{i}} \diff p_{i} + \pdv{H}{t} \diff t$ to conclude
	\begin{equation*}
		\pdv{H}{p_{i}} = \dot{q}_{i} \qquad \pdv{H}{t} = -\pdv{L}{t} \qquad \pdv{H}{q_{i}} = - \pdv{L}{q_{i}} = - \dv{}{t}\left(\pdv{L}{\dot{q}_{i}}\right) \equiv - \dot{p}_{i}
	\end{equation*}
	where we use the Euler-Lagrange equations $ \pdv{L}{q_{i}} = \dv{}{t}\left(\pdv{L}{\dot{q}_{i}}\right) $ in the last equality.
	
	\item The last results are important: they are the equations of motion in the Hamiltonian formalism. They are most commonly written
	\begin{equation*}
		 \dot{q}_{i} = \pdv{H}{p_{i}} \qquad \dot{p}_{i} = - \pdv{H}{q_{i}} 
	\end{equation*}
	Note that the Hamiltonian formalism replaces the Lagrangian's $ n $ second order differential equations with $ 2n $ first order equations for $ q_{i} $ and $ p_{i} $.
\end{itemize}

\subsubsection{Examples Using the Hamiltonian Equations of Motion}
\textbf{A Particle in a Potential Field}
\begin{itemize}
	\item The generalized coordinate is simply the position vector $ \bm{r} = (x, y, z) $ and the Lagrangian $ L $ is
	\begin{equation*}
		L = \frac{1}{2}m\dot{\bm{r}}^{2} - V(\bm{r})
	\end{equation*}
	
	\item The conjugate momenta $ p = \pdv{L}{\dot{q}} $ are
	\begin{equation*}
		\bm{p} = m \dot{\bm{r}}
	\end{equation*}
	which in this case coincides with the usual definition of momentum.
	
	\item The Hamiltonian $ H = p_{i}\dot{q}_{i} - L $ is
	\begin{equation*}
		H = \bm{p}\cdot \dot{\bm{r}} - \left(\frac{1}{2}m\dot{\bm{r}}^{2} - V(\bm{r})\right) = \frac{\bm{p}^{2}}{2m} + V(\bm{r})
	\end{equation*}
	Notice the Hamiltonian is written as a function of $ \bm{p} $ in favor of $ \dot{\bm{q}} $.
	
	\item The Hamiltonian equations of motion are 
	\begin{equation*}
		\bdot{r} = \pdv{H}{\bm{p}} = \frac{\bm{p}}{m} \eqtext{and} \bdot{p} = - \pdv{H}{\bm{r}} = - \grad V
	\end{equation*}
	These equations are familiar; the first is the definition of momentum $ \bm{p} = m \bdot{r} $ while the second is Newton's second law of motion for a particle in a potential field.

\end{itemize}

\textbf{A Charged Particle in an Electromagnetic Field}

\smallskip
Here is the charged particle in an EM field \`{a} la Hamilton. We studied the Lagrangian approach in Subsection \ref{ssec:lag:em_lag}
\begin{itemize}
	\item Recall that electric field $ \bm{E} $ and magnetic field $ \bm{B} $ can be written in terms of a scalar potential $ \phi(\bm{r}, t) $ and a vector potential $ \bm{A}(\bm{r}, t) $
	\begin{equation*}
		 \bm{E} = -\grad{\phi} - \pdv{\bm{A}}{t} \eqtext{and} \bm{B} = \cross \bm{A} 
	\end{equation*} 
	The Lagrangian for a particle of charge $ e $ in an EM field is
	\begin{equation*}
		L = \frac{1}{2}m \bdot{r}^{2} - e(\phi - \bdot{r}\cdot \bm{A})
	\end{equation*}
	while the momentum $ \bm{p} $ conjugate to the position $ \bm{r} $ is
	\begin{equation*}
		\bm{p} = \pdv{L}{\bdot{r}} = m \bdot{r} + e\bm{A}
	\end{equation*}
	
	\item Inverting the expression for $ \bm{p} $ gives us
	\begin{equation*}
		\bdot{r} = \frac{1}{m}(\bm{p}-e\bm{A})
	\end{equation*}
	from which we can calculate the Hamiltonian
	\begin{align*}
		H(\bm{p}, \bm{r}) &= \bm{p} \bdot{r} - L = \frac{\bm{p} }{m}(\bm{p} - e\bm{A}) - \left[\frac{1}{2m} (\bm{p} - e\bm{A})^{2} - e \phi + \frac{e}{m}(\bm{p} - e\bm{A})\cdot \bm{A} \right]\\
		&=\frac{1}{2m}(\bm{p}^{2} - 2e \bm{p}\cdot \bm{A} + e^{2}\bm{A}^{2}) + e \phi\\
		&=\frac{1}{2m}(\bm{p} - e \bm{A})^{2} + e \phi
	\end{align*}
	
	\item The first equation of motion is
	\begin{equation*}
		\bdot{r} = \pdv{H}{\bm{p}} = \frac{1}{m}(\bm{p} - e \bm{A})
	\end{equation*}
	The equation for $ \bdot{p} = - \pdv{H}{\bm{r}} $ is best given in terms of indices and components
	\begin{equation*}
		\dot{p}_{a} = - \pdv{H}{r_{a}} = \frac{e}{m}(p_{b} - eA_{b}) \pdv{A_{b}}{r_{a}} - e \pdv{\phi}{r_{a}}
	\end{equation*}
	some manipulation of the indices and the definition of the cross product in component form shows this is equivalent to the Lorentz force $ \bm{F} = e(\bm{E} - \bm{v} \cross \bm{B}) $.
\end{itemize}
We now consider a concrete example of a particle in a uniform one-directional magnetic field $ \bm{B} = (0, 0, B) $.
\begin{itemize}
	\item The magnetic field $ \bm{B} = (0, 0, B) $ corresponds to a vector potential
	\begin{equation*}
		\bm{A} = (-By, 0, 0)
	\end{equation*}
	Consider a particle moving in the $ (x,y) $ plane. Then $ \bm{p} = (p_{x}, p_{y}, 0) $ and the Hamiltonian is
	\begin{align*}
		H &= \frac{1}{2m}\left[p_{x}^{2} + p_{y}^{2} + 2ep_{x}B y + e^{2}B^{2}y^{2}\right]\\
		&=\frac{1}{2m}(p_{x} + e By)^{2} + \frac{p_{y}^{2}}{2m}
	\end{align*}
	
	\item The equations of motion are
	\begin{align*}
		&\dot{x} = \pdv{H}{p_{x}} = \frac{1}{m} (p_{x} + e By) \qquad \dot{y} = \pdv{H}{p_{y}} = \frac{p_{y}}{m} \qquad \dot{z} = 0\\
		&\dot{p}_{y} = - \pdv{H}{y} = -\frac{eB}{m}(p_{x} + eBy) \qquad \dot{p}_{x} = \dot{p}_{z} = 0
	\end{align*}
	
	\item Next, we note that
	\begin{equation*}
		eBx + m\dot{y} = \text{constant} \equiv a  \eqtext{and}
		p_{x} = m\dot{x} - eBy = \text{constant} \equiv b
	\end{equation*}
	The first equality can be found by combining the equations for $ \dot{x} $ and $ \dot{p}_{y} $, integrating and using $ p_{y} = m \dot{y} $; the second e.g. by definition $ p_{x} = \pdv{L}{\dot{x}} $ from the Lagrangian. 
	
	\item The result is a simple system of coupled LDEs for $ x $ and $ y $
	\begin{equation*}
		m\dot{y} + eBx = a \eqtext{and} m\dot{x} - eBy = b
	\end{equation*}
	The system is essentially a harmonic oscillator; the solution is sinusoidal
	\begin{equation*}
		x = \frac{a}{eB} + R \sin (\omega(t - t_{0})) \eqtext{and} y = -\frac{b}{eB} + R \cos (\omega(t - t_{0}))
	\end{equation*}
	where $ a, b, R $ and $ t_{0} $ determined by the initial conditions. The particle makes circles of radius $ R $ in the $ (x, y) $ plane at the \textit{cyclotron frequency}
	\begin{equation*}
	 	\omega = \frac{eB}{m}
	\end{equation*}
\end{itemize}
 This magnetic field corresponds to the vector potential 




\subsubsection{Hamiltonian Mechanics and Conservation Laws}
We return briefly to two of conservation laws and associated constants of motion that we introduced in Lagrangian mechanics. These conservation laws are often simple to see the Hamiltonian formalism.
\begin{itemize}
	\item If the Hamiltonian $ H $ is not explicitly time dependent (i.e. $ \pdv{H}{t} = 0 $) then $ H $ is a constant of motion (i.e. $ \dv{H}{t} = 0 $).
	\begin{align*}
		\dv{H}{t} = \pdv{H}{q_{i}} \dot{q}_{i} + \pdv{H}{p_{i}} \dot{p}_{i} + \pdv{H}{t} = -p_{i} \dot{q}_{i} + \dot{q}_{i} p_{i} + \pdv{H}{t} = \pdv{H}{t} 
	\end{align*}
	The equality $ \dv{H}{t} = \pdv{H}{t} $ means $ \pdv{H}{t} = 0 \implies  \dv{H}{t} = 0 $. 
	
	\item If an ignorable (aka cyclic) coordinate $ q $ doesn't appear in the Lagrangian, the conjugate momentum $ p_{q} = \pdv{L}{\dot{q}} $ is a constant of motion. Because $ q $ doesn't appear in the Lagrangian it certainly doesn't appear in the Hamiltonian, which is constructed from the Lagrangian, so $ \pdv{H}{q} = 0 $. We then have
	\begin{equation*}
		\dot{p}_{q} \equiv \pdv{H}{q} = 0
	\end{equation*}
	so $ p_{q} $ is a constant of motion.
\end{itemize}

\subsubsection{Principle of Least Action \'{a} la Hamilton}
\begin{itemize}
	\item In Lagrangian mechanics we defined action as 
	\begin{equation*}
		S = \int_{t_{1}}^{t_{2}} L(q_{i}, \dot{q}_{i}, t) \diff t = 0
	\end{equation*}
	and then derived the Lagrange equations of motion from the least action principle by requiring that $ \delta S = 0 $ for all paths with fixed endpoints so that $ \delta q_{i}(t_{1}) = \delta q_{i}(t_{2}) = 0 $.
	
	\item In the Hamiltonian formalism, we define action as
	\begin{equation*}
		S = \int_{t_{1}}^{t_{2}}(p_{i}\dot{q}_{i} - H(q_{i}, p_{i}, t))
	\end{equation*}
	where $ \dot{q}_{i} = \dot{q}_{i}(q_{i}, p_{i}) $.
	
	We then consider varying $ q_{i} $ and $ p_{i} $ \textit{independently}, whereas in the Lagrangian formalism a variation of $ q_{i} $ lead to a variation of $ \dot{q}_{i} $. The independent approach makes sense: a theme of the Hamiltonian approach is treating $ q_{i} $ and $ p_{i} $ on equal footing. We have
	\begin{equation*}
		\delta S = \int_{t_{1}}^{t_{2}} \left[\delta p_{i} \dot{q}_{i} + p_{i} \delta \dot{q}_{i} - \pdv{H}{q_{i}}\delta q_{i} - \pdv{H}{p_{i}}\delta p_{i}\right] \diff t
	\end{equation*}
	Adding and subtracting $ \dot{p}_{i}\delta q_{i} $ in the integrand and factoring gives
	\begin{equation*}
			\delta S = \int_{t_{1}}^{t_{2}} \left[\left(\dot{q}_{i} - \pdv{H}{p_{i}}\right)\delta p_{i} + \left(-\dot{p}_{i} - \pdv{H}{p_{i}}\right)\delta q_{i} +  \{ p_{i}\delta \dot{q}_{i} + \dot{p}_{i} \delta q_{i}  \} \right] \diff t
	\end{equation*}
	
	\item The last term in the curly brackets can be written as $ \dv{}{t}[p_{i}\delta q_{i}] $ and integrated:
	\begin{equation*}
		\delta S = \int_{t_{1}}^{t_{2}} \left[\left(\dot{q}_{i} - \pdv{H}{p_{i}}\right)\delta p_{i} + \left(-\dot{p}_{i} - \pdv{H}{p_{i}}\right)\delta q_{i} \right] \diff t + \big[p_{i}\delta q_{i} \big]_{t_{1}}^{t_{2}}
	\end{equation*}
	
	\item Hamilton's equations await us in the large parentheses. If we look for extrema $ \delta S = 0 $ that hold for all $ \delta p_{i} $ and $ \delta q_{i} $ we must have
	\begin{equation*}
		\left(\dot{q}_{i} - \pdv{H}{p_{i}}\right) = 0 \eqtext{and} \left(-\dot{p}_{i} - \pdv{H}{p_{i}}\right) = 0
	\end{equation*}
	and the boundary conditions $ \delta q_{i}(t_{1}) = \delta q_{i}(t_{2}) = 0 $ so that the term $ \big[p_{i}\delta q_{i} \big]_{t_{1}}^{t_{2}} $ vanishes and $ \delta S = 0 $.
\end{itemize}



\subsection{Poisson Brackets}

\subsubsection{Definition and Properties}
\begin{itemize}
	\item Let $ f(q_{i}, p_{i}) $ and $ g(q_{i}, p_{i}) $ be two functions defined on phase space where $ i = 1, \ldots, n $. The \textit{Poisson bracket} of the functions $ f $ and $ g $ is 
	\begin{equation*}
		\{f, g\} = \sum_{i=1}^{n}\left(\pdv{f}{q_{i}} \pdv{g}{p_{i}} - \pdv{f}{p_{i}} \pdv{g}{q_{i}}\right)
	\end{equation*}
	We generally use Einstein summation notation and drop the sum symbol $ \sum $.
	
	\item Some properties of Poisson brackets are:
	\begin{itemize}
		\item $ \{f, g\} = - \{g, f\} $
		\item Linearity: $ \{\alpha f + \beta g, h \} = \alpha \{f, h \}  + \beta \{g, h \} $ for all real scalars $ \alpha, \beta \in \R $
		\item Leibniz (product) rule: $ \{fg, h\} = f\{g, h\} + g\{f, h\} $
		\item Jacobi identity: $ \{f, \{g, h\} \} + \{g, \{h, f\} \} + \{h, \{f, g\} \} = 0 $
	\end{itemize}
	Note that the Poisson bracket obeys a similar algebraic structure as the differentiation operator $ \diff $ and the matrix commutator $ [\cdot, \cdot] $.
	
	\item The next set of interesting identities are
	\begin{equation*}
		\{q_{i}, q_{j}\} = 0 \qquad \{p_{i}, p_{j}\} = 0 \qquad \{q_{i}, p_{j}\} = \delta_{ij}
	\end{equation*}
	These are fairly trivial to prove, but I was confused with the proofs in my first encounter and couldn't easily find a good explanation in the literature, so here is a step-by-step walk-through for other slow learners like me. Feel free to skip. The key to all three is using the (obvious) relations
	\begin{equation*}
		\pdv{p_{i}}{q_{j}} = \pdv{q_{i}}{p_{j}} = 0  \eqtext{and} \pdv{p_{i}}{p_{j}} = \pdv{q_{i}}{q_{j}} = \delta_{i j} 
	\end{equation*}
	and being comfortable with the implicit summation notation. I'll write the sum explicitly for the first, then follow the Einstein convention
	\begin{equation*}
		\{q_{i}, q_{j}\} = \sum_{k=1}^{n} \left(\pdv{q_{i}}{q_{k}} \pdv{q_{j}}{p_{k}} - \pdv{q_{i}}{p_{k}} \pdv{q_{j}}{q_{k}}\right) = \sum_{k=1}^{n} (0 + 0)
	\end{equation*}
	Here the $ \pdv{q}{p} $ terms guarantee zeros everywhere. The second identity is completely analogous. In Einstein summation notation we have
	\begin{equation*}
		\{p_{i}, p_{j}\} = \pdv{p_{i}}{q_{k}} \pdv{p_{j}}{p_{k}} - \pdv{p_{i}}{p_{k}} \pdv{p_{j}}{q_{k}} = 0
	\end{equation*}
	This time the $ \pdv{p}{q} $ terms give us zeros everywhere. Finally,
	\begin{equation*}
		\{q_{i}, p_{j}\} = \pdv{q_{i}}{q_{k}} \pdv{p_{j}}{p_{k}} - \pdv{q_{i}}{p_{k}}\pdv{p_{j}}{q_{k}}
	\end{equation*}
	The $ \pdv{q_{i}}{p_{k}}\pdv{p_{j}}{q_{k}} $ is zero everywhere. The only possible non-zero term occurs if $ k = i = j $ in which case $ \pdv{q_{i}}{q_{i}} \pdv{p_{j}}{p_{j}} = 1\cdot 1 = 1$. If $ i \neq j $ either $ \pdv{q_{i}}{q_{i}} $ or $ \pdv{p_{j}}{p_{j}} $ is zero. 
	
	\item Next, a more interesting identity: for any function $ f(q_{i}, p_{i}, t) $ we have
	\begin{equation*}
		\dv{f}{t} = \{f, H\} + \pdv{f}{t} 
	\end{equation*}
	We first differentiate $ f $, then recognize the Hamilton equations $ \dot{q}_{i} = \dv{q}{t} = \pdv{H}{p_{i}} $ and $ \dot{p} = \dv{p}{t} = -\pdv{H}{q} $
	\begin{align*}
		\dv{f}{t} &= \pdv{f}{q_{i}}\dv{q_{i}}{t} + \pdv{f}{p_{i}} \dv{p_{i}}{t} + \pdv{f}{t} \dv{t}{t} = \pdv{f}{q_{i}} \pdv{H}{p_{i}} - \pdv{f}{p_{i}} \pdv{H}{q_{i}} + \pdv{f}{t}\\
		&=\{f, H\} + \pdv{f}{t}
	\end{align*}
	The result is important. It tells us that any function $ I = I(p_{i}, q_{i}) $ for which $ \{I, H\} = 0 $ is a constant of motion. Why? Simple: if $ \{I, H\} = 0 $ then $ \dv{f}{t} = \pdv{f}{t} $ and $ \pdv{f}{t} = 0 \implies \dv{f}{t} = 0 $. If $ \{I, H\} = 0 $ we say that the functions $ I $ and $ H $ \textit{Poisson commute}. 
	
	As an example, we know from Lagrangian mechanics that if $ q_{i} $ is a cyclic coordinate (i.e. $ \pdv{H}{q_{i}} = 0 $) then the corresponding generalized momentum $ p_{i} $ is a constant motion. Does this hold in the language of Poisson brackets? Indeed. From the identities $ \pdv{p}{q} = 0 $ and $ \pdv{p_{i}}{p_{j}} = \delta_{i j} $ and then applying $ \dot{p}_{i} \equiv 0 $ we have
	\begin{equation*}
		\{p_{i}, H\} = \pdv{p_{i}}{q_{j}} \pdv{H}{p_{j}} - \pdv{p_{i}}{p_{j}}\pdv{H}{q_{j}} = 0 - \pdv{H}{q_{i}} = \dot{p_{i}} = 0
	\end{equation*}
	
	\item Next, an important consequence of the Jacobi identity and $ \{f, g\} = - \{g, f\} $. If $ I $ and $ J $ are both constants of motion, then
	\begin{equation*}
		\{\{I, J\}, H\} = \{I, \{J, H \}\} + \{\{I, H\}, J\} = 0
	\end{equation*}
	which means $ \{I, J\} $ is a constant of motion. In other words, if we know two constants of motion, we can generate more using the Poisson brackets and the Jacobi identity.
\end{itemize}

\subsubsection{Poisson Brackets and Angular Momentum}
\begin{itemize}
	\item Poisson bracket show us something cool: if two components of angular momentum (e.g. $ L_{1} $ and $ L_{2} $) are conserved, the third component $ L_{3} $ must also be conserved. This is an application of the theorem stating $ \{I, J\} $ is conserved if $ I $ and $ J $ are separately conserved. We just need to show that $ \{L_{1}, L_{2}\} = L_{3}$. We have
	\begin{align*}
		&L_{1} = r_{2}p_{3} - r_{3}p_{2} && \text{and} && L_{2} = r_{3}p_{1} - r_{1}p_{3}\\
		&\pdv{L_{1}}{\bm{r}} = (0, p_{3}, -p_{2}) && \text{and} && \pdv{L_{2}}{\bm{r}} = (-p_{3},0, p_{1})\\
		&\pdv{L_{1}}{\bm{p}} = (0, -r_{3}, r_{2}) && \text{and} && \pdv{L_{2}}{\bm{p}} = (r_{3},0, -r_{1})
	\end{align*}
	Now we just need to put the pieces together. Using the dot product gives
	\begin{equation*}
		\{L_{1}, L_{2}\} = \pdv{L_{1}}{\bm{r}}\cdot \pdv{L_{2}}{\bm{p}} - \pdv{L_{1}}{\bm{p}}\cdot \pdv{L_{2}}{\bm{r}} = r_{1}p_{2} - r_{2}p_{1} = L_{3}
	\end{equation*}
	
	\item Now if $ L_{1}, L_{2} $ and $ L_{3} $ are conserved, the entire vector $ \bm{L} $ is conserved. In other words, if two components (e.g. $ L_{1} $ and $ L_{2} $) are conserved, the entire vector $ \bm{L} $ is automatically conserved. Note also the quantum mechanic-like relationship
	\begin{equation*}
		\{L^{2}, L_{i} \} = \{L_{1}^{2} + L_{2}^{2} + L_{3}^{2}, L_{i} \} = 0 \eqtext{for} i = 1, 2, 3
	\end{equation*}
	
	\item Next, we consider the Laplace-Runge-Lenz vector in the language of Poisson brackets. Recall the LRL vector is
	\begin{equation*}
		\bm{A} = \frac{1}{m} \bm{p} \cross \bm{L} - \hat{\bm{r}}
	\end{equation*}
	where $ \hat{\bm{r}} = \bm{r}/r$. The vector satisfies $ \bm{A}\cdot \bm{L} = 0 $ since both $ \bm{r} \cross \bm{L} $ and $ \hat{\bm{r}} $ are orthogonal to $ \bm{L} $. More complicated are the Poisson bracket identities
	\begin{equation*}
		\{L_{a} A_{b} \} = \epsilon_{abc}A_{c} \eqtext{and} \{A_{a}, A_{b}\} = -\frac{2}{m} \left(\frac{\bm{p}^{2}}{2m} - \frac{1}{r}\right)\epsilon_{abc}L_{c}
	\end{equation*}
	where $ \epsilon_{abc} $ is the Levi-Civita symbol. For a system with a central potential $ V = -\frac{1}{r} $ and thus a Hamiltonian $ H = \frac{\bm{p}^{2}}{2m} - \frac{1}{r} $, the last equality is simply
	\begin{equation*}
		\{A_{a}, A_{b}\} = -\frac{2H}{m}\epsilon_{abc}L_{c}
	\end{equation*}
	in which case $ \{H, \bm{A} \} = 0 $, meaning the LRL vector is a constant of motion in an $ -\frac{1}{r} $ potential.
	
	Kepler's elliptical orbits follow from the conservation of $ \bm{A} $. The dot product $ \hat{\bm{r}}\bm{A}$ gives
	\begin{equation*}
		 \hat{\bm{r}}\cdot \bm{A} = \frac{1}{m} \hat{\bm{r}} \cdot (\bm{p} \cross \bm{L}) - 1 \implies \hat{\bm{r}}\cdot \bm{A} + 1 = \frac{\bm{L}^{2}}{r}
	\end{equation*}
	which is the equation for an ellipse.
\end{itemize}


\end{document}





