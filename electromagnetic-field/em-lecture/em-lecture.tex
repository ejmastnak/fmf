\documentclass[11pt, a4paper]{article}

\usepackage{mwe}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{esint}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{bm} % for bold vectors in math mode
\usepackage{physics} % for differential notation, etc...
\usepackage[separate-uncertainty=true]{siunitx}

\usepackage[normalem]{ulem}  % for underline with line wrapping
\usepackage[margin=3cm]{geometry}
\usepackage{fancyhdr}
\usepackage{truncate}
\usepackage[colorlinks = true, allcolors=blue]{hyperref}

\setlength{\parindent}{0pt} % to stop indenting new paragraphs
\newcommand{\diff}{\mathop{}\!\mathrm{d}} % differential
\newcommand{\dr}{\diff^{3} \r}  % d^3 r
\newcommand{\dtr}{\diff^{3} \tilde{\r}}  % d^3 r
\newcommand{\dk}{\diff^{3} \vec{k}}  % d^3 k

\newcommand{\Poy}{Poynting\xspace} 
\newcommand{\eqtext}[1]{\qquad \text{#1} \qquad}

\renewcommand{\L}{\mathcal{L}}  % Lagrange density

\renewcommand{\vec}[1]{\bm{#1}} % for vectors
\newcommand{\uvec}[1]{\hat{\vec{#1}}} % for vectors
\newcommand{\mat}[1]{\mathbf{#1}} % for matrices
\newcommand{\dvec}[1]{\dot{\vec{#1}}} % for dotted vector quantity
\newcommand{\tvec}[1]{\tilde{\vec{#1}}} % for tilde vector quantities
\renewcommand{\t}[1]{\tilde{#1}} % shorthand for tilde

\newcommand{\bdot}[1]{\dot{\vec{#1}}}
\newcommand{\bddot}[1]{\ddot{\vec{#1}}}

\renewcommand{\r}{\vec{r}}
\renewcommand{\k}{\vec{k}}
\newcommand{\E}{\vec{E}} % for electric field; it's used alot!
\newcommand{\D}{\vec{D}}  % electric displacement field
\newcommand{\B}{\vec{B}} % for magnetic field; it's used alot!
\renewcommand{\H}{\vec{H}}  % magnetic field strength
\newcommand{\A}{\vec{A}} % for magnetic vector potential
\renewcommand{\P}{\vec{P}}  % electric polarization
\newcommand{\M}{\vec{M}}  % magnetization
\renewcommand{\S}{\mathbf{S}}  % Poynting vector---conflicts somewhat with slanted \bm{S} for vector surface element, but is better than \bm{P}, which directly conflicts with polarization
\newcommand{\T}{\mathbf{T}}  % electric stress-energy tensor
\newcommand{\TT}{\mathrm{T}}  % electric stress-energy tensor
\newcommand{\e}{\epsilon}
\newcommand{\ee}{\epsilon_{0}}  % vacuum permittivity
\newcommand{\mm}{\mu_{0}}  % vacuum permeability
\newcommand{\pe}{\vec{p}_{\text{e}}}  % electric dipole moment
\newcommand{\m}{\vec{m}}  % magnetic dipole moment
\renewcommand{\j}{\vec{j}}  % electric current density

\newcommand{\s}{\vec{s}}  % for multipole expansion
\newcommand{\ds}{\diff^{3} \s}  % for multipole expansion


\renewcommand{\div}{\nabla \cdot}
\renewcommand{\curl}{\nabla \cross}
\renewcommand{\grad}{\nabla}
\renewcommand{\laplacian}{\nabla^{2}}

\newcommand{\divp}{\nabla' \mspace{-1mu} \cdot}  % for use in system S' for special relativity
\newcommand{\curlp}{\nabla' \mspace{-2mu} \cross}
\newcommand{\gradp}{\nabla'}
\newcommand{\laplacianp}{\nabla^{2}}

% begin header configuration
\pagestyle{fancy}

% Header and footer on non-section pages (default style)
\fancyhf{}
\fancyhead[R]{\href{https://github.com/ejmastnak/fmf}{\small{\texttt{github.com/ejmastnak/fmf}}}} 
\fancyhead[L]{\textit{\truncate{0.65\headwidth}{\rightmark}}}
\fancyfoot[C]{\thepage} 
\renewcommand{\headrulewidth}{0.1pt}

% Header and footer on section pages---identical to default style, but must be explicitly included
\fancypagestyle{plain}{
    \fancyhf{}  
    \fancyhead[R]{\href{https://github.com/ejmastnak/fmf}{\small{\texttt{github.com/ejmastnak/fmf}}}}  
    \fancyhead[L]{\textit{\truncate{0.65\headwidth}{\rightmark}}} 
    \fancyfoot[C]{\thepage}  % centered page number in footer
    \renewcommand{\headrulewidth}{0.1pt}
}

\renewcommand{\sectionmark}[1]{%
  \markboth{\sectionname \thesection}
  {\noexpand\firstsubsectiontitle}}
\renewcommand{\sectionmark}[1]{}

\renewcommand{\subsectionmark}[1]{%
  \markright{\thesubsection\ \, #1}\gdef\firstsubsectiontitle{#1}}

\newcommand\firstsubsectiontitle{}
% end header configuration

\begin{document}
\title{Electromagnetic Field Lecture Notes}
\author{Elijan Mastnak}
\date{Winter Semester 2020-2021}
\maketitle

\thispagestyle{empty}  % remove headers from introductory page

\begin{center}
    \textbf{About These Notes}
\end{center}

These are my lecture notes from the course \textit{Elektromagnetno polje} (Electromagnetic Field), a required course for third-year physics students at the Faculty of Math and Physics in Ljubljana, Slovenia. The course covers electro- and magnetostatics, quasistatic fields, dynamic electromagnetic fields, the Maxwell equations in free space and in matter, and concludes with brief chapters on the integration of electromagnetism with the Hamiltonian formalism and special relativity. The exact material herein is specific to the physics program at the University of Ljubljana, but the content is fairly standard for a late-undergraduate course in electromagnetism. I am making the notes publicly available in the hope that they might help others learning the same material---the most recent version can be found on \href{https://github.com/ejmastnak/fmf/tree/main/electromagnetic-field}{\underline{GitHub}}.

\vspace{2mm}
\textit{Navigation}: For easier document navigation, the table of contents is ``clickable'', meaning you can jump directly to a section by clicking the colored section names in the table of contents. Unfortunately, the \textit{clickable links do not work in most online or mobile PDF viewers}; you have to download the file first.

\vspace{2mm}
\textit{On Authorship:} The content of these notes is far from original. The lectures were given by Professor Miha Ravnik and, to the best of my knowledge, draw from the content of the textbook \textit{Elektromagnetno polje} by Rudolf Podgornik and Andrej Vilfan, published by FMF's publishing house DMFA in 2012. Accordingly, credit for the material in these notes goes to Professors Ravnik, Podgornik and Vilfan; I have simply typeset the notes, translated to English and provided an additional explanation or two where I saw fit.

\vspace{2mm}
\textit{Disclaimer:} Mistakes---both trivial typos and legitimate errors---are likely. Keep in mind that these are the notes of an undergraduate student in the process of learning the material himself---take what you read with a grain of salt. If you find mistakes and feel like telling me, by \href{https://github.com/ejmastnak/fmf}{\underline{GitHub}} pull request, \href{mailto:ejmastnak@gmail.com}{\underline{email}} or some other means, I'll be happy to hear from you, even for the most trivial of errors.

\newpage

\pagestyle{empty}  % no header in table of contents

\tableofcontents

\newpage

\pagestyle{fancy}  % turn on headers for remainder of document

\section{Electrostatics}
Electrostatics is the study of static (time-independent) charge distributions.

\subsection{The Electrostatic Force}
\begin{itemize}
    \item Two point charges $ q_{1} $ and $ q_{2} $ experience a mutual electrostatic force
    \begin{equation*}
        \vec{F} = \frac{q_{1}q_{2}}{4\pi \ee r^{2}} \frac{\r}{r},
    \end{equation*}
    where $ \ee = \SI{8.85e-12}{\coulomb \, \volt^{-1}\, \meter^{-1}} $ is the vacuum permittivity constant. The force is attractive for charges of opposite sign and repulsive for charges of like sign. We stress that this relationship is experimental---it is the relationship we measure in nature, and we have not derived it from fundamental principles. 

    \item Electric charge is measured in units of coulombs, which in fundamental SI units equals one ampere-second. In symbols, $ 1\si{\coulomb} = 1\si{\ampere \second} $. Charge is quantized in multiples of the fundamental charge
    \begin{equation*}
        e_{0} = \SI{1.6e-19}{\coulomb},
    \end{equation*}
    which is the absolute value of the electron charge. Note that although some elementary particles, namely quarks, can have charges of $ +(2/3)e_{0} $ and $ -(1/3)e_{0} $, fractional charges never (or have not been observed to) occur in isolation, and are always bound together into multiples of the fundamental charge $ e_{0} $.

    \item Some representative magnitudes of electric charge are given in the table below:

    \begin{center}
        \begin{tabular}{c|c}
            Charge... & Magnitude \\
            \hline
            of an electron & $ -e_{0} $\\
            stored in a typical capacitor & \SI{e-7}{\coulomb}\\
            in a lightning strike & \SIrange{1}{100}{\coulomb}\\
            in car battery & \SI{0.2e6}{\coulomb}\\
            of the Earth, without atmosphere & \SI{5e5}{\coulomb}\\
            of the Earth, with atmosphere & \SI{1}{\coulomb}\\
            generated by a power plant in one year & \SI{3e11}{\coulomb}
        \end{tabular}
    \end{center}
    
\end{itemize}

\subsection{Electric Field Strength}
\begin{itemize}

    \item For the entirety of this course, we will analyze the interaction of charged particles in terms of the concept of an electric field. We must consider at least two charges when speaking of an electric field: one charge creates the electric field, which is then experienced by the second charge.

    \item In terms of electric field, the Coulomb electrostatic force $ \vec{F}_{21} $ experienced by particle 2 because of the field created by particle $ 1 $ is
    \begin{equation*}
        \vec{F}_{21} = q_{2} \E_{1}.
    \end{equation*}
    More generally, the electric force on a particle of charge $ q $ in an electric field $ \E $ is
    \begin{equation*}
        \vec{F} = q \E.
    \end{equation*}
    Note that the electric field and electric force felt by a charged particle are closely related---they differ only in the scalar factor $ q $. 

    \item The direct proportionality between the electrostatic force $ \vec{F} $ and the electric field $ \E $ has an important consequence: the direction of an electric field $ \E $ at any position in space is the same as the direction of the electrostatic force $ \vec{F} = q \E $ on a hypothetical charged particle at that position. 

    \item By comparing the relationship $ \vec{F} = q \E $ to the Coulomb force, it follows that the electric field of a particle of charge $ q $ is
    \begin{equation*}
        \E = \frac{q}{4\pi \ee r^{2}}\frac{\r}{r}.
    \end{equation*}
    By convention, the electric field of a positively charge particle points radially outward from the particle, while the electric field of a negatively charged particle points radially inward toward the particle. Also by convention, we use a positive ``test charge'' to determine the direction of an electric field---the field direction is the direction of the electrostatic force on a hypothetical \textit{positively} charged particle (as opposed to using a negatively charged particle).

\end{itemize}

\subsubsection{Transformation Properties of the Electric Field}
\begin{itemize}
    \item The electric field is a vector, and thus transforms like a vector under orthogonal transformations, i.e. rotations and reflections, which preserve the inner product. 

    Under an orthogonal transformation in Euclidean space encoded by the orthogonal transformation $ \mat{Q} $, the electric field transforms in the familiar form
    \begin{equation*}
        \E' = \mat{Q} \E \qquad \text{or} \qquad E_{j}' = \sum_{j = i}^{3} \mathrm{Q}_{ij}E_{j}.
    \end{equation*}

    \item The quantity $ \abs{\E}^{2} = E^{2} $ is a scalar, and is preserved under orthogonal transformations.
    
\end{itemize}

\subsubsection{Representative Magnitudes of Electric Field Strength}
\begin{itemize}
    \item Electric field is measured in volts per meter. Some representative magnitudes of electric field strength are given are given in the table below
    \begin{center}
        \begin{tabular}{c|c}
            Electric field... & Magnitude \\
            \hline
            in cosmic radiation & $ \SI{10}{\micro \volt \per \meter} $\\
            polje znotraj ¿tanke? \v{z}ice & $ \SI{0.5}{\milli \volt \per \meter} $\\
            in the Earth's atmosphere & \SIrange{100}{300}{\volt \per \meter} \\
            for atmospheric dielectric breakdown & \SIrange{1}{3}{\mega \volt \per \meter}\\
            polje preko ¿biolo\v{s}ke? membrane & $ \SI{10}{\mega \volt \per \meter} $\\
            polje v mo\v{c}nem ¿laserskem? snopu & $ \SI{100}{\tera \volt \per \meter} $\\
        \end{tabular}
    \end{center}

    \item As an example, we will estimate the electric field in the screen of a typicaly smartphone. A typical smartphone screen might be exposed to a voltage of order $ U \sim \SI{5}{\volt} $, while a typical screen thickness is $ d \sim \SI{10}{\micro \meter} $. The electric field estimate is thus
    \begin{equation*}
        E = \frac{U}{d} = \SI{5e5}{\volt \, \meter^{-1}} = \SI{10}{\mega \volt \, \meter^{1}}
    \end{equation*}
    \end{itemize}


\subsubsection{Electric Field Lines}
\begin{itemize}
    \item Electric field lines follow the direction of the electric field, and are defined in terms of the arc length parameter $ s $ via
    \begin{equation*}
        \dot{\vec{r}}(s) = \dv{\r}{s} = \frac{\E(\r(s))}{\abs{\E(\r(s))}}
    \end{equation*}

    \item Electric field lines may be defined in terms of the so-called Faraday construction, which rests on the following properties:
    \begin{enumerate}
        \item Electric field lines point in the direction of the electric field $ \E $ and do not cross. If electric field lines could cross, the electrostatic force on a point charge would not be well-defined in terms of the electric field.

        \item The density of electric field lines in a region of space is proportional to the magnitude of the electric field in that region. 

        \item Electric field lines arise from positive charges and disappear into negative charges (recall that the electric field of a point charge points radially outward for a positive charge and radially inward for a negative charge).

        \item Electric field lines are not closed curves.
    \end{enumerate}
\end{itemize}

\subsubsection{Electric Circulation}
\begin{itemize}
    \item The electric circulation around a closed curve $ C $ is defined as the line integral
    \begin{equation*}
        \Gamma_{\text{E}} = \oint_{C} \E \cdot \diff \r.
    \end{equation*}
    In other words, electric circulation is the ``sum'' of the tangentional component of the electric field lines around the loop. Because the electrostatic field is conservative, the electric circulation of an arbitrary closed loop in a static electric field is zero. As a result, we have
    \begin{equation*}
        \Gamma_{\text{E}} = \oint_{C} \E \cdot \diff \r = 0.
    \end{equation*}


    \item Next, we apply Stokes' theorem to the static electric field identity $ \Gamma_{\text{E}} = 0 $. The result is
    \begin{equation*}
        0 \equiv \Gamma_{\text{E}} = \oint_{C}\E \cdot \diff \r = \iint_{S} \curl \E \cdot \diff \vec{S} \implies \curl \E = 0.
    \end{equation*}
    In other words, the curl of any static electric field is zero. Note that this result does not hold in general for time-varying electric fields, which we will discuss in future chapters. 

\end{itemize}

\subsubsection{Electric Flux}
\begin{itemize}
    \item The electric flux through an arbitrary surface $ S $ is defined as
    \begin{equation*}
        \Phi_{\text{E}} = \iint_{S} \E \cdot \diff \vec{S}.
    \end{equation*}

    \item The electric flux through a closed surface $ S $ obeys the relationship
    \begin{equation*}
        \Phi_{\text{E}} = \oiint \E \cdot \diff \vec{S} = \frac{q_{\text{enc}}}{\ee},
    \end{equation*}
    where $ q_{\text{enc}} $ is the total electric charge enclosed within the surface $ S $. This result is the integral form of Gauss's law, which we will discuss more in the coming sections.
    
    
    
\end{itemize}

\subsection{Electric Potential and Charge Density}
\begin{itemize}
	\item Electric potential $ \phi $ is a scalar quantity, defined in terms of electric field $ \E $ as
	\begin{equation*}
		\E(\r) = - \grad \phi(\r).
	\end{equation*}
	As a side note, we remark that it will be useful for the coming sections to memorize the identity
	\begin{equation*}
		\grad \frac{1}{\r} = - \frac{\r}{r^{3}}.
	\end{equation*}
	
	\item As an example, we find the electric potential of a point charge, which has electric field
	\begin{equation*}
		\E(\r) = \frac{q}{4\pi \ee} \frac{\r}{r^{3}}.
	\end{equation*}
    Using the above gradient identity $ \grad \frac{1}{\r} = - \frac{\r}{r^{3}} $, the electric potential $ \phi $  satisfying the equality $ \E(\r) = -\grad \phi(\r) $ is
	\begin{equation*}
		\phi = \frac{q}{4\pi \ee}\frac{1}{r} + \phi_{0}.
	\end{equation*}
	Note that $ \phi $ is determined only up to a constant $ \phi_{0} $.
	
	\item The property of $ \phi $ being determined only up to a constant is a simple introduction to gauge theory---more on this in the sections on relativistic electromagnetism. Choosing a condition such that $ \phi $ is precisely determined is called fixing a gauge. For electric potential, the gauge is simply a constant, but in more complicated situations, the gauge can be a variable field.
	
\end{itemize}

\subsubsection{The Superposition Principle}
\begin{itemize}
	\item Consider a set of point charges $ \{q_{i}\} $. We then place another charge $ q $ in the system at the position $ \r $. Via the superposition principle, the force acting on the additional charge $ q $ is the vector sum
	\begin{equation*}
		\vec{F}(\r) = \frac{q}{4\pi \ee} \sum_{i}\frac{(\r - \r_{i})}{\abs{\r - \r_{i}}^{3}}q_{i}.
	\end{equation*}
	
	\item Because the superposition principle holds for force, it also holds for electric field, and the electric field felt by the additional charge is thus
	\begin{equation*}
		\vec{E}(\r) = \frac{1}{4\pi \ee} \sum_{i}\frac{(\r - \r_{i})}{\abs{\r - \r_{1}}^{3}}q_{i}.
	\end{equation*}
	Similarly, electric potential felt by the additional charge obeys the superposition principle and is equal to
	\begin{equation*}
		\phi(\r) = \frac{1}{4\pi \ee} \sum_{i}\frac{q_{i}}{\abs{\r - \r_{1}}}.
	\end{equation*}
	The superposition principle is useful for finding the electric field and potential of complicated charge distributions.
\end{itemize}

\subsubsection{Charge Density}
\begin{itemize}
	\item At the fundamental atomic level, charge is discrete. However, on a macroscopic level, it is more convenient to work in terms of charge density. The charge density of a discrete charge distribution $ \{q_{i}\} $ is
	\begin{equation*}
		\rho (\r) = \sum_{i} q_{i}\delta^{3}(\r - \r_{i}),
	\end{equation*}
	where we note that the delta function $ \delta^{3} $ has units $ \si{length^{-3}} $. We find the distribution's total charge by integrating the charge density over the volume $ V $ containing the charges:
	\begin{equation*}
		\iiint_{V} \rho(\r) \dr  = \sum_{i} q_{i}\iiint_{V} \delta^{3}(\r - \r_{i})\dr = \sum_{i} q_{i} = q_{\text{total}}.
	\end{equation*}
	Meanwhile, the charge density of a continuous charge distribution is
	\begin{equation*}
		\rho(\r) = \dv{q}{V} \implies q_{\text{total}} = \iiint_{V} \rho(\r) \dr.
	\end{equation*}
	
	\item The electric force, electric field and electric potential of a charge distribution with charge density $ \rho(\r) $  contained in the volume $ V $ are
	\begin{align*}
		& \vec{F} = \iiint_{V} \rho(\r) \E(\r) \dr \\
		& \E(\r) = \frac{1}{4\pi \ee} \iiint_{V}\frac{\rho(\t{\r})(\r - \t{\r})}{\abs{\r - \t{\r}}^{3}} \dtr\\
		& \phi (\r) = \frac{1}{4\pi \ee}\iiint_{V}\frac{\rho(\t{\r})}{\abs{\r - \t{\r}}}\dtr.
	\end{align*}
\end{itemize}

\subsubsection{Charge Density Examples}

\vspace{2mm}
\textbf{Point Charge} 
\begin{itemize}
	\item The charge density of a point charge located at the position $ \r_{0} $ is
	\begin{equation*}
		\rho (\r) = q \delta^{3}(\r - \r_{0}).
	\end{equation*}
\end{itemize}	
	

\textbf{Electric Dipole} 
\begin{itemize}
	\item The charge density of an electric dipole dipole with positive and negative charges at $ \r_{+} $ and $ \r_{-} $, respectively, is
	\begin{equation*}
		\rho(\r) = q \delta^{3}(\r - \r_{+}) - q \delta^{3}(\r - \r_{-}).
	\end{equation*}
	Alternatively, if the dipole's center occurs at $ \r_{0} $ and the positive and negative charges occur at $ \r_{0} + \delta \r$ and $ \r_{0} - \delta \r $, the dipole's charge density is
	\begin{equation*}
		\rho(\r) = q \delta^{3}(\r - \r_{0} - \delta \r) - q\delta^{3}(\r - \r_{0} + \delta \r).
	\end{equation*}
	Next, we consider the limit case $ \abs{\delta \r} \ll \abs{\r_{0}} $, i.e. when the distance $ \abs{\delta \vec{r}} $ between the dipole charges is small compared to the distance $ \abs{\vec{r}_{0}} $ to the dipole. We expand the charge density to get
	\begin{equation*}
		\rho(\r) \approx - q \delta \r \cdot \grad \big[\delta^{3}(\r - \r_{0})\big] - q \delta \r \cdot \grad \big[\delta^{3}(\r - \r_{0})\big] = -2 q \delta \r \cdot \grad \big[\delta^{3}(\r - \r_{0})\big].
	\end{equation*}
	The term $ 2q\delta \r $ is the dipole moment $ \pe $, and the dipole's charge density is then
	\begin{equation*}
		\rho(\r) = -\pe \cdot \grad \big[\delta^{3}(\r - \r_{0})\big].
	\end{equation*}

	\item Next, we make the auxiliary calculation
	\begin{align*}
		\div \big[\pe \delta^{3}(\r - \r_{0})\big] &= (\div \pe) \delta^{3}(\r - \r_{0}) + \pe \cdot \grad \big[\delta^{3}(\r - \r_{0})\big] \\
		&= 0 + \pe \cdot \grad \big[\delta^{3}(\r - \r_{0})\big]  \implies \\
		\pe \cdot \grad \big[\delta^{3}(\r - \r_{0})\big]  & = - \div \big[\pe \delta^{3}(\r - \r_{0})\big].
	\end{align*}
	where we've used $ \div \pe = 0 $. The dipole's charge density is then
	\begin{equation*}
		\rho(\r) = - \div \big[\pe \delta^{3}(\r - \r_{0})\big] \equiv - \div \vec{P}(\r).
	\end{equation*}
	where $ \vec{P} $ is electric polarization. The relationship 
	\begin{equation*}
		\rho(\r) = - \div \vec{P}(\r).
	\end{equation*}
	holds for any charge distribution with the form of an electric dipole.
\end{itemize}

\textbf{Surface Charge Distribution}
\begin{itemize}
	\item We analyze a surface charge distribution in terms of surface charge density $ \sigma(\r) $. The corresponding volume charge density $ \rho $ is
	\begin{equation*}
		\rho(\r) = \sigma(\r) \delta(z - z_{0}),
	\end{equation*}
	where we assume the surface occurs at $ z = z_{0} $. Recall the delta function has units $ \si{length}^{-1} $, so units are consistent.
\end{itemize}

\textbf{Spherical Charge Distribution}
\begin{itemize}	
	\item The charge density of a uniform spherical charge distribution of radius $ a $ is
	\begin{equation*}
		\rho(\r) = \rho_{0}H(a - r)
		\begin{cases}
			\rho_{0} & r < a\\
			0 & r > a,
		\end{cases}
	\end{equation*}
	where $ H $ is the Heaviside function.
	
	\item The polarization of a spherically-distributed dipole within a sphere of radius $ a $ is 
	\begin{equation*}
		\vec{P}(\r) = \dv{\pe}{V} = 
		\begin{cases}
			\vec{P}_{0} & r < a\\
			0 & r > a
		\end{cases}
		= \vec{P}_{0}H(a - r).
	\end{equation*}
	The corresponding charge density is
	\begin{align*}
		\rho(\r) &= - \div \vec{P} = - \div \big[\vec{P}_{0}H(a - r)\big] = - (\div \vec{P}_{0})H(a - r) - \vec{P}_{0} \grad H(a -r)\\
		&= 0 - \vec{P}_{0} \delta(a-r) \cdot \left (-\frac{\r}{r}\right) = \vec{P}_{0}\frac{\r}{r} \delta(a-r).
	\end{align*}
	Note that the charge density occurs only at $ r = a $ (at the sphere's surface) this is because internal charges from internal electric dipoles within the sphere cancel each other out.
\end{itemize}

\subsection{Gauss's Law}
\subsubsection{Integral Form of Gauss's Law}
\begin{itemize}
	\item Consider a distribution of charges $ \{q_{i}\} $ at the positions $ \{\r_{i}\} $. We enclose the charges with a sphere of radius $ r $ with normal vector $ \uvec{n} $. In general, the electric flux through a closed surface containing the charges is
	\begin{equation*}
		\Phi_{\text{E}} = \oiint_{S} \E \cdot \diff \vec{S} = \oiint_{S} \E \cdot \uvec{n} \diff S = \oiint_{S} E \diff S \cos \theta,
	\end{equation*}
	where $ \theta $ is the angle between the electric field and normal vector to the surface.
	
	\item In our case, for the collection of charges $ \{q_{i}\} $, the electric flux is
	\begin{align*}
		\Phi_{\text{E}} &= \oiint_{S} \E \cdot \diff \vec{S} = \sum_{i} \frac{q_{i}}{4\pi \ee} \oiint_{S} \frac{\cos \theta_{i}}{\abs{\r - \r_{i}}^{2}} \diff S \\
		& = \frac{1}{4\pi \ee} \left[ \oiint_{S} \frac{ q_{1} \cos \theta_{1}}{\abs{\r - \r_{2}}^{2}} \diff S + \oiint_{S} \frac{ q_{2} \cos \theta_{2}}{\abs{\r - \r_{2}}^{2}} \diff S  + \cdots \right],
	\end{align*}
	where $ \theta_{i} $ represent the angle between each particle's $ \E $ field and $ \uvec{n} $. 
	
	\item Next, note that for charges at the origin, the angle $ \theta_{i} $  is zero. We choose the origin so that $ \r_{1} = 0 $. Then $ \theta_{1} = 0 $, $ \cos \theta_{1} = 1 $ and the first integral is (using $ \diff S = \sin \theta \diff \theta \diff \phi $)
	\begin{equation*}
		\oiint_{S} \frac{q_{1}}{r^{2}} \diff S = \int_{\phi = 0}^{2\pi} \int_{\theta = 0}^{\pi} \frac{q_{1}}{r^{2}}r^{2} \sin \theta \diff \theta \diff \phi = 4\pi q_{1}.
	\end{equation*}
	The idea is to play the same game for each integral, switching the origin one at a time and arguing that the value of the integral is the same regardless of the choice of origin. The end result is Gauss's law:
	\begin{equation*}
		\Phi_{\text{E}} = \oiint_{S} \E \cdot \diff \S = \frac{1}{4\pi \ee} \big[4\pi q_{1} + 4\pi q_{2} + \cdots \big] = \frac{Q}{\ee},
	\end{equation*}
	where $ Q = \sum_{i} q_{i} $. In terms of charge density, this relationship reads
	\begin{equation*}
		\Phi_{\text{E}} = \oiint_{\partial V} \E \cdot \diff \vec{S} = \frac{1}{\ee}\iiint_{V} \rho(\r) \dr,
	\end{equation*}
	where $ \partial V $ denotes the boundary surface enclosing the charges in the volume $ V $.
	
	\item Finally, note that if the charges occur at the volume's surface, then $ \abs{\r_{i}} = r $, giving a singularity in the integral denominators. Because of this singularity, Gauss's law is thus not valid for a surface that does not fully enclose the charges.
\end{itemize}

\subsubsection{Differential Form of Gauss's Law}
\begin{itemize}
	\item To find the differential form of Gauss's law, we begin with the integral form
	\begin{equation*}
		\oiint_{\partial V} \E \cdot \diff \vec{S} = \frac{1}{\ee}\iiint_{V}\rho(\r) \dr.
	\end{equation*}
	We then recall the divergence theorem, which reads
	\begin{equation*}
		\oiint_{\partial V} \E \cdot \diff \vec{S} = \iiint_{V}\div \E \dr.
	\end{equation*}
	Applied to Gauss's law, the divergence theorem gives
	\begin{equation*}
		\oiint_{\partial V} \E \cdot \diff \vec{S} = \iiint_{V}\div \E \dr = \frac{1}{\ee} \iiint_{V} \rho(\r) \dr.
	\end{equation*}
	We then equate the integrands in the last equality to get the differential form of Gauss's law:
	\begin{equation*}
		\div \E = \frac{\rho}{\ee}.
	\end{equation*}
\end{itemize}

\subsection{The General Expression for Electric Potential}
\subsubsection{The Poisson and Laplace Equations for Electric Potential}
\begin{itemize}
	\item The Poisson equation is used to find the electrostatic potential $ \phi(\r) $ of an arbitrary charge distribution $ \rho(\r) $. To derive the Poisson equation, we substitute $ \E = - \grad \phi $ into the differential form of Gauss's law to get
	\begin{equation*}
		\frac{\rho}{\ee} \equiv \div \E = \div \big[- \grad \phi \big]= - \laplacian \phi.
	\end{equation*}
	The result is the Poisson equation
	\begin{equation*}
		\laplacian \phi = - \frac{\rho}{\ee}.
	\end{equation*}
	In empty space (i.e. in the absence of electric charge) charge density is simply $ \rho(\r) = 0 $, and the Poisson equation reduces to the Laplace equation
	\begin{equation*}
		\laplacian \phi = 0.
	\end{equation*}
	In principle, the Laplace equation is always solved with the trivial solution $ \phi(\r) = 0 $, but we are usually interested in nontrivial results arising from the boundary conditions of various charge distributions. 
\end{itemize}

\subsubsection{Green's Function for the Poisson Equation}
\begin{itemize}
	\item We find the general solution of the Poisson equation using a Green's function, i.e. we want to find the Green's function $ G $ for the Poisson equation
	\begin{equation*}
		\laplacian \phi = - \frac{\rho}{\ee}.
	\end{equation*}
	We find the solution using the convolution
	\begin{equation*}
		\phi(\r) = \iiint_{V} G(\r - \t{\r})\rho(\t{\r}) \dtr,
	\end{equation*}
	where $ G $ is the Green's function for the equation. Note that we have assumed a priori that the Green's function exists, which is not necessarily trivial in general cases.
	
% Interpretation: imagine multiplying $ \rho $ by a constant factor---in this case $ \phi $ should increase by the same constant factor. As a result, $ \rho $ and $ \psi $ are related, and this relationship is encoded in the convolution.
	
	\item We then substitute the convolution ansatz for $ \phi $ into the Poisson equation to get
	\begin{equation*}
		\laplacian \phi(\r) = \laplacian \left[\iiint_{V}  G(\r - \t{\r})\rho(\t{\r}) \dtr \right] = \iiint_{V} \laplacian G(\r - \t{\r})\rho(\t{\r}) \dtr = - \frac{\rho(\r)}{\ee}.
	\end{equation*}
	Note that the Laplacian $ \laplacian $ applies only to the coordinates of $ \r $ and not to $ \t{\r} $.
	
	We want to find the $ G $ satisfying the above equality. For the equality to hold, the Green's function must obey
	\begin{equation*}
		\laplacian G(\r - \t{\r}) = -\frac{\delta^{3}(\r - \t{\r})}{\ee},
	\end{equation*}
	which reproduces the desired equality
	\begin{equation*}
		\iiint_{V} \laplacian G(\r - \t{\r})\rho(\t{\r}) \dtr = \iiint_{V} \left(-\frac{\delta^{3}(\r - \t{\r})}{\ee}\right)\rho(\t{\r}) \dtr =  - \frac{\rho(\r)}{\ee}.
	\end{equation*}
	
	As a side note, we point out the similarity of the expression
	\begin{equation*}
		\laplacian G(\r - \t{\r}) = -\frac{\delta^{3}(\r - \t{\r})}{\ee}
	\end{equation*}
	to the charge density of a point charge. In fact, it turns out that the Green's function (up to the charge factor $ q $) is the solution to the Poisson equation for a point charge. 
	
	\item Point charge aside, we find the Green's function for an arbitrary charge distribution by transforming to Fourier space, which simplifies the Laplace operator. 
	
	As an auxiliary calculation, the Green's function in Fourier space is
	\begin{equation*}
		G(\r - \t{\r}) = \iiint \frac{\dk}{(2\pi)^{3}}e^{i\k(\r - \t{\r})}G(\k),
	\end{equation*}
	while the delta function in Fourier space is
	\begin{equation*}
		\delta(\r - \t{\r}) = \iiint \frac{\dk}{(2\pi)^{3}}e^{i\k(\r - \t{\r})}\cdot 1.
	\end{equation*}
	Substituting these two results into the Poisson equation gives
	\begin{equation*}
		\laplacian \left(\iiint \frac{\dk}{(2\pi)^{3}} e^{i\k(\r - \t{\r})} G(\k)\right) = -\frac{1}{\ee} \left(\iiint \frac{\dk}{(2\pi)^{3}}e^{i\k(\r - \t{\r})} \right).
	\end{equation*}
	We write the equation in terms of a single integral to get
	\begin{equation*}
		\iiint \frac{\dk}{(2\pi)^{3}} \left[\laplacian e^{i\k(\r - \t{\r})}G(\k) + \frac{1}{\ee}e^{i\k(\r - \t{\r})}\right] = 0.
	\end{equation*}
	We then factor out the exponential term to get
	\begin{equation*}
		\iiint \frac{\dk}{(2\pi)^{3}} \left[-k^{2} G(\k) + \frac{1}{\ee}\right]e^{i\k(\r - \t{\r})} = 0.
	\end{equation*}
	For this equality to hold for all $ \k $ and $ \r $, the quantity in brackets must be zero, which gives us for the expression for the Green's function in $ \k $ space:
	\begin{equation*}
		-k^{2} G(\k) + \frac{1}{\ee} \equiv 0 \implies G(\k) = \frac{1}{\ee k^{2}}.
	\end{equation*}
	
	\item We now aim to transform $ G(\k) $ from $ \k $ space back into position space via
	\begin{equation*}
		G(\r - \t{\r}) = \iiint \frac{\dk}{(2\pi)^{3}}e^{i\k(\r - \t{\r})}G(\k) = \iiint \frac{\dk}{(2\pi)^{3}}e^{i\k(\r - \t{\r})}\left(\frac{1}{\ee k^{2}}\right).
	\end{equation*}
	We perform the integral over $ \k $ by converting to spherical coordinates
	\begin{align*}
		G(\r - \t{\r}) &= \frac{1}{\ee}\int_{0}^{\infty} \int_{0}^{\pi} \int_{0}^{2\pi} \diff \phi \sin \theta \diff \theta k^{2} \diff k \frac{1}{(2\pi)^{3}}e^{i\k(\r - \t{\r})} \frac{1}{k^{2}} \\
		& = \frac{1}{\ee}\frac{1}{(2\pi)^{2}}\int_{0}^{\infty} \int_{-1}^{1} \diff [\cos \theta]  e^{ik\abs{\r - \t{\r}}\cos \theta} \diff k\\
		& = \frac{1}{4\pi \ee \abs{\r - \t{\r}}}.
	\end{align*}
	where the last equality relies on the integral $ \int_{0}^{\infty}\frac{\sin x}{x} = \frac{\pi}{2} $. Note that the $ k^{2} $ terms in the first line cancel, which is what makes the conversion back to position space feasible.
	
	\item  Using the just-derived Green's function, the general solution to the Poisson equation for electric potential $ \phi(\r) $  is
	\begin{equation*}
		\phi(\r) = \iiint_{V} G(\r - \t{\r})\rho(\t{\r}) \dtr = \iiint_{V} \frac{\rho(\t{\r})}{4\pi \ee \abs{\r - \t{\r}}}\dtr.
	\end{equation*}
	This result is important: it means that as long as we know a charge distribution charge density $ \rho(\r) $, we can find the corresponding electric potential $ \phi(\r) $. 
	
	\item Note that the general solution for $ \phi(\r) $ is a generalized form of the electric potential of a point particle of charge $ q $, for which the electric potential is
	\begin{equation*}
		\phi(\r) = \frac{q}{4\pi \ee r}.
	\end{equation*}
	This similarity indicates the Poisson equation and its general solution is consistent with Coulomb's law and the potential of a point particle.
	

	
	\item Finally, with $ \phi(\r) $ known, we can find the electric field of a charge distribution $ \rho(\r) $ from the gradient of the electric potential:
	\begin{equation*}
		\E = - \grad \phi(\r) = - \grad \iiint \frac{\rho(\t{\r})}{4\pi \ee \abs{\r - \t{\r}}}\dtr = \iiint \frac{\rho(\t{\r})\dtr}{4\pi \ee} \frac{\r - \t{\r}}{\abs{\r - \t{\r}}^{3}}.
	\end{equation*}
	Note that the gradient acts only on $ \r $ and not on $ \t{\r} $. As for electric potential, the general solution for the electric field of charge distribution is a generalization of Coulomb's law for a point charge. 
\end{itemize}

\subsection{In Passing: Earnshaw's Theorem and the Thomson Problem}
\begin{itemize}
	\item Earnshaw's theorem states that a collection of point charges cannot exist in \textit{stable} equilibrium due solely to the electrostatic interaction between the charges. 
	
	\item At a hypothetical point of stable electrostatic equilibrium in free space, all electrostatic force lines would locally point towards the point. In this case the electric force's divergence is nonzero, which implies
	\begin{equation*}
		0 \neq \div \vec{F} = \div (q \E) = - \div (q \grad \phi) = - q \laplacian \phi \neq 0.
	\end{equation*}
	In other words, stable electrostatic equilibrium results in $ \laplacian \phi = 0 $, which violates the Laplace equation.
	
	\item More mathematically, in free space (with zero charge density), electric potential obeys the Laplace equation and is thus a harmonic function with no minima or maxima; at most, electric potential in free space can have saddle points, which correspond to points of \textit{unstable} electrostatic equilibrium. 
	
	\item Note that the Earnshaw theorem only applies in the regime of classical electromagnetism, and matter is nonetheless stable, despite the Earnshaw theorem, because of the existence of quantum mechanical effects such as stationary orbital states and the Pauli exclusion principle.
\end{itemize}

\textbf{The Thomson Problem}
\begin{itemize}
	\item The electrostatic energy of a charge distribution can have minima if the electric charges are fixed. The Thomson problem involves finding the distribution in space of a collection of point charges such that the charges' collective electrostatic energy is minimized.
	
	\item The problem is important in chemistry and biology, when investigating molecular bonds. We mention the problem because of its historical significance but don't investigate it further.
\end{itemize}

\subsection{Electrostatic Energy}
\subsubsection{Electrostatic Energy in an External Field}
\begin{itemize}
	\item Consider a charge $ q $ in a known external electric field $ \E $. Naturally, we cannot create an electric field out of thin air, but for this section we ignore the charges responsible for the electric field and take the field's existence for granted.
	

	
	\item In the electric field, the particle experiences a force $ \vec{F} = q \E $. We interpret electrostatic energy as the potential energy needed to keep the particle at rest, or alternatively, the work against the electrostatic force needed to bring the particle to its position from infinity. The differential of work is
	\begin{equation*}
		\diff W = - \vec{F} \cdot \diff \r = - q \E \cdot  \diff \r = q \grad \phi \cdot \diff \r.
	\end{equation*}
	By the work-energy theorem, the total work $ W $ and electrostatic energy $ W_{\text{E}} $ are related by
	 \begin{equation*}
		W = \int_{(1)}^{(2)} \diff W = W_{\text{E}}^{(2)} - W_{\text{E}}^{(1)} = q \int_{(1)}^{(2)}\grad \phi \diff \r = q\big(\phi^{(2) }- \phi^{(1)}\big).
	\end{equation*}
	From the equality $ W_{\text{E}}^{(2)} - W_{\text{E}}^{(1)} = q\big(\phi^{(2) }- \phi^{(1)}\big) $, the electrostatic energy of a point charge in an external electric field is thus
	\begin{equation*}
		W_{\text{E}} = q \phi,
	\end{equation*}
	where $ \phi $ is the electric potential arising from the \textit{external} field. 
	
	\item For a continuous charge distribution $ \rho(\r) $, the appropriate generalization is
	\begin{equation*}
		W_{\text{E}} = \iiint_{V} \rho(\r) \phi (\r) \dr,
	\end{equation*}
	where $ \phi $ is again the electric potential arising from the external field only (and has nothing to do with the charge distribution $ \rho(\r) $), while $ V $ is the region of space containing $ \rho $.
\end{itemize}

\subsubsection{Total Electrostatic Energy}
\begin{itemize}
	\item In the previous section, we ignored the  ``background'' charges creating an external field. We now consider the total electrostatic energy of charge distribution in an electric field with respect to both the charge distribution and the charges creating the external field. 
	
	To do this, we consider a charge distribution $ \rho(\r) $ that generates a potential $ \phi(\r) $, and ask what is the associated electrostatic energy needed to assemble the charge distribution $ \rho(\r) $ from empty space. To make this easier, we introduce parameter $ \alpha \in [0, 1] $, which continuously ``turns on'' our charge distribution. 
	
	\item We now consider the change in energy $ \diff W_{\text{E}} $ from adding additional charge density $ \diff \rho = \rho(\r) \diff \alpha $ to the charge we have already assembled. The existing charges create an external field like in the previous problem, where the associated electrostatic energy is $ W_{\text{E}} = \int \t{\rho}(\r) \t{\phi} (\r) \dr $. 	The corresponding differential $ \diff W_{\text{E}} $ is
	\begin{align*}
		\diff W_{\text{E}} &= \iiint_{V} \diff \t{\rho}(\r)\t{\phi}(\r) \dr = \iiint_{V} \rho(\r) \diff\alpha \big[\alpha \phi (\r)\big ] \dr \\
		& = \alpha \diff \alpha \iiint_{V} \rho(\r) \phi(\r) \dr.
	\end{align*}
	where we have applied the linearity of the Poisson equation, i.e. $ \laplacian [\alpha \phi] = - \frac{\alpha \rho }{\ee} $. 
	
	We find the total energy by integrating over $ \alpha $ from 0 to 1:
	\begin{equation*}
		W_{\text{E}} = \diff W_{\text{E}} = \int_{0}^{1} \left[ \alpha \iiint_{V} \rho(\r) \phi(\r) \dr \right] \diff \alpha = \frac{1}{2} \iiint_{V} \rho(\r) \phi(\r) \dr.
	\end{equation*}
	This final result is sometimes referred to as the electrostatic energy of an electric field, and refers to the energy of the charge distribution $ \rho $ creating the electric potential $ \phi $.
	
	Although this result is quantitatively similar to the electrostatic energy of charge distribution in an external field, differing only by a factor $ 1/2 $, the two energies are fundamentally different quantities. 
	
	In this section, the charge distribution $ \rho(\r) $ creates the electric potential $ \phi $, and in the previous section, the charge density $ \rho $ was unrelated to the electric potential $ \phi $, whose existence we took for granted and otherwise ignored.
	
	\item Next, we will derive an expression for the just-derived electrostatic energy of an electric field in terms of only the charge density creating the field. We substitute the Green's function representation of electric potential, i.e.
	\begin{equation*}
		\phi(\r) = \frac{1}{4\pi \ee}\iint_{V} \frac{\rho(\t{\r})}{\abs{\r - \t{\r}}} \dtr,
	\end{equation*}
	into the electric field energy $ W_{\text{E}} $ to get
	\begin{equation*}
		W_{\text{E}} = \frac{1}{2} \iiint_{V} \rho(\r) \phi(\r) \dr = \frac{1}{8 \pi \ee} \iiint_{V} \left[\iiint_{V} \frac{\rho(\r) \rho(\t{\r})}{\abs{\r - \t{\r}}} \dtr\right] \dr,
	\end{equation*}
	where we stress that $ \rho $ is the charge distribution creating the electric field.
\end{itemize}


\subsubsection{Electric Field Energy In Terms of Electric Field}
\begin{itemize}
	\item Next, we will derive and an expression total electric field energy in terms of only the electric field $ \E $. We start with
	\begin{equation*}
		W_{\text{E}} = \frac{1}{2} \iiint_{V} \rho(\r) \phi(\r) \dr
	\end{equation*}
	and use Gauss's law $ \div \E = \frac{\rho}{\ee} $ to get
	\begin{equation*}
		W_{\text{E}}  = \frac{1}{2} \iiint_{V} \ee (\div \E) \phi(\r) \dr.
	\end{equation*}
	
    \item Next, we use a reverse-engineered form of the vector calculus identity 
	\begin{equation*}
		\div (f \vec{g}) = \grad f \cdot \vec{g} + f (\div \vec{g}) \implies (\div \E) \phi(\r) = \div (\phi \E) - \grad \phi \cdot \E,
	\end{equation*}
	followed by the divergence theorem, to get
	\begin{align*}
		W_{\text{E}} &= \frac{\ee}{2} \iiint_{V}\left[\div (\phi \E) - \grad \phi \cdot \E\right] \dr = \frac{\ee}{2} \oiint_{\partial V} \phi \E \diff \vec{S} - \frac{\ee}{2} \iiint_{V} (\grad \phi) \E \dr\\
		& =  \frac{\ee}{2} \oiint_{\partial V} \phi \E \diff \vec{S} - \frac{\ee}{2} \iiint_{V} (- \E) \E \dr,
	\end{align*}
	where we've used $ \grad \phi = - \E $ in the second integral. 
	
	\item We then assume the integration volume $ V $ enclosing the charge distribution $ \rho $ is large, in which case the integral of $ \phi \E $ over the surface $ \partial V $ is zero. Here's why: The electric potential falls as $ \phi \sim r^{-1} $ with increasing distance $ r $, and the electric field falls as $ \E \sim r^{-2} $, while surface area grows as $ \vec{S} \sim r^{2} $. The integrand  $ \phi \E \cdot \diff \vec{S} $ thus falls as $ r^{-1} $ and vanishes as $ r \to \infty $. What remains is the familiar formula
	\begin{equation*}
		W_{\text{E}} = \frac{\ee}{2} \iiint_{V} E^{2} \dr.
	\end{equation*} 
	\textit{Interpretation}: This is the energy associated with the electric field $ \E $ resulting from assembling a charge distribution $ \rho(\r) $ in the region $ V $ in what was originally empty space.

\end{itemize}


\subsection{Electrostatic Force and the Stress-Energy Tensor}

\subsubsection{Electric Force in Terms of of Electric Field}
\begin{itemize}
	\item Consider a body with charge distribution $ \rho(\r) $ in an external electric field $ \E_{\text{ext}} $. We are interested in the force acting on the charge distribution due to the total electric field $ \E $, accounting for both the external field $ \E_{\text{ext}} $ and the field $ \E_{\rho} $ created by the charge distribution $ \rho(\r) $, and we want to write this force in terms of only the total electric field $ \E $.
	
	\item We find the electric force on the charge distribution by generalizing $ \vec{F} = q \E_{\text{ext}} $. Without proof, we note that the field $ \E_{\rho} $ created by the charge distribution $ \rho(\r) $ does not contribute to the electric force on the charged body---this makes sense, since a body cannot create a net force on itself. As a result, we can write
	\begin{equation*}
		\vec{F} = \iiint_{V} \rho(\r) \E_{\text{ext}}(\r) \dr = \iiint_{V} \rho(\r) \E(\r) \dr,
	\end{equation*}
	where $ V $ is the region of space containing the charge distribution.
	
	\item Next, we use Gauss's law $ \rho(\r) = \ee \div \E_{\rho} $, to write the electric force in the form
	\begin{equation*}
		\vec{F} = \ee \iiint_{V} (\div \E_{\rho}) \E(\r) \dr \stackrel{?}{=} \ee \iiint_{V} (\div \E) \E(\r) \dr 
	\end{equation*}
	Note that the field in the $ \div \E_{\rho} $ term arises from the charge distribution $ \rho(\r) $ and is different from $ \E $. We resolved this (seems hand-wavy to me) by saying that $ \rho(\r) $ now includes both the charge distribution of the body and the distance charge distribution responsible for the external field $ \E_{\text{ext}} $. As I understood it, the argument is that because the external charge distribution is far away and thus negligible compared to the localized distribution corresponding to the charged body, we can safely incorporate $ \rho_{\text{ext}} $ into $ \rho $. 
	
	In any case, we proceed with the expression
	\begin{equation*}
		\vec{F} = \ee \iiint_{V} (\div \E) \E(\r) \dr,
	\end{equation*}
	where $ \E $ is the total electric field.
	

	\item The integral currently runs over the entire body's volume. In practice, it is hard to measure the electric field inside a body, so our next step is to convert to an integral over the body's surface. We apply the vector analysis identity
	\begin{equation*}
		\div (\E \otimes \E) = \E (\div \E) + (\E \cdot \grad) \E,
	\end{equation*}
	in terms of which the electric force reads
	\begin{align*}
		\vec{F} &= \ee \iiint_{V} \big[\div (\E \otimes \E) - (\E \cdot \grad) \E \big] \dr \\
		& = \ee \oiint_{\partial V} \E(\E \cdot \diff \vec{S}) - \ee \iiint_{V}(\E \cdot \grad)\E \dr,
	\end{align*}
	where the last equality uses the divergence theorem. 
	
	\item Next, we introduce a normal vector $ \uvec{n} $ to the body's surface to get
	\begin{equation*}
		\vec{F} = \ee \oiint_{\partial V} \E (\E \cdot \uvec{n}) \diff S - \ee \iiint_{V} (\E \cdot \grad)\E \dr.
	\end{equation*}
	Next we use the vector identity $ \frac{1}{2} \grad (E^{2}) = (\E \cdot \grad)\E + \E \cross (\curl \E) $, combined with the electrostatic Maxwell equation $ \curl \E = 0 $ (which doesn't hold in the presence of a time-varying magnetic field) to get
	\begin{equation*}
		\vec{F} = \ee \oiint_{\partial V} \E (\E \cdot \uvec{n}) \diff S - \frac{\ee}{2} \iiint_{V} \grad E^{2}\dr.
	\end{equation*}
	Finally, we apply the scalar field corollary of the divergence theorem to the integral of $ \grad E^{2} $ over the volume $ V $ to get
	\begin{equation*}
		\vec{F} = \ee \oiint_{\partial V} \E (\E \cdot \uvec{n}) \diff S - \frac{\ee}{2} \oiint_{\partial V}E^{2}\uvec{n} \diff S = \ee \oiint_{\partial V} \left[\E(\E\cdot \uvec{n}) - \frac{E^{2}}{2}\uvec{n} \right] \diff S.
	\end{equation*}
	As desired, the integral runs only over the body's surface $ \partial V $, and the electric force is expressed only in terms of the total electric field $ \E $.
	
	\item Finally, we note that the information about the body's charge distribution $ \rho $ is hidden in the body's contribution to the total electric field, since we converted $ \rho(\r) $ to electric field using Gauss's law.
	
\end{itemize}

\subsubsection{The Electrostatic Stress-Energy Tensor}
\begin{itemize}
	\item We can write the above expression for electrostatic force using a rank-two tensor called the electrostatic stress-energy tensor. By components, in terms of the stress tensor $ \TT_{ik} $, the force is
	\begin{equation*}
		F_{i} = \oiint_{\partial V} \TT_{ik} \hat{n}_{k} \diff S,
	\end{equation*}
	where the components of the stress tensor are defined as
	\begin{equation*}
		\TT_{ik} = \ee \left(E_{i}E_{k} - \frac{1}{2}E^{2}\delta_{ik} \right).
	\end{equation*}
	
	\item We can also write the electrostatic force as a volume integral:
	\begin{equation*}
		F_{i} = \oiint_{\partial V} \TT_{ik} \hat{n}_{k} \diff S = \iiint_{V} \pdv{\TT_{ik}}{r_{k}} \dr.
	\end{equation*}
	The quantity $ \pdv{\TT_{ik}}{r_{k}} $ represents electrostatic force density $ f(\r) $ in the direction $ \uvec{r}_{i} $:
	\begin{equation*}
		f_{i}(\r) = \pdv{\TT_{ik}}{r_{k}}.
	\end{equation*}
	Note that stress-energy tensors are widely used (i.e. not just in electromagnetism) to describe the force density associated with a field, for example in hydrodynamics and continuum mechanics.
	
	
\end{itemize}

\subsection{The Multipole Expansion in Electrostatics}

\subsubsection{Multipole Expansion of Electric Potential}
\begin{itemize}
	\item We begin by approximating an arbitrary charge distribution with $ n $-poles (e.g. monopoles, dipoles, quadrupoles, etc...).
	
    Consider a charge distribution with density $ \rho(\s) $ localized in the region of space $ V_{0} $. Our goal is to find an expression for the electric potential $ \phi(\r) $ far from the charge distribution, written in terms of a multipole expansion of $ \rho(\s) $.
	
    Note that the charge distribution $ \rho(\s) $ must be localized in space for the idea of ``far away'' to make sense---we take ``far away'' to be around an order of magnitude larger than a characteristic distance of the region $ V_{0} $, although smaller distances may be used in practice with high-order multipole expansions.

    \item We begin by writing the electric potential $ \phi(\r) $ in the form
	\begin{equation*}
		\phi(\r) = \frac{1}{4\pi \ee}\iiint_{V_{0}}\frac{\rho(\s)}{\abs{\r - \s}} \ds.
	\end{equation*}
    We then expand the integrand to second order in the limit $ \abs{\r} \gg \abs{\s}  $, which produces
	\begin{align*}
        \frac{1}{\abs{\r - \s}} &= \frac{1}{\abs{\r}} - \s \cdot \grad\left(\frac{1}{\abs{\r}}\right) + \frac{1}{2\abs{\r}} \s^{T}\mat{H}\s + \cdots\\
        &= \frac{1}{\abs{\r}} + \frac{\s \cdot \r}{\abs{\r}^{3}} + \frac{1}{2\abs{\r}} \s^{T}\mat{H}\s + \cdots,
	\end{align*}
    where we have used the identity $ \grad \frac{1}{\abs{\r}} = \frac{\r}{\abs{\r^{3}}} $ and $ \mat{H} $ is the Hessian matrix.

    \item We then substitute the first-order expansion into the expression for $ \phi(\r) $ to get
	\begin{align*}
		\phi(\r) &= \frac{1}{4\pi \ee \abs{\r}}\iiint_{V_{0}} \rho(\s) \ds + \frac{1}{4\pi \ee}\frac{\r}{\abs{\r}^{3}}\iiint_{V_{0}} \s \rho(\s)\ds\\
		& = \frac{q}{4\pi \ee r} + \frac{\r \cdot \pe}{4\pi \ee r^{3}},
	\end{align*}
    where we have written the integrals in terms of the charge $ q $ and dipole moment $ \pe $, which are defined as
	\begin{equation*}
		q = \iiint_{V_{0}} \rho(\s) \ds \eqtext{and} \pe = \iiint_{V_{0}} \s \rho(\s) \ds.
	\end{equation*}
	
	\item Without derivation, a higher-order expansion of the electrostatic potential reads
	\begin{equation*}
		\phi(\r) = \frac{1}{4\pi \ee} \sum_{l=0}^{\infty}\sum_{m=-l}^{l}\frac{4\pi}{(2l+1)}\frac{Q_{lm}}{r^{l+1}}Y_{l}^{m}(\theta, \phi).
	\end{equation*}
	In other words, the multipole expansion is an expansion of $ \phi(\r) $ in the basis of the spherical harmonics $ Y_{l}^{m} $. We find the multipole moments $ Q_{lm} $ with
	\begin{equation*}
		Q_{lm} = \iiint_{V_{0}} \rho(\s)s^{l}Y_{l}^{m}(\theta, \phi) \ds.
	\end{equation*}
\end{itemize}

\subsubsection{Multipole Expansion of Electrostatic Energy}
\begin{itemize}
    \item We now aim to express the electrostatic energy of a charge distribution in an external field in terms of a multipole expansion of the charge distribution. As before, we consider a charge distribution localized in the region $ V_{0} $, centered around the position $ \r_{0} $. We then place this charge distribution in an \textit{external} potential $ \phi(\r) $. We stress that the external potential $ \phi(\r) $ is unrelated to the charge distribution $ \rho $.
	
	\item Recall the general form of electrostatic energy for a charge distribution in an external field is
	\begin{equation*}
		W_{\text{E}} = \iiint_{V} \rho(\r) \phi(\r) \dr.
	\end{equation*}
	In our case, we assume the majority of the charge in the distribution is concentrated around the distribution's ``center'' $ \r_{0} $, in which case the majority of the distribution's electrostatic energy is also concentrated around $ \r_{0} $. 
	
	\item We then expand the electric potential about $ \r_{0} $ according to
	\begin{equation*}
		\phi(\r) = \phi(\r_{0}) + (\r - \r_{0}) \grad \phi(\r_{0}) + \cdots,
	\end{equation*}
    where $ \grad $ acts on $ \r $. Substituting this expression for $ \phi(\r) $ into the general expression for energy $ W_{\text{E}} $ gives
	\begin{align*}
		W_{\text{E}} &= \iiint_{V}\dr \rho(\r)\big[\phi(\r_{0}) + (\r - \r_{0})\grad \phi(\r_{0}) + \cdots \big]\\
		& = \phi(\r_{0}) \iiint_{V} \dr \rho(\r) + \grad \phi(\r_{0}) \iiint_{V} \dr \rho(\r)(\r - \r_{0})\\
		& = q \phi(\r_{0}) - \E(\r_{0}) \cdot \pe + \cdots,
	\end{align*}
    where we have substituted in the charge $ q $ and electric dipole $ \pe $ defined in the previous section. Note also the use of $ \grad\phi(\r_{0}) = - \E(\r_{0}) $. 

    The two terms in the above expression for $ W_{\text{E}} $ are, respectively, the energy of a point charge and the energy of an electric dipole in an external electric field. The dipole term indicates that the energy of dipole in an external field is minimized when the dipole is parallel to the external field.
	
\end{itemize}

\subsubsection{Multipole Expansion of Force in an External Field}

\begin{itemize}
	\item Again, we consider a charge distribution $ \rho $ localized in the region $ V_{0} $, centered around the position $ \r_{0} $. We place the distribution in an \textit{external} potential $ \phi(\r) $ corresponding to an electric field $ \E(\r) $. As before, the electric field and potential are unrelated to the charge distribution $ \rho $.
	
    Continuing the pattern of previous sections, we aim to find an expression for the electrostatic force on the charge distribution $ \rho $ in terms of a multipole expansion of the charge distribution. 
	
	\item We find force from the gradient of potential energy via $ \vec{F} = - \grad W_{\text{E}} \iff \diff W_{\text{E}} = - \vec{F} \cdot \diff \r $. The electrostatic potential energy is known from two sections and reads
    \begin{equation*}
        W_{\text{E}} = q \phi(\r_{0}) - \E(\r_{0}) \cdot \pe + \cdots. 
    \end{equation*}

	\item We begin by differentiating $ W_{\text{E}} $ to get $ \diff W_{\text{E}} $, which reads
	\begin{equation*}
		\diff W_{\text{E}} = q \grad \phi(\r_{0})\diff \r - \grad \big[\pe \cdot \E(\r_{0})\big]\diff \r \equiv - \vec{F} \cdot \diff \r.
	\end{equation*}
	Next, we cancel the common factor $ \diff \r $ and substitute in the identity $ \grad \phi(\r_{0}) = - \E(\r_{0}) $, along with the vector identity 
	\begin{equation*}
		\grad\big[\pe \cdot \E(\r_{0})\big] = \pe \cross (\curl \E(\r_{0})) + (\pe \cdot \grad)\E(\r_{0}).
	\end{equation*}
    The electrostatic force then simplifies to
    \begin{equation*}
        \vec{F} = q \E(\r_{0}) + \pe \cross (\curl \E(\r_{0})) + (\pe \cdot \grad)\E(\r_{0}).
    \end{equation*}
    
    \item Finally, we substitute in the electrostatics identity $ \curl \E = 0 $. The final expression for electrostatic force is then
	\begin{equation*}
		\vec{F} = q \E + (\pe \cdot \grad)\E(\r_{0}).
	\end{equation*}
    The two terms in this expression are the electrostatic force on a monopole (point charge) and a dipole, respectively.
	
\end{itemize}

\subsubsection{Multipole Expansion of Torque in an External Field}
\begin{itemize}
	\item  Finally, we will find an expression for the electrostatic torque on a charge distribution in an external electric field in terms of a dipole expansion of the charge distribution. As before, we consider a charge distribution $ \rho $ centered at the position $ \r_{0} $ in the localized region of space $ V_{0} $. 
	
	\item To find the electrostatic torque, we consider a small rotation $ \diff \vec{\phi} $ of the charge distribution in space. We will relate energy and torque with the general relationship
	\begin{equation*}
		\diff W_{\text{E}} = - \vec{M} \cdot \diff \vec{\phi}.
	\end{equation*}
	We begin with the dipole expansion of the charge distribution's electrostatic energy, which reads
	\begin{equation*}
		W_{\text{E}} = q \phi(\r_{0}) - \E (\r_{0}) \cdot \pe + \cdots.
	\end{equation*}
    We then take the total differential of this expression to find $ \diff W_{\text{E}} $. The term $ q \phi(\r_{0}) $ is a constant quantity and vanishes, and the result is
	\begin{equation*}
		\diff W_{\text{E}} = - \diff \pe \cdot \E(\r_{0}).
	\end{equation*}
    
    \item The differential $ \diff \pe $ can be written as the infinitesimal rotation $ \diff \pe = \diff \vec{\phi} \cross \pe $, in which case $ \diff W_{\text{E}} $ becomes
	\begin{equation*}
		\diff W_{\text{E}} = - (\diff \vec{\phi} \cross \pe)\cdot \E(\r_{0}).
	\end{equation*}
	This expression for $ \diff W_{\text{E}} $ contains a scalar triple product, which we rearrange to get
	\begin{equation*}
		\diff W_{\text{E}} = - \diff \vec{\phi} \cdot (\pe \cross \E) = - \diff \vec{\phi} \cdot \vec{M}.
	\end{equation*}
    The resulting torque on the charge distribution is thus 
    \begin{equation*}
       \vec{M}(\r_{0}) = \pe \cross \E(\r_{0}),
    \end{equation*}
    which is the expression for the torque on an electric dipole in an external electric field. Note that the dipole's potential energy $ \diff W_{\text{E}} $ is minimized when the dipole and external field are parallel.
	
\end{itemize}

\newpage
\section{Magnetostatics}
In this chapter we consider only static magnetic fields that do not change with respect to time, hence the name magnetostatics. Magnetic fields are created by electric currents or time-varying electric fields. In this chapter we will consider current sources of magnetic fields---we will consider magnetic fields generated by time-varying electric fields when studying electrodynamics.

\subsection{Ampere's Force Law and Magnetic Force}

\subsubsection{Magnetic Force Between Parallel Wires}
\begin{itemize}
	\item We begin with a simple expression for magnetic force. Consider two parallel wires carrying currents $ I_{1} $ and $ I_{2} $. If the currents flow in the same direction, the force between the wires is attractive, and vice versa.
	
	We work in a planar cross section, and assume the wires occur at the positions $ \r_{1} $ and $ \r_{2} $. In this case, the force between the wires is
	\begin{equation*}
        \vec{F} = \frac{\mm I_{1} I_{2} L}{2\pi} \frac{\r_{2}- \r_{1}}{\abs{\r_{2} - \r_{1}}^{2}}
	\end{equation*}
	where $ L $ is the length of the wires. 

    \textit{Important:} We take this relationship as an empirical law---we have not derived it from theory or fundamental principles. This expression for the magnetic force between parallel wires can be considered a magnetic analog to Coulomb's law for the electric force between static electric charges.
	
\end{itemize}

\subsubsection{Force Between Current-Carrying Conductors}
\begin{itemize}
	\item We now consider the magnetic force between two conductors (wires) that are not necessarily parallel. We parameterize the position along each conductor with the following quantities:
    \begin{itemize}
        \item $ l_{1} $ and $ l_{2} $ are the distance travelled along the first and second conductor, respectively

        \item $ \diff \vec{l}_{1} $ and $ \diff \vec{l}_{2} $ are infinitesimal segements of each conductor. They point tangent to the conductor in the direction of the electric current.

        \item $ \r(l_{1})  $ and $ \r(l_{2})  $ are the positions along the conductor
    \end{itemize}
    
	\item The force on the first wire due to the second conduwire ctor, considering two infinitesimal pieces of each wire, is
	\begin{equation*}
		\diff^{2}\vec{F} = \frac{\mm}{4\pi}\frac{(I_{1}\diff \vec{l}_{1}) \cdot (I_{2}\diff \vec{l}_{2})}{\abs{\r(l_{2}) - \r(l_{1})}^{2}}\frac{\r(l_{2}) - \r(l_{1})}{\abs{\r(l_{2}) - \r(l_{1})}}.
	\end{equation*}
    Note that this is a double differential, since it involves the product of two differential segments $ \diff \vec{l}_{1} $ and $ \diff \vec{l}_{2} $. This expression may look daunting, be it is really just a generalization of the magnetic force between parallel wires given above.
	
	\item In integral form, the force on the first conductor $ C_{1} $ due to the current in $ C_{2} $ is written in terms of the line integrals over both $ C_{1} $ and $ C_{2} $. The expression reads
	\begin{equation*}
		\vec{F} = \frac{\mm I_{1}I_{2}}{4\pi}\oint_{C_{1}}\oint_{C_{2}}\frac{\diff \vec{l}_{1} \cdot \diff \vec{l}_{2}}{\abs{\r(l_{2}) - \r(l_{1})}^{2}} \frac{\r(l_{2}) - \r(l_{1})}{\abs{\r(l_{2}) - \r(l_{1})}}.
	\end{equation*}
	To find the force on $ C_{2} $ due to $ C_{1} $, we just reverse the role of $ \r(l_{1}) $ and $ \r(l_{2}) $.
	
	\item Finally, without derivation, we note that the above expression for the force between two conductors can be written in the equivalent vector-product form
	\begin{equation*}
		\vec{F} = - \frac{\mm I_{1}I_{2}}{4\pi}\oint_{C_{1}}\oint_{C_{2}} \frac{\diff \vec{l}_{1}\cross \big[\diff \vec{l}_{2} \cross (\r(l_{2}) - \r(l_{1}) )\big]}{\abs{\r(l_{2}) - \r(l_{1})}^{3}}.
	\end{equation*}
    This expression will useful when analyzing magnetic flux density.
	
\end{itemize}


\subsection{Fundamental Quantities in Magnetostatics}

\subsubsection{Electric Current and its Magnitude}
We dedicate a brief section to review electric current, since we will be working with electric current constantly in magnetostatics. 
\begin{itemize}
	\item Electric current is the motion of charged particles---for the time being, we will limit ourselves to currents along wire-like conductors. Electric current is defined as
	\begin{equation*}
		I = \dv{q}{t}
	\end{equation*}
    and is a scalar quantity. In magnetostatics, we consider only time-independent currents for which $ \dv{I}{t} = 0 $.
	
	\item Some typical orders of magnitude for electric current are given in the table below
	
	\begin{center}
	\begin{tabular} {c|c}
        Current in... & Typical order of magnitude \\
        \hline
        a cell membrane channel &  \SIrange{1}{10}{\pico \ampere} \\
        a nerve impulse &  \SI{1}{\micro \ampere}  \\
        common household devices &  \SI{1}{\ampere} \\
        superconducting magnets at the LHC & \SI{12}{\kilo \ampere} \\
        lightning &  \SIrange{10}{200}{\kilo \ampere} \\
        the Earth's core &  \SI{1}{\giga \ampere} 
	\end{tabular}
	\end{center}
	
\end{itemize}

\subsubsection{The Biot-Savart Law for Magnetic Field}
\begin{itemize}
	\item We now aim to convert the expression for the magnetic force between conductors into an expression for magnetic field, just like we used Coulomb's law for the electric force between charges to derive an expression for electric field. 
	
	We begin with the vector-product form of the force between two conductors $ C_{1} $ and $ C_{2} $, which reads
	\begin{equation*}
		\vec{F} = - \frac{\mm I_{1}I_{2}}{4\pi}\oint_{C_{1}}\oint_{C_{2}} \frac{\diff \vec{l}_{1}\cross \big[\diff \vec{l}_{2} \cross (\r(l_{2}) - \r(l_{1}) )\big]}{\abs{\r(l_{2}) - \r(l_{1})}^{3}}.
	\end{equation*}
    We then rearrange this expression into the form
	\begin{equation*}
		\vec{F} = \oint_{C_{1}}I_{1}\diff \vec{l}_{1}\cross \left(\frac{\mm I_{2}}{4\pi} \oint_{C_{2}}\frac{\diff \vec{l}_{2} \cross \big(\r(l_{1}) - \r(\l_{2})\big)}{\abs{\r(l_{1}) - \r(l_{2})}^{3}}\right).
	\end{equation*}
	
    \item Comparing this expression for force to $ \vec{F} = \oint_{C_{1}} I_{1} \diff \vec{l}_{1} \cross \B $ motivates the definition
	\begin{equation*}
		\B(\r(l_{1})) \equiv \frac{\mm I_{2}}{4\pi} \oint_{C_{2}}\frac{\diff \vec{l}_{2} \cross \big(\r(l_{1}) - \r(\l_{2})\big)}{\abs{\r(l_{1}) - \r(l_{2})}^{3}}.
	\end{equation*}
	This is the magnetic field generated by the conductor $ C_{2} $ carrying current $ I_{2} $. Note that this expression is essentially the familiar Biot-Savart law. 

    Finally, note that the expression for the magnetic force on the conductor $ C_{1} $, which reads
	\begin{equation*}
		\vec{F} = \oint I_{1}\diff \vec{l}_{1} \cross \B(\r(l_{1})),
	\end{equation*}
	is just the integral form of the familiar expression $ \vec{F} = I (\vec{l}\cross \vec{B}) $. 
	
	\item Some typically values of magnetic field are given in the table below
	\begin{center}
		\begin{tabular}{c | c}
			Phenomenon & Magnetic Field\\
			\hline
			brain activity & $ \SI{1}{\femto \tesla} $\\
			intergalactic magnetic fields & \SIrange{1}{10}{\pico \tesla}\\
			heart activity & \SI{100}{\pico \tesla}\\
			earth's magnetic field & \SIrange{20}{70}{\micro \tesla}\\
			iron ferromagnet & \SI{100}{\milli \tesla}\\
			sunspot & \SI{1}{\tesla}\\
			simple particle accelerator & \SI{10}{\tesla}\\
			neutron star & \SIrange{e6}{e11}{\tesla}\\
			atomic nucleus & \SI{1}{\tera \tesla}
		\end{tabular}
	\end{center}
	
\end{itemize}

\subsubsection{Magnetic Field Lines}
\begin{itemize}
    \item In terms of the arc length parameter $ s $, magnetic field lines $ \r(s) $ are closed curves related to magnetic field $ \B $ by
	\begin{equation*}
		\dot{\r}(s) = \dv{\r}{s} = \frac{\B(\r(s))}{\abs{\B(\r(s))}}.
	\end{equation*}
	Note that all magnetic field lines are closed curves---there are no magnetic monopoles. 
	
\end{itemize}

\subsubsection{Magnetic Circulation}
\begin{itemize}
	\item Magnetic circulation $ \Gamma_{\text{M}} $ is defined as the line integral
	\begin{equation*}
		\Gamma_{\text{M}} = \oint_{C}\B \cdot \diff \r \neq 0.
	\end{equation*}
	Magnetic circulation is nonzero because magnetic field lines are closed. In contrast, electric circulation can be zero for static fields, since electric field lines are not necessarily closed.
	
	The statement that all magnetic field lines are closed is equivalent to stating that magnetic monopoles do not exist (have not been observed) in nature.
	
	\item Example: the magnetic circulation circular wire of radius $ R $ in a magnetic field $ \B $ is
	\begin{equation*}
		\Gamma_{\text{M}} = \oint_{C}\B \cdot \diff \r = B \cdot (2\pi R) \neq 0.
	\end{equation*}
	
	\item Writing magnetic circulation as a surface integral using Stokes' theorem leads to the conclusion
	\begin{equation*}
		0 \neq \oint_{C}\B \cdot \diff \r = \iint_{S} \curl \B \cdot \diff \vec{S} \implies \curl \B \neq 0.
	\end{equation*}
	
\end{itemize}

\subsubsection{Magnetic Flux}
\begin{itemize}
	\item The magnetic flux through a surface $ S $ is defined as
	\begin{equation*}
		\Phi_{\text{M}} = \iint_{S} \B \cdot \diff \vec{S}.
	\end{equation*}
	In the above expression, $ S $ is an arbitrary surface. However, if $ S $ is a closed surface, we can immediately write
	\begin{equation*}
	 	\oiint_{S} \B \cdot \diff \vec{S} = 0
	\end{equation*}
	This is a consequence of magnetic field lines being closed. This result differs from it electric analog, Gauss's law, which reads $ \Phi_{E} = Q/\ee \neq 0 $.
	
	\item In integral form, using the divergence theorem, the magnetic flux through a closed surface is
	\begin{equation*}
		0 \equiv \Phi_{\text{M}} = \oiint_{\partial V} \B \cdot \diff \vec{S} = \iiint_{V} \div \B \diff V.
	\end{equation*}
	In differential form the above equation is equivalent to the requirement
	\begin{equation*}
		\div \B = 0,
	\end{equation*}
    which is a special case of a Maxwell equation for magnetostatics. The relationship $ \div \B = 0 $ is another manifestation of the absence of magnetic monopoles in nature.
	
\end{itemize}

\subsection{Electric Current Density}
\begin{itemize}
	\item Electric current density allows us to generalize currents in a wire-like conductor to currents in a three-dimensional region of space, which will give us a much more general formalism for describing magnetic fields.
	
    Current density is defined in terms of the relationship
	\begin{equation*}
		I = \iint_{S} \vec{j} \cdot \diff \vec{S} = \iint_{S} \vec{j} \cdot \uvec{n} \diff S,
	\end{equation*}
    where $ I $ is the current through the planar cross-sectional surface $ S $. Note that $ I $ is scalar and $ \vec{j} $ is a vector quantity. Since current density is a vector quantity, it can have arbitrary direction in space and is not tied to a conductor. 
	
\end{itemize}

\subsubsection{Examples of Current Densities}
\begin{itemize}
	\item Our first exqmple is the current density of continuous charge distribution. We begin by considering the current
	\begin{equation*}
		\diff I = \vec{j}\cdot \diff \vec{S}
	\end{equation*}
	through some surface $ \diff \vec{S} $. By definition of current, we have
	\begin{equation*}
		\diff I = \diff \left[\dv{q}{t}\right] = \diff \left(\frac{\rho(\r)\diff V}{\diff t}\right) = \diff \left(\frac{\rho(\r)\diff S \diff x}{\diff t}\right)  = \rho \frac{(\vec{v} \cdot \uvec{n}) \diff S \diff t}{\diff t} = \rho v \diff S,
	\end{equation*}
	where $ (\vec{v} \cdot \uvec{n}) $ is the charge carrier velocity normal to $ \diff \vec{S} $. The above implies
	\begin{equation*}
		\vec{j}(\r, t) = \rho(\r) \vec{v}(\r),
	\end{equation*}
	where $ \vec{v} $ is the velocity field of the charge distribution at position $ \r $---which we have assumed is uniformly distributed.
	
	\item Next, the current density of a one-dimensional conductor embedded in a plane at the origin is
	\begin{equation*}
		\j(\r) = I \delta^{2}(\vec{\rho}) \uvec{l},
	\end{equation*}
	where $ \uvec{l} $ is the unit vector tangent to the conductor and parallel to the current.
	
	\item The current density of a point charge with velocity $ \vec{v} $ and position vector $ \r_{q} $ is
	\begin{equation*}
		\j(\r) = q \delta^{3}(\r - \r_{q}(t))\vec{v}(t).
	\end{equation*}
	
    \item The current density of charge distributed through a planar surface at $ z = z_{0} $ and moving with velocity $ \vec{v} $ is
	\begin{equation*}
		\j(\r) = \sigma \delta (z - z_{0})\vec{v},
	\end{equation*}
	where $ \sigma $ is surface charge density. 
	
	% \textit{Note}: We can also introduce a surface current density
	% \begin{equation*}
	% 	\vec{j}_{S} = \sigma \vec{v}
	% \end{equation*}
	% This will come in handy later in Maxwell's equations.
\end{itemize}

\subsection{Ampere's Law}
\begin{itemize}
	\item Ampere's law will allow us to explicitly connect a magnetic field to its current sources. We begin by considering a closed loop $ C' $ carrying current $ I $ and parameterized by the following quantities:
    \begin{itemize}
        \item the arc length $ l' $,

        \item the infinitesimal arc segment $ \diff \vec{l}' $ pointing tangent to the conductor in the direction of the electric current,

        \item and the position $ \r(l')  $ along the conductor.
    \end{itemize}

	\item We then consider enclosing a portion of the loop $ C' $ with another  loop $ C $ parameterized by the analogously defined quantities $ l $, $ \diff \vec{l} $ and $ \r(l) $.
	
	% We are interested in the relationship between $ \curl \B $ and $ \j $. 
	
	We begin the analysis by finding the magnetic circulation along the curve $ C $. Using the Biot-Savart law to express $ \B $, the circulation $ \Gamma_{\text{M}} $ is
	\begin{align*}
        \Gamma_{\text{M}} = \oint_{C} \B \cdot \diff \vec{l} & = \oint_{C}\left[\frac{\mm I}{4 \pi} \oint_{C'}\diff \vec{l}' \cross \left(\frac{\r(l) - \r(l')}{\abs{\r(l) - \r(l')}^{3}}\right) \right] \cdot \diff \vec{l}\\
        & = \oint_{C}\left[ - \frac{\mm I}{4 \pi} \oint_{C'}\diff \vec{l}' \cross \grad \left(\frac{1}{\abs{\r(l) - \r(l')}}\right) \right] \cdot \diff \vec{l}.
	\end{align*}
	where we've written the last equality with a reverse-engineered gradient. 

    \item The integrand is a scalar triple product, which we can rearrange to get
	\begin{equation*}
		\Gamma_{\text{M}} =  - \frac{\mm I}{4\pi} \oint_{C} \oint_{C'} (\diff \vec{l} \cross \diff \vec{l}') \cdot \grad \left(\frac{1}{\abs{\r(l) - \r(l')}}\right).
	\end{equation*}
	Note that $ \diff \vec{l} \cross \diff \vec{l}' $ corresponds to a surface element---we'll call it $ \diff \vec{S} $. We then calculate the gradient and evaluate the dot product to get
	\begin{align*}
        \Gamma_{\text{M}} & =  - \frac{\mm I}{4\pi} \iint_{S} \diff \vec{S}\cdot \grad \left(\frac{1}{\abs{\r(l) - \r(l')}}\right) \\
        & = +  \frac{\mm I}{4\pi} \iint_{S}  \frac{\diff S \cos \theta}{\abs{\r(l) - \r(l')}^{2}},
	\end{align*}
	where $ \theta $ is the angle between $ \diff \vec{S} $ and the gradient. 

    \item Next, we recognize the integrand is precisely the solid angle element $ \diff \Omega $. In terms of $ \diff \Omega $, the magnetic circulation becomes
	\begin{equation*}
		\Gamma_{\text{M}} = \frac{\mm I}{4\pi} \iint_{S} \diff \Omega =  \frac{\mm I}{4\pi}  \cdot 4 \pi = \mm I.
	\end{equation*}
	This result is Ampere's law, which, in terms of magnetic circulation, reads
	\begin{equation*}
		\Gamma_{\text{M}} = \mm I.
	\end{equation*}
    In words, Ampere's law states that the magnetic circulation in a loop (our $ C $) enclosing a current-carrying loop carrying current $ I $ (our $ C' $) is proportional to the current $ I $ through the $ C' $.
	
	\item Finally, we will combine Ampere's law with the definition of magnetic circulation. To review, the two relationships are
	\begin{equation*}
		\Gamma_{\text{M}} = \oint_{\partial S} \B \cdot \diff \vec{S} = \iint_{S} \curl \B \cdot \diff \vec{S} \eqtext{and} \Gamma_{\text{M}} = \mm I = \mm \iint_{S} \j \cdot \diff \vec{S}.
	\end{equation*}
    Combining the two relationships produces the important result
	\begin{equation*}
		\curl \B = \mm \j.
	\end{equation*}
	This is a Maxwell equation for magnetostatics and is an equivalent, often more common expression of Ampere's law.
	
\end{itemize}

\subsection{The Magnetic Vector Potential}
\begin{itemize}
	\item Like for electric field, it is often convenient to analyze magnetic fields in terms of a potential rather than the field itself; our goal in this section is to find an expression for the magnetic potential.
	
    \item Recall that magnetic field lines are closed, which results in $ \curl \B \neq 0 $. The equality $ \curl \B \neq 0 $ prohibits the introduction of a scalar potential in the style $ \B = - \grad \phi $.

    The reason is straightforward: the curl of a gradient is always zero. If we were to take the curl of a hypothetical equality $ \B = - \grad \phi $, we would get $ \curl \B = - \curl \big[ \grad \phi \big] = 0 $, which contradicts $ \curl \B \neq 0 $. 
	
	\item As a solution, we turn to the relationship $ \div \B = 0 $ (which corresponds to the fact that magnetic field lines are closed). Recall from vector calculus that the divergence of the curl of a vector field is always zero, which means we can write $ \B $ as the curl of a vector field:
	\begin{equation*}
		\div \B \equiv \div \left(\curl \A\right) = 0 \implies \B = \curl \A. 
	\end{equation*}
    The relationship $ \B = \curl \A $ gives us an implicit definition of the magnetic vector potential $ \A $. Again, we stress that this definition rests on the identity $ \div \B = 0 $. 
	
	\item Magnetic flux is written in terms of $ \A $ using Stokes' theorem according to
	\begin{equation*}
		\Phi_{\text{M}} \equiv \iint_{S}\B \cdot \diff \vec{S} = \iint_{S} (\curl \A) \cdot \diff \vec{S} = \oint_{\partial S} \A \cdot \diff \r.
	\end{equation*}
	In other words, the magnetic flux through a surface equals the circulation of the magnetic potential $ \A $ around the surface's boundary $ \partial S $.

\end{itemize}

\subsubsection{Example: Magnetic Vector Potential of an Inductor}
\begin{itemize}
    \item We consider a long, straight inductor, which has the simple magnetic field: inside the inductor, the magnetic field is approximately homogeneous and obeys $ \B(\r) = \B_{0} $. Outside the inductor, the magnetic field is zero. We choose our coordinate system so that $ \B_{0} = (0, 0, B_{0}) $. 
	
	\item The magnetic vector potential is defined by $ \B = \curl \A $. Without derivation, the correct expression for of $ \A $ inside the inductor is 
	\begin{equation*}
		\A = \frac{1}{2}\B_{0} \cross \r.
	\end{equation*}
	Since there is not a standard inverse-curl operation, one would have to play around a bit to derive this result---we simply quote it to save time on vector calculus acrobatics. Note that although $ \B $ is constant, $ \A $ has a much more complicated dependence on position.
	
	\item Outside the inductor, we know $ \B = 0 $. What about $ \A $? We assume inductor has radius $ a $ and consider a loop just hugging the outside of the inductor and bounding the planar surface $ S $, which aligns with the inductor's circular cross section.
	
	The magnetic flux through the surface $ S $ is then
	\begin{equation*}
		\Phi_{\text{M}} = \iint_{S} \B \cdot \diff \vec{S} = \B_{0} (\pi a^{2}).
	\end{equation*}
    Note that only the porition of $ S $ inside the inductor (for $ r < a $) contributes non-zero magnetic flux, since $ \B = 0 $ outside the inductor.
	
	Next, we recall the general definition of flux in terms of vector potential, which reads
	\begin{equation*}
		\Phi_{\text{M}} = \iint_{S} \B \cdot \diff \vec{S} = \oint_{\partial S} \A \cdot \diff \r.
	\end{equation*}
    Comparing this general definition to our just-derived result $ \Phi_{\text{M}} = \pi a^{2}\B_{0} $ gives
	\begin{equation*}
		\oint_{\partial S} \A \cdot \diff \r = \Phi_{\text{M}} = \B_{0} (\pi a^{2}) \neq 0  \implies \A \neq 0.
	\end{equation*}
    In other words, the vector potential $ \A $ is non-zero outside the inductor, even though $ \B $ is zero in the same region.
	
	\item It turns out (again without derviation) that the vector potential outside the inductor is
	\begin{equation*}
		\A = C \B_{0} \cross \frac{\r}{r^{2}},
	\end{equation*}
	where $ C $ is a constant. Using this expression for $ \A $, the magnetic flux $ \Phi_{\text{M}} $ through the loop $ \partial S $ comes out to
	\begin{equation*}
		\Phi_{\text{M}} = \oint_{\partial S} \A \cdot \diff \r  = \oint_{\partial S} C\left(\B_{0} \cross \frac{\r}{r^{2}}\right) \diff \r = \cdots = 2\pi C B_{0}
	\end{equation*}
	The result of the integral is quoted without derivation. Combining the above result with the earlier equality $ \Phi_{M} = B_{0}\pi a^{2} $ gives
	\begin{equation*}
		B_{0}\pi a^{2} = \Phi_{M} = 2\pi C B_{0} \implies C = \frac{a^{2}}{2}.
	\end{equation*}
	The magnetic vector potential outside the inductor is thus
	\begin{equation*}
		\A = \frac{a^{2}}{2} \B_{0} \cross \frac{\r}{r^{2}}.
	\end{equation*}
    Once again, we note the complexity of $ \A $ outside the inductor relative to the trivial magnetic field $ \B = 0 $. Finally, we note that $ \A $ changes continuously across the inductor boundary at $ r = a $, which we can see by comparing the expressions for $ \A $ inside and outside the inductor.

\end{itemize}

\subsubsection{Gauges and the Magnetic Potential of an Inductor}
\begin{itemize}
	\item Consider the inductor example above. Even for a simple magnetic field, the corresponding magnetic potential $ \A $ turned out to be quite complicated. However, we can often simplify the magnetic vector potential using gauge transformation. 
	
	% In the following discussion of gauge transforms, keep in mind that $ \A $ is the vector potential corresponding to the magnetic field $ \B $, which is the quantity actually measured in experiment.
	
	\item For more convenient calculations, we are free to define a new vector potential using the transform
	\begin{equation*}
		\A' = \A + \grad \zeta (\r).
	\end{equation*}
	We can safely add the term $ \grad \zeta (\r) $ because the curl of the gradient of a scalar field is always zero, and won't affect the end result for $ \B $, which is the quantity actually measured in experiment.

    In other words, both $ \A $ and $ \A' $ correspond to the same magnetic field $ \B $:
	\begin{equation*}
		\B = \curl \A = \curl \A'.
	\end{equation*}
	
	\item For the specific case of a long, straight inductor, we can simplify the expression for $ \A $ by choosing
	\begin{equation*}
		\zeta (\r)  = -\frac{B_{0}a^{2}}{2} \arctan \frac{y}{x}.
	\end{equation*}
	For this choice of $ \zeta $, the vector potential outside the inductor simplifies to
	\begin{align*}
		\A' &= \A + \grad \zeta (\r) = \frac{a^{2}}{2}\B_{0}\curl \frac{\r}{r^{2}} - \grad \left(\frac{\B_{0}a^{2}}{2} \arctan \frac{y}{x}\right)\\
		& = \frac{\B_{0}a^{2}}{2} \frac{2\pi}{a} \delta (\phi - \pi) \uvec{e}_{\phi}.
	\end{align*}
	In this case, $ \A' $ is zero everywhere except along the curve $ \phi = \pi $, corresponding to the negative portion of the $ x $ axis.
	
	\item To summarize, gauge transforms allow us to simplify the expression for vector potential $ \A $ without changing the value of the magnetic field $ \B $, which is the physically relevant quantity measured in experiment.
\end{itemize}


\subsection{Magnetic Force on a Charged Particle}
\begin{itemize}
	\item Recall from previous sections that the magnetic force on a wire-like conductor $ C $ in the presence of an external magnetic field $ \B $ is
	\begin{equation*}
		\vec{F} = \int_{C} I \diff \vec{l} \cross \vec{B}(\r(l)),
	\end{equation*}
	where the direction of $ \diff \vec{l} $ aligns with the direction of current. If the field is homogeneous (same direction and same magnitude in all space) and the conductor is straight, the force simplifies to
	\begin{equation*}
		\vec{F} = I \vec{l} \cross \vec{B}.
	\end{equation*}
	
	\item More generally, we can describe magnetic force in terms of current density $ \j $, which is related to current via
	\begin{equation*}
		I \diff \vec{l} = \vec{j} \dr.
	\end{equation*}
    In terms of current density, the magnetic force on a current distribution contained in the region $ V $ is
	\begin{equation*}
		\vec{F} = \iiint_{V} \vec{j} \cross \vec{B} \dr.
	\end{equation*}
	
	\item Next, we consider a the magnetic force on a moving charge particle, for which current density and charge are related via
	\begin{equation*}
		\vec{j}(\t{\r}) = \rho(\t{\r}) \vec{v} = q \delta^{3}(\t{\r} - \r(t))\vec{v},
	\end{equation*}
	where $ \r(t) $ is the particle's trajectory and $ \vec{v} $ is the particle's velocity. Substituting this expression for $ \j $ into the expression for magnetic force leads to
	\begin{align*}
		\vec{F} &= \iiint_{V} \j \cross \B \dr = \iiint_{V} q \delta^{3}(\t{\r} - \r(t))\vec{v} \cross \B \dtr\\
		& = q \vec{v} \cross \B,
	\end{align*}
    which is the familiar Lorentz force on a charged particle in a magnetic field.
	
\end{itemize}

\subsection{The Magnetic Analog of the Poisson Equation}
\begin{itemize}
	\item Next, we aim to find an equation for magnetic vector potential analogous to the Poisson equation for electric potential. 

    We begin with Ampere's law in terms of $ \A $, which leads to
	\begin{equation*}
		\mm \j = \curl \B = \curl (\curl \A) = \grad (\div \A) - \laplacian \A.
	\end{equation*}
	It is possible to make the $ \div \A $ term vanish. We do this with Helmholtz's theorem, which tells us that we can write an arbitrary vector field in the form
	\begin{equation*}
		\A = \A_{1} + \A_{2},
	\end{equation*}
	where $ \div \A_{1} = 0 $ and $ \curl \A_{2} = 0 $, i.e. $ \A $ can be written as the sum of a solenoidal and irrotational vector field.
	
    \item We then introduce a gauge transformation of $ \A $ such that $ \A_{2} = 0 $. We are free to set $ \A_{2} $ to whatever value we want, since, after applying the definition $ \curl \A_{2} = 0 $, the value of $ \A_{2} $ will have zero contribution to $ \B $, which is defined as $ \B = \curl \A $. Substituting $ \A_{2} = 0 $ into the Helmholtz composition gives $ \A = \A_{1} $. We then take the divergence of this equality and apply $ \div \A_{1} = 0 $ to get
    \begin{equation*}
        \A = \A_{1} \implies \div \A = \div \A_{1} \equiv 0 \implies \div \A = 0.
    \end{equation*}
    Finally, we substitute $ \div \A = 0 $ into Ampere's law to get the desired equation
    \begin{equation*}
        \mm \j = 0 - \laplacian \A \implies \laplacian \A = - \mm \j.
    \end{equation*}
	Note the similarity to the Poisson equation for electric potential.
	
    \item Formally, we would solve this equation using a vector Green's function, similarly to how we solved the electrostatic Poisson equation with a Green's function. However, given the close similarity between the magnetostatic and electrostatic Poisson equations, we can simply guess the solution for $ \A $ with reference to the solution for $ \phi $. Without derivation, the result comes out to be
	\begin{equation*}
		\A(\r) = \frac{\mm}{4\pi} \iiint_{V} \frac{\j(\t{\r})}{\abs{\r - \t{\r}}} \dtr,
	\end{equation*}
	where $ V $ is the region of space with non-zero current density $ \j $. This is the general expression for magnetic vector potential $ \A $. 
	
	\item The above general solution for $ \A $ is closely related to the Biot-Savart law. To show this, we take the curl of $ \A(\r) $ with respect to $ \r $ to get
	\begin{align*}
		\B(\r) &= \curl \A(\r) = \curl \left(\frac{\mm}{4\pi} \iiint_{V} \frac{\j(\t{\r})}{\abs{\r - \t{\r}}} \dtr\right)\\
		& = \frac{\mm}{4\pi} \iiint_{V} \frac{\j \cross (\r - \t{\r})}{\abs{\r - \t{\r}}^{3}} \dtr,
	\end{align*}
    which is the Biot-Savart law for a current distribution $ \j $. The Biot-Savart law and the magnetic Poisson equation are closely related, and it is difficult to say which is more fundamental. In the coming chapters, we will sidestep this dilemma by using the Maxwell equations as the foundation of electromagnetism.

\end{itemize}

\subsection{Magnetic Energy}
 Our analysis of magnetostatic energy will proceed analogously to the analysis of electrostatic energy, in that we will first consider the magnetic energy of a current distribution an external magnetic field (whose source we take for granted and otherwise ignore), and then use that result to find the total energy of current distribution in a magnetic field where we will include the field's source.

\subsubsection{Magnetic Field Energy in an External Field}
\begin{itemize}
	\item We begin by considering a current loop $ C $ carrying current $ I $ in an external magnetic field $ \B $. We stress that we don't consider the source of the field $ \B $---we simply take its existence for granted. 
	
    Note also that we will work in the quasi-static regime of electromagnetism meaning we take currents to be nonzero, but constant with respect to time, ie. $ I \neq 0 $ and $ \dot{I} = 0 $. Finally, for use in the next bullet, recall that the magnetic force on a current carrying-conductor is
	\begin{equation*}
		\vec{F} = \oint_{C} I \diff \vec{l} \cross \B = I \oint_{C} \uvec{t} \cross \B \diff l,
	\end{equation*}
	where $ \uvec{t} $ is the tangent to the conducting loop pointing in the direction of current.
	
	\item We then consider moving the loop by the infinitesimal displacement $ \diff \r $---in which case we do work $ W $ against the magnetic field force, which is related to the desired magnetic energy $ W_{\text{M}} $ by the work-energy theorem. The work $ W $ associated with the displacement $ \diff \r $ is
	\begin{align*}
		\diff W &= - \vec{F} \cdot \diff \r =  -I \oint_{C} \uvec{t} \cross \B \diff l \cdot \diff \r\\
		& = - I \oint_{C}\diff \r \cdot (\uvec{t} \cross \B) \diff l.
	\end{align*}
    The last result is a scalar triple product, which we rearrange to get
	\begin{equation*}
		\diff W = - I \oint_{C} (\diff \r \cross \uvec{t})\cdot \B \diff l.
	\end{equation*}
	Next, we recognize that quantity $ (\diff \r \cross \uvec{t}) \diff l $ is the surface element $ \diff \vec{S} $  of the loop during the displacement $ \diff \r $. In terms of $ \diff \vec{S} $, the work reads
	\begin{equation*}
		W = - I \iint_{S} \B \cdot \diff \vec{S} \equiv - I \Phi_{\mathrm{M}}.
	\end{equation*}
    We stress that the magnetic flux in the above expression is the flux arising from the external field $ \B $ only, and is unrelated to the current distribution.
	
    Note also that if $ \B $ is homogeneous and the quantity $ \B \cdot \vec{S} $ does not change through time (i.e. $ \diff [\B \cdot \vec{S}] = 0 $), then $ 0 \equiv \diff [\B \cdot \vec{S}] = \B \cdot \diff \vec{S} = 0 $, meaning that the magnetic flux $ \Phi_{\text{M}} $ and thus the magnetic work $ W $ is zero.
	
    \item We then use $ \B = \curl \A $ to write the work in terms of the magnetic potential:
	\begin{equation*}
		W = - I \iint_{S}\B \cdot \diff \vec{S} = - I \iint_{S} (\curl \A) \cdot \diff \vec{S}.
	\end{equation*}
	The last term is the surface integral of a curl quantity, which we can rewrite as an integral over the surface boundary $ \partial S $ using Stokes' theorem. But which surface boundary---this is important! Assume the initial conductor before the displacement $ \diff \r $ is described by the curve $ C_{1} $, and that after the displacement $ \diff \r $ the conductor is described by the curve $ C_{2} $. In this case, the appropriate surface is the surface between the curves $ C_{1} $ and $ C_{2} $, and the expression for work becomes
	\begin{equation*}
        W = - I \iint_{S} (\curl \A) \cdot \diff \vec{S} = - I \oint_{C_{2}} \A \cdot \diff \r  + I \oint_{C_{1}} \A \cdot \diff \r,
	\end{equation*}
	which is the difference of the line integrals over the two curves.
	
	\item Next, we generalize our expression from a current loop $ C $ to a generalized current distribution described by the current density $ \j $. 

    First, an intermediate step: we use the identity $ I \diff \r = \j \dr $ to write
	\begin{equation*}
		I \oint_{C} \A \cdot \diff \r = \iiint_{V} \j(\r)\A(\r) \cdot \dr,
	\end{equation*}
	where $ V $ is the region of space containing the current density $ \j $. Using this relantionship, the work energy theorem for magnetic energy then reads
	\begin{equation*}
		W \equiv W_{\text{M}}^{(1)} - W_{\text{M}}^{(2)} = - \iiint_{V_{2}} \j_{2}(\r) \A(\r) \cdot \dr + \iiint_{V_{1}} \j_{1}(\r) \A(\r) \cdot \dr,
	\end{equation*}
    where the $ (2) $ terms correspond to quantities after the displacement $ \diff \r $ and the $ (1) $ terms to quantities before the displacement $ \diff \r $. The magnetostatic energy $ W_{\text{M}} $ of a charge distribution $ \j $ in an \textit{external} magnetic field $ \B $ is thus
	\begin{equation*}
		W_{\text{M}} = - \iiint_{V}\j(\r) \A(\r) \dr,
	\end{equation*}
	and the corresponding magnetic energy density $ w_{\text{M}} $ is
	\begin{equation*}
		w_{\text{M}}(\r) = - \j(\r) \A (\r).
	\end{equation*}
	
\end{itemize}
\subsubsection{Magnetic Field Energy as a Function of Current}
\begin{itemize}
	\item Using the general solution to the magnetic Poisson equation, the magnetic vector potential $ \A $ associated with the \textit{external} magnetic field $ \B $ is
	\begin{equation*}
		\A(\r) = \frac{\mm}{4\pi}\iiint_{\tilde{V}}\frac{\t{\j}(\r)}{\abs{\r - \t{\r}}} \dtr.
	\end{equation*}
    where we have used $ \tilde{\j} $ to denote the current distribution creating the external magnetic field $ \B $, which we otherwise took for granted in the previous section, while $ \tilde{V} $ denotes the region of space containing $ \tilde{\j} $.

    \item We then substitute this expression for $ \A $ into magnetic field energy $ W_{\text{M}} $ to get
	\begin{equation*}
		W_{\text{M}} = - \frac{\mm}{4\pi} \iiint_{V} \iiint_{\t{V}} \frac{\j(\r) \t{\j}(\t{\r}) \dr \dtr}{\abs{\r - \t{\r}}}.
	\end{equation*}
\end{itemize}

\subsubsection{Total Magnetic Field Energy}
\begin{itemize}
    \item We now consider the total magnetic field energy associatd with the field $ \B $ described by the vector potential $ \A $ and arising from the current distribution $ \j $. 

    \item Following the same procedure as for total electric field energy, we introduce a parameter $ \alpha \in [0, 1] $, which controls ``turning on'' the total magnetic field. As $ \alpha $ increases from $ 0 $ to $ 1 $, the distribution's current density correspondingly increases from $ 0 $ to $ \j $.

    We then consider the change in energy $ \diff W_{\text{M}} $ from adding additional current $ \diff \j = \j \diff \alpha $ to the current density we have already accumulated. The existing current creates an external magnetic field like with associated magnetostatic potential energy is $ W_{\text{M}_{0}} = - \iiint_{V} \tilde{\j} \tilde{\A}(\r) \dr $. The corresponding differential $ \diff W_{\text{M}_{0}} $ is
    \begin{equation*}
        \diff W_{\text{M}_{0}} = - \iiint_{V} \diff \tilde{\j} \tilde{\A}(\r) \dr = - \iiint_{V} \j \diff \alpha \big[ \alpha \A(\r) \big] \dr.
    \end{equation*}
    \textit{Note}: the reason for using the subscript $ 0 $ in $ W_{\text{M}_{0}} $ will become clear in the following bullet points. Note also that the transition between the two integrals relies on the linearity of the vector Poisson equation, i.e. $ \laplacian[\alpha \A] = - \mm \alpha \j $.

    \item Next, integrate over $ \alpha $ to ``turn on'' the current distribution
    \begin{equation*}
        W_{\text{M}_{0}}  = - \int_{0}^{1} \alpha \diff \alpha \iiint_{V} \j(\r)\A(\r)\dr = - \frac{1}{2} \iiint_{V} \j(\r) \cdot \A(\r) \dr.
    \end{equation*}
    This expression is the field energy assuming the current distribution $ \j $ already exists. Note that $ \A $ in the above expression is the magnetic vector potential formed by $ \j $.
    
    \item The above expression does not account for an important fact: creating and maintaining the currents associociated with the distribution $ \j $ requires energy in itself. 

    This situation does not have an electrostatic analog, where the field source, i.e. charge, is a static quantity. A magnetic field only arises from current, i.e. moving charge, and moving that charge requires energy.
    
    Maintaining the current distribution thus requires a power input:
    \begin{align*}
        P &= - UI = -I \oint_{C} \E \cdot \diff \r = - I \iint_{S} \curl \E \cdot \diff \vec{S} = - I \iint_{S} \left( - \pdv{\B}{t} \right) \cdot \diff \vec{S}\\
        &= I \pdv{t} \iint_{S} \B \cdot \diff \vec{S},
    \end{align*}
    where the line integral runs over the curve(s) carrying the current. 

    As a side note, we can reassure ourselves that the above result for power is correct by recalling the earlier expression $ W = + I \iint_{S} \B \cdot \vec{S} $, which gives the result
    \begin{equation*}
        P = I \pdv{t} \iint_{S} \B \cdot \diff \vec{S} = \dv{W}{t}.
    \end{equation*}
    In other words, our expression for power comes out to the time derivative of work, which agrees with the definition of power. Note that we have used a plus sign because the earlier expression for work involved magnetic force doing positive work on a charged particle. Now we consider dissipitative power, and the sign is reversed.

    \item By putting the pieces from the last two equations together and using $ \B = \curl \A $, the energy $ W_{\j} $ required to maintain the magnetic field comes out to
    \begin{equation*}
        W_{\j} = I \iint_{S} \B \cdot \diff \vec{S} = I \iint_{S} \curl \A \cdot \diff \vec{S} = \oint_{C} I \A \cdot \diff \r = \iiint_{V} \j \cdot \A \dr.
    \end{equation*}
    
    \item The total energy associated with the magnetic field of a current distribution is then
    \begin{equation*}
        W_{\text{M}} = W_{\text{M}_{0}} + W_{\vec{j}} = \left( -\frac{1}{2} + 1 \right) \iiint_{V} \j \cdot \A \dr = + \frac{1}{2} \iiint_{V} \j \cdot \A \dr.
    \end{equation*}
    This is the total energy associated with the magnetic field generated by the current distribution $ \j $, and includes the energy required to create and sustain the current distribution.
    
\end{itemize}

\subsubsection{Magnetic Field Energy Density}
\begin{itemize}
    \item We now aim to write the total magnetic field energy derived in the previous section in terms of only the magnetic field $ \B $. We begin by substituting Ampere's law $ \curl \B = \mm \j $ into the just-derived expression for total magnetic field energy $ W_{\text{M}} $ to get
    \begin{equation*}
        W_{\text{M}} = \frac{1}{2} \iiint_{V} \j(\r) \A(\r) \dr = \frac{1}{2\mm}\iiint_{V}(\curl \B) \A \dr.
    \end{equation*}
    Next, we reverse-engineer the vector identity $ \div (\B \cross \A) = - \B \cdot (\curl \A) + \A \cdot (\curl \B) $ to get
    \begin{equation*}
        W_{\text{M}} = \frac{1}{2\mm} \iiint_{V} \B \cdot (\curl \A)\dr + \frac{1}{2\mm} \iiint_{V} \div (\B \cross \A) \dr.
    \end{equation*}
    Using $ \B = \curl \A $, the first integrand simplifies to $ B^{2} $, while the second can be rewritten using the divergence theorem. The result is
    \begin{equation*}
        W_{\text{M}} = \frac{1}{2\mm} \iiint_{V} B^{2} \dr + \oiint_{\partial V} (\B \cross \A) \diff \S.
    \end{equation*}
    Using an similar argument as in the analogous treatment of electric field energy, the second term vanishes for large $ \r $. Here's why: the surface term $ \diff \S $ grows as $ \sim r^{2} $, the field term $ \B $ falls as $ \sim 1/r $, and the potential term $ \A $ falls as $ \sim 1/r^{2} $. The result is that the entire integrand falls as $ 1/r $, which vanishes for large $ r $, i.e. for a large enough volume $ V $ containing the charge distribution. In this limit, the magnetic field energy reduces to
    \begin{equation*}
        W_{\text{M}} = \frac{1}{2\mm} \iiint_{V}B^{2}(\r)\dr.
    \end{equation*}
    The corresponding expression for magnetic energy density is thus
    \begin{equation*}
        w_{\text{M}} = \frac{1}{2\mm} B^{2}.
    \end{equation*}
    
    
\end{itemize}


\subsection{Magnetic Force and the Stress-Energy Tensor}

\subsubsection{Magnetic Force as a Function of Magnetic Field}

\begin{itemize}
	\item Consider a current distribution $ \j(\r) $ consisting of an arbitrary system of closed current loops. We then place the current distribution in an external magnetic field $ \B $ and consider the total magnetic field, i.e. the sum of the external magnetic field and the field generated by the current distribution. Our goal in this section is to find the force acting on the current distribution written in terms of only the external field. 
	
	\item In general, the magnetic force on a current distribution is
	\begin{equation*}
		\vec{F}_{\text{M}} = \iiint_{V}\j \cross \B \dr,
	\end{equation*}
	where $ V $ is the region of space containing the current distribution $ \j $ and $ \B $ is the total magnetic field, including the ``internal'' field generated by the current distribution itself. 

    Note, however, (quoted and not proven) that the contribution of the internal field to the magnetic force integrates to zero. This makes sense---the current distribution shouldn't be able to generate a force on itself. 

    For a simple current loop, we could show that the internal field contributes zero force by substituting in the Biot-Savart law for $ \B $ and applying $ \j \cross \j = 0 $. 
	
    \item Next, we write $ \j $ in terms of $ \B $ using Ampere's law $ \curl \B = \mm \j $. The resulting expression for $ \vec{F}_{\text{M}} $ is
	\begin{equation*}
		\vec{F}_{\text{M}} = \iiint_{V}\j \cross \B \dr = \frac{1}{\mm}\iiint (\curl \B) \cross \B \dr.
	\end{equation*}
	Next, we use the general vector identity
	\begin{equation*}
		\B \cross (\curl \B) = \frac{1}{2}\grad B^{2} - \div (\B \otimes \B) + \B(\div \B),
	\end{equation*}
	which simplifies in our case because $ \div \B = 0 $ (absence of magnetic monopoles). The expression for $ \vec{F}_{\text{M}} $ becomes
	\begin{equation*}
		\vec{F}_{\text{M}} = \frac{1}{\mm}\iiint_{V} \div (\B \otimes \B)\dr - \frac{1}{2\mm}\iiint_{V} \grad B^{2}\dr.
	\end{equation*}
	
	\item Next, we want to write $ \vec{F}_{\text{M}} $ in terms of a surface integral---this is easier to measure than a volume integral. We do this with the divergence theorem:
	\begin{equation*}
		\vec{F}_{\text{M}} = \frac{1}{\mm}\oiint_{\partial V}\left(\B \otimes \B - \frac{1}{2}B^{2}\mat{I}\right)\diff \vec{S},
	\end{equation*}
	where $ \mat{I} $ is the identity matrix and $ \partial V $ is the surface of the region containing the original current distribution $ \j $. Note that the quantity $ \B $, which is the total field, now implicitly contains the current distribution $ \j $.
\end{itemize}


\subsubsection{Magnetostatic Stress Tensor}
\begin{itemize}
	\item We write the magnetostatic force in terms of the magnetostatic stress tensor, using Einstein summation notation, as
	\begin{equation*}
		F_{\text{M}_{i}} = \oiint_{\partial V} \TT_{ik} \hat{n}_{k}\diff S,
	\end{equation*}
	where $ \hat{n}_{k} $ is the normal to the surface $ \partial V $ and $ \mat{T} $ is the $ (3 \cross 3) $ magnetostatic stress tensor with components given by
	\begin{equation*}
		\TT_{ik} = \frac{1}{\mm}\left(B_{i}B_{k} - \frac{1}{2}B^{2}\delta_{ik}\right).
	\end{equation*}
	
	\item We can also write the force as a volume integral in the form
	\begin{equation*}
		F_{\text{M}_{i}} = \iiint_{V}\pdv{\TT_{ik}}{x_{k}}\dr \equiv \iiint_{V}f_{\text{M}_{i}} \dr,
	\end{equation*} 
	where we have introduced the volume force density $ f_{\text{M}} $, motivated by the fact that $ \pdv{\TT_{ik}}{x_{k}} $ has units $ \si{\newton \, m^{-3}} $.
	
\end{itemize}


\subsection{The Multipole Expansion of Magnetic Field}
\begin{itemize}
	\item We begin with the multipole expansion of the magnetic vector potential $ \A $---we consider the behavior of $ \A(\r) $ far from the source of $ \A $. The general expression for $ \A $, from the solution to the magnetic Poisson equation, is
	\begin{equation*}
		\A(\r) = \frac{\mm}{4\pi}\iiint_{V}\frac{\j(\s)}{\abs{\r - \s}}\ds,
	\end{equation*}
	where $ V $ is the region of space containing the current density $ \j $. 
	
	\item We then expand $ \A $ in the regime of $ \abs{\r} \gg \abs{\s} $, using only the first-order expansion:
	\begin{equation*}
		\frac{1}{\abs{\r - \s}} \approx \frac{1}{r} - (\s \cdot \grad) \frac{1}{r} + \cdots = \frac{1}{r} + \frac{\s \cdot \r}{r^{3}} + \cdots.
	\end{equation*}
    Using this expansion, the magnetic potential becomes
	\begin{equation*}
		\A(\r) \approx \frac{\mm}{4\pi r}\iiint_{V} \j(\s) \ds + \frac{\mm}{4\pi r^{3}} \iiint_{V}(\r \cdot \s)\j(\s)\ds.
	\end{equation*}
	The first term in the above expansion is called the monopole term---note that the monopole is a vector quantity (as opposed to the electric monopole, which corresponds to a point charge, which is a scalar quantity).
	
	The second term---the dipole term---is a tensor (as opposed to the electric field dipole, which is a vector). In general, the vector quantities arising in the magnetic multipole expansion have one more index than the analogous terms in the electric multipole expansion because $ \A $ is a vector field while electric potential $ \phi $ is a scalar field.

    \item \textbf{The Monopole Term:} The monopole term is zero, which corresponds to the fact that in magnetostatics all current loops contributing the current density $ \j $ are closed, meaning $ \div \j = 0 $. The result is
	\begin{equation*}
		\iiint_{V} \j(\s) \ds = 0.
	\end{equation*}
    Note, however, that $ \div \j = 0 $ only applies in magnetostatics.

    \item \textbf{The Dipole Term:} Since the monopole term is zero, the multiple expression for $ \A(\r) $ simplifies to
	\begin{equation*}
		 \A(\r) = \frac{\mm}{4\pi r^{3}} \iiint_{V}(\r \cdot \s)\j(\s)\ds.
	\end{equation*}
    Without derivation, we state that we can use the divergence theorem and some vector calculus acrobatics to write $ \A(\r) $ in the form
	\begin{equation*}
		\A(\r) = \frac{\mm}{4\pi}\frac{\m \cross \r}{r^{3}},
	\end{equation*}
	where we have defined the magnetic dipole moment
	\begin{equation*}
		\m = \frac{1}{2}\iiint_{V} \s \cross \j(\s) \ds.
	\end{equation*}
	As a side note, the dipole term can also be written in the form
	\begin{equation*}
		\A(\r) =  \frac{\mm}{4\pi} \curl \frac{\m}{\abs{\r}}
	\end{equation*}
\end{itemize}

\subsubsection{The Magnetic Field of a Magnetic Dipole}
\begin{itemize}
	\item We now have everything we need to find the magnetic field of a magnetic dipole. We start with the just-derived expression for magnetic vector potential, which reads
	\begin{equation*}
		\A(\r) = \frac{\mm}{4\pi}\frac{\m \cross \r}{r^{3}}.
	\end{equation*}
	Using $ \A $, we find the magnetic field $ \B \equiv \curl \A $ via
	\begin{equation*}
		\B = \curl \A = \curl \left(\frac{\mm}{4\pi}\frac{\m \cross \r}{r^{3}}\right) = \frac{\mm}{4\pi} \frac{3\r(\r \cdot \m) - \m r^{2}}{r^{5}}.
	\end{equation*}
	
\end{itemize}


\subsubsection{Ampere Equivalence for a Circular Current Loop}
\begin{itemize}
	\item We start with the magnetic dipole moment of a circular current loop of radius $ a $ and carrying current $ I $. From introductory electromagnetism, the magnetic dipole moment of a circular current loop is
    \begin{equation*}
       \vec{m} = IS\uvec{n},
    \end{equation*}
    where $ \uvec{n} $ is the normal to the current loop. However, we will now formally derive this result.
	
	\item Using the formalism of the magnetic dipole expansion, we find the circular loop's magnetic dipole moment via
	\begin{equation*}
		\m = \frac{1}{2}\iiint_{V}\s \cross \j(\s)\ds =  \frac{1}{2}\oint \s \cross (I \diff \vec{s}).
	\end{equation*}
    We then transition to polar coordinates in which $ \vec{s} \cross \diff \s = a \uvec{e}_{r} \cross \uvec{e}_{\phi} $ to get
	\begin{equation*}
		\m = \frac{1}{2}I\oint (a \uvec{e}_{r}) \cross  (\uvec{e}_{\phi})\diff l = \frac{aI}{2} \oint \uvec{e}_{z} \diff l = \pi a^{2}I \uvec{e}_{z} = IS\uvec{e}_{z}.
	\end{equation*}
    The result $ \m = I S \uvec{e}_{z} $ is the known expression for a circular loop's magnetic dipole moment.
	
	\item Ampere equivalence refers to the following: a circular current-carrying loop is equivalent to a magnetic dipole in an external magnetic field.
\end{itemize}

\subsubsection{Multipole Expansion of Magnetic Energy}
\begin{itemize}
	\item We consider an arbitrary system of current carrying loops with current density $ \j $ localized in space around the position $ \r_{0} $---a current distribution \textit{must} be localized to use a multipole expansion. 
	
	We assume the current distribution occurs in an external magnetic field described with the vector potential $ \A $. 
	
	\item The current distribution's magnetic field energy in the \textit{external} magnetic field is
	\begin{equation*}
		W_{\text{M}} = - \iiint_{V} \j(\r) \cdot \A(\r) \dr,
	\end{equation*}
	where $ V $ is the region containing the localized current distribution $ \j $. 
	
	\item We then expand the magnetic potential about $ \r_{0} $ to get
	\begin{equation*}
		\A(\r) \approx \A(\r_{0}) + \big[(\r - \r_{0}) \cdot \grad_{0}\big] \A(\r_{0}) + \cdots,
	\end{equation*}
	where the gradient acts on $ \r_{0} $. We then substitute the expansion into $ W_{\text{M}} $ to get
	\begin{align*}
		W_{\text{M}} &= - \iiint_{V}\j(\r) (\r)\cdot \A(\r_{0}) \dr - \iiint_{V} \j(\r) \big[(\r - \r_{0}) \cdot \grad_{0}\big] \A(\r) \dr\\
		& = - \A(\r_{0})\iiint \j(\r)\dr - \iiint \j(\r)\big[(\r - \r_{0})\cdot \grad_{0}\big] \A(\r_{0})\dr.
	\end{align*}
	The first term is the monopole term and integrates to zero. The second term is more complicated---we will handle it by components in the next bullet point.

    \item First, we note that
	\begin{equation*}
		\grad_{0} \A(\r_{0}) = \pdv{\A(\r_{0})_{j}}{\r_{0_{i}}}.
	\end{equation*}
	Note that this term depends only on $ \r_{0} $, and thus can be moved outside the integral over $ \r $ in the energy expression.
	
	
	Next, we apply tensor symmetrization (justified in the next section), which allows us to write
	\begin{equation*}
		\iiint_{V}\j(\r)_{j} (\r - \r_{0})_{i} \dr = - \iiint \j(\r)_{i}(\r - \r_{0})_{j}\dr.
	\end{equation*}
    Basically, the indexes $ i $ and $ j $ of the components of the vectors $ \j $ and $ (\r - \r_{0}) $ are switched, with the addition of a minus sign. We use this symmetry to write
	\begin{equation*}
		\iiint_{V}\j(\r)_{j} (\r - \r_{0})_{i} \dr = \frac{1}{2}\iiint_{V}  \big[\j(\r)_{j} (\r - \r_{0})_{i} - \j(\r)_{i}(\r - \r_{0})_{j}\big]\dr.
	\end{equation*}
    The symmetry that permits the index switching comes from a generalized form of the divergence theorem---we postpone a derivation to the next section.
	
	\item Putting the pieces together, the magnetic energy is
	\begin{equation*}
		W_{\text{M}} = -\frac{1}{2}\pdv{\A(\r_{0})_{j}}{\r_{0_{i}}} \iiint_{V}  \big[\j(\r)_{j} (\r - \r_{0})_{i} - \j(\r)_{i}(\r - \r_{0})_{j}\big]\dr.
	\end{equation*}
	Back in vector form, the magnetic energy in the external field reads
	\begin{equation*}
		W_{\text{M}} = - \frac{1}{2}\iiint_{V} \Big\{\j(\r) \big[ (\r - \r_{0})\cdot \grad_{0} \big ] \A(\r_{0}) - (\r - \r_{0})(\j\cdot \grad_{0})\A(\r_{0}) \Big\} \dr.
	\end{equation*}
	
    \item Next, to make a subsequent step more clear, we define the following vectors:
	\begin{equation*}
		\vec{a} \equiv (\r - \r_{0}) \qquad \vec{b} \equiv \j(\r) \qquad \vec{c} \equiv \grad_{0} \qquad \vec{d} \equiv \A(\r_{0}).
	\end{equation*}
	In this notation, the magnetic energy is
	\begin{align*}
		W_{\text{M}} &= -\frac{1}{2}\iiint_{V}\Big[\vec{b}   (\vec{a} \cdot \vec{c}) \vec{d} - \vec{a}(\vec{b}\cdot \vec{c})\vec{d} \Big] \dr\\
		& = -\frac{1}{2}\iiint_{V}\Big[(\vec{a} \cdot \vec{c}) (\vec{b}\cdot\vec{d}) - (\vec{a} \cdot \vec{d}) (\vec{b}\cdot \vec{c}) \Big] \dr.
	\end{align*}
	We then use the vector identity\footnote{This is the Binet–Cauchy identity in three dimensions.}
	\begin{equation*}
		(\vec{a}\cross \vec{b}) \cdot (\vec{c} \cross \vec{d}) = 	(\vec{a}\cdot \vec{c}) (\vec{b} \cdot \vec{d}) - 	(\vec{a}\cdot \vec{d}) (\vec{b} \cdot \vec{c})
	\end{equation*}
	to rewrite the magnetic field energy in the form
	\begin{align*}
		W_{\text{M}} &= - \frac{1}{2}\iiint_{V} \Big\{\big[(\r - \r_{0}) \cross \j\big] \cdot \big[\grad_{0}\cross \A(\r_{0})\big] \Big\}\dr\\
		& = -\frac{1}{2} \big[\grad_{0}\cross \A(\r_{0})\big] \cdot \iiint_{V}\big[(\r - \r_{0}) \cross \j\big] \dr,
	\end{align*}
	where we have moved the $ \r_{0} $-dependent term $ \grad_{0} \cross \A $ out of the integral over $ \r $. 
	
	\item Recognizing $ \B = \curl \A $ and the magnetic dipole in the integrand, the result is
	\begin{align*}
		W_{\text{M}} &=  -\frac{1}{2} \big[\grad_{0}\cross \A(\r_{0})\big] \cdot \iiint_{V}\big[(\r - \r_{0}) \cross \j\big] \dr\\
		&= - \B(\r_{0})  \cdot \m,
	\end{align*}
	which is the familiar expression for the energy of a magnetic dipole in an external magnetic field.
	
\end{itemize}


\subsubsection{More on Tensor Symmetrization}
\begin{itemize}
	\item The general idea of tensor symmetrization is to write a complicated tensor as a sum of tensors with a simpler structure. We consider a generic vector field $ \A $ (not necessarily magnetic vector potential) start with the divergence theorem, in the familiar form
	\begin{equation*}
		\oiint_{\partial V} \A \cdot \diff \vec{S} = \iiint_{V}\div \A \dr.
	\end{equation*}
	However, the divergence theorem can be generalized. In our case, applied to the third-rank tensor $ \r \otimes \r \otimes \A $, the divergence theorem, in component form, reads
	\begin{equation*}
		\oiint_{\partial V}r_{i}r_{j}A_{k}\hat{n}_{k}\diff S = \iiint_{V}\big[r_{i}A_{j} + r_{j}A_{i} + r_{i}r_{j}(\div \A)\big]\dr.
	\end{equation*}
	
	\item We now apply this generalized divergence theorem to the previous section involving the multipole expansion of magnetic energy, and take $ \A = \j $, where $ \j $ is the current density of our current distribution. The result is
	\begin{equation*}
		\oiint_{\partial V}r_{i}r_{j}j_{k}\hat{n}_{k}\diff S = \iiint_{V}\big[r_{i}j_{j} + r_{j}j_{i} + r_{i}r_{j}(\div \j)\big]\dr.
	\end{equation*}
	In our magnetostatic situation with closed current loops we have $ \div \j = 0 $, and the above expression simplifies to
	\begin{equation*}
		\oiint_{\partial V}r_{i}r_{j}j_{k}\hat{n}_{k}\diff S = \iiint_{V}\big[r_{i}j_{j} + r_{j}j_{i}\big]\dr.
	\end{equation*}
	
    \item Next, we note that on the current distribution's border $ \partial V $, the current density is $ \j = 0 $ (since $ \j $ is zero outside of $ V $ and must change continuously across the border). Note that the simplification $ \j \big|_{\partial V} = 0 $ is possible only because we assumed our charge distribution is localized, as is reasonable for a magnetic dipole. 
	 
    From $  \j \big|_{\partial V} = 0 $ follows
	\begin{equation*}
		\oiint_{\partial V}r_{i}r_{j}j_{k}\hat{n}_{k}\diff S = 0 \implies \iiint_{V}\big[r_{i}j_{j} + r_{j}j_{i}\big]\dr = 0.
	\end{equation*}
	The integral in the last equality can be zero for all $ \r $ only if
	\begin{equation*}
		r_{i}j_{j} = - r_{j}j_{i}.
	\end{equation*}
	In other words, the tensor $ \r \otimes \r \otimes \j $ is symmetric, which justifies the use of tensor symmetrization in the derivation of a magnetic dipole's magnetic energy in an external magnetic field in the previous section.
	
\end{itemize}



\subsubsection{Force on a Magnetic Dipole in an External Magnetic Field}
\begin{itemize}
	\item In this section, we aim to find an expression for the force on a magnetic dipole in an external magnetic field. We begin with the general relationship between force and energy:
	\begin{equation*}
		\diff W_{\text{M}} = - \vec{F}_{\text{M}} \cdot \diff \r,
	\end{equation*}
	and take $ \diff \r $ to be a small displacement of a current distribution $ \j $ in an \textit{external} magnetic field.
	
    \item Combining the expression for a magnetic dipole's energy, i.e. $ W_{\text{M}} = - \B(\r) \cdot \m $, with the relationship $ \vec{F}_{\text{M}} = - \grad W_{\text{M}}  $ gives
    \begin{equation*}
        \vec{F}_{\text{M}} = - \grad W_{\text{M}} = \grad \big[ \m \cdot \B(\r) \big].
    \end{equation*}
    Combining this result with $ \diff W_{\text{M}} = - \vec{F}_{\text{M}} \cdot \diff \r $ gives
	\begin{equation*}
		\diff W_{\text{M}} = - \grad\big[\m \cdot \B(\r)\big] \cdot \diff \r.
	\end{equation*}
	The gradient evaluates to 
	\begin{equation*}
		\grad\big[\m \cdot \B(\r)\big] = \m \cross (\curl \B) + (\m \cdot \grad)\B,
	\end{equation*}
    which results in
    \begin{equation*}
        \diff W_{\text{M}} = - \big[ \m \cross (\curl \B) + (\m \cdot \grad)\B \big] \cdot \diff \r.
    \end{equation*}
    
	\item We know from Ampere's law that $ \curl \B = \mm \j $. But careful here! So far, when evaluating energy and force, we have considered only the external magnetic field, and not the contribution of the current distribution $ \j $ to the total magnetic field. However, the magnetic field in the expression $ \m \cdot \B $ and thus $ \curl \B $ refers only to the external field.
	
	To make this distinction clear, we write Ampere's law for our problem as 
	\begin{equation*}
		\curl \B = \mm \t{\j},
	\end{equation*}
	where $ \t{\j} $ is the current distribution generating the external field $ \B $---note that the $ \t{\j} $ generating the external field is unrelated to the current $ \j $ for which we are calculating magnetic force.
	
	\item We now make an approximation---we assume the current distribution $ \t{\j} $ generating the external field is far from the current distribution $ \j $ for which we are calculating magnetic force. This assumption implies $ \big |\t{\j}\big | \ll \abs{\j} $ near the localized region of space containing $ \j $. Since $ \t{\j} $ is negligible compared to $ \j $, we can approximate
	\begin{equation*}
		\curl \B = \mm \t{\j} \approx 0.
	\end{equation*}

	\item Using $ \curl \B \approx 0 $ leads to
	\begin{equation*}
		\grad\big[\m \cdot \B(\r)\big] = \m \cross (\curl \B) + (\m \cdot \grad)\B \approx (\m \cdot \grad)\B,
	\end{equation*}
	and thus
	\begin{equation*}
		\diff W_{\text{M}} = - \grad\big[\m \cdot \B(\r)\big]\cdot  \diff \r \approx - \big[ (\m \cdot \grad)\B\big]\cdot \diff \r.
	\end{equation*}
	Comparing this to the general force-energy relation $ \diff W_{\text{M}} = - \vec{F}_{\text{M}}\diff \r $ produces
	\begin{equation*}
		\vec{F}_{\text{M}} = (\m \cdot \grad)\B(\r).
	\end{equation*}
	In other words, the magnetic force on a magnetic dipole in an external magnetic field is the directional derivative of $ \B $ in the direction of $ \m $.
\end{itemize}

\subsubsection{Torque on a Magnetic Dipole in an External Magnetic Field}
\begin{itemize}
	\item Finally, we will find an expression for the torque on a magnetic dipole in an external magnetic field. 

	\item We begin with the general relationship between torque and energy, which reads
	\begin{equation*}
		\diff W = - \vec{M} \cdot \diff \vec{\phi},
	\end{equation*}
    where $ \M $ is torque, $ \diff \vec{\phi} $ is an infinitesimal rotation in space, and $ \diff W $ is the corresponding change in potential energy.
	
	\item A small rotation of a magnetic dipole in an external magnetic field reads
	\begin{equation*}
		\diff \vec{m} = \diff \vec{\phi} \cross \m,
	\end{equation*}
	and the corresponding change in the dipole's energy because of this rotation, using $ W_{\text{M}} = - \m \cdot \B $, is
	\begin{equation*}
		\diff W_{\text{M}} = - \diff \m \cdot \diff \B = - (\diff \vec{\phi} \cross \m)\cdot \B.
	\end{equation*}
	This is a scalar triple product, which we can rearrange to get
	\begin{equation*}
		\diff W_{\text{M}} = - \diff \vec{\phi} \cdot (\m \cross \B).
	\end{equation*}
    Comparing $ \diff W_{\text{M}} = - \diff \vec{\phi} \cdot (\m \cross \B) $ to the general relation $ \diff W = - \vec{M} \cdot \diff \vec{\phi} $ produces the desired expression for magnetic torque:
	\begin{equation*}
		\vec{M}_{\text{M}} = \m \cross \B.
	\end{equation*}
	This is the torque on a magnetic dipole in an external magnetic field. We are familiar with this result from introductory electromagnetism, and now we have derived it from fundamental principles.
\end{itemize}

\newpage
\section{Quasi-Static Electromagnetic Fields}
By convention, the quasi-static approximation to electromagnetic fields adds the consideration of magnetic induction to magnetostatics. 

\subsection{Electromagnetic Induction}
\begin{itemize}
	\item We begin by recalling Lenz's law from introductory electromagnetism:
    \begin{quote}
        The change in magnetic flux through a current loop induces an electric current that opposes the magnetic flux inducing the current. 
    \end{quote}
	Note that the law in this form is qualitative. We will instead use Maxwell's formulation of Lenz's law, which states that the electric circulation $ \Gamma_{\mathrm{E}} $ in a current loop and the magnetic flux $ \Phi_{\mathrm{M}} $ through the loop are observed to obey the relationship
	\begin{equation*}
		\Gamma_{\mathrm{E}} = -\dv{t} \Phi_{\mathrm{M}}.
	\end{equation*}
    We stress that this result comes from experiment. We have not derived it from fundamental principles, it is simply the observed physical behavior.
	
	\item In integral form, the quantitative formulation of Lenz's law reads
	\begin{equation*}
		\oint_{\partial S}\E \cdot \diff \r = - \dv{t} \iint_{S} \B \cdot \diff \vec{S}.
	\end{equation*}
	We then apply Stokes' theorem to transform this equation to the differential form
	\begin{equation*}
		\iint \curl \E \cdot \diff \vec{S} = - \iint \pdv{\B}{t} \cdot \diff \vec{S},
	\end{equation*}
    where we have assumed the shape of the current loop is constant through time. The above equation implies
	\begin{equation*}
		\curl \E = - \pdv{\B}{t}.
	\end{equation*}
	This is important result is one of the Maxwell equations for electromagnetism. Note that $ \E $ and $ \B $ are coupled, and that this equation does not include constants---only $ \E $ and $ \B $ and their derivatives. 
	
\end{itemize}

\subsubsection{Maxwell Magnetic Field Impulse}
\begin{itemize}
	\item We now combine the just-derived Maxwell equation with $ \B = \curl \A $ to get
	\begin{equation*}
		\curl \E = - \pdv{\B}{t} = - \curl \pdv{\A}{t},
	\end{equation*}
	which leads to to interesting relationship
	\begin{equation*}
		\E = - \pdv{\A}{t}.
	\end{equation*}
	This relationship holds as long as magnetic field lines are closed, which is what allowed us to write $ \B = \curl \A $. However, this expression for $ \E $ is not complete---$ \E $ is undetermined up to the gradient of a scalar field. We will correct this shortly.
	
	\item We can combine the above expression for $ \E $ with Newton's law and the electrostatic force to get
	\begin{equation*}
		\dv{\mat{p}}{t} = \vec{F} = q \E = - \pdv{(q \A)}{t}.
	\end{equation*} 
    In other words, we've derived the relationship $ \vec{p} = q \A $---note that $ q\A $ behaves as a momentum. The quantity $ q \A + m \\vec{v} $ is often called canonical momentum, while the familiar expression $ \vec{p} = m \vec{v} $ is kinetic momentum.
	
    % \item The canonical momentum $ \vec{p} = q \A $ leads to an interesting interpretation. Namely, we can interpret magnetic induction as the impulse of the momentum $ \vec{p} = q \A $. 
\end{itemize}

\subsection{The Quasistatic Maxwell Equations}
\begin{itemize}
	\item In the form we have used them so far (in the quasi-static scope of electrostatics and magnetostatics), the four Maxwell equations are
	\begin{align*}
		&\div \E = \frac{\rho}{\ee} \qquad \curl \E = - \pdv{\B}{t}\\
		& \div \B = 0 \ \, \qquad \curl \B = \mm \j.
	\end{align*}
	We note that these equations hold only in the quasistatic regime in which all current loops are closed, i.e. $ \div \j = 0 $. 
	
	The above Maxwell equations completely describe quasistatic electromagnetism. They do not, however, describe all of electromagnetism---the equations $ \div \j = 0 $ and $ \curl \B = \mm \j  $ must be generalized.
\end{itemize}

\subsubsection{The Electromagnetic Potentials for Quasistatic Fields}
\begin{itemize}
	\item We now return to the incomplete relationship between $ \E $ and $ \A $. More generally, our goal in this section is to write $ \E $ and $ \B $ in terms of the fundamental electromagnetic potentials $ \phi $ and $ \A $.
	
    \item Recall that the definition of magnetic potential via $ \B = \curl \A $ was possible because of the relationship $ \div \B = 0 $, which is always satisfied if $ \B $ is written as the curl of a vector field---the divergence of a curl of a vector field is always zero. The expression $ \B = \curl \A $ thus holds in dynamic as well as quasistatic situations, and we don't need to generalize if further.

	\item We now ask how to write $ \E $ in terms of $ \phi $ and $ \A $. 

    In electrostatics, we began with $ \curl \E = 0 $. Using the law of induction, we then generalized this relationship in the quasistatic regime to
	\begin{equation*}
		\curl \E = - \pdv{\B}{t} = - \curl \pdv{\A}{t}.
	\end{equation*}
    We then rewrite the above equation for $ \curl \E $ in the form
	\begin{equation*}
		\curl \left(\E + \pdv{\A}{t}\right) = 0.
	\end{equation*}
	Recall that the curl of the gradient of a scalar field is always zero. This means that the above expression in parentheses is determined only up to the gradient of a scalar field. This implies
	\begin{equation*}
        \E + \pdv{\A}{t} = - \grad \phi \qquad \text{or} \qquad \E = - \grad \phi - \pdv{\A}{t}.
	\end{equation*} 
	In the quasistatic regime, the complete expression for electric field is thus
	\begin{equation*}
		\E = - \grad \phi - \pdv{\A}{t}.
	\end{equation*}
	
    We note that the Maxwell equations $ \div \B = 0 $ and $ \curl \E = - \pdv{B}{t} $ allow us to write $ \E $ and $ \B $ in terms of the fundamental electromagnetic potentials $ \A $ and $ \phi $ in the quasistatic regime. 
	
\end{itemize}

\subsection{Conductors and Ohm's Law}
\begin{itemize}
	\item At a basic level, conductors are materials permitting the motion of charged particles through the material. The charged particles are typically electrons, holes, or ions.
	
	\item Conductors obey Ohm's law, which we will write in the general form
	\begin{equation*}
		\j = \sigma_{\mathrm{E}} \E,
	\end{equation*}
	where $ \j $ is the current density in the material, $ \E $ is the electric field in the material, and $ \sigma_{\mathrm{E}} $ is electric conductivity.
	
	\item We take a material containing mobile charge carriers as our model of a conductor. 

    \textit{Important}: Conductors are electrically neutral! The charges in the material my move around, but the conductor as a whole is neutral.
	
	When we turn on an external electric field---positive charges move in the direction of the external field and negative charges opposite the external field. 
	
	The effect is that the free charges in the conductor rearrange in a configuration that cancels out the external field. The total electric field in the conductor at equilibrium, after the charge redistribution, is thus zero--if it weren't zero, the charges would keep moving! At equilibrium, we have $ \j = 0 $ and $ \E = 0 $ within the conductor.
	
	\item Continuing with the example of an conductor in an external electric field at equilibrium, we recall that $ \E $ and $ \rho $ are related by Gauss's law via
	\begin{equation*}
		\div \E = \frac{\rho}{\ee}.
	\end{equation*}
	Because $ \E = 0 $ at equilibrium, it follows from Gauss's law that $ \rho $ is also zero at equilibrium. In other words, there is zero volume charge density in a conductor at equilibrium.
	
	\item If the charges are not within the conductor, they must then be at the conductor's surface. 

    We let $ \uvec{n} $ and $ \sigma $ denote the normal to the surface and the surface charge density, respectively. Near the conductor's surface we must have 
	\begin{equation*}
		\E \cdot \uvec{n} = \frac{\sigma}{\ee},
	\end{equation*}
	which means $ \E $ is perpendicular to the conductor's surface (to be discussed further).
	
	\item \textit{Keep in mind}: Assume we increase the external electric field. As we increase the external field, the conductor must naturally redistribute more and more charge to its surface to cancel out the external field. 
	
	In principle, at some point, there might not be enough charge left in the material to cancel out the external field. In this course, however, we will assume conductors always have enough available charge pairs (e.g. electrons and holes) to cancel out an external magnetic field. 
	
    \item Review: a conductor at equilbrium obeys $ \E = \j = 0 $, which implies $ \rho = 0 $, implying the conductor's charge is concentrated at the surface. This induced surface charge cancels out the external field such that the total electric field inside the conductor is zero. 
	
	\item For the conductor to be in equilibrium, the electric field must always be normal to the surface (i.e. $ \E \cross \uvec{n} = 0 $). If the electric field at the surface had a tangential component, charges would move along the surface in the tangent direction, and the conductor wouldn't be in equilibrium. 
	
	Since $ \E $ is perpendicular to the conductor's surface at equilibrium, the surface is an equipotential surface and obeys
	\begin{equation*}
		\phi_{2} - \phi_{1} = \int \E \cdot \diff \vec{l} = \int \E \cdot \uvec{t} \diff l = \int 0 \diff l = 0 \implies \phi \text{ constant}.
	\end{equation*}
	where $ \uvec{t} $ is the tangent to the surface---$ \E \cdot \uvec{t} = 0$ since $ \E $ is normal to the surface. 

\end{itemize}

\subsubsection{The Relaxation Time Constant of a Conductor}
\begin{itemize}
	\item We now ask how quickly a conductor can react to an external electric field, i.e. how quickly charges redistribute in response to the external field to create equilibrium. 
	
	\item We begin with the continuity equation, which reads
	\begin{equation*}
		\div \j + \pdv{\rho}{t} = 0.
	\end{equation*}
	Note that this is a generalization of the earlier expression $ \div \j = 0 $ to electrodynamic situations involving time-varying charge distributions. 
	
	\item We then substitute Ohm's law $ \j = \sigma_{\mathrm{E}}\E $ into the continuity equation to get
	\begin{equation*}
		\div (\sigma_{\mathrm{E}} \E) + \pdv{\rho}{t} = 0.
	\end{equation*}
	Next, we write $ \E $ in terms of $ \rho $ using Gauss's law $ \div \E = \frac{\rho}{\ee} $, which produces
	\begin{equation*}
		\pdv{\rho}{t} + \frac{\sigma_{\mathrm{E}}}{\ee} \rho = 0.
	\end{equation*}
	The general solution for $ \rho $ is exponential:
	\begin{equation*}
        \rho(\r, t) = \rho(\r, 0)e^{-\frac{t}{\tau}}, \quad \text{where } \tau = \frac{\ee}{\sigma_{\text{E}}}.
	\end{equation*}
	The larger the conductivity $ \sigma_{\mathrm{E}} $, the smaller the characteristic response time $ \tau $, and the sooner the conductor reaches equilibrium when placed in an external electric field. 
	
	\item As an example, for iron, we have $ \tau \approx \SI{8.85e-19}{\second} $. In other words, the time constant is incredibly small---on a macroscopic scale, the conductor reaches equilibrium essentially instantly.
	
\end{itemize}

\subsubsection{The Drude Model of Conductivity}
\begin{itemize}
	\item We will now derive Ohm's law from fundamental principles, using a simple model of microscopic charge carriers called the Drude model.
	
	We begin with Newton's law for a charge carrier moving through a conductor in an electric field. We consider two forces on the charge carrier:
	\begin{enumerate}
		\item a dissipative velocity-dependent force $ - m \gamma \vec{v}(t) $, where $ \gamma $ is a damping constant,
		
		\item and the accelerating electric force $ q \E(t) $.
	\end{enumerate}
	In terms of these two forces, Newton's law for the particle in the conductor reads
	\begin{equation*}
		m \dv{v}{t} = - m \gamma \vec{v}(t) + q \E(t).
	\end{equation*}
	
	\item When $ \E = 0 $, the solution is $ \vec{v}(t) = \vec{v}_{0} e^{- \gamma t}$. In this case, the particle's velocity exponentially decays with time, which means particles in the conductor rapidly stop moving. This makes sense---electric current is not observed to flow in the absence of an external electric field.
	
	Energy interpretation: the particle's kinetic energy dissipates into thermal energy, which increases the conductor's internal energy.
	
	\item When $ \E \neq 0 $, we use the ansatz (which is quoted, not derived or explained further)
	\begin{equation*}
		\vec{v}(t) = \frac{q}{m}\int_{-\infty}^{t}e^{-\gamma(t - \t{t})}\E(\t{t}) \diff \t{t},
	\end{equation*}
    where $ \tilde{t} $ is a placeholder variable for time integration.
	
    \item Next, we write current density to charge carrier velocity $ \vec{v} $ via
	\begin{equation*}
		\j = \rho \vec{v} = n q \vec{v},
	\end{equation*}
	where $ q $ is the charge of a single charge carrier, $ n $ is the number density of charge carriers in the conductor, and $ \vec{v} $ is the charge carriers' drift velocity. Substituting the ansatz for charge carrier velocity $ \vec{v} $ into the equation for $ \j $ gives
	\begin{equation*}
		\j = \frac{nq^{2}}{m}\int_{-\infty}^{t}e^{-\gamma(t - \t{t})}\E(\t{t}) \diff \t{t}.
	\end{equation*}
	
	\item For a constant field, $ \E(t) = \E_{0} $, we can easily solve the integral to get Ohm's law
	\begin{equation*}
		\j = \frac{nq^{2}}{m\gamma}\E_{0}.
	\end{equation*}
	The Drude model thus gives a prediction for conductivity
	\begin{equation*}
		\sigma_{\mathrm{E}} = \frac{nq^{2}}{m \gamma}
	\end{equation*}
    Note that the Drude model gives an expression for conductivity in terms of fundamental quantities, rather than taking conductivity itself to be fundamental.
	
	\item Some numerical values of conductivity (measured in siemens \si{\siemens} = $ \si{\ohm^{-1}} $) are given in the table below
	\begin{center}
	\begin{tabular}{c|c}
		Material & Conductivity\\
		\hline {\rule{0pt}{2.6ex}} \hspace{-7pt}
		aluminum & $ \SI{3.7e7}{\siemens \, \meter^{-1}} $\\
		iron & $ \SI{9.9e6}{\siemens \, \meter^{-1}} $\\
		YBa$ _{2} $Ca$ _{3} $O$ _{7} $, $ T > \SI{92}{\kelvin} $ & $ \SI{1e6}{\siemens \, \meter^{-1}} $\\
		YBa$ _{2} $Ca$ _{3} $O$ _{7} $, $ T < \SI{92}{\kelvin} $ & $ \infty \, \si{\siemens \, \meter^{-1}} $\\
		glass, $ T = \SI{300}{\kelvin} $ & $ \SI{1e-15}{\siemens \, \meter^{-1}} $\\
		glass, $ T = \SI{1000}{\kelvin} $ & $ \SI{1e-7}{\siemens \, \meter^{-1}} $\\
	\end{tabular}
	\end{center}
    The material YBa$ _{2} $Ca$ _{3} $O$ _{7} $ is a superconductor at low temperatures, which examplains $ \sigma_{\text{E}} = \infty $. Note also that $ \sigma_{\mathrm{E}} $ is in general strongly temperature dependent, as seen in the case of glass and, more extermely, the superconductor YBa$ _{2} $Ca$ _{3} $O$ _{7} $.
	
\end{itemize}

\subsubsection{Energy Dissipation}
\begin{itemize}
    \item In general a charge distribution experiences two forces---the electric and magnetic forces. The magnetic force $ \vec{F}_{\text{M}} = q \vec{v} \cross \B  $ is perpendicular to velocity and cannot do work, and we thus expect that the magnetic force cannot contribute to dissipative forces. 
	
	\item More formally, the dissipative power associated with a charge carrier in terms of electromagnetic force density $ \vec{f} $ is
	\begin{equation*}
		P = \iiint_{V} \vec{v} \cdot \vec{f} \dr = \iiint_{V} \frac{\j}{\rho} \left(\rho \E + \j \cross \B\right)\dr,
	\end{equation*}
	where we have substituted in $ \vec{v} = \j/\rho $. The second integrand contains the term $ \j \cdot (\j \cross \B) = 0 $, which is why the magnetic force cannot dissipate power. The dissipated power thus reduces to
	\begin{equation*}
		P = \iiint_{V} \j \cdot \E \dr.
	\end{equation*}
	This expression represents the power dissipated because of charge carrier motion associated with the current density $ \j $ in the electric field $ \E $. Note that this analysis assumes the charge carriers obey $ \vec{v} = \j / \rho $. 
	
    Finally, we note that in a classic scenario $ \j \propto \E $ and thus $ P \propto \j \cdot \E \propto E^{2} $. 
		
\end{itemize}

\subsubsection{Capacitance}
\begin{itemize}
	\item Our goal in this section is to develop a general expression for a conductor's capacitance. Capacitance describes how much charge can accumulate on a capacitor at a given potential difference. A conductor's capacitance depends on its geometry (and also permittivity, but we leave that for later).
	
	\item We consider $ N $ conductors indexed by $ i = 1, \ldots, N $. For example, for a parallel-plate capacitor with two plates, we would have $ N = 2 $. 

    In a more general situation, however, we can have many ``conductors'' (e.g. in batteries) contributing to a cumulative capacitance. 
	
    \item The surface of any conductor is an equipotential surface, which we write for our system of $ i = 1, \ldots, N $ conductors in the form
	\begin{equation*}
        \phi(\r) \big |_{\partial V_{i})}  = k_{i},
	\end{equation*}
	where the $ k_{i} $ are constants encoding the constant potential on the $ i $-th conductor's surface.
	
	\item Next, we consider the total electric energy associated with the collection of conductors, which is
	\begin{equation*}
		W_{\text{E}} = \frac{1}{2}\iiint_{V}\rho(\r)\phi(\r)\dr,
	\end{equation*}
	where $ \rho(\r) $ is the volume charge density in the conductor collection. However, since all charges in the conductors occur at the surface, we can change the expression for $ W_{\text{E}} $ to a surface integral of the form
	\begin{equation*}
		W_{\text{E}} = \frac{\phi}{2} \iint_{S} \sigma(\r) \diff \vec{S},
	\end{equation*}
	where $ \phi $ is moved out of the integral because it is constant along the surface. Writen in terms of the individual contributions of each conductor, the energy becomes
	\begin{equation*}
		W_{\text{E}} = \frac{1}{2}\sum_{i} \phi_{i} \iint_{S} \sigma_{i}(\r) \diff \vec{S}_{i} = \frac{1}{2}\sum_{i} \phi_{i} q_{i}
	\end{equation*}
	where $ q_{i} $ is the charge on the $ i $th conductor's surface. The total electric field energy in the conductor collection is thus
	\begin{equation*}
		W_{\text{E}} = \frac{1}{2}\sum_{i} \phi_{i}q_{i}.
	\end{equation*}
	
	\item We will now find the same total electric field energy with a different approach. We will then equate the two expressions for $ W_{\text{E}} $ to get a generalized expression for capacitance. As before, we begin with the definition
	\begin{equation*}
		W_{\text{E}} = \frac{1}{2}\iiint_{V} \rho(\r) \phi(\r) \dr.
	\end{equation*}
	Our goal is to write the integrand purely in terms of charge $ q $. We begin by writing $ \phi $ in terms of $ \rho $ using the Poisson equation, which gives
	\begin{equation*}
		\phi(\r) = \frac{1}{4\pi \ee}\iiint_{V}\frac{\rho(\t{\r})}{\abs{\r - \t{\r}}} \dtr.
	\end{equation*}
    Using this expression for $ \phi $, the electric field energy is thus
	\begin{equation*}
		W_{\text{E}} = \frac{1}{8\pi \ee} \iiint_{V}\left(\iiint_{V} \frac{\rho(\r)\rho(\t{\r})}{\abs{\r - \t{\r}}}\dtr \right) \dr.
	\end{equation*}
	Because the conductor charge is on the surface only, we re-write the integral in terms surface charge density and surface elements, which gives
	\begin{equation*}
		W_{\text{E}} = \frac{1}{8\pi \ee}\sum_{i, k} \iint_{S} \iint_{S} \frac{\sigma_{i}\sigma_{k}\diff S_{i}\diff S_{k}}{\abs{\r_{i} - \r_{k}}},
	\end{equation*}
	where $ \diff S_{i} $ and $ \diff S_{k} $ are the surface elements of the $ i $th and $ k $th conductors, and $ \r_{i} $ and $ \r_{k} $ are the position vectors on the $ i $th and $ k $th surfaces. 
	
	Finally, we multiply above and below by $ q_{i}q_{k} $ to get
	\begin{equation*}
		W_{\text{E}} = \frac{1}{2} \sum_{i, k} \frac{1}{4\pi \ee q_{i}q_{k}}q_{i}q_{k} \iint_{S} \iint_{S} \frac{\sigma_{i}\sigma_{k}\diff S_{i}\diff S_{k}}{\abs{\r_{i} - \r_{k}}}.
	\end{equation*}
	
	\item Next, we equate the above expression for $ W_{\text{E}} $ to the earlier $ W_{\text{E}} $, which results in the general expression for capacitance
	\begin{equation*}
		\frac{1}{C_{ik}} = \frac{1}{4\pi \ee q_{i} q_{k}} \iint_{S} \iint_{S} \frac{\sigma_{i}\sigma_{k}\diff S_{i}\diff S_{k}}{\abs{\r_{i} - \r_{k}}}.
	\end{equation*}
	In terms of capacitance, the system's total electric field energy is
	\begin{equation*}
		W_{\text{E}} = \frac{1}{2}\sum_{i}\phi_{i}q_{i} = \frac{1}{2}\sum_{i, k}(C_{ik})^{-1}q_{i}q_{k}.
	\end{equation*}

	\item Note that the expression for capacitance $ C_{ik} $ is consistent with capacitance depending only on geometry (and not charge): the $ q_{i}q_{k} $ in the denominator cancel with the $ \sigma_{i} \sigma_{k} $ after the charge densities are integrated over the surfaces $ \diff S_{i} $ and $ \diff S_{k} $. This exact cancellation works out since the expression $ \abs{\r_{i} - \r_{k}} $ ``normalizes'' the geometric properties of the potentially varying surface charge densities. 

	\item Summary: Capacitance relates the charge on a given conductor to the potential difference across the conductor. Capacitance depends only on geometry. For a generalized collection of $ N $ conductors, capacitance, charge, and electric potential are related by
	\begin{equation*}
		\phi_{i} = \sum_{k} (C^{-1})_{ik}q_{k} \eqtext{where} q_{k} = C_{ki}\phi_{i}.
	\end{equation*}
	Note that these expressions generalize capacitance $ C $  to a $ N\cross N $ rank-two tensor. Finally, note that the charge on a given conductor depends on the capacitance and potential difference of all of the other conductors in the collection---this is a consequence of the principle of superposition. 
	
\end{itemize}

\subsubsection{Inductance}

\begin{itemize}
	\item Inductance relates magnetic flux and electric current. Like capacitance, inductance depends only on an inductor's geometry. In this section, we will derive general expression for the inductance of a generalized system of inductors, i.e. $ N $ current-carrying loops carrying currents $ I_{1}, I_{2}, \ldots, I_{N} $.
	
	\item We first find the system's total magnetic field energy. We begin with the definition
	\begin{equation*}
		W_{\text{M}} = \frac{1}{2}\iiint_{V}\j \cdot \A \dr,
	\end{equation*}
	where we integrate over the volume with non-zero current density $ \j $. We then rewrite the current in the form $ \j \dr = I \diff \vec{l} $ and consider all $ N $ loops together to get
	\begin{equation*}
		W_{\text{M}} = \frac{1}{2}\sum_{i}I_{i}\oint_{C_{i}} \A \cdot \diff \vec{l}_{i},
	\end{equation*}
	where the current $ I_{i} $ in the $ i $-th conductor is constant along the conductor's curve $ C_{i} $, and thus moves out of the integral. Finally, we write the integrand in terms of magnetic flux, for which we use Stokes's theorem:
	\begin{align*}
        W_{\text{M}} &= \frac{1}{2}\sum_{i}I_{i}\oint_{C_{i}} \A \cdot \diff \vec{l}_{i} = \frac{1}{2}\sum_{i}I_{i}\iint_{S_{i}} \curl \A \cdot \diff \vec{S}_{i} \\
        &= \frac{1}{2}\sum_{i}I_{i}\iint_{S_{i}} \B \cdot \diff \vec{S}_{i} = \frac{1}{2}\sum_{i}I_{i} \Phi_{\text{M}_{i}}.
	\end{align*}
	
	\item We will now find the same magnetic field energy with a second approach. We will then equate the two results for $ W_{\text{M}} $ to get a generalized expression for inductance. As before, we begin with the general definition
	\begin{equation*}
		W_{\text{M}} = \frac{1}{2}\iiint_{V} \j \cdot \A \dr.
	\end{equation*}
	We then express $ \A $ in terms of $ \j $ via
	\begin{equation*}
		\A(\r) = \frac{\mm}{4\pi}\iiint_{V}\frac{\j(\t{\r})}{\abs{\r - \t{\r}}}\dtr,
	\end{equation*}
    and substitute this expression for $ \A(\r) $ into $ W_{\text{M}} $ to get
	\begin{equation*}
		W_{\text{M}} = \frac{\mm}{8\pi}\iiint_{V} \left(\iiint_{V}\frac{\j(\r)\j(\t{\r})}{\abs{\r - \t{\r}}}\dtr\right)\dr.
	\end{equation*}
	Finally, we convert $ \j \dr $ to current, $ I \diff \vec{l} $, and sum over all loop pairs to get
	\begin{equation*}
		W_{\text{M}} = \frac{\mm}{8\pi}\sum_{i, k}I_{i}I_{k}\oint_{C_{i}}\oint_{C_{k}}\frac{\diff \vec{l}_{i}\diff \vec{l}_{k}}{\abs{\r(l_{1}) - \r(l_{k})}},
	\end{equation*}
	where $ C_{i} $ and $ C_{k} $ are the space curves associated with the $ i $th and $ k $th conducting loops.
	
	\item We then equate the two expressions for $ W_{\text{M}} $ to get
	\begin{equation*}
		\frac{1}{2}\sum_{i}I_{i}\Phi_{\text{M}_{i}} = \frac{\mm}{8\pi}\sum_{i, k}I_{i}I_{k}\oint_{C_{i}}\oint_{C_{k}}\frac{\diff \vec{l}_{i}\diff \vec{l}_{k}}{\abs{\r(l_{1}) - \r(l_{k})}}.
	\end{equation*}
    This relationship motivates the definition of inductance $ L_{ik} $ as
	\begin{equation*}
		L_{ik} = \frac{\mm}{4\pi}\oint_{C_{i}}\oint_{C_{k}}\frac{\diff \vec{l}_{i}\diff \vec{l}_{k}}{\abs{\r(l_{1}) - \r(l_{k})}},
	\end{equation*}
    in terms of which the relationship between the two forms of $ W_{\text{M}} $ simplifies to
	\begin{equation*}
        W_{\text{M}} = \frac{1}{2}\sum_{i}I_{i}\Phi_{\text{M}_{i}} = \frac{1}{2} \sum_{i, k}I_{i}I_{k} L_{ik}.
	\end{equation*}
	
	\item A few final remarks on inductance:
    \begin{itemize}
        \item Note that $ L_{ik} $ depends only on geometric quantities and is thus consistent with inductance depending only on the loops' geometry.

        \item The rank-two tensor $ L_{ik} $'s diagonal terms $ L_{ii} $ are called self-inductance, while the off-diagonal terms correspond to mutual inductance between different current loops.

        \item In general, the magnetic flux through the $ i $th loop is
        \begin{equation*}
            \Phi_{\text{M}_{i}} = \sum_{i} L_{ik}I_{k}.
        \end{equation*}
    \end{itemize}

\end{itemize}


\subsubsection{The Skin Effect}
\begin{itemize}
	\item Qualitatively, the skin effect is summarized as follows:
    \begin{quote}
        At high frequencies, alternative current tends to run mostly along a conductor's surface. More formally, the current density is largest at a conductor's surface for high frequency alternating currents.
    \end{quote}
	Of course, we will want to perform a more quantitative analysis of the skin effect, for which we begin with the Maxwell equations
	\begin{equation*}
		\div \E = \frac{\rho}{\ee} = 0 \eqtext{and} \curl \E = - \pdv{\B}{t},
	\end{equation*}
	where volume charge density is $ \rho = 0 $ in a conductor. For magnetic fields, we have
	\begin{equation*}
		\div \B = 0 \eqtext{and} \curl \B = \mu_{0}\j = \mm \sigma_{\text{E}} \E
	\end{equation*}
	where we have substituted in Ohm's law $ \j = \sigma \E $. 

    \item We then take the curl of $ \curl \E $ and $ \curl \B $  to get
	\begin{align*}
        & \curl \big[ \curl \E \big] = - \pdv{t}\big[ \curl \B\big] = - \mm \sigma_{\text{E}} \pdv{\E}{t}\\
        & \curl [\curl \B] = \mm \sigma_{\text{E}}\curl \E = - \mm \sigma_{\text{E}}\pdv{\B}{t}.
	\end{align*}
	Note the symmetry of the two equations for $ \E $ and $ \B $.

	
	\item Next, we use the general vector calculus identity
	\begin{equation*}
		\curl (\curl \vec{F}) = \grad (\div \vec{F}) - \laplacian \vec{F},
	\end{equation*}
    where $ \vec{F} $ is a vector field. We apply this identity to both double curl equations, together with $ \div \E = \div \B = 0 $, to replace the double curl with the Laplacian:
	\begin{equation*}
		\laplacian \E = \mm \sigma_{\text{E}}\pdv{\E}{t} \eqtext{and} \laplacian \B = \mm \sigma_{\text{E}} \pdv{\B}{t}.
	\end{equation*}
	These are diffusion equations for $ \E $ and $ \B $---their perfect symmetry is a consequence of $ \rho = 0 $ for a conductor and $ \j = \sigma_{\text{E}} \E $ from Ohm's law. 
	
	\item We solve the diffusion equations with separation of variables using the ansatzes
	\begin{equation*}
		\E(\r, t) = \E(\r)e^{-i\omega t} \eqtext{and} \B(\r, t) = \B(\r)e^{-i\omega t}.
	\end{equation*}
	These ansatzes produce
	\begin{equation*}
		\laplacian \E = k^{2} \E \eqtext{and} \laplacian \B = k^{2} \B,
	\end{equation*}
	where $ k^{2} = -i \omega \mm \sigma_{\text{E}} $. The value of $ k $, using the complex number identity $ \sqrt{i} = \frac{1-i}{\sqrt{2}} $, is
	\begin{equation*}
		k = \frac{\sqrt{2}}{2}(1 - i) \sqrt{\omega \mm \sigma_{\text{E}}}.
	\end{equation*}
	In one positional dimension, the position solutions are
	\begin{equation*}
		\begin{Bmatrix}
            \E(z)\\
            \B(z)
		\end{Bmatrix}
        \sim e^{-kz} = \exp\left(- \frac{\sqrt{2}}{2}\sqrt{\omega \mm \sigma_{\text{E}}}\cdot z\right)\exp\left(i \frac{\sqrt{2}}{2}\sqrt{\omega \mm \sigma_{\text{E}}}\cdot z\right).
	\end{equation*}
	Qualitatively: the $ \sim e^{iz} $ term describes oscillation, while the $ \sim e^{-z} $ term describes exponential decay, with characteristic decay length $ z_{0} = \sqrt{\frac{2}{\omega \mm \sigma}} $. Note that $ z_{0} $ decreases with increasing $ \omega $, so the electric field (and thus $ \j $ via Ohm's law) decays more rapidly with position at increasing frequencies. 
	
	\item As an example, at $ \omega = \SI{50}{\hertz} $, the decay distance of copper is $ z_{0} \sim \SI{1}{\centi \meter} $. This distance is much larger than the diameter of most wires, so the skin effect is negligible.
	
	Meanwhile, for copper at $ \omega = \SI{750}{\mega \hertz} $ (which is a typical radio frequency for a \texttt{Cat-6} Ethernet cable) we have $ z_{0} \sim \SI{1}{\nano \meter} $. Only the very outside of the conducting wire carries a signal. Keep in mind that a nanometer is only of order 5-10 atomic radii. At higher frequencies we thus ``run out'' of atoms to carry current. We solve this skin-effect induced problem by using optical cables instead of metal conductors.
	
\end{itemize}

\subsubsection{Electromagnetic Field Geometry in the Skin Effect}
\begin{itemize}
	\item We now consider a long, straight wire, which we model as a cylinder with the longitudinal axis in the $ z $ direction. Our goal is to completely solve the earlier diffusion equations for $ \E $ and $ \B $. We use a cylindrical basis and cylindrical coordinates $ (r, \phi, z) $. 
	
	\item The current runs in the $ z $ direction, so $ \j = (0, 0, j_{z}) $, which corresponds to an electric field $ \E = (0, 0, E_{z}) $. Because of rotational symmetry about the angle $ \phi $, the electric field $ E_{z} $ depends only on $ r $:
	\begin{equation*}
		E_{z}(\r, t) = E_{z}(r)e^{-i\omega t}.
	\end{equation*}
	The magnetic field points only tangent to the cylinder's circular cross section, i.e. in the $ \uvec{e}_{\phi} $ direction in cylindrical coordinates. The expression for magnetic field is thus
	\begin{equation*}
		B_{\phi}(\r, t) = B_{\phi}(r)e^{-i\omega t}.
	\end{equation*}
	
    \item Next, recall the diffusion equations for $ \E $ and $ \B $ were
	\begin{equation*}
		\laplacian \E = \mm \sigma_{\text{E}}\pdv{\E}{t} \eqtext{and} \laplacian \B = \mm \sigma_{\text{E}} \pdv{\B}{t}.
	\end{equation*}
	We evaluate the Laplacian operators in cylindrical coordinates to get
	\begin{align*}
		& \frac{1}{r}\pdv{r}\left(r\pdv{E_{z}}{r}\right)  = -i \mm \omega \sigma_{\text{E}}E_{z} \\
		& \frac{1}{r}\pdv{r}\left(r\pdv{B_{\phi}}{r}\right) - \frac{B_{\phi}}{r^{2}} = -i \mm \omega \sigma_{\text{E}}B_{\phi}.
	\end{align*}
	As before, we define $ k^{2} = -i\mm \omega \sigma_{\text{E}} $. 

    \item Next, recall the Maxwell equation $ \curl \E = - \pdv{\B}{t} $. In our cylindrical basis and coordinate system, this equation implies $ \E $ and $ \B $ are related according to
	\begin{equation*}
		i \omega B_{\phi} = (\curl \E)_{\phi} = -\pdv{E_{z}}{r}.
	\end{equation*}
	If we solve for $ E_{z}(r) $, the solution turns out to be
	\begin{equation*}
		E_{z}(r) = A J_{0}(kr) \eqtext{and} B_{\phi} = i A \frac{k}{\omega} J_{1}(kr),
	\end{equation*}
	where $ A $ is an unknown constant, $ k = \frac{\sqrt{2}}{2}(1- i)\sqrt{\omega \mm \sigma_{\text{E}}} $,	and $ J_{0} $ and $ J_{1} $ are the Bessel functions.
	
\end{itemize}

\subsubsection{Electric Current the Skin Effect}
\begin{itemize}
	\item Recall from the previous section that the electric and magnetic field in a cylindrical conductor, using the spherical coordinate ($ r, \phi, z $), were
	\begin{align*}
		& \E = (0, 0, E_{z}), \qquad E_{z}(r) = A J_{0}(kr) \\
		& \B = (0, B_{\phi}, 0), \qquad B_{\phi} = i A \frac{k}{\omega} J_{1}(kr),
	\end{align*}
	where $ k = \frac{\sqrt{2}}{2}(1- i)\sqrt{\omega \mm \sigma_{\text{E}}} $, $ A $ is an unknown constant, and the $ J_{0} $ and $ J_{1} $ are the Bessel functions.
	
	We will now find the electric current in the conductor. We start with current density, which we find with Ohm's law according to
	\begin{equation*}
		\j = \sigma_{\text{E}}\E = \sigma_{\text{E}}AJ_{0}(kr)\uvec{e}_{z}.
	\end{equation*}
	The total current through the conductor is thus
	\begin{equation*}
		I = \iint_{S} \j \cdot \diff \vec{S} = \iint_{S} (\j \cdot \uvec{n})\diff S = \sigma_{\text{E}} \int_{0}^{a}E_{z}(r)(2\pi r\diff r).
	\end{equation*}
	
	\item Next, without derivattion, we can write the electric field component $ E_{z} $ in cylindrical coordinates in the form
	\begin{equation*}
		E_{z}(r) \cdot r = \frac{1}{-i\mm \sigma_{\text{E}}\omega} \pdv{r}\left(r \pdv{E_{z}(r)}{r}\right).
	\end{equation*}
	We then subsitute this expression for $ E_{z} $ in the expression for $ I $, which eliminiates the integral and leaves us with
	\begin{equation*}
		I = \frac{2\pi a}{-i\omega \mm}\pdv{E_{z}}{r}\bigg |_{0}^{a} = \frac{2\pi a}{\mm}B_{\phi}(a),
	\end{equation*}
	where the last equality follows from $ \curl \E = - \pdv{\B}{t} $ and $ \pdv{E_{z}}{r} = -i \omega B_{\phi}$.
	
	To summarize: we can express the electric current through the wire in terms of the radial derivative of $ \E $ or in terms of the $ \phi $ component of $ \B $. 
	
%	\item Note also: in electric engineering, we distinguish between weak and strong skin effects, which depend on the frequency $ \omega $. 
\end{itemize}

\newpage

\section{Maxwell's Equations}
\subsection{Charge Conservation and the Continuity Equation}

\begin{itemize}
	\item The Maxwell equations relate the fields $ \E(\r, t) $ and $ \B(\r, t) $ to their sources, which are charges for electric field and currents for magnetic field. More generally, these sources are analyzed in terms of charge density $ \rho(\r, t) $ and current density $ \j(\r, t) $.
	
	\item Note that the fields $ \E $ and $ \B $ are expressed in terms of their divergence and curl. The mathematical background is the Helmholtz decomposition theorem, which states that a vector field is uniquely determined by its divergence and curl, as discussed in the section gauge transformations of the magnetic vector potential.
	
	% The Helmoholtz decomposition is the mathematical basis for why the Maxwell's equations are written in terms of the divergence and curl of $ \E $ and $ \B $. 
	
	\item Interesting interpretation: the Helmholtz theorem (i.e. mathematical theory) tells us that $ \E $ and $ \B $ are fully determined by the expressions
	\[
	\begin{array}{ll}
		\div \E = \text{something} & \quad \div \B = \text{something} \\
		\curl \E = \text{something} & \quad \curl \B = \text{something}.
	\end{array}
	\]
	It is then up to physics to determine what these ``something'' terms are. Determining the ``something'' terms and thus completing the Maxwell equations is the subject of this chapter.
	
\end{itemize}

\subsubsection{Charge Conservation}
\begin{itemize}
	\item We begin by considering a volume $ V $ containing a charge density $ \rho(\r, t) $. In general, the volume can exchange charge with its surroundings, and we encode the flow of charge in and out with current density $ \j $.
	
	\item The total charge $ q $ in the volume $ V $ is
	\begin{equation*}
		q(t) = \iiint_{V}\rho(\r, t)\dr,
	\end{equation*}
	while the change in charge over time is
	\begin{equation*}
		\dv{q}{t} = - \iint_{\partial V} \j(\r, t)\uvec{n}\diff S,
	\end{equation*}
	where $ \uvec{n} $ is the normal to the surface $ \partial V $---we assume $ \uvec{n} $ points out of the region $ V $. The charge's time derivative is then
	\begin{equation*}
		\dv{q}{t} = \pdv{t}\iiint_{V} \rho(\r, t)\dr = \iiint_{V} \pdv{t}\rho(\r, t)\dr \equiv I = - \iint_{\partial V} \j(\r, t)\diff \vec{S}.
	\end{equation*}
	We rewrite the surface integral with the divergence theorem, which produces
	\begin{equation*}
		\pdv{\rho}{t} = - \div \j.
	\end{equation*}
	This important result is the continuity equation. It generalizes the electrostatic relationship $ \div \j = 0 $ to allow for conservation of charge in dynamic situations.
	
    \item The time dependence in the continuity equations allows for the possibility that, as long as $ \pdv{\rho}{t} $ is nonzero, we have $ \div \j \neq 0 $, meaning that current loops are not closed---they could simply end, and charge could accumulate at their ends. 

\end{itemize}


\subsubsection{Displacement Current}
\begin{itemize}
	\item First, we recall the (incomplete) Maxwell equations from the chapter on quasi-static fields:
	\begin{align*}
		&\div \E = \frac{\rho}{\ee} && \div \B = 0\\
		& \curl \E = - \pdv{\B}{t} && \curl \B = \mm \j.
	\end{align*}
	The last equation, $ \curl \B = \mm \j $, is based on the assumption that all current loops are closed. This holds in the quasi-static regime, but violates the continuity equation for more general dynamic situations. To explicitly show this violation, we take the equation's divergence, which produces
	\begin{equation*}
		\mm \div \j = \div (\curl \B) = 0 \implies \div \j = 0,
	\end{equation*}
    where we have used the fact that the divergence of a curl is always zero. 

    \item Evidently, we must generalize the equation $ \curl \B = \mm \j $ if the continuity equation is to hold. We make this generalization by introducing a displacement current. This produces
	\begin{equation*}
		\curl \B = \mm \j + \ee \mm \pdv{\E}{t},
	\end{equation*}
	where $ \ee \mm \pdv{\E}{t} $ is displacement current. The displacement current is created by time-dependent electric fields. 

    Now that we have added the displacement current term, taking the divergence of the last Maxwell equation gives
	\begin{equation*}
		\mm \div \j + \ee \mm \pdv{t}(\div \E) = 0 \implies \div \j = - \pdv{\rho}{t},
	\end{equation*}
	where we've used $ \div \E = \frac{\rho}{\ee} $. This result agrees with the continuity equation, as it must.
	
\end{itemize}

\subsubsection{Maxwell's Equations}
\begin{itemize}
	\item In one place, the complete set of Maxwell's equations is
	\begin{align*}
		& \div \E = \frac{\rho}{\ee} && \div \B = 0\\
		& \curl \E = - \pdv{\B}{t} && \curl \B = \mm \j + \ee \mm \pdv{\E}{t}
	\end{align*}
	The divergence equations relate fields to their sources, while the curl equations (sometimes called the kinematic Maxwell equations) encode the relationship between $ \E $ and $ \B $. These equations completely describe the entirety of classical electromagnetism, and thanks to the introduction of displacement current to the $ \curl \B $ equation, also the continuity equation $ \div \j + \pdv{\rho}{t} = 0 $, meaning the Maxwell equations preserve conservation of charge.
	
	
	\item In the following sections, we will show that Maxwell's equations, in addition to conserving charge, also conserve electromagnetic generalizations of momentum, angular momentum and electromagnetic field energy, as any physically complete theory must.
\end{itemize}

\subsection{Conservation Laws and Maxwell's Equations}

\subsubsection{Conservation of Energy}
\begin{itemize}
	\item We begin with the continuity equation for energy. First, we cross-multiply the third and fourth Maxwell equations, which produces
	\begin{align*}
		& \B \cdot (\curl \E) = - \B \cdot \pdv{\B}{t}\\
		& \E \cdot (\curl \B) = \mm \j \cdot \E + \mm \ee \E \cdot \pdv{\E}{t}.
	\end{align*}
	We then subtract the two equations to get
	\begin{equation*}
		\mm \ee \E \pdv{\E}{t} + \B \pdv{\B}{t} = \E\cdot(\curl \B) - \B\cdot(\curl \E) - \mm \j \E.
	\end{equation*}
	Next, we divide by $ \mm $ and rewrite the right hand side with a reverse-engineered ``divergence product rule'' to get
	\begin{equation*}
		\ee \E \pdv{\E}{t} + \frac{1}{\mm}\B \pdv{\B}{t} = - \frac{1}{\mm}\div(\E\cross\B) - \j \E.
	\end{equation*}
	We now turn our attention to the left hand side, and reverse-engineer the time derivative to get
	\begin{equation*}
		\pdv{t}\left(\frac{\ee}{2} \E^{2} + \frac{1}{2\mm}\B^{2}\right) = - \frac{1}{\mm}\div(\E\cross\B) - \j \E.
	\end{equation*}
	The left hand side is exactly the electromagnetic field energy density $ w $ from earlier sections, which reads
	\begin{equation*}
		w = \frac{\ee}{2} \E^{2} + \frac{1}{2\mm}\B^{2}.
	\end{equation*}
	
	\item In terms of energy density $ w $, the energy continuiuty equation becomes
	\begin{equation*}
		\pdv{w}{t} + \div \S - \j \cdot \E,
	\end{equation*}
    where we have introduced the \Poy vector\footnote{Choosing a good notation for the Poynting vector is somewhat troublesome. The symbol $ \vec{P} $ is used at FMF, but this interferes with both polarization and potentially electric power. I have used the more conventional symbol $ \S $, which can lead to confusion when integrating over vector surface elements $ \diff \vec{S} $. I have tried to mitigate this confusion by always writing the Poynting vector in upright font $ \S $, while surface elements are always italic, as in $ \vec{S} $.}
	\begin{equation*}
		\S \equiv \frac{1}{\mm}\E \cross \B.
	\end{equation*}
	The \Poy vector corresponds to energy current density, i.e. power per unit cross-sectional area or simply intensity. Finally, we note that the term $ \j \cdot \E $ corresponds to Ohmic (dissipative) energy losses, which we showed in the energy dissipation section of the chapter on quasi-static electromagnetic fields.
	
	\item Putting the pieces together, conservation of electromagnetic energy is encoded in the equation
	\begin{equation*}
        \pdv{w}{t} + \div \S + \j \cdot \E = 0.
	\end{equation*}
    In integral form for a region of space $ V $, using the divergence theorem, the equation reads
	\begin{equation*}
		\pdv{t}\iiint_{V}w \dr = - \oiint_{\partial V} \S \cdot \uvec{n} \diff \vec{S} - \iiint_{V} \j \cdot \E \dr.
	\end{equation*}
	Interpretation: in a given volume $ V $, electromagnetic energy changes either because of energy flow through the surface, encoded by $ \S $, or because of dissipative losses inside the volume, encoded by $ \j \cdot \E $. 
\end{itemize}


\subsubsection{Conservation of Momentum and Maxwell's Equations}
\begin{itemize}
	\item Next, we aim to find a continuity equation encoding conservation of momentum. We begin by considering the time derivative
	\begin{equation*}
		\pdv{t}\ee (\E \cross \B).
	\end{equation*}
	Evaluating the derivative with the product rule produces
	\begin{equation*}
		\pdv{t}\ee (\E \cross \B) = \ee \left[\pdv{\E}{t}\cross \B + \E \cross \pdv{\B}{t}\right].
	\end{equation*}
	We then substitute in the third and fourth Maxwell equation to replace the time derivatives, which leads to
	\begin{equation*}
		\pdv{t}\ee (\E \cross \B) = \ee \left[\frac{1}{\ee \mm}(\curl \B)\cross \B - \frac{1}{\ee}\j \cross \B - \E \cross (\curl \E)\right].
	\end{equation*}
	
    \item Next, some vector calculus acrobatics (only quoted and not proven) leads us to the expression
	\begin{equation*}
		\pdv{t}\big[\ee (\E \cross \B)\big] = \grad \left[\ee \E \otimes \E - \frac{1}{2}\ee \E^{2} + \frac{1}{\mm} \B \otimes \B - \frac{1}{2\mm}\B^{2}\right] - \big[\rho \E - \j \cross \B\big].
	\end{equation*}
	The large brackets contain the electromagnetic stress tensor. Meanwhile, the very last term is the electromagnetic (or Lorentz) force density. Note that in general (e.g. from basic mechanics) the time derivative of momentum is force. This implies the quantity $ \ee (\E \cross \B) $ on the left hand side of the equation is some form of momentum.
	
	\item Collected in one place, these terms are:
    \begin{itemize}
        \item electromagnetic momentum $ \vec{p}_{\text{em}} = \ee (\E \cross \B) $,

        \item the electromagnetic stress tensor 
        \begin{equation*}
            \TT_{ik} = \ee \left(E_{i}E_{k} - \frac{1}{2}E^{2}\delta_{ik}\right) + \frac{1}{\mm}\left(B_{i}B_{k} - \frac{1}{2}B^{2}\delta_{ik}\right),
        \end{equation*}
        
        \item and the Lorentz force density $ \vec{f}_{\text{em}} = \rho \E + \j \cross \B $.
    \end{itemize}
	In this notation, the complicated momentum relationship between $ \E $ and $ \B $ becomes
	\begin{equation*}
		\pdv{p_{\text{em}_{i}}}{t} - \pdv{\TT_{ik}}{x_{k}} + f_{\text{em}_{i}} = 0.
	\end{equation*}
	This is the Cauchy continuity equation for electromagnetic momentum---we note that a similar Cauchy equation holds for momentum in other transport situations.
	
	\item In integral form for a volume $ V $ (using the divergence theorem), the momentum continuity equation reads
	\begin{equation*}
		\pdv{t}\iiint_{V}p_{\text{em}_{i}}\dr = \oiint_{\partial V}\TT_{ik}\hat{n}_{k} \diff \vec{S} - \iiint_{V} f_{\text{em}_{i}}\dr.
	\end{equation*}
	Interpretation: electromagnetic momentum in a region of space $ V $ can change because of of momentum flux through the surface (encoded by $ \TT_{\text{ik}} $) and because of the Lorentz force acting on the entire volume (encoded by $ \vec{f}_{\text{em}} $). 
	
%	\item Note: we have just ascribed momentum to a mass-less field, as opposed to a body with mass as in introductory mechanics. Cool!
	
\end{itemize}

\subsubsection{Angular Momentum and Maxwell's Equations}
\begin{itemize}
	\item Next, we aim to find a continuity equation encoding conservation angular momentum. 

    We begin with the just-derived continuity equation for electromagnetic momentum
	\begin{equation*}
		\pdv{p_{\text{em}_{i}}}{t} - \pdv{\TT_{ik}}{x_{k}} + f_{\text{em}_{i}} = 0.
	\end{equation*}
	From basic mechanics, momentum $ \vec{p} $ and angular momentum $ \vec{L} $ are related by $ \vec{L} = \r \cross \vec{p} $. With this relationship in mind, we will try to introduce a cross product into the momentum continuity equation, which will produce an equation for angular momentum.
	
	\item We start by multiplying the momentum continuity equation by $ x_{j} $ to get
	\begin{equation*}
		\pdv{x_{j}p_{\text{em}_{i}}}{t} = x_{j} \pdv{\TT_{ik}}{x_{k}} - x_{j}f_{\text{em}_{i}} = \pdv{x_{k}}(x_{j}\TT_{ik}) - \TT_{ij} - x_{j}f_{\text{em}_{i}}.
	\end{equation*}
	To create a cross product, we then multiply by the Levi-Civita tensor $ \e_{lji}  $ to get
	\begin{equation*}
		\pdv{t}(\e_{lji}x_{j}p_{\text{em}_{i}}) = \pdv{x_{k}}(\e_{lji}x_{j}\TT_{ik}) - \e_{lji}\TT_{ij} - \e_{lji}x_{j}f_{\text{em}_{i}}.
	\end{equation*}
	Note that $ \TT_{ij} $ is symmetric and $ \e_{lji} $ is antisymmetric, so the term $ \e_{lji}\TT_{ij} $ always sums to zero because $ \TT_{ij} = \TT_{ji} $. The quantity $ \e_{lji}x_{j}p_{\text{em}_{i}} $ is now a proper cross product, in component form, of the quantities $ \r $ and $ \vec{p}_{\text{em}} $, and thus corresponds to electromagnetic angular momentum $ \vec{L}_{\text{em}} $.
	
	\item In component form, the terms in the above equation are:
    \begin{itemize}
        \item electromagnetic angular momentum $ L_{\text{em}_{l}} = \e_{lji}x_{j}p_{\text{em}_{i}} $,

        \item and electromagnetic torque density $ m_{\text{em}_{l}} = \e_{lji}x_{j}f_{i} $.
    \end{itemize}
	In terms of $ L_{\text{em}_{l}} $ and $ m_{\text{em}_{l}} $, the continuity equation for electromagnetic angular momentum is
	\begin{equation*}
		\pdv{L_{\text{em}_{l}}}{t} - \pdv{(\e_{lji} x_{j}\TT_{ik})}{x_{k}} + m_{\text{em}_{l}} = 0.
	\end{equation*}
	
	\item In integral form for a region of space $ V $, the continuity equation reads
	\begin{equation*}
		\pdv{t}\iiint_{V} L_{\text{em}_{l}}\dr  = \oiint_{\partial V}\e_{lji}x_{j}\TT_{ik}\hat{n}_{k}\diff \vec{S} - \iiint_{V} m_{\text{em}_{l}}\dr.
	\end{equation*}
	Interpretation: the electromagnetic angular momentum in a region of space can change because of surface flux, encoded by by $ \TT_{ik} $, or because of electromagnetic torque acting on the entire volume, encoded by the electromagnetic torque $ \vec{m}_{\text{em}} $, which results from the Lorentz force.
\end{itemize}

\newpage
\section{Electromagnetic Field in Matter}
In this chapter, we analyze how a material responds to the presence of an external electromagnetic field, and discuss how Maxwell's equations change and why they change. 

\subsection{Electric Field in Matter}

\subsubsection{Bound Charge}
\begin{itemize}
	\item We will consider atoms as a fundamental building block of matter. All atoms carry electrons and protons, so charge is thus present in all matter. Often, the charge cannot move from the atoms or the crystal structure---charge that cannot move is called bound charge and has a generally complex dependence on the material's microscopic structure. 
	
	Free charge can freely move in space---since we have so far only considered Maxwell's equations in free space, the charge we have been working with up to now was free charge. However, the $ \rho $ in Maxwell's equations is technically total charge density---the sum of both bound and free charge. 
	
	\item We define the bound charge in a material as
	\begin{equation*}
		\rho_{\text{b}} = \ev{\sum_{i}q_{i}\delta^{3}(\r - \r_{i})},
	\end{equation*}
    where sum runs over all charges bound in the material's crystal lattice and the brackets denote an average.
	
	The average is calculated over ``hydrodynamic volume''---this allows for a slightly continuous distribution of charge; think of the particles spreading around their delta functions into Gauss functions. The idea of a ``hydrodynamic volume average'' is to allow for microscopic variation around the discrete charge positions in material, which thus allows us to treat bound charge as a continuous quantity. 
	
	\item In terms of bound charge, the first Maxwell equation becomes
	\begin{equation*}
		\div \E (\r, t) = \frac{\rho(\r, t)}{\ee}  = \frac{\rho_{\text{f}}(\r, t)}{\ee} + \frac{\rho_{\text{b}}(\r, t)}{\ee},
	\end{equation*}
	where $ \rho_{\text{f}} $ is free charge. Note that we are treating charge as a continuous quantity, using a charge field, on a macroscopic scale. Keep in mind, however, that charge is fundamentally discrete, and that a field approach can differ to the results of quantum mechanics, where the charges are treated as discrete.
\end{itemize}

\subsubsection{Electric Polarization}
\begin{itemize}
	\item Bound charge and electric polarization are related according to
	\begin{equation*}
		\rho_{\text{b}} = - \div \P.
	\end{equation*}
    We have already discussed this relationship in the electric dipole section of the electrostatics chapter, but at that point we had not yet introduced the concept of bound charge.
	
	\item Substituting the relationship $ \rho_{\text{b}} = - \div \P $ into the Mawell equation
    \begin{equation*}
		\div \E (\r, t) = \frac{\rho_{\text{f}}(\r, t)}{\ee} + \frac{\rho_{\text{b}}(\r, t)}{\ee}
    \end{equation*}
    and rearranging produces the relationship
	\begin{equation*}
		\div (\ee \E + \P) = \rho_{\text{f}}.
	\end{equation*}
	Note that the bound charge is contained in the $ \E $ field. This just-derived relationship motivates the introduction of the $ \D $ field:
	\begin{equation*}
		\D = \ee \E + \P \implies \div \D = \rho_{\text{f}}.
	\end{equation*}
    The $ \D $ field arises only from free charge (as encoded by $ \div \D = \rho_{\text{f}} $), which is encoded within the polarization term $ \P $ (recall that $ \E $ contains bound charge).
\end{itemize}
	
\textbf{Example: Homogeneous Polarization}
\begin{itemize}
	\item As an example, we consider homogeneous polarization $ \P = (0, 0, P_{0}) $ in a long and wide rectangular material whose height, which is much smaller than both the length and width, aligns with the $ z $ axis and varies from $ z = 0 $ to $ z = h $. The bound charge in the material is
	\begin{equation*}
		\rho_{\text{b}} = - \div \P = - \pdv{P_{z}}{z},
	\end{equation*}
    where we have used the material's long and wide geometry to approximate the divergence operator with $ \div \to \pdv{x} $. Since $ \P $ is homogeneous, the derivative is nonzero only at the boundary between material and free space, which leads to
	\begin{equation*}
		\rho_{\text{b}} = - \div \P = - \pdv{P_{z}}{z} = - P_{z}\delta(x) + P_{z}\delta(z - h).
	\end{equation*}
	In other words, the bound charge is confined to the planes at $ z = 0 $ and $ z = h $, i.e. the material's surface. 

    In general, in a material with homogeneous polarization, bound charge occurs only along the boundaries.
\end{itemize}

\subsubsection{The Constitive Relation for Electric Field in Matter}
\begin{itemize}
	\item Polarization in matter depends on the $ \D $ field according to the general relationship
	\begin{equation*}
		\P = \P(\D),
	\end{equation*}
	which we call the constitutive relation. In general, the constitutive relationship is nonlinear and may be quite complicated. However, in an isotropic, homogeneous material, we can expand the relation to first order in $ \D $ to get
	\begin{equation*}
		\P(\D) \approx \chi_{\text{E}} \D + \mathcal{O}(\D^{2}),
	\end{equation*}
    where we have introduced electric susceptibility $ \chi_{\text{E}} $. Electric susceptibility is often defined in terms of relative permittivity $ \epsilon $ (the dielectric constant) via
	\begin{equation*}
        \chi_{\text{E}} = 1 - \frac{1}{\epsilon}.
	\end{equation*}
	
	\item In terms of $ \chi_{\text{E}} $ and $ \epsilon $, the linear constitutive relation reads
	\begin{equation*}
        \D = \ee \E + \P \approx \ee \E + \chi_{\text{E}} \D = \ee \E + \left( 1 - \frac{1}{\epsilon} \right) \D.
	\end{equation*}
	Thus, with a little algebra, the $ \E $ and $ \D $ fields are related to first order by
	\begin{equation*}
        \D = \epsilon \ee \E.
	\end{equation*}
    In terms of the relationship $ \D = \epsilon \ee \E $, the relationship between polarization and the $ \E $ field is
	\begin{equation*}
        \P = \D - \ee \E \approx \ee (\epsilon - 1)\E.
	\end{equation*}
    \textit{Important:} we stress that the relationships between $ \E $, $ \D $ and $ \P $ given in this last bullet point are not general. They hold only for an isotropic, homogeneous material in the regime of a first-order approximation of the constitutive relation $ \P = \P(\D) $.
	
\end{itemize}

\subsubsection{Dielectrics and Conductors}
\begin{itemize}
	\item Dielectric have a finite dielectric constant $ \epsilon $ (also called the dielectric function) and can store electric field energy. In ideal dielectrics, $ \epsilon $ is constant. More generally, the dielectric constant is a function of electric field frequency.
	
	\item Conductors have an infinite value of $ \e $ and shadow (cancel out) external electric fields within their volume. In an external electric field, charge occurs only on the conductor's surface, as discussed in more detail in the section on conductors.
\end{itemize}

\subsection{Magnetic Field in Matter}
\begin{itemize}
	\item As before, we consider the model to be the fundamental building block of matter, and model an atom as a positive nucleus with classically ``orbiting'' electrons, which give rise to the localized microscopic currents. More accurately, we can view microscopic bound currents in material arising from quantum mechanical fluctuations of charge carriers within atoms. In any case, we assume the presence of microscopic currents on an atomic scale within matter. 
	
	\item In the absence of an external magnetic field, these microscopic internal currents have no macroscopic effect---the ``hydrodynamic volume average'' of the bound currents is zero. In the presence of an external magnetic field, however, the microscopic bound currents can give rise to macroscopic effects. 
\end{itemize}

\subsubsection{Bound Currents}
\begin{itemize}
	\item Analogously to our definition of bound charge, we define the bound current density $ \j_{\text{b}} $ in a material as
	\begin{equation*}
		\j_{\text{b}}(\r, t) = \ev{\sum_{i}\j_{i}\delta^{3}(\r - \r_{i})},
	\end{equation*}
    where the sum runs over the positions $ \r_{i} $ of atoms or molecules in the material and the brackets denote a hydrodynamic average, which allows us to treat the bound current density as a continuous quantity (even though on a quantum level the microscopic currents are technically discrete).

    \item Total current density is then the some of free and bound current density, i.e.
    \begin{equation*}
        \j(\r, t) = \j_{\text{f}}(\r, t) + \j_{\text{b}}(\r, t).
    \end{equation*}
    In terms of free and bound current density, the third Maxwell equation becomes
	\begin{equation*}
		\curl \B(\r, t) = \mm \j_{\text{f}}(\r, t) + \mm \j_{\text{b}}(\r, t) + \ee \mm \pdv{\E(\r, t)}{t}.
	\end{equation*}
\end{itemize}

\subsubsection{Magnetization}
\begin{itemize}
    \item We usually analyze bound current in terms of magnetization (analogous to analyzing bound charge in terms of electric polarization). We define magnetization $ \M $ with the relationship
	\begin{equation*}
		\j_{\text{b}} = \curl \M + \pdv{\P}{t}.
	\end{equation*}
	Note that polarization and magnetization are coupled---which means that bound currents depend on the time derivative of $ \P $ as well as on magnetization. 
	
	\item The time derivative of $ \P $ is included in the above relationship between bound current and magnetization to satisfy the continuity equation
    \begin{equation*}
        \div \j_{\text{b}} + \pdv{\rho_{\text{b}}}{t} = 0.
    \end{equation*}
    To show this, we substitute the expression for $ \j_{\text{b}} $ into the continuiuty equation to get
	\begin{equation*}
		\div \j_{\text{b}} + \pdv{\rho_{\text{b}}}{t} = \div (\curl \M) + \div \pdv{\P}{t} - \pdv{\div \P}{t} = 0.
	\end{equation*}
	Since the divergence of a curl quantity is zero, we have $ \div (\curl \M) = 0 $ and thus
    \begin{equation*}
        \div \j_{\text{b}} + \pdv{\rho_{\text{b}}}{t} = 0 + \div \pdv{\P}{t} - \pdv{\div \P}{t} = 0,
    \end{equation*}
    which satisfies the continuity equation $ \div \j_{\text{b}} + \pdv{\rho_{\text{b}}}{t} = 0 $. 
    
	
    \item In terms of bound current and magnetization, the third Maxwell equation (skipping a few steps of algebra) becomes
	\begin{equation*}
		\curl \left(\frac{\B}{\mm} - \M\right) = \j_{\text{f}} + \pdv{\D}{t}.
	\end{equation*}
    This expression motivates the definition of magnetic field strength $ \H $ as
	\begin{equation*}
		\H = \frac{\B}{\mm} - \M \implies \B = \mm (\H + \M).
	\end{equation*}
	Note that $ \H $ arises only from free currents and free charge, analogously to how the $ \D $ field arises from only free charge. In terms of $ \H $, the Maxwell equation reads
	\begin{equation*}
		\curl \H = \j_{\text{f}} + \pdv{\D}{t}.
	\end{equation*}
\end{itemize}
\textbf{Example: Homogeneous Magnetization}
\begin{itemize}
	\item Consider a cuboid of base $ a \cross b $ and height $ h $ with homogeneous magnetization $ \M = (0, 0, M_{0}) $ in the $ z $ direction. 

    The bound current corresponding to this homogeneous magnetization is
	\begin{equation*}
		\j_{\text{b}} = \curl \M + \pdv{\P}{t} = \curl \M + 0 = \left(\pdv{M_{z}}{y}, - \pdv{M_{z}}{x}, 0\right).
	\end{equation*}
	The derivatives are nonzero only at the borders, which produces
	\begin{equation*}
		\j_{\text{b}} = \cdots = \big[M_{0}\delta(y) - M_{0}\delta(y-b), -M_{0}\delta(x) + M_{0}\delta(x - a), 0\big].
	\end{equation*}
	Lesson: the bound currents in a material with homogeneous magnetization occur only on the material's lateral surface enclosing the axis of magnetization. 
	
	The surface currents shadow the magnetic field in the material, analogously to how surface charge shadows electric field in conductors.
\end{itemize}

\subsubsection{The Constitive Relation for Magnetic Field in Matter}
\begin{itemize}
	\item Magnetization depends on external magnetic field $ \H $ according to the general relationship
	\begin{equation*}
		\M = \M(\H),
	\end{equation*}
	which we call the constitutive relation. In general, the constitutive relationship is nonlinear and may be quite complicated. However, in an isotropic, homogeneous material, we can expand the relation to first order in $ \H $ to get
	\begin{equation*}
		\M(\H) \approx \chi_{\text{M}} \H + \mathcal{O}(\H^{2}),
	\end{equation*}
    where we have introduced magnetic susceptibility $ \chi_{\text{M}} $. Magnetic susceptibility is often defined in terms of magnetic permeability $ \mu $ via
	\begin{equation*}
		\chi_{\text{M}} = \mu - 1.
	\end{equation*}
    For most materials $ \chi_{\text{M}} $ is close to zero and $ \mu $ is close to one. Magnetic permeability $ \mu $ is the magnetic analog of relative permittivity $ \epsilon $, i.e. the dielectric constant.
	
	\item In terms of $ \chi_{\text{M}} $ and $ \mu $, the linear constitutive relation reads
	\begin{equation*}
        \H = \frac{\B}{\mm} - \M \approx \frac{\B}{\mm} - \chi_{\text{M}} \H = \frac{\B}{\mm} - (\mu - 1)\H.
	\end{equation*}
	Thus, to first order, the $ \B $ and $ \H $ fields are related by:
	\begin{equation*}
		\H = \frac{\B}{\mu \mm} \implies \B = \mu \mm \H.
	\end{equation*}
    In terms of the relationship $ \B = \mu \mm \H $, the relationship between magnetization and the $ \B $ field is
	\begin{equation*}
		\M = \left(1 - \frac{1}{\mu}\right)\frac{\B}{\mm}.
	\end{equation*}
    \textit{Important:} we stress that the relationships between $ \B $, $ \H $ and $ \M $ given in this last bullet point are not general. They hold only for an isotropic, homogeneous material in the regime of a first-order approximation to the constitutive relation $ \M = \M(\H) $.
	
\end{itemize}

\subsubsection{Magnetization and Magnetic Dipole Density}
\begin{itemize}
	\item Recall that electric polarization corresponds to the volume density of electric dipole moments in a material. In this section, we will derive an analogous relationship between magnetization $ \M $ and density of magnetic dipoles.
	
	\item We begin with Maxwell's equation
	\begin{equation*}
		\curl \B = \mm \j_{\text{f}} + \mm (\curl \M)
	\end{equation*}
	We then introduce magnetic potential via $ \B = \curl \A $ to get
    \begin{equation*}
        \curl \big[ \curl \A \big] = \mm \j_{\text{f}} + \mm (\curl \M),
    \end{equation*}
    and apply the vector calculus identity $ \curl \big[ \curl \A \big] = \grad (\div \A) - \laplacian \A $ to get
    \begin{equation*}
        \grad (\div \A) - \laplacian \A  = \mm \j_{\text{f}} + \mm (\curl \M)
    \end{equation*}
	
	 \item \textbf{TODO:} Sketched derivation: One converts the double curl to divergence of $ \A $, writes the equation for $ \A $, find the solution for $ \A $. Compare the result to the magnetic potential of a magnetic dipole. The result is that $ \M $ is the volume density of magnetic dipole moments in a material.
	
	\item Recall, via the Ampere equivalence relation, that we can consider a magnetic dipole as a circular current loop, so it makes sense that magnetic dipoles are related to magnetization and thus bound electric current density.
	
\end{itemize}


\subsubsection{Classifying Materials By Their Magnetic Field Response}
\begin{itemize}
	\item We classify materials based on the value of their magnetic susceptibility $ \chi_{\text{M}} $. 
	
	\item Ferromagnetic materials have a permanent nonzero magnetization independent of the external magnetic field. However, the magnetization in ferromagnetic materials has a strong temperature dependence, and ferromagnetic materials demagnetize above the so-called Curie temperature (more on this in solid state physics).
	
    \item Diamagnetic materials have a magnetization only in the presence of an external electric field. Typical values of susceptibility are $ \chi_{\text{M}} \lesssim 0 $, i.e. slightly less than zero.
	
	A superconductor is an ideal diamagnetic and has $ \chi_{\text{M}} = -1 $---magnetic field is completely expelled from the material.
	
	\item Paramagnetic materials have $ \mu > 1 $, and an external magnetic field increase the magnetization in the material. Paramagentic materials behave like magnets in an external magnetic field, but demagnetize in the absence of an external field. 
\end{itemize}

\subsection{Maxwell's Equations in Matter}
\begin{itemize}
	\item The complete set of Maxwell's equations in materials is
	\begin{align*}
		& \div \D = \rho_{\text{f}} && \div \B = 0\\
		& \curl \E = - \pdv{\B}{t} &&  \curl \H = \j_{\text{f}} + \pdv{\D}{t}.
	\end{align*}
	Note that to complete the description of electomagnetism in matter, we must also consider the constitutive relationships
    \begin{equation*}
        \P = \P(\D) \qquad \text{and} \qquad \M = \M(\H).
    \end{equation*}
    In isotropic, homogeneous materials, we can expand the constitutive relations to first order in $ \D $ and $ \H $ to produce the relationships
    \begin{equation*}
        \D = \e \ee \E \qquad \text{and} \qquad \B = \mu \mm \H
    \end{equation*}
    between the field flux densitities ($ \D $ and $ \B $) and their strengths ($ \E $ and $ \H $).
	In anisotropic materials, $ \e $ and $ \mu $  generalize to rank-two tensors.
	
\end{itemize}


\subsection{Conservation Laws in Matter}

\subsubsection{Conservation of Energy}
\begin{itemize}
    \item Recall from the chapter on Maxwell's equations (in free space) that electromagnetic energy conservation is encoded by the Poynting theorem
	\begin{equation*}
		\pdv{w}{t} + \div \S  + \j \cdot \E = 0,
	\end{equation*}
	where $ \S $ is the \Poy vector, $ \j \cdot \E $ encodes Ohmic losses, and $ w $ is electromagnetic energy density. This expression still holds in matter, except that we generalize the definition of energy density to
	\begin{equation*}
		w = \int_{0}^{\D} \E(\D') \diff \D' + \int_{0}^{\B}\H(\B')\diff \B',
	\end{equation*}
	and define the \Poy vector as $ \S = \E \cross \H $. Note if we have a linear constitutive relation i.e. $ \E \propto \D $ and $ \H \propto \B $, the expression for $ w $ simplifies to an expression involving quadratic forms, just like for $ w $ in free space.
	
\end{itemize}

\subsubsection{Electric Field Energy in Matter}
\begin{itemize}
    \item We now consider how electric field energy in a region of empty space changes when we place an dielectric material (with $ \epsilon \neq 1 $) in the region.
	
	\item First, using $ W $ to denote electric field energy and letting the subscript zero denote vacuum, we integrate the generalized expression for energy density in matter to get
	\begin{equation*}
        W - W_{0} = \iiint_{V}(w - w_{0})\dr = \iiint_{V} \left[\int \E(\D) \diff \D - \int \E_{0}(\D_{0}) \diff \D_{0} \right] \dr.
	\end{equation*}
	We then assume a linear constitutive relation, which implies
	\begin{equation*}
		\E \propto \D \implies \int \E(\D) \diff \D \propto \frac{\D^{2}}{2}.
	\end{equation*}

    \item Next, we substitute the relation $ \int \E(\D) \diff \D \propto \frac{\D^{2}}{2} $ into the energy difference, move the factor $ 1/2 $ otuside the integral, and rewrite $ \D $ in terms of $ \E $ to get
	\begin{equation*}
		W - W_{0} = \frac{1}{2}\iiint_{V} \E \cdot \D \dr - \frac{1}{2}\iiint_{V}\E_{0}\cdot \D_{0}\dr.
	\end{equation*}
	Next, a trick: using reverse-engineered multiplication, we rewrite the above expression in the algebraically equivalent form
	\begin{equation*}
		W - W_{0} = \frac{1}{2}\iiint_{V}(\E \cdot \D_{0} - \E_{0}\cdot\D)\dr + \frac{1}{2}\iiint_{V}(\E + \E_{0})\cdot (\D - \D_{0})\dr.
	\end{equation*}
    It turns out the second term is zero, which we prove in the following bullet points.

    \item To show the aforementioned second term is zero, we first consider the sum $ \E + \E_{0} $, which we rewrite in terms of electric potential as $ \E + \E_{0} = - \grad \phi $. Using this expression for $ \E $ and some vector calculus acrobatics, the second term becomes
	\begin{align*}
        I & \equiv \frac{1}{2}\iiint_{V}(\E + \E_{0})\cdot (\D - \D_{0})\dr = \frac{1}{2}\iiint_{V} (- \grad \phi)(\D - \D_{0}) \dr \\
        & = -\frac{1}{2}\iiint_{V}\big[\div (\phi \cdot (\D - \D_{0})) - \div (\D - \D_{0})\phi \big]\dr.
	\end{align*}
    Next, recall that the $ \D $ field arises from free charge via $ \div \D = \rho_{\text{f}} $. Since placing a dielectric material into a region of space changes only bound charge and not free charge, the free charge in the region of space is the same before and after filling it with dielectric material, i.e. $ \rho_{\text{f}} = \rho_{\text{f}_{0}}$, which implies $ \div (\D - \D_{0}) = 0 $ and thus
    \begin{equation*}
        I = -\frac{1}{2}\iiint_{V}\div (\phi \cdot (\D - \D_{0}))\dr.
    \end{equation*}
	The remaining term is a divergence integrated over the region of space $ V $ containing the material, which we rewrite with the divergence theorem to get
	\begin{equation*}
        I = -\frac{1}{2}\oiint_{\partial V} \phi \cdot (\D - \D_{0})\diff S.
	\end{equation*}
    But along the region's surface $ \D = \D_{0} $, so we are integrating $ \phi \cdot 0 $ over the surface, which is zero. The result is the quoted expression $ I = 0 $.
	
    \item The difference in electric field energies, using the linear constitutive relation to relate $ \E $ and $ \D $ along with the just-derived result $ I = 0 $, is then
	\begin{align*}
		W - W_{0}  &= \frac{1}{2}\iiint_{V}(\E \cdot \D_{0} - \E_{0}\cdot\D)\dr + 0\\
		& = - \frac{1}{2}\iiint_{V} \ee(\epsilon - 1)\E_{0}\E \dr\\
		& = -\frac{1}{2}\iiint_{V}\P \cdot \E_{0}\dr,
	\end{align*}
	where $ \P $ is the electric polarization in the dielectric material and $ \E_{0} $ is the electric field that would be present in the region of space in the absence of the material.
	
	
	
\end{itemize}


\subsubsection{Magnetic Field Energy in Matter}
\begin{itemize}
	\item The derivation is analogous to the above derivation for electric field energy. We assume a linear constitutive relation for the magnetic field, and use $ W $ to denote magnetic field energy, and write the energy difference $ W - W_{0} $ using an integral of energy density difference $ w - w_{0} $. This reads
	\begin{align*}
        W - W_{0} &= \frac{1}{2}\iiint_{V}(w - w_{0}) \dr = \frac{1}{2} \iiint_{V} \H \cdot \B  \dr - \frac{1}{2}\iiint_{V}\H_{0}\cdot\B_{0}\dr\\
		& = \frac{1}{2}\iiint_{V}\big(\B \H_{0} - \B_{0}\H\big)\dr + \frac{1}{2}\iiint_{V}(\B + \B_{0})\cdot(\H - \H_{0}) \dr.
	\end{align*}
    As for electric energy, the second integral comes out to zero, as derived below.

    \item To show the second integral is zero, we use $ \B + \B_{0} = \curl \A $ and some vector calculus acrobatics to rewrite the second integral in the form
    \begin{align*}
        \mathcal{I} & \equiv \frac{1}{2}\iiint_{V}(\B + \B_{0})\cdot(\H - \H_{0}) \dr = \frac{1}{2}\iiint_{V}\curl \A \cdot (\H - \H_{0}) \dr\\
        & = \frac{1}{2} \iiint_{V} \Big\{ \div \big[ \A \cross (\H - \H_{0}) \big] + \A \cdot \big[ \curl (\H - \H_{0}) \big] \Big \} \dr
    \end{align*}
    If we assume $ \pdv{\D}{t} = 0 $ and that free currents in the region of space do not change after adding the magnetically active material (just like we assumed free charge didn't change when adding a dielectric material), we have $ \curl (\H - \H_{0}) = \j_{\text{f}} - \j_{\text{f}_{0}} = 0 $. 

    The above integral $ \mathcal{I} $ then reduces to
    \begin{equation*}
        \mathcal{I} = \frac{1}{2} \iiint_{V} \Big\{ \div \big[ \A \cross (\H - \H_{0}) \big] \Big \} \dr = \frac{1}{2} \oiint_{\partial V} \big[ \A \cross (\H - \H_{0}) \big] \dr,
    \end{equation*}
    where we have written the second equality with the divergence theorem. Since $ \H = \H_{0} $ on the region's surface $ \partial V $, we have $ \mathcal{I} = 0 $.

    \item The difference in magnetic field energies, using the just-derived result $ \mathcal{I} = 0 $ and the linear constitutive identity $ \B = \mu \mm \H $  and $ \H_{0} = \mu_{0} \H_{0} $ to relate $ \H $ and $ \B $, is
	\begin{align*}
		W - W_{0} &= \frac{1}{2}\iiint_{V}\big(\B \H_{0} - \B_{0}\H\big)\dr \\
        & = \frac{1}{2} \iiint_{V}\mm (\mu - 1)\H_{0}\H\dr\\
		& = \frac{1}{2}\iiint_{V}\M \cdot \B_{0}\dr.
	\end{align*}
	Lesson: the change in magnetic field energy that results from placing a magnetically active material in empty space permeated by the magnetic field $ \B_{0} $ is proportional to the original field $ \B_{0} $ and the magnetization $ \M $ induced in the magnetically active material. Keep in mind that this result holds only for a linear constitutive relation.
\end{itemize}

\subsubsection{Electromagnetic Momentum Conservation in Matter}
\begin{itemize}
	\item We now turn our attention to electromagnetic momentum conservation in matter. We begin with the continuity equation for electromagnetic momentum, assume a linear constitutive relation, and write electromagnetic momentum density as
	\begin{equation*}
		\vec{p}_{\text{em}} = \D \cross \B.
	\end{equation*}
	Recall that in free space we had defined EM momentum as $ \vec{p}_{\text{em}} = \ee \E \cross \B $.
	
	\item In terms of the $ \D $ field, the Cauchy continuity equation in matter reads
	\begin{equation*}
		\pdv{p_{\text{em}_{i}}}{t} - \pdv{\TT_{ik}}{x_{k}} + f_{\text{em}_{i}} = 0,
	\end{equation*}
	where $ f_{\text{em}_{i}} $ is electromagnetic force density and $ \TT_{ik} $ is the electromagnetic stress tensor, which is defined in matter as
	\begin{equation*}
		\TT_{ik} = E_{i}D_{k} - \frac{1}{2}(\D \cdot \E)\delta_{ik} + B_{i}H_{i} - \frac{1}{2}(\B \cdot \H)\delta _{ik}
	\end{equation*}
	
	\item \textbf{Note:} For a general constitutive relation, the expression $ \pdv{\vec{p}_{\text{em}} }{t} $ cannot be written in terms of a divergence of a vector field. As a result, it becomes impossible to write the surface term involving $ \TT_{\text{ik}} $ in closed form. As a result, the electromagnetic stress tensor does not generally exist (we don't know how to write it) for a general constitutive relation.
	
	Physical interpretation: the stress tensor is related to the expression for the force on a body in terms of a field on the body's surface. If we can't write the stress tensor, it means the expression for force involves interactions within the body's volume than cannot be written as surface interactions.
	
\end{itemize}


\subsection{Force on a Nonhomogeneous Material in an Electromagnetic Field}

\subsubsection{Nonhomogeneous Material in an Electric Field}
\begin{itemize}
	\item In a nonhomogeneous material, $ \e = \e(\r) $ and $ \mu = \mu(\r) $ vary throughout the material. In this section, we consider how such a material reacts to the presence of an electromagnetic field field.
	
	\item If we move the material within the field, the value of $ \e $ and $ \mu $ change relative to the field $ \E $ and $ \B $, so the electromagnetic force on the material changes. We consider only the electric field in this section, and then consider the magnetic field in the following section.

    \item Assuming we can assign the field an electrostatic stress tensor, the electric force on the material can be written in terms of the tensor as
	\begin{equation*}
		F_{\text{E}_{i}} = \iiint_{V}\pdv{\TT_{ik}}{x_{k}} \dr.
	\end{equation*}
	
	\item First, we consider the electrostatic term
	\begin{equation*}
		\pdv{\TT_{ik}}{x_{k}} = \pdv{x_{k}} \left[ E_{i}D_{k} - \frac{1}{2}(\E \cdot \D) \delta_{ik}\right].
	\end{equation*}
    We then recall $ \e = \e(\r) $ and assume a linear constitutive relation $ \D = \e \ee \E $, which leads to 
	\begin{equation*}
		\pdv{\TT_{ik}}{x_{k}} = E_{i}\pdv{D_{k}}{x_{k}} + E_{k}\pdv{D_{i}}{x_{k}} - \frac{1}{2}\pdv{\e}{x_{i}}\ee E^{2} - \frac{1}{2}\e \ee \pdv{E^{2}}{x_{i}}.
	\end{equation*}
	Next, we rewrite the term $ \pdv{E^{2}}{x_{i}} $ according to
	\begin{equation*}
		\frac{1}{2}\grad E^{2} = \E \cross (\curl \E) + (\E \cdot \grad)\E,
	\end{equation*}
	which leads to a vector expression for electric force:
	\begin{align*}
		\vec{F}_{\text{E}} = &\iiint_{V}\left[\E (\div \D) + (\E \cdot \grad )\D - \D \cross (\curl \E) - (\E \cdot \grad )\D\right] \dr\\
		& - \frac{1}{2}\iiint_{V}(\grad \e(\r))\ee E^{2}\dr.
	\end{align*}
	
	\item Next, we consider a simplified case of the above result. We make two assumptions:
    \begin{enumerate}
        \item We assume that $ \div \D \approx 0 $, which corresponds to working in the absence of appreciable free charge (recall $ \div \D \equiv \rho_{\text{f}} $). The approximation $ \div \D \approx 0 $ often gives satisfactory results, but is of course not valid in general.
        
        \item We also assume $ \curl \E = 0 $, which corresponds to working in a system without induction, i.e. in the absence of a time-varying magnetic field (recall the relationship $ \curl \E = - \pdv{\B}{t} $).
    \end{enumerate}
    Under these assumptions, the first integral vanishes and the force on the nonhomogeneous dielectric simplifies to
	\begin{equation*}
		\vec{F}_{\text{E}} = - \frac{1}{2}\iiint_{V}(\grad \e(\r))\ee E^{2}\dr.
	\end{equation*}
	In other words, $ \vec{F} $ at a given point depends on the gradient of $ \e $. 
	
	
\end{itemize}

\textbf{TODO: Force on a Nonhomogeneous Magnetic Material}
\begin{itemize}
    \item The analysis of the magnetic force on a nonhomogeneous material with $ \mu = \mu(\r) $ is analogous to the above derivation for electric force on a material with $ \e = \e(\r) $, so we only briefly skecthed it in lecture. The procedure reads: assume a linear constitutive relation $ \H = \mu \mm \B $ and write the magnetic stress-energy tensor in component form. Write the term $ \pdv[2]{B}{x_{i}} $ and magnetic force in vector form. Assume $ \curl \H = 0 $ (absence of free currents) and use $ \div \B = 0 $ to get
	\begin{equation*}
		\vec{F}_{\text{M}} = -\frac{1}{2}\iiint_{V} (\grad \mu(\r))\mm H^{2}\dr.
	\end{equation*}
\end{itemize}


\subsection{Boundary Conditions For Maxwell's Equations}
Consider a boundary between two materials with different electromagnetic properties, i.e. different values of $ \epsilon $ and $ \mu $, where each material is assigned a surface normal vector $ \uvec{n} $ point into the material. Our goal in this section is to find the appropriate boundary conditions on the $ \E $, $ \D $, $ \H $, and $ \B $ fields at the interface between the two materials.

\subsubsection{Boundary Condition for the \textit{B} Field}
\begin{itemize}
	\item Let the magnetic field in the first and second materials be $ \B_{1} $ and $ \B_{2} $, respectively. We begin with the Maxwell equation
	\begin{equation*}
        \div \B = 0 \implies \iiint_{V} \div \B \dr = 0,
	\end{equation*}
	which must hold for any region of space $ V $. 
	
	
    \item We then consider a cylinder of infinitesimal height $ \diff \vec{l} $ just enclosing the boundary between the two materials (a so-called Gaussian pillbox). We integrate over the cylindrical volume to get
	\begin{align*}
        0 & \equiv \iiint_{V} \div \B \dr = \oiint_{\partial V} \B \cdot \diff \vec{S}  \\
        & = \iint_{S_{1}}\B_{1}\cdot \uvec{n}_{1}\diff S + \iint_{S_{2}}\B_{2}\cdot \uvec{n}_{2}\diff S + \iint_{S_{3}}\B_{3}\cdot \uvec{n}\diff S,
	\end{align*}
	where $ S_{3} $ is the cylinder's lateral surface area. 

    \item We send the cylinder height $ \diff \vec{l} $ to zero, since we're interested only in the boundary between the two materials. The third integral over the lateral surface area vanishes in the limit $ \diff \vec{l} \to 0 $, leaving
	\begin{equation*}
		\iint_{S_{1}}\B_{1}\cdot \uvec{n}_{1}\diff S + \iint_{S_{2}}\B_{2}\cdot \uvec{n}_{2}\diff S = 0.
	\end{equation*}
    At the boundary, the $ \B $ field thus obeys the relationship
	\begin{equation*}
        \B_{1} \cdot \uvec{n}_{1} + \B_{2} \cdot \uvec{n}_{2} = 0 \implies B_{1}^{\perp} - B_{2}^{\perp} = 0,
	\end{equation*}
    where $ B^{\perp} $ denotes the magnetic field component perpendicular to the surface. Note the change in sign of the component expression relative to the vector expression, which occurs because the normal vector $ \uvec{n}_{1} $ points in the opposite direction as $ \uvec{n}_{2} $.
	
	
\end{itemize}

\subsubsection{Boundary Condition for the \textit{D} Field}
\begin{itemize}
	\item We consider the same interface between two materials as before and let $ \D_{1} $ and $ \D_{2} $ denote the $ \D $ fields in the first and second material, respectively. We now base our analysis on the Maxwell equation
	\begin{equation*}
		\div \D = \rho_{\text{f}}.
	\end{equation*}
	
	\item As before, we consider a cylinder with infinitesimal height $ \diff \uvec{l} $ enclosing the boundary between the two materials. In integral form, the Maxwell equation reads
	\begin{equation*}
		\iiint_{V} \div \D \dr = \iiint_{V}\rho_{\text{f}}\dr.
	\end{equation*}
	We use the divergence theorem to write the left-hand integral as an integral over the cylinder surface, which gives
    \begin{equation*}
        \iiint_{V} \rho_{\text{f}} \dr = \oiint_{\partial V} \D \cdot \diff \vec{S} = \iint_{S_{1}}\D_{1} \cdot \uvec{n}_{1}\diff S +  \iint_{S_{2}}\D_{2} \cdot \uvec{n}_{2}\diff S +  \iint_{S_{3}}\D_{3} \cdot \uvec{n}\diff S,
    \end{equation*}
	where $ S_{3} $ again denotes the cylinder's lateral surface area. 
    
    \item We then send the cylinder height to zero, in which case the integral $ \iiint_{V}\rho_{\text{f}}\dr $ becomes a surface integral over the cylinder's cross-sectional area and the volume charge density $ \rho_{\text{f}} $ approaches the surface charge density $ \sigma_{\text{f}} $, leaving us with
	\begin{equation*}
		 \iint_{S_{1}}\D_{1} \cdot \uvec{n}_{1}\diff S +  \iint_{S_{2}}\D_{2} \cdot \uvec{n}_{2}\diff S = \iint_{S}\sigma_{\text{f}} \diff S.
	\end{equation*}
    Along the boundary between the materials, the $ \D $ field must thus obey
	\begin{equation*}
        D_{1}^{\perp} - D_{2}^{\perp} = \sigma_{\text{f}}.
	\end{equation*}
	
\end{itemize}

\subsubsection{Boundary Condition for the \textit{E} Field}
\begin{itemize}
	\item We now consider the boundary between two materials with electric fields $ \E_{1} $ and $ \E_{2} $, respectively. This time around, we use the Maxwell equation
	\begin{equation*}
		\curl \E = - \pdv{\B}{t}.
	\end{equation*}
	We then integrate this equation over the boundary and apply Stoke's theorem to get
	\begin{equation*}
        - \pdv{t}\iint_{S}\B \cdot \diff \vec{S} = \iint_{S} \curl \E \cdot \diff \vec{S} = \oint_{\partial S} \E \cdot \diff \vec{s},
	\end{equation*}
    where $ S $ is a rectangular surface of length $ l $ and height $ h $ whose boundary $ \partial S $ encloses the interface between the two materials. The loop's length runs parallel to the interface while the height is perpendicular to the interface, so that decreasing the height $ \diff h $ causes the loop to approach the interface between the materials. The tangents to the loop (along its lengths) are $ \uvec{t}_{1} = - \uvec{t}_{2} $ in the two regions, respectively. 
    
    \item Next, we split the closed line integral over the rectangular surface's boundary $ \partial S $ into integrals over the loop's length and height to get
    \begin{equation*}
        - \pdv{t}\iint_{S}\B \cdot \diff \vec{S} = \int_{l_{1}}\E \cdot \diff \vec{l} + \int_{l_{2}}\E \cdot \diff \vec{l} + \int_{h_{1}}\E \cdot \diff \vec{h} + \int_{h_{2}}\E \cdot \diff \vec{h}.
    \end{equation*}
    We then send the surface's height to zero, i.e. $ \diff h \to 0 $, in which case the integrals over height vanish, leaving us with
    \begin{align*}
        - \pdv{t}\iint_{S}\B \cdot \diff \vec{S} &= \int_{l_{1}}\E \cdot \diff \vec{l} + \int_{l_{2}}\E \cdot \diff \vec{l} + 0 + 0\\
        & = \int_{l} (\E_{1}\cdot \uvec{t}_{1} + \E_{2}\cdot \uvec{t}_{2}) \diff l,
    \end{align*}
    where we have written the line elements in terms of the tangent vectors $ \uvec{t}_{1} $ and $ \uvec{t}_{2} $. However, we can write the surface element $ \diff S $ in the form $ \diff S = \diff l \diff h $, which shows that $ \diff S $ also vanishes\footnote{The fact that the surface integral vanishes should make intuitive sense; as $ \diff h \to 0 $ the rectangle approaches a line and there is no surface left to integrate over!} in the limit $ \diff h \to 0 $, leaving us with
    \begin{equation*}
        \int_{l} (\E_{1}\cdot \uvec{t}_{1} + \E_{2}\cdot \uvec{t}_{2}) \diff l.
    \end{equation*}
    It follows that at the boundary between the two materials, the $ \E $ field must obey
    \begin{equation*}
        E_{1}^{\parallel} - E_{2}^{\parallel} = 0,
    \end{equation*}
    where $ E^{\parallel} $ denotes the component of the electric field parallel to the boundary between the two materials. Alternatively, in terms of the normal to the surface, we can write the above condition as
	\begin{equation*}
		(\uvec{n}_{1} \cross \E_{1}) - (\uvec{n}_{2}\cross \E_{2}) = 0.
	\end{equation*}
	This expression is useful, since the normal to the material interface is always well-defined, while the tangent is more ambiguous.

\end{itemize}

\subsubsection{Boundary Condition for the \textit{H} Field}
\begin{itemize}
	\item We now consider an interface between two materials with $ \H $ fields $ \H_{1} $ and $ \H_{2} $, and base our analysis on the Maxwell equation
	\begin{equation*}
		\curl \H = \j + \pdv{\D}{t}.
	\end{equation*}
	In an analogous procedure as for $ \E $, we introduce a small planar surface $ S $ in the interface between the two materials with height $ h $ perpendicular to the interface and length $ l $, defined by the tangent vectors $ \uvec{t}_{1} $ and $ \uvec{t}_{2} $, parallel to the interface.
	
	\item Using Stokes' theorem, the integral of the above Maxwell equation is
    \begin{equation*}
        \iint_{S} \j \cdot \diff \vec{S} + \pdv{t} \iint_{S} \D \cdot \diff \vec{S} = \iint_{S} \curl \H \cdot \diff \vec{S} = \oint_{\partial S} \H \cdot \diff \vec{s}.
	\end{equation*}

    \item We then perform a geometrically identical procedure as in the analysis of the $ \E $ field boundary condition, in which we send the loop height to zero, i.e. $ \diff h \to 0 $ and thus $ \diff S = \diff l \diff h \to 0 $. In this case, the $ \D $-dependent term vanishes, while the line integral over $ \partial S $ keeps only the portions over the loop's length, leaving us with
	\begin{equation*}
        \iint_{S} \j \cdot \diff \vec{S} = \iint_{S} \j \cdot \uvec{e} \diff S = \int (\H \cdot \uvec{t}_{1} + \H_{2}\cdot \uvec{t}_{2}) \diff l.
	\end{equation*}
    
    \item Note that we have kept the surface integral containing $ \j $. The integrand contains $ \j \cdot \uvec{e} $, i.e. the component of $ \j $ parallel to the normal of the Stokes' theorem-derived integration surface $ \uvec{S} $. Keep in mind that $ \uvec{e} $ is normal to the vectors $ \uvec{n}_{1} $ and $ \uvec{n}_{2} $, which are the normal vectors to the interface between the two materials.

    \item As $ \diff h \to 0 $, the current density $ \j $ aligns with $ \uvec{n}_{S} $, and represents a ``surface current density'' with units $ \si{\ampere \, \meter^{-1}} $, which we will denote $ \vec{k} $; the direction of $ \vec{k} $ is determined by the right hand rule in the direction of the tangent vectors $ \uvec{t}_{1} $ and $ \uvec{t}_{1} $ round the loop. In terms of $ \vec{k} $ in the limit $ \diff h \to 0 $, the integral of $ \j $ over the surface becomes
    \begin{equation*}
        \iint_{S} \j \cdot \uvec{e} \diff S \to \int \vec{k} \cdot \diff \vec{l},
    \end{equation*}
    which produces the relationship
    \begin{equation*}
        \int \vec{k} \cdot \diff \vec{l} = \int (\H \cdot \uvec{t}_{1} + \H_{2}\cdot \uvec{t}_{2}) \diff l.
    \end{equation*}
    Thus, at the interface between the two materials, the $ \H $ field obeys the condition 
	\begin{equation*}
        H_{1}^{\parallel} - H_{1}^{\parallel} = k,
	\end{equation*}
    where $ k $ is the magnitude of the surface current density. Alternatively, in terms of the normal vectors to the materials, the boundary condition reads
	\begin{equation*}
        (\uvec{n}_{1} \cross \H_{1}) - (\uvec{n}_{2}\cross \H_{2}) = \vec{k}, \qquad \uvec{k} = k \uvec{e}.
	\end{equation*}
\end{itemize}

\newpage
\section{Frequency Dependence of the Dielectric Function}
As mentioned in the previous chapter, the dielectric function is generally a function of frequency, $ \epsilon = \epsilon(\omega) $. As a side note, although it is really a subject of optics, we mention that the dielectric function and index of refraction in matter are related according to
\begin{equation*}
    \epsilon = \epsilon(\omega) \qquad \text{and} \qquad \epsilon(\omega) = n^{2}(\omega)
\end{equation*}

    
\subsection{Frequency-Dependent Dielectric Function}
\begin{itemize}
    \item So far, we have analyzed electromagnetism exclusively in the time domain. To analyze the dielectric fucntion's frequency dependence, it is naturally more convient to work in the frequency domain---we transform between time and frequency space with the Fourier transform. 

    \item We begin by assuming a linear constitutive relation, which gives us the time-domain relationship
    \begin{equation*}
        \D(\r, t) = \epsilon(t)\epsilon_{0} \E(\r, t).
    \end{equation*}
    We then Fourier-transform this relationship to the frequency domain to get
    \begin{equation*}
        \D(\r, \omega) = \epsilon(\omega)\epsilon_{0}\E(\r, \omega).
    \end{equation*}
    Note that, under the Fourier transform, $ \epsilon(\omega) $ is a complex number, and the real and imaginary components both have important implications for the behavior of electromagnetic waves in matter.

    \item The real component $ \Re(\epsilon) $ is associated with reflection and refraction and encodes the classical index of refraction, as in the context of the law of refraction. Meanwhile, the imaginary component $ \Im(\epsilon) $ encodes the absorption of electromagnetic waves in the material---a large imaginary component corresponds to high absorption. 

            
\end{itemize}

\subsection{Kramers-Kronig Relations}
\begin{itemize}
    \item The Kramers-Kronig relations relate the real and imaginary components of $ \epsilon $. In other words, if one knows one component of $ \epsilon $, one can then use the Kramers-Kronig relations to find the other component.

    \item Without derivation, the Kramers-Kronig relations read:
    \begin{align*}
        & \Re \big[\epsilon(\omega)\big ] = 1 + \frac{2}{\pi} \mathcal{P} \int_{0}^{\infty} \frac{\omega' \Im \big[ \epsilon(\omega') \big]}{\omega'^{2} - \omega^{2}} \diff \omega'\\
        & \Im \big[ \epsilon(\omega) \big] = - \frac{2\omega}{\pi} \mathcal{P} \int_{0}^{\infty} \frac{ \Re \big[ \epsilon(\omega')  \big]- 1}{\omega'^{2} - \omega^{2}} \diff \omega'.
    \end{align*}
    Note that the real and imaginary components of $ \epsilon $ are coupled, and that each component is given in terms of an integral of the other component.

    The symbol $ \mathcal{P} $ denotes the integral's Cauchy principle value and is defined as 
    \begin{equation*}
        \mathcal{P}\int_{-\infty}^{\infty} \frac{g(\omega')}{\omega' - \omega} \diff \omega' = \lim_{\epsilon \to 0} \left[ \int_{-\infty}^{\omega-\epsilon} \frac{g(\omega')}{\omega'-\omega}\diff \omega' + \int_{\omega+\epsilon}^{\infty} \frac{g(\omega')}{\omega'-\omega}\diff \omega' \right].
    \end{equation*}
    Put simply, the principle value is a way to avoid the pole in the left-hand integral at $ \omega' = \omega $. We note in passing that the Kramers-Kronig relations are derived from the definition of the Cauchy principle value, followed by Hilbert transforms, followed by the Plemelj equations, but this is beyond the scope of this course.

\end{itemize}

\subsection{Dissipation of Electromagnetic Energy and the Imaginary Dielectric Component}
\begin{itemize}
    \item As long as a material has nonzero $ \Im(\epsilon) $, then electromagnetic energy dissipates when passing through the material.

    \item We begin our analysis by writing the complex number $ \epsilon $ in terms of amplitude and phase, in which case the relationship $ \D = \epsilon \ee \E $ implies that a nonzero imaginary component $ \Im \epsilon \neq 0 $ results in the $ \E $ and $ \D $ fields falling out of phase in matter.

    \item We will consider only the electric component of electromagnetic energy density. Neglecting the magnetic component is generally acceptable because $ \epsilon $ tends to vary with frequency across multiple order of magnitude, while $ \mu $ tends to be of order one. As a result, only $ \epsilon $ and thus electric energy vary appreciably with frequency.

    \item Assuming a linear constitutive relation, the EM power density in material is
    \begin{equation*}
        \pdv{w}{t} = \E \pdv{\D}{t}.
    \end{equation*}
    We then integrate the above expression to get the change in energy over time:
    \begin{equation*}
        w(2) - w(1) = \int_{t_{1}}^{t_{2}} \pdv{w}{t}\diff t = \int_{t_{1}}^{t_{2}} \E \pdv{\D}{t} \diff t.
    \end{equation*}
    
    \item Next, we Fourier-transform $ \E $ and $ \D $ to the frequency domains to get
    \begin{equation*}
        \E(t) = \frac{1}{2\pi} \int \E(\omega) e^{-i\omega t} \diff \omega \qquad \text{and} \qquad \D(t) = \frac{1}{2\pi} \int \D(\omega) e^{-i\omega t} \diff \omega.
    \end{equation*}
    We then substitute these transformations into the energy difference and evaluate the derivative of $ \D $, which produces
    \begin{align*}
        w(2) - w(1) = \frac{1}{(2\pi)^{2}}\int_{t_{1}}^{t_{2}} \left[ \int \E(\omega)e^{-i\omega t} \diff \omega \cdot \int -i \omega' \D(\omega')e^{-i\omega't} \diff \omega' \right] \diff t.
    \end{align*}
    Next, we substitute in the linear constitutive relation
    \begin{equation*}
        \D(\omega') = \epsilon(\omega')\ee \E(\omega'),
    \end{equation*}
    which leads to
    \begin{equation*}
        w(2) - w(1) = \frac{\ee}{(2\pi)^{2}} \int \E(\omega) \diff \omega \int  (-i\omega')\epsilon(\omega')\E(\omega') \diff \omega' \int_{t_{1}}^{t_{2}} e^{-i(\omega + \omega')t} \diff t.
    \end{equation*}
    
    \item Next, we send the integration limits of the time integral to $ t_{1, 2} \to \pm \infty $, in which case the time integral becomes the delta function $ 2\pi \delta(\omega + \omega') $, leaving
    \begin{equation*}
        w(2) - w(1) = \frac{\ee}{2\pi} \int \E(\omega) \diff \omega \int  (-i\omega')\epsilon(\omega')\E(\omega') \diff \omega' \delta(\omega + \omega').
    \end{equation*}
    Sketched derivation from here forward: the presence of the delta function means the frequency integrals give non-zerp contributions only when $ \omega = \omega' $. Combining this fact with the complex number identity $ i\epsilon(-\omega) - i \epsilon(\omega) = 2\Im \epsilon(\omega)$ leads to
    \begin{equation*}
        w(2) - w(1) = \frac{\ee}{2\pi} \int \omega \Im \epsilon(\omega) \big |\E(\omega)\big |^{2}  \diff \omega.
    \end{equation*}
    Finally, we integrate over volume to get electric energy from energy density, and write the $ \E $ field's position dependence explicitly to get
    \begin{equation*}
        W(2) - W(1) = \frac{\ee}{2\pi} \int \omega \Im \epsilon(\omega) \diff \omega \iiint_{V} \big |\E(\r, \omega)\big |^{2} \dr.
    \end{equation*}
    This is the desired end result for the change in electromagnetic energy as it passes through material over the course of two distance times $ t_{1,2} \to \pm \infty $.

    Interpretation: if $ \Im(\epsilon) \neq 0 $, then electromagnetic energy in a material dissipates with time, and the dissipation is proportional to $ \Im(\epsilon) $.

\end{itemize}
    
\subsection{Basic Models for the Dielectric Constant's Frequency Dependence}

\subsubsection{Equation of Motion for Bound Charge}
\begin{itemize}
    % \item Recall that we have bound charge in a dielectric; these charges are bound to a crystal lattice. We will consider only a classical model. 

    \item We begin with a simple, classical equation of motion for a bound charge $ q $, in which reads
    \begin{equation*}
        m \dv[2]{\r}{t} = - m \omega_{0}^{2}\r - m\gamma \dot{\r} + q\E(t),
    \end{equation*}
    where $ \r $ is the charge's position. The charge is bound within the dielectric's crystal lattice by a harmonic potential encoded by the harmonic frequency $ \omega_{0} $, and the second term encodes a velocity-dependent dissipative force. 

    \item We then take the Fourier transform of the equation of motion. The time derivatives in Fourier space simplify to multiplication by $ i\omega $, and the result is
    \begin{align*}
        -m\omega^{2}\r(\omega) &= - m\omega_{0}^{2}\r(\omega) + i\omega\gamma\r(\omega) + q\E(\omega),\\
        \r(\omega) &= \frac{q}{m} \frac{\E(\omega)}{(\omega_{0}^{2} - \omega^{2}) - i \gamma\omega}.
    \end{align*}
    Note that this function takes the shape of a resonance curve. 

    \item We now want to derive an expression for $ \epsilon $, and begin by introducing polarization
    \begin{equation*}
        \P(\omega) = nq\r(\omega),
    \end{equation*}
    where $ n $ is the volume charge density of electric dipoles contributing to the polarization. We then substitute the earlier expression for $ \r(\omega) $ into the expression for polarization, which gives
    \begin{equation*}
        \P(\omega) = \frac{q^{2}n}{m} \frac{\E(\omega)}{\omega_{0}^{2} - \omega^{2} - i \gamma \omega}.
    \end{equation*}
    Finally, we use $ \P(\omega) = \ee \big[ \epsilon(\omega)-1 \big]\E(\omega) $ to get the desired relationship for $ \epsilon $,
    \begin{equation*}
        \ee \big[ \epsilon(\omega) -1 \big] = \frac{q^{2}n}{m} \frac{1}{\omega_{0}^{2} - \omega^{2} - i\gamma\omega}. 
    \end{equation*}
    Again, we note that $ \epsilon(\omega) $ has resonance behavior. The resonance frequency $ \omega_{0} $ is determined by the nature of the harmonic potential binding the bound charges.
    
    \item We often work with the above expression for $ \epsilon $ in one of three limit cases, which are called:
    \begin{itemize}
        \item Debye relaxation,

        \item Lorentz relaxation,

        \item and plasma relaxation.
    \end{itemize}
    Since electromagnetic frequencies vary over many orders of magnitude, it makes sense that we might have different dissipative and binding mechanism at different frequencies. We note also that in real materials, we often have multiple sources of harmonic-like potentials, which results in multiple eigenfrequencies $ \omega_{0_{i}} $ and multiple modes of dissipation (multiple $ \gamma_{i} $).

    
\end{itemize}

\subsubsection{Debye Relaxation}
\begin{itemize}
    \item Debye relaxation is relevant at low frequencies, e.g. in the range $ \omega \sim $ \SIrange{e7}{e9}{\hertz}, and is commonly used to model the relaxation of electric dipoles in matter.

    At low frequencies we can neglect the term proportional to $ \omega^{2} $, which case the expression for polarization simplifies to
    \begin{equation*}
        \P(\omega) = \frac{q^{2}n}{m\omega_{0}^{2}} \frac{\E(\omega)}{1 - i\omega\tau},
    \end{equation*}
    where the Debye relaxation time $ \tau $ is defined as $ \tau = \frac{\gamma}{\omega_{0}^{2}} $.
    
    \item Using this expression for polarization, the dielectric constant in the Debye regime is
    \begin{equation*}
        \epsilon(\omega) = 1 + \frac{(\epsilon(0) -1)(1 + i\omega\tau)}{1 + \omega^{2}\tau^{2}},
    \end{equation*}
    where $ \epsilon(0) $ is the dielectric constant at $ \omega = 0 $ and we have assumed the relationship
    \begin{equation*}
        \ee \big[ \epsilon(0) -1 \big] = \frac{q^{2}n}{m\omega_{0}^{2}}.
    \end{equation*}
    The real component of $ \epsilon $ decays to 0 at large frequencies in a sort of half-sigmoid curve. The imaginary component grows to a maximum and then falls to zero at large frequencies.
\end{itemize}

\subsubsection{Lorentz Relaxation}
\begin{itemize}
    \item The Lorentz regime is not an approximation at all---it accounts for all frequency terms in the general expression for $ \epsilon(\omega) $. Lorentz relaxation applies to frequencies in the range \SIrange{e12}{e16}{\hertz}, which includes the range of visible light, and is used, for example, to model the oscillation of molecules. 

    \item In the regime of Lorentz relaxation, polarization retains the general expression
    \begin{equation*}
        \P(\omega) = \frac{q^{2}n}{m} \frac{\E(\omega)}{(\omega_{0}^{2} - \omega^{2}) - i \gamma \omega},
    \end{equation*}
    while the corresponding dielectric function is given by the relationship
    \begin{equation*}
        \ee \big[ \epsilon(\omega) - 1 \big] = \frac{q^{2}n}{m}\frac{1}{\omega_{0}^{2} - \omega^{2} - i \gamma\omega}.
    \end{equation*}
    In terms of the dielectric constant at $ \omega = 0 $, the dielectric function reads
    \begin{equation*}
         \epsilon(\omega) = 1 + \frac{ \big[ \epsilon(0) - 1 \big]\omega_{0}^{2}}{\omega_{0}^{2} - \omega^{2} - i \gamma\omega}.
    \end{equation*}
    The real component has two extrema and a node at the resonance frequency; in general form, it resembles the first excited quantum state of a finite potential well, although the functional dependence is of course different.

    The imaginary component has a single extrema at the resonance frequency, and decays to zero at $ \omega \to \pm \infty $. 

\end{itemize}

\subsubsection{Plasma Relaxation}
\begin{itemize}
    \item Plasma relaxation applies to very high frequencies, where we can neglect all $ \omega $-dependent terms in the equation of motion except the accelerating electric force.

    \item In the plasma regime, the polarization reads
    \begin{equation*}
        \P(\omega) = - \frac{q^{2}n}{m} \frac{\E(\omega)}{\omega^{2}},
    \end{equation*}
    and the corresponding dielectric constant is
    \begin{equation*}
        \epsilon(\omega) = 1 - \frac{\omega_{\text{p}}^{2}}{\omega^{2}} \qquad \text{where} \qquad \omega_{\text{p}} = \frac{nq^{2}}{m\epsilon_{0}}. 
    \end{equation*}
    
    \item The plasma model corresponds to electrons behaving as free particles in material, and begins to apply at frequencies approximately greater than \SI{e16}{\hertz}.
\end{itemize}

\subsubsection{Example: Dielectric Function in Water}
\begin{itemize}
    \item As mentioned in the introduction to this section, real materials have multiple dissipative and binding mechanics, and thus multiple eigenfrequencies $ \omega_{0_{i}} $ that contribute differently at different electric field frequencies. The resulting dielectric function is quite complex, as seen in the following example of water. 

    \item We model water with a single Debye relaxation term for low electric field frequencies and fully eleven Lorentz relaxation terms to encode various binding mechanisms at larger frequencies. The result is the phenomenolgical relationship
    \begin{equation*}
        \epsilon(i\omega) = 1 + \frac{d}{1 + \omega\tau} + \sum_{i = 1}^{11} \frac{f_{i}}{\omega_{0_{i}}^{2} + g_{i}\omega + \omega^{2}},
    \end{equation*}
    where $ d $, $ \tau $, $ \omega_{0_{i}} $, $ g_{i} $, and $ f_{i} $ are phenomenologically-determined constants found with measurements and fitting.

    The first term uses the Debye model and the further 11 terms use the Lorentz model---note that we need 12 different modes in total to describe the frequency dependence of water's dielectric function.
    
\end{itemize}



\newpage
\section{Hamiltonian Formalism for the Electromagnetic Field}

\subsection{Review of the Hamiltonian Formalism}
Before analyzing the electromagnetic field, we briefly review the Hamiltonian formalism from classical mechanics. Note, however, that this is only a brief review---it is assumed the reader is already familiar with the Hamiltonian formalism.

\subsubsection{The Lagrange Equations}
\begin{itemize}
    \item In a few sentences, we summarize the Lagrangian formalism by considering a system of particles, introducing a Lagrangian function $ L $ describing the system's kinetic and potential energy; and then defining action $ S $ as the integral of the Lagrange function over time. The minimum of the action, via the least action principle, then encodes the system's physical state.

    \item As a concrete example, the Lagrangian function for a point particle might read
    \begin{equation*}
        L = \frac{1}{2}m \dot{\vec{r}}^{2} - V(\r),
    \end{equation*}
    and the corresponding action is for the particle moving along the trajectory $ \r(t) $ with velocity $ \dot{\r}(t) $ is
    \begin{equation*}
        S = \int L(\r(t), \dot{\r}(t), t)\diff t.
    \end{equation*}
    We then vary the action and require $ \delta S = 0 $. The result is the Euler-Lagrange equations
    \begin{align*}
        \dv{t} \left(\pdv{L}{\dot{\r}} \right) - \pdv{L}{\r} = 0,
    \end{align*}
    which are equivalent to Newton's second law but often more convenient for analyzing systems in classical mechanics.

\end{itemize}

\subsubsection{The Hamilton Equations}
\begin{itemize}
% Particularly useful in the transition to quantum mechanics. 
    \item In the Hamiltonian formalism we introduce the generalized momenta
    \begin{equation*}
        \vec{p} = \pdv{L}{ \dot{\r}}
    \end{equation*}
    and the Hamiltonian function
    \begin{equation*}
        H(\r(t), \vec{p}(t), t) = \dot{\vec{r}} \vec{p} - L(\r, \dot{\vec{r}}, t).
    \end{equation*}

    \item For a single particle, the Hamiltonian typically reads
    \begin{equation*}
        H = \frac{ \vec{p}^{2}}{2m} + V(\r).
    \end{equation*}
    
    \item The equations of motion in the Hamiltonian formalism are
    \begin{equation*}
        \dot{\vec{r}}(t) = \pdv{H}{ \vec{p}} \qquad \text{and} \qquad \dot{\vec{p}}(t) = - \pdv{H}{\r}.
    \end{equation*}
    
\end{itemize}

\subsection{Lagrangian Function of a Charged Particle in an EM Field}
\begin{itemize}
    \item We consider a particle of charge $ q $ in an external electric field $ \E(\r, t) $ and magnetic field $ \B(\r, t) $. The particle experiences the Lorentz force
    \begin{equation*}
        \vec{F} = q(\E + \vec{v}\cross \B).
    \end{equation*}
    We then substitute the Lorentz force into Newton's second law to get
    \begin{equation*}
        m \ddot{\vec{r}} = q\E + q \vec{v} \cross \B = - q\grad \phi - q \pdv{\A}{t} + q \vec{v}\cross \big( \curl \A \big),
    \end{equation*}
    where we stress the need to write the electric field in terms of both $ \phi $ and $ \A $. 

    \item Next, we apply the curl vector identity
    \begin{equation*}
        \vec{v}\cross \big( \curl \A \big) = \grad ( \vec{v}\cdot \A) - ( \vec{v}\cdot \grad)\A,
    \end{equation*}
    in terms of which Newton's second law becomes
    \begin{equation*}
        m \ddot{\vec{r}} = - q \grad \phi - q \pdv{\A}{t} + q \grad ( \vec{v}\cdot \A) - q( \vec{v} \cdot \grad)\A.
    \end{equation*}
    Finally, we join the time and directional derivative of $ \A $ into a material derivative, i.e. $ q \pdv{\A}{t} + q(\vec{v}\cdot \grad)\A = q \dv{\A}{t}$, which simplifies the above equation to
    \begin{equation*}
        m \ddot{\vec{r}} = -q \grad \phi + q \grad ( \vec{v} \cdot \A) - q \dv{\A}{t}.
    \end{equation*}
    
    \item We will now rewrite the above equation of motion into a form matching the Euler-Lagrange equation, which will reveal the Lagrange function. The first step is
    \begin{equation*}
        \dv{t} \left( m \dot{\vec{r}} + q\A \right) = - \grad ( q \phi - q \vec{v}\cdot \A ) \equiv - \pdv{\r} ( q \phi - q \dot{\vec{r}} \cdot \A ).
    \end{equation*}
    We then further reverse-engineer the time derivative on the left-hand side to get
    \begin{equation*}
        \dv{t} \left[ \pdv{ \dot{\vec{r}}} \left( \frac{1}{2} m \dot{\vec{r}}^{2} + q \A \cdot \dot{\vec{r}} \right) \right] = - \pdv{\r} ( q \phi - q \dot{\vec{r}} \cdot \A ).
    \end{equation*}
    Comparing this expression to the Lagrange equation $ \dv{t} \left(\pdv{L}{\dot{\r}} \right) = \pdv{L}{\r} $ motivates the following definition for the Lagrangian of a particle in an EM field:
    \begin{equation*}
        L(\r(t), \dot{\vec{r}}(t), t) \equiv \frac{1}{2}m \dot{\vec{r}}^{2} - q \phi(\r(t)) + q \dot{\vec{r}} \cdot \A(\r(t), t).
    \end{equation*}
    Note that even though the $ q\phi $ term doesn't explicitly appear in the left-hand side of the Lagrange equation and the $ \frac{1}{2}m \dot{\vec{r}}^{2} $ term doesn't explicitly appear in the right-hand side, these terms would vanish under the derivatives $ \pdv{\dot{\vec{r}}} $ and $ \pdv{\r} $, respectively, which ends up satisfying the Lagrange equations.

    Interpretation: The Lagrangian $ L $ has three contributions: kinetic energy, coupling of $ q $ and $ \phi $, and coupling of $ q $, $ \dot{\vec{r}} $ and $ \A $. Note also that the Lagrangian is written in terms of field potentials and not the fields themselves.
    
\end{itemize}

\subsection{Hamiltonian Function for a Charged Particle in an EM Field}
\begin{itemize}
    \item We find the Hamiltonian $ H $ for a charged particle in an EM field using the just-derived Lagrangian $ L $ with the general relationship
    \begin{equation*}
        H( \vec{p}, \vec{r}, t) = \dot{\vec{r}} \vec{p} - L.
    \end{equation*}
    First, the appropriate generalized momentum $ \vec{p} $ is
    \begin{equation*}
        \vec{p} = \pdv{L}{ \dot{\vec{r}}} = m \dot{\vec{r}} + q \A,
    \end{equation*}
    while the corresponding time derivative of position is
    \begin{equation*}
        \dot{\vec{r}} = \frac{\vec{p} - q\A}{m}.
    \end{equation*}
    Note that the quantity $ q \A $ corresponds to momentum in the Hamiltonian formalism. 

    \item In terms of $ \vec{p} $, $ \dot{\vec{r}} $ and $ L $, the charged particle's Hamiltonian is then
    \begin{equation*}
        H = \frac{1}{m} ( \vec{p} - q\A) \vec{p} - \frac{1}{2m} ( \vec{p} - q\A)^{2} - q\A \left( \frac{ \vec{p} - q \A}{m} \right) + q \phi.
    \end{equation*}
    Finally, we combine like terms to get
    \begin{equation*}
        H = \frac{1}{2m}( \vec{p}(t) - q\A (\r, t))^{2} + q \phi(\r, t).
    \end{equation*}
    Note that the $ \vec{p} = m \dot{\vec{r}} + q \A $ is often called canonical momentum while $ m \dot{\vec{r}} = \vec{p} $ is called kinetic momentum. Keep in mind that despite all the complicated analysis up to now the Lagrange and Hamiltonian functions fundamentally arise from Newton's second law and the Lorentz force on a charged particle in an electromagnetic field.
    
\end{itemize}


\subsection{Hamiltonian Formalism for a Continuous Charge Distribution}

\subsubsection{Schwarzschild Invariant}
\begin{itemize}
	\item Up to now, we had consider only a point particle; we now aim to find the Lagrangian for a continuous distribution of charged particles in an external electromagnetic field, which we will describe in terms of the potentials $ \phi $ and $ \A $. 
	
	\item Recall that for a single a particle, the Lagrangian reads
	\begin{equation*}
		L = \frac{1}{2}m\bdot{r}^{2} - q \phi(\r, t) + q \bdot{r}\cdot \A(\r, t) \equiv \frac{1}{2}m \dot{\vec{r}}^{2} + L_{\text{ext}},
	\end{equation*}
    where $ L_{\text{ext}} = - q \phi(\r, t) + q \bdot{r}\cdot \A(\r, t) $ encodes the coupling of the particle to the external electromagnetic field. 

    We then generalize the field-coupled Lagrangian to a charge distribution $ \rho(\r, t) $ via
	\begin{equation*}
		L_{\text{ext}} = - \iiint_{V}\rho(\r, t) \phi(\r, t) \dr + \iiint_{V}\j(\r, t) \cdot \A(\r, t)\dr,
	\end{equation*}
    where we stress that $ L_{\text{ext}} $ encodes only the external EM field-coupled portion of the total Lagrangian $ L $ (and leaves out the kinetic energy term $ \frac{1}{2}m \dot{\vec{r}}^{2} $).
    
    Finally, we introduce the Lagrangian density $ \L_{\text{ext}} $, also called the Schwarzschild invariant, via
	\begin{equation*}
		\L_{\text{ext}} = - \rho(\r, t) \phi(\r, t) + \j(\r, t)\cdot \A(\r, t).
	\end{equation*}
    Note that $ \L_{\text{ext}} $ encodes coupling with an \textit{external} field---it does not account for electromagnetic field of the charge distribution itself (analogous to the considerations of external versus total electromagnetic field energy in the chapters on electrostatics and magnetostatics).
	
\end{itemize}

\subsubsection{Lagrangian Function for the Total EM Field}
\begin{itemize}
	\item We now aim to derive a Lagrangian encoding the ``total'' field---both the external field and the field arising from the charge distribution itself. Interpretation: we consider the charge distribution as a field source in itself, and then allow for the distribution to occur in an additional external field.
	
	Motivatived by this separation into internal and external field terms, we write the total electromagnetic Lagrangian in the form
	\begin{equation*}
		L_{\text{EM}} = \iiint_{V} \L_{\text{EM}}(\r, t) \dr = \iiint_{V} \L_{\text{int}}(\r, t) \dr + \iiint_{V} \L_{\text{ext}}(\r, t)\dr,
	\end{equation*}
    where $ \L_{\text{int}} = - \rho(\r, t) \phi(\r, t) + \j(\r, t)\cdot \A(\r, t) $, derived in the previous section, represents the charge distribution's coupling to the external EM field, while $ \L_{\text{int}} $ (internal), which we derive in this section, represents the contribution of the field generated by the charge distribution itself. Without derivation, the correct expression for $ \L_{\text{int}} $ is
	\begin{equation*}
		\L_{\text{int}}(\r, t) = \frac{1}{2}\ee E^{2}(\r, t) - \frac{1}{2\mm}B^{2}(\r, t),
	\end{equation*}
    where $ E $ and $ B $ are the magntitudes of the total electric and magnetic fields.
    
	We note, again without proof, that precisely this choice of $ \L_{\text{int}} $ leads to the correct form of Maxwell's equations. Note also that the above expression is precisely electromagnetic energy density contained in a field. In other words, $ \L_{\text{int}} $ qualitatively represents the electromagnetic energy density of the charge distribution's internal field, which is an intuitively appropriate quantity for the $ \L_{\text{int}} $ term.
	
	\item In terms of $ \L_{\text{int}} $ and $ \L_{\text{ext}} $, the total electromagnetic Lagrangian density $ \L_{\text{EM}} $ is then
	\begin{equation*}
		\L_{\text{EM}}(\r, t) = \frac{1}{2}\ee E^{2}(\r, t) - \frac{1}{2\mm}B^{2}(\r, t) - \rho(\r, t)\phi(\r, t) + \j(\r, t) \cdot \A(\r, t),
	\end{equation*}
	where $ \E $ and $ \B $ are defined in terms of the funamental potentials by the relationships $ \E = - \grad \phi - \pdv{\A}{t} $ and $ \B = \curl \A $.
\end{itemize}

\subsubsection{Euler-Lagrange and Riemann-Lorenz Equations}
\begin{itemize}
	\item The action $ S $ associated with the above total electromagnetic Lagrangian is 
	\begin{equation*}
        S \equiv \int L(\r, t) \diff t = \int \left[ \iiint_{V} \L_{\text{EM}}(\phi(\r, t), \A(\r, t))\dr \right] \diff t.
	\end{equation*}
	The Euler-Lagrange equations for the above action read
	\begin{align*}
		&\dv{t}\left[\pdv{\L}{\left(\pdv{\phi}{t}\right)}\right] + \grad \left[\pdv{\L}{(\grad \phi)}\right] - \pdv{\L}{\phi} = 0\\
		& \dv{t} \left[\pdv{\L}{\left(\pdv{A_{i}}{t}\right)}\right] + \grad \left[\pdv{\L}{(\grad A_{i})}\right] - \pdv{\L}{A_{i}} = 0,
	\end{align*}
    where we have written $ \L_{\text{EM}} \to \L $ for conciseness. 
	
	\item Without proof, the above Euler-Lagrange equations lead to the Riemann-Lorenz equations
	\begin{align*}
		\laplacian \phi - \frac{1}{c^{2}}\pdv[2]{\phi}{t} = -\frac{\rho}{\ee} \eqtext{and} \laplacian A_{i} - \frac{1}{c^{2}} \pdv[2]{A_{i}}{t} = - \mm j_{i}.
	\end{align*}
	These two equations encode the fully time-dependent form of the Maxwell equations in terms of the fundamental field potentials $ \phi $ and $ \A $. In passing, we note that the equations are derived using the Lorenz gauge.
	
	The Riemann-Lorenz equations conclude the generalization of the Lagrange-Hamiltonian formalism from a single charged particle to a continuous charge distribution.
\end{itemize}

\newpage

\section{Introduction to Special Relativity}

\subsection{EM Fields and the Lorentz Transformation}
\begin{itemize}
	\item We consider two systems $ S $ and $ S' $, where $ S' $  moves at near-light speed $ v \lesssim c $ in the $ x' $ direction relative to $ S $. System $ S $ contains the fields $ \E $ and $ \B $ and has the coordinates $ (x, y, z, t) $, while system $ S' $ contains the fields $ \E' $ and $ \B' $ and has coordinates $ (x', y', z', t') $.
	
	\item In the theory of special relativity, we transform between the systems $ S $ and $ S' $ using the Lorentz transformations, which read
    \begin{equation*}
        \begin{array}{cc}
            x' = \gamma(x - \beta ct) & \qquad y' = y \\
            ct' = \gamma(ct - \beta x) & \qquad z' = z
        \end{array}
    \end{equation*}
    where $ \beta = v/c $ and $ \gamma = \left( 1 - \beta^{2} \right)^{-1/2} $.
	
	\item In this section, we aim to find the transformations for $ \E $ and $ \B $ from $ S $ to $ S' $ corresponding to the above Lorentz transformations. The transformation rests on the following condition:
    \begin{quote}
        We assume the Maxwell equations for $ \E $ and $ \B $ in $ S $ have the same form as the Maxwell equations for $ \E' $ and $ \B' $ in $ S' $.
    \end{quote}
    We note that although this assumption makes intuitive sense---and it indeed leads to a correct result---it is formally not a trivial assumption, and we do not discuss the theoretical framework for making it.
	
    \item For simplicity, we make another assumption: we neglect (or assume an absence of) electromagnetic field sources in the frame $ S' $, which allows use to write the first two Maxwell equations as
    \begin{equation*}
        \divp \E' = 0 \qquad \text{and} \qquad \divp \B' = 0.
    \end{equation*}
    The remaining two Maxwell equations in the frame $ S' $ are
	\begin{equation*}
		\curlp \E' = - \pdv{\B'}{t'}  \eqtext{and} \curlp \B' = \frac{1}{c^{2}}\pdv{\E'}{t'},
	\end{equation*}
    where we have used $ \ee \mm = 1 / c^{2} $. 

    \item As an intermediate step, we write the Maxwell equations in Cartisian components, starting with the equation for $ \curl \B' $, which reads
	\begin{align*}
		& \pdv{E'_{z'}}{y'} - \pdv{E'_{y'}}{z'} = - \pdv{B'_{x'}}{t'} \\ 
		&\pdv{E'_{x'}}{z'} - \pdv{E'_{z'}}{x'} = - \pdv{B'_{y'}}{t'}\\
		&\pdv{E'_{y'}}{x'} - \pdv{E'_{x'}}{y'} = - \pdv{B'_{z'}}{t'}.
	\end{align*}
    Meanwhile, the equation for $ \divp \E' $ reads
	\begin{equation*}
		\pdv{E'_{x'}}{x'} + 	\pdv{E'_{y'}}{y'} + 	\pdv{E'_{z'}}{z'} = 0.
	\end{equation*}
    
    \item According to the Lorentz transformations, the coordinate derivatives transform as
	\begin{equation*}
		\pdv{x'}  = \gamma \left(\pdv{x} + \beta \pdv{(ct)}\right) \eqtext{and} \pdv{(ct')} = \gamma \left(\pdv{(ct)} + \beta \pdv{x}\right).
	\end{equation*}
    Note the presence of plus (and not minus) signs in the transformations, which is related to contravariant vector notation and is beyond the scope of our limited treatment of special relativity. The transformations of the $ y $ and $ z $ derivatives are simpler:
	\begin{equation*}
		\pdv{y'} = \pdv{y} \eqtext{and} \pdv{z'} = \pdv{z}.
	\end{equation*}
    We then apply these transformations to the component-form Maxwell equations. The $ \curlp \B' $ equation transforms to
	\begin{align*}
		& \pdv{E'_{z'}}{y} - \pdv{E'_{y'}}{z} = - \gamma v \pdv{B'_{x'}}{x} - \gamma \pdv{B'_{x'}}{t}\\
		& \pdv{E'_{x'}}{z} - \left(\gamma \pdv{E'_{z'}}{x} + \gamma \frac{v}{c^{2}} \pdv{E'_{z'}}{t}\right) = - \gamma v \pdv{B'_{y'}}{x} - \gamma \pdv{B'_{y'}}{t}\\
		& \left(\gamma \pdv{E'_{y'}}{x} + \gamma \frac{v}{c^{2}}\pdv{E'_{y'}}{t}\right) - \pdv{E'_{x'}}{y} = - \gamma v \pdv{B'_{z'}}{x} - \gamma \pdv{B'_{z'}}{t},
	\end{align*}
	while divergence equation $ \divp \E' = 0$ becomes
	\begin{equation*}
		\gamma \pdv{E'_{x'}}{x} + \gamma \frac{v}{c^{2}} \pdv{E'_{x'}}{t} + \pdv{E'_{y'}}{y} + \pdv{E'_{z'}}{t} = 0.
	\end{equation*}
    
    \item We would then perform analogous transformations of the equations $ \divp \B' = 0 $ and $ \curlp \E' = - \pdv{B'}{t'} $, which we leave out for lack of time. The end result is a system of equations relating the components of the electromagnetic field.
    
    The next question is: what combination of primed field quantities (i.e. which combination of components $ E'_{x,y,z} $ and $ B'_{x,y,z} $) should we take so that, when substituted into the above equations, we recover the Maxwell equations in terms of the $ S $ frame field quantities $ \E $ and $ \B $.
	
	Without proof, it turns out the correct transformations are 
    \begin{equation*}
        \begin{array}{ll}
            E_{x} = E'_{x'} & \qquad B_{x} = B'_{x'}\\
            E_{y} = \gamma (E'_{y'} + v B'_{z'}) & \qquad B_{y} = \gamma \left (B'_{y'} - \frac{v}{c^{2}} E'_{z'}\right)\\
            E_{z} = \gamma (E'_{z'} - vB'_{y'}) & \qquad B_{z} = \gamma \left (B'_{z'} + \frac{v}{c^{2}} E'_{y'}\right ).
        \end{array}
    \end{equation*}
   	Note that the $ x $	components are preserved and the $ y $ and $ z $ components are mixed up, which is opposite the transformations of the $ (x, y, z, t) $ coordinates themselves.
\end{itemize}

\textbf{Implications}
\begin{itemize}
	\item We now consider some implications of the above transformations for the $ \E $ and $ \B $ fields. First, we calculate $ \E \cdot \B $, which comes out to
	\begin{align*}
		\E \cdot \B &= E_{x}B_{x} + E_{y}B_{y} + E_{z}B_{z} \\
		& = E'_{x'}B'_{x'} + \gamma^{2}\left(1 - \frac{v^{2}}{c^{2}}\right)E'_{y'}B'_{y'} + \gamma^{2}\left(1 - \frac{v^{2}}{c^{2}}\right)E'_{z'}B'_{z'}.
	\end{align*}
	Note that $ \gamma^{2}(1 - \frac{v^{2}}{c^{2}}) = 1 $ which simplifies the above relationship to
	\begin{equation*}
		\E \cdot \B = \E' \cdot \B'
	\end{equation*}
    In other words, the dot product $ \E \cdot \B $ is Lorentz-invariant (i.e. angles are preserved) with respect to the Lorentz transformations of the electromagnetic field.
	
	\item Next, we consider the quantity $ E^{2} - c^{2}B^{2} $, which is essentially electromagnetic energy, as long as we multiply through by $ \ee/2 $. Writing the quantities $ E^{2} $ and $ B^{2} $ in component form and applying the electromagnetic field transformations leads to
	\begin{equation*}
		 E^{2} - c^{2}B^{2} =  E'^{2} - c^{2}B'^{2},
	\end{equation*}
	which corresponds to conservation of energy. 
	
%	Recall also that these two terms occur in the EM Lagrangian.

    \item Summary: In free space, the solutions to the Maxwell equations in $ S' $ have the same form as in $ S $, which follows from preservation of angles under the invariance relationship $ \E \cdot \B = \E' \cdot \B' $. The relative magnitudes of the $ \E' $ and $ \B' $ fields however, change relative to $ \E $ and $ \B $.
\end{itemize}

\subsection{Minkowski Space}
\begin{itemize}
    \item For the remainder of this chapter, we will work in terms of four-vectors in four-dimensional Minkowski space, where we introduce time coordinate $ ct $ to the familiar Euclidean position coordinates $ x $, $ y $ and $ z $. We will work with the $ (+++-) $ metric, which is preserved in special relativity.

	\item The fundamental element of Minkowski space is the position four-vector, which we write in the form
	\begin{equation*}
		x_{\mu} = (x, y, z, ct).
	\end{equation*}
    In our convention, Greek letter indices (e.g. $ \mu $) run over all four components, while Latin indices (e.g. $ i $) run over the position components only. The index $ \mu $ occuring in the subscript denotes that $ x_{\mu} $ is a covariant vector. An index above, as in $ x^{\mu} $, represents a contravariant vector and reads
	\begin{equation*}
		x^{\mu} = (x, y, z, -ct).
	\end{equation*}

	\item Importantly, the Lorentz transformation preserves the square of the four-vector:
	\begin{equation*}
		x_{\mu}x^{\mu} = x^{2} + y^{2} + z^{2} - c^{2}t^{2} = x'_{\mu} x'^{\mu}.
	\end{equation*}
    This expression is a generalization of the Euclidean dot product to four-dimensional Minkowski space---the use of the minus sign before the time coordinate corresponds to the $ (+++-) $ metric.

\end{itemize}

\subsubsection{Current Density Four-Vector}

\begin{itemize}
	\item We now consider the generalization of current density to Minkowski space. 

    We begin by requiring conservation of total charge across all systems, i.e. 
	\begin{equation*}
		q = \iiint_{V} \rho \dr = \iiint_{V'} \rho' \dr'.
	\end{equation*}
	Working in components and applying the Lorenz transformations of the coordinates leads to the expression
	\begin{equation*}
		q = \iiint_{V}\rho \diff x \diff y \diff z = \iiint_{V'}\rho' \diff x' \diff y' \diff z' = \iiint_{V}\rho' \gamma \diff x \diff y \diff z,
	\end{equation*}
	which implies $ \rho' = \rho/\gamma $. In other words, the quantity $ \frac{\rho}{\gamma} $ is Lorentz-invariant, and not simply $ \rho $.
	
	\item We now turn to the current density four-vector. We start with the classical exprssion $ \j = \rho \vec{v} $. Using the velocity four-vector $ u_{\mu} $ and the just-derived expression $ \rho \to \rho/\gamma $, the classical expression generalizes to the four vector
	\begin{equation*}
		j_{\mu} = \frac{\rho}{\gamma} u_{\mu} = \frac{\rho}{\gamma}\left(\gamma \vec{v}, \gamma c\right) = \rho(\vec{v}, c) = (\j, c\rho),
	\end{equation*}
    Note that neither $ \gamma $ nor $ \beta $ occur in the current density four-vector.
	
	\item Since $ j_{\mu} $ is independent of $ \gamma $ and $ \beta $, it is a well-defined four vector and obeys the familiar four-vector transformation rules:
	\begin{equation*}
        \begin{array}{ll}
            j'_{x'} = \gamma (j_{x} - \beta c \rho) & \qquad j'_{y'} = j_{y}\\
            j'_{z'} = j_{z} &  \qquad c \rho' = \gamma(c \rho - \beta j_{x}).
        \end{array}
	\end{equation*}
	More so, $ j_{\mu} $ is Lorentz invariant, i.e. 
	\begin{equation*}
		j_{\mu}j^{\mu} = j_{\mu}'j'^{\mu} = \j \cdot \j - c^{2}\rho^{2}.
	\end{equation*}
    Interpretation: Like for the electromagnetic field components $ \E $ and $ \B $, the relative magnitudes of $ \j $ and $ \rho $ are mixed in the transformation between frames of reference. In other words, the relative composition of the current density four vector in terms of current density $ \j $ and charge density $ \rho $ depends on the system in which the four vector is measured. However, the quantity $ \j \cdot \j - c^{2}\rho^{2} $ is preserved across all systems.

    Note that the two field sources $ \j $ and $ \rho $ are now coupled, and it makes sense to speak of a total electromagnetic field instead of the independent fields $ \E $ and $ \B $.
	
\end{itemize}

\subsubsection{Electromagnetic Potential Four Vector}
\begin{itemize}
	\item We will now write the four-vector encoding the electromagnetic field potential. First, we recall the Riemann-Lorenz equations for $ \A  $ and $ \phi $, which we write in terms of the d'Alembert box operator $ \Box $ as
	\begin{align*}
		& \Box^{2}\phi = \laplacian \phi - \frac{1}{c^{2}}\pdv[2]{\phi}{t} = - \frac{\rho}{\ee}\\
		&\Box^{2} \A = \laplacian \A - \frac{1}{c^{2}} \pdv[2]{\A}{t} = - \mm \j.
	\end{align*}
    We then combine the above two equations and introduce the current density four vector $ j_{\mu} = (\j, c\rho) $ to get the electromagnetic potential four vector:
	\begin{equation*}
		A_{\mu} = \left (\A, \frac{\phi}{c}\right ) \eqtext{and} A^{\mu} = \left (\A, -\frac{\phi}{c}\right ).
	\end{equation*}
	In terms of the EM potential four vector, the Riemann-Lorenz equations can be written in the Lorentz-invariant form
	\begin{equation*}
		\Box ^{2}A_{\mu} = - \mm j_{\mu} \eqtext{and} \Box^{2}A^{\mu} = - \mm j^{\mu},
	\end{equation*}
    where $ \Box $ again denotes the d'Alembert box operator.
	
	\item Since $ A_{\mu} $, like $ j_{\mu} $, is independent of $ \gamma $ and $ \beta $, it is a well-defined four vector and obeys the usual Lorentz transformations:
	\begin{equation*}
        \begin{array}{ll}
            A'_{x'} = \gamma \left(A_{x} - \beta \frac{\phi}{c} \right) & \frac{\phi'}{c} = \gamma \left(\frac{\phi}{c} - \beta A_{x}\right) \\
            A'_{y'} = A_{y} & A'_{z'} = A_{z}
        \end{array}
	\end{equation*}
	More so, the EM potential four vector obeys the Lorentz invariance relation
	\begin{equation*}
		A_{\mu}A^{\mu} = A_{\mu}' A'^{\mu} = \A \cdot \A - \frac{\phi^{2}}{c^{2}}.
	\end{equation*}
    Analogously to $ j_{\mu} $, the relative magnitudes of the components $ \A $ and $ \phi $ are mixed in the transformation of $ A_{\mu} $ between different frames of reference, while the invariant quantity $ \A \cdot \A - \frac{\phi^{2}}{c^{2}} $ is preserved.
\end{itemize}

\subsubsection{Covariant EM Field Tensor}
\begin{itemize}
	\item For the purposes of this course, we take covariant to denote a quantitiy that, like $ x_{\mu} $, $ j_{\mu} $ or $ A_{\mu} $, is manifestly invariant under the Lorentz transformations. Our goal in this section is to find a covariant expression for the electromagnetic fields $ \E $ and $ \B $.
	
	\item We begin with the expressions for $ \E $ and $ \B $ in terms of their potentials, i.e.:
	\begin{equation*}
		\B = \curl \A \eqtext{and} \E = - \grad \phi - \pdv{\A}{t}.
	\end{equation*}
    Next, we introduce a four vector derivative, which we define according to
	\begin{equation*}
		\pdv{x_{\mu}} = \left(\pdv{\r}, \pdv{(ct)} \right).
	\end{equation*}
    In terms of $ \A = \big( \A, \tfrac{\phi}{c} \big) $ and $ \pdv{x_{\mu}} $, we now have contravariant four-vector expressions for all of the terms in the right hand side of the equations for $ \E $ and $ \B $. With these four vector quantities in mind, we then define the antisymmetric EM field tensor
	\begin{equation*}
        \operatorname{F}_{\mu \nu} = \pdv{A_{\nu}}{x^{\mu}} - \pdv{A_{\mu}}{x^{\nu}} = \partial_{\mu}A_{\nu} - \partial_{\nu}A_{\mu}.
	\end{equation*}
	Without formal proof, we note that this tensor is Lorentz-invariant, although this should make intuitive sense---it is constructed from the invariant quantity $ A_{\mu} $.
	
	\item In terms of components, the electromagnetic field tensor reads
	\begin{equation*}
		\operatorname{F}_{\mu\nu} = 
	\begin{bmatrix}
        0 & B_{z} & - B_{y} & -\frac{E_{x}}{c}\\[1mm]
		- B_{z} & 0 & B_{x} & -\frac{E_{y}}{c}\\[1mm]
		B_{y} & -B_{x} & 0 & -\frac{E_{z}}{c}\\
		\frac{E_{x}}{c} & \frac{E_{y}}{c} & \frac{E_{z}}{c} & 0
	\end{bmatrix},
	\end{equation*}
	where the components of the tensor are the components of the $ \E $ and $ \B $ fields. In four dimensions, the $ \E $ and $ \B $ fields thus become a single unified electromagnetic field, written in terms of a tensor.
	
	\item The covariant electromagnetic action associated with the EM tensor is
	\begin{equation*}
		S = \frac{1}{c}\int \left[- \frac{1}{4}\operatorname{F}^{\mu\nu}\operatorname{F}_{\mu\nu} + A^{\mu}j_{\mu}\right]\diff^{4}x_{\lambda}.
	\end{equation*}
	This action is the basis for quantizing the electromagnetic field in more advanced physics. This concludes our course.
	
\end{itemize}

\end{document}














